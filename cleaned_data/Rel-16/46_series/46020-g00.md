# Foreword
This Technical Specification has been produced by the 3^rd^ Generation
Partnership Project (3GPP).
The present document specifies the speech codec to be used for the GSM half
rate channel for the digital cellular telecommunications system. The present
document is part of a series covering the half rate speech traffic channels as
described below:
GSM 06.02 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Half rate speech processing functions\".
GSM 06.06 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; ANSI-C code for the GSM half rate speech codec\".
GSM 06.07 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Test sequences for the GSM half rate speech codec\".
**GSM 06.20 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Half rate speech transcoding\".**
GSM 06.21 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Substitution and muting of lost frames for half rate speech traffic
channels\".
GSM 06.22 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Comfort noise aspects for half rate speech traffic channels\".
GSM 06.41 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Discontinuous Transmission (DTX) for half rate speech traffic
channels\".
GSM 06.42 \"Digital cellular telecommunications system (Phase 2+); Half rate
speech; Voice Activity Detector (VAD) for half rate speech traffic channels\".
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
The present document specifies the speech codec to be used for the GSM half
rate channel. It also specifies the test methods to be used to verify that the
codec implementation complies with the present document.
The requirements are mandatory for the codec to be used either in GSM Mobile
Stations (MS)s or Base Station Systems (BSS)s that utilize the half rate GSM
speech traffic channel.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
  * References are either specific (identified by date of publication, > edition number, version number, etc.) or non‑specific.
  * For a specific reference, subsequent revisions do not apply.
```{=html}
``` \- For a non-specific reference, the latest version applies. In the case
of a reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] GSM 06.02: \"Digital cellular telecommunications system (Phase 2+); Half
rate speech; Half rate speech processing functions\".
[2] GSM 06.06: \"Digital cellular telecommunications system (Phase 2+); Half
rate speech; ANSI-C code for the GSM half rate speech codec\".
[3] GSM 06.07: \"Digital cellular telecommunications system (Phase 2+); Half
rate speech; Test sequences for the GSM half rate speech codec\".
# 3 Definitions, symbols and abbreviations
## 3.1 Definitions
For the purposes of the present document, the following definitions apply:
**adaptive codebook:** adaptive codebook is derived from the long term filter
state. The lag value can be viewed as an index into the adaptive codebook.
**adaptive pitch prefilter:** in the GSM half rate speech decoder, this filter
is applied to the excitation signal to enhance the periodicity of the
reconstructed speech. Note that this is done prior to the application of the
short term filter.
**adaptive spectral postfilter:** in the GSM half rate speech decoder, this
filter is applied to the output of the short term filter to enhance the
perceptual quality of the reconstructed speech.
**allowable lags:** set of lag values which may be coded by the GSM half rate
speech encoder and transmitted to the GSM half rate speech decoder. This set
contains both integer and fractional values (see table 3).
**analysis window:** for each frame, the short term filter coefficients are
computed using the high pass filtered speech samples within the analysis
window. The analysis window is 170 samples in length, and is centered about
the last 100 samples in the frame.
**basis vectors:** set of M, M1, or M2 vectors of length Ns used to generate
the VSELP codebook vectors. These vectors are not necessarily orthogonal.
**closed loop lag search:** process of determining the near optimal lag value
from the weighted input speech and the long term filter state.
**closed loop lag trajectory:** for a given frame, the sequence of near
optimal lag values whose elements correspond to each of the four subframes as
determined by the closed loop lag search.
**codebook:** set of vectors used in a vector quantizer.
**Codeword (OR Code):** M, M1, or M2 bit symbol indicating the vector to be
selected from a VSELP codebook.
**Delta (LAG) code:** four bit code indicating the change in lag value for a
subframe relative to the previous subframe\'s coded lag. For frames in which
the long term predictor is enabled (MODE 1, 2, or 3), the lag for subframe 1
is independently coded using eight bits, and delta codes are used for
subframes 2, 3, and 4.
**direct form coefficients:** one of the formats for storing the short term
filter parameters. All filters which are used to modify speech samples use
direct form coefficients.
**fractional lags:** set of lag values having sub-sample resolution. Note that
not every fractional lag value considered in the GSM half rate speech encoder
is an allowable lag value.
**frame:** time interval equal to 20 ms, or 160 samples at an 8 kHz sampling
rate.
**harmonic noise weighting filter:** this filter exploits the noise masking
properties of the spectral peaks which occur at harmonics of the pitch
frequency by weighting the residual error less in regions near the pitch
harmonics and more in regions away from them. Note that this filter is only
used when the long term filter is enabled (MODE = 1, 2 or 3).
**high pass filter:** this filter is used to de-emphasize the low frequency
components of the input speech signal.
**integer lags:** set of lag values having whole sample resolution.
**interpolating filter:** FIR filter used to estimate sub-sample resolution
samples, given an input sampled with integer sample resolution.
**lag:** long term filter delay. This is typically the pitch period, or a
multiple or sub-multiple of it.
**long term filter:** this filter is used to generate the periodic component
in the excitation for the current subframe. This filter is only enabled for
MODE = 1, 2 or 3.
**LPC coefficients:** Linear Predictive Coding (LPC) coefficients is a generic
descriptive term for describing the short term filter coefficients.
**open loop lag search:** process of estimating the near optimal lag directly
from the weighted speech input. This is done to narrow the range of lag values
over which the closed loop lag search shall be performed.
**open loop lag trajectory:** for a given frame, the sequence of near optimal
lag values whose elements correspond to the four subframes as determined by
the open loop lag search.
**reflection coefficients:** alternative representation of the information
contained in the short term filter parameters.
**residual:** output signal resulting from an inverse filtering operation.
**short term filter:** this filter introduces, into the excitation signal,
short term correlation which models the impulse response of the vocal tract.
**soft interpolation:** process wherein a decision is made for each frame to
use either interpolated or uninterpolated short term filter parameters for the
four subframes in that frame.
**soft interpolation bit:** one bit code indicating whether or not
interpolation of the short term parameters is to be used in the current frame.
**spectral noise weighting filter:** this filter exploits the noise masking
properties of the formants (vocal tract resonances) by weighting the residual
error less in regions near the formant frequencies and more in regions away
from them.
**subframe:** time interval equal to 5 ms, or 40 samples at an 8 kHz sampling
rate.
**vector quantization:** method of grouping several parameters into a vector
and quantizing them simultaneously.
**GSP0 vector quantizer:** process of vector quantization, its intermediate
parameters (GS and P0) for the coding of the excitation gains β and γ.
**VSELP codebook:** Vector-Sum Excited Linear Predictive (VSELP) codebook,
used in the GSM half rate speech coder, wherein each codebook vector is
constructed as a linear combination of the fixed basis vectors.
**zero input response:** output of a filter due to all past inputs, i.e. due
to the present state of the filter, given that an input of zeros is applied.
**zero state response:** output of a filter due to the present input, given
that no past inputs have been applied, i.e. given the state information in the
filter is all zeroes.
## 3.2 Symbols
For the purposes of the present document, the following symbols apply:
A(z) Short term spectral filter.
αi The LPC coefficients.
bL(n) The output of the long term filter state (adaptive codebook) for lag L.
β The long term filter coefficient.
C(z) Second weighting filter.
e(n) Weighted error signal
fj(i) The coefficients of the jth phase of the 10th order interpolating filter
used to evaluate candidate fractional lag values; i ranges from 0 to Pf‑1.
gj(i) The coefficients of the jth phase of the 6th order interpolating filter
used to interpolate C\'s and G\'s as well as fractional lags in the harmonic
noise weighting; i ranges from 0 to Pg‑1.
γ The gain applied to the vector(s) selected from the VSELP codebook(s).
H A M2 bit code indicating the vector to be selected from the second VSELP
codebook (when operating in mode 0).
I A M or M1 bit code indicating the vector to be selected from one of the two
first VSELP codebooks.
L The long term filter lag value.
Lmax 142 (samples), the maximum possible value for the long term filter lag.
Lmin 21 (samples), the minimum possible value for the long term filter lag.
M 9, the number of basis vectors, and the number of bits in a codeword, for
the VSELP codebook used in modes 1, 2, and 3.
M1 7, the number of basis vectors, and the number of bits in a codeword, for
the first VSELP codebook used in mode 0.
M2 7, the number of basis vectors, and the number of bits in a codeword, for
the second VSELP codebook used in mode 0.
MODE A two bit code indicating the mode for the current frame (see annex A).
NA 170, the length of the analysis window. This is the number of high pass
filtered speech samples used to compute the short term filter parameters for
each frame.
NF 160, the number of samples per frame (at a sampling rate of 8 kHz).
Np 10, the short term filter order.
Ns 40, the number of samples per subframe (at a sampling rate of 8 kHz).
P1 6, the number of bits in the prequantizer for the r1 - r3 vector quantizer.
P2 5, the number of bits in the prequantizer for the r4 - r6 vector quantizer.
P3 4, the number of bits in the prequantizer for the r7 - r10 vector
quantizer.
Pf The order of one phase of an interpolating filter used to evaluate
candidate fractional lag values. Pf equals 10 for j ≠ 0 and equal to 1 for j =
0.
Pg The order of one phase of an interpolating filter, fj(n), used to
interpolate C\'s and G\'s as well as fractional lags in the harmonic noise
weighting, Pg equals 6.
pitch The time duration between the glottal pulses which result when the vocal
chords vibrate during speech production.
Q1 11, the number of bits in the r1 - r3 reflection coefficient vector
quantizer.
Q2 9, the number of bits in the r4 - r6 reflection coefficient vector
quantizer.
Q3 8, the number of bits in the r7 - r10 reflection coefficient vector
quantizer.
R0 A five bit code used to indicate the energy level in the current frame.
r(n) The long term filter state (the history of the excitation signal); n \ 0.
+---------+-----------------------------------------------------------+ | STEP 1 | Initialize the subframe counter | | | | | | m=1 | +---------+-----------------------------------------------------------+ | STEP 2 | Initialize the peak index | | | | | | Lp,m = 0 | +---------+-----------------------------------------------------------+ | STEP 3 | Using interpolated versions of the C and G arrays, | | | allowable lag values k\' in the range: | | | | | | Lpeak(0,m) - 1 \ 0 and GI(k) > 0 values are considered. If | | | no positive correlation is found, then set | | | | | | λhnw,m = 0, Lpeak(1,m)=Lmin, and go to Step 22. | | | | | | Otherwise, store the information related to the valid | | | best allowable lag k. | | | | | | Lp,m=Lp,m+1 (54) | | | | | | Lpeak(Lp,m,m)=k (55) | | | | | | Cpeak(Lp,m,m)=CI(k) (56) | | | | | | Gpeak(Lp,m,m)=GI(k) (57) | | | | | | The next part of the search evaluates , for C > 0 and G | | | > 0, at the submultiples of the lag Lpeak(Lp,m,m) to | | | find candidate peaks. | +---------+-----------------------------------------------------------+ | STEP 4 | Initialize the divisor | | | | | | J = 2 | +---------+-----------------------------------------------------------+ | STEP 5 | Find nearest integer lag corresponding to submultiple of | | | maximum peak | | | | | | k1 = round[Lpeak(1,m)/J] (58) | +---------+-----------------------------------------------------------+ | STEP 6 | Determine if submultiple is within allowable lag range | | | | | | If k1 \ \frac{C^{2} | | | \left( k\text{',}m \right)}{G\left( k\text{',}m \right)}$ | | | (60) | | | | | | Go to step 11 | | | | | | If | | | | | | $\frac{C^{2}\left( | | | k' + 1,m \right)}{G\left( k' + 1,m \right)} > \frac{C^{2} | | | \left( k\text{',}m \right)}{G\left( k\text{',}m \right)}$ | | | (61) | | | | | | Go to step 11 | +---------+-----------------------------------------------------------+ | STEP 9 | A peak has been found at an integer lag, k\'. Using | | | interpolated versions of the C and G arrays, allowable | | | lag values within [+]{.underline} 1 (exclusive) of k\' | | | are searched. | | | | | | Find k where | | | | | | (62) | | | | | | is a maximum, where | | | | | | $C_{I}(k) = \sum_{i = 0}^{5}{g_{j} | | | (i)C\left( \left\lceil k \right\rceil - 3 + i,m \right)}$ | | | (63) | | | | | | $G_{I}(k) = \sum_{i = 0}^{5}{g_{j} | | | (i)G\left( \left\lceil k \right\rceil - 3 + i,m \right)}$ | | | (64) | | | | | | where | | | | | | $j = 6\left( \left\lceil k \right\rceil - k \right)$ (65) | | | | | | and k\'‑1 \ 0 and GI(k) > 0 are considered. | +---------+-----------------------------------------------------------+ | STEP 10 | If the prediction gain exceeds a threshold, the | | | corresponding lag, CI, and GI are stored in the Lpeak(), | | | Cpeak(), and Gpeak() arrays; otherwise, these values are | | | not stored. | | | | | | If | | | | | | where | | | $x = | | | 7,5\text{log}_{\text{10}}\left( \frac{R\left( 0,m \right | | | )}{R\left( 0,m \right) - \frac{C_{\text{peak}}^{2}\left( | | | 0,m \right)}{G_{\text{peak}}\left( 0,m \right)}} \right)$ | | | (67) | +---------+-----------------------------------------------------------+ | | then | | | | | | Lp,m=Lp,m+1 (68) | | | | | | Lpeak(Lp,m,m)=k (69) | | | | | | Cpeak(Lp,m,m)=CI(k) (70) | | | | | | Gpeak(Lp,m,m)=GI(k) (71) | +---------+-----------------------------------------------------------+ | STEP 11 | Increment divisor and check the next submultiple | | | | | | J=J+1 | | | | | | Go to step 5 | +---------+-----------------------------------------------------------+ | STEP 12 | A full-resolution search (1/6 sample resolution) is done | | | for a peak within 1 integer lag (exclusive) of the | | | shortest lag. | | | | | | Find k such that | | | | | | (72) | | | | | | is a maximum, where | | | | | | $C_{I}(k) = \sum_{i = 0}^{5}{g_{j} | | | (i)C\left( \left\lceil k \right\rceil - 3 + i,m \right)}$ | | | (73) | | | | | | $G_{I}(k) = \sum_{i = 0}^{5}{g_{j} | | | (i)G\left( \left\lceil k \right\rceil - 3 + i,m \right)}$ | | | (74) | | | | | | $j = 6\left( \left\lceil k \right\rceil - k \right)$ (75) | | | | | | $\text{max}\lef | | | t( L_{\text{min}} - \frac{1}{6},L_{\text{peak}}(L_{p,m}) | | | - 1 \right)  Lmax | | | | | | Go to step 22 | +---------+-----------------------------------------------------------+ | STEP 17 | Find value of k\' where C2(k\',m)/G(k\',m) is a maximum | | | for | | | | | | max(Lmin,k1‑3) ≤ k \'≤ min(Lmax,k1+3) (81) | | | | | | If either C(k\',m) ≤ 0 or G(k\',m) ≤ 0 go to step 21. | +---------+-----------------------------------------------------------+ | STEP 18 | Determine if maximum in step 17 is a peak | | | | | | If | | | | | | $\frac{C^{2}\left( | | | k' - 1,m \right)}{G\left( k' - 1,m \right)} > \frac{C^{2} | | | \left( k\text{',}m \right)}{G\left( k\text{',}m \right)}$ | | | (82) | | | | | | Go to step 21 | | | | | | If | | | | | | $\frac{C^{2}\left( | | | k' + 1,m \right)}{G\left( k' + 1,m \right)} > \frac{C^{2} | | | \left( k\text{',}m \right)}{G\left( k\text{',}m \right)}$ | | | (83) | | | | | | Go to step 21 | +---------+-----------------------------------------------------------+ | STEP 19 | A peak has been found at an integer lag, k\'. Using | | | interpolated versions of the C and G arrays, allowable | | | lag values within [+]{.underline} 1 (exclusive) of k\' | | | are searched. | | | | | | Find k where | | | | | | (84) | | | | | | is a maximum, where | | | | | | $C_{I}(k) = \sum_{i = 0}^{5}{g_{j} | | | (i)C\left( \left\lceil k \right\rceil - 3 + i,m \right)}$ | | | (85) | +---------+-----------------------------------------------------------+ | | $G_{I}(k) = \sum_{i = 0}^{5}{g_{j} | | | (i)G\left( \left\lceil k \right\rceil - 3 + i,m \right)}$ | | | (86) | | | | | | where | | | | | | $j = 6\left( \left\lceil k \right\rceil - k \right)$ (87) | | | | | | and k\'‑1 \ 0 and GI(k) > 0 are considered. | +---------+-----------------------------------------------------------+ | STEP 20 | If the prediction gain exceeds a threshold, the | | | corresponding lag, CI, and GI are stored. | | | | | | If | | | | | | where | | | $x = | | | 7,5\text{log}_{\text{10}}\left( \frac{R\left( 0,m \right | | | )}{R\left( 0,m \right) - \frac{C_{\text{peak}}^{2}\left( | | | 0,m \right)}{G_{\text{peak}}\left( 0,m \right)}} \right)$ | | | (89) | | | | | | then | | | | | | Lp,m=Lp,m+1 (90) | | | | | | Lpeak(Lp,m)=k (91) | | | | | | Cpeak(Lp,m)=CI(k) (92) | | | | | | Gpeak(Lp,m)=GI(k) (93) | +---------+-----------------------------------------------------------+ | STEP 21 | Increment multiplier and check the next multiple | | | | | | J=J+1 | | | | | | Go to step 15 | +---------+-----------------------------------------------------------+ | STEP 22 | Increment subframe pointer and repeat for all subframes | | | | | | m=m+1 | | | | | | If m≤4 | | | | | | Go to step 2. | | | | | | Otherwise, the list of correlation peaks and the harmonic | | | noise weighting filter parameters for each subframe have | | | been found. | +---------+-----------------------------------------------------------+
#### 4.1.8.3 Frame lag trajectory search (Mode ≠ 0)
The frame lag trajectory search uses the list of potential lag values to
determine the one lag value for each subframe which minimizes the open loop
prediction error energy for the frame subject to the constraints of the delta
lag coding employed for subframes 2, 3 and 4. Several candidate lag
trajectories are determined. The trajectory which minimizes the open loop
prediction error energy for the frame is chosen.
In subclause 4.1.8.2, the open loop lag search found a list of lags,
Lpeak(i,m), corresponding to the peaks, for each subframe. Each trajectory
evaluation begins with one of the subframes and selects a lag corresponding to
a peak for that subframe as the anchor for that candidate trajectory.
A maximum of 2 trajectories are anchored per subframe. From the anchor lag,
the trajectory is extended forward and backward to the adjacent subframes in
the frame subject to the lag differential coding constraints. The lag for each
subframe on the trajectory is chosen to minimize the open loop frame
prediction error energy. The trajectory search is described below.
The steps involved in the frame lag trajectory evaluation and selection are:
* * *
STEP 1 Set m, the pointer to the selected subframe, equal to 1.  
STEP 2 Choose the lag at the selected subframe, m, to be an anchor lag for the
frame lag trajectory; i.e., the frame lag trajectory being evaluated needs to
pass through that lag. The lag which is chosen, corresponds to the highest
peak in the list of peaks at subframe m, which has not been crossed by a
trajectory evaluated previously. If no peaks qualify, no peaks are left, or
two trajectories have already been anchored and evaluated at subframe m, go to
step 7. Otherwise, compute the open loop subframe weighted error energy
corresponding to the chosen lag, and store the result in the frame weighted
error accumulator corresponding to the trajectory currently being evaluated.  
STEP 3 If m \ 1, initiate the backward search:  
STEP 4a Define the current subframe to be m‑1. STEP 4b Define the backward
search range as ‑6 to +7 levels relative to the current subframe\'s lag level.
STEP 4c Check that the lower bound does not point to a level below the lowest
allowable lag level, clipping if necessary. Similarly, check that the upper
bound does not point past the highest allowable lag level; clip if necessary.
STEP 4d Find lag within the range which maximizes. .
* * *
NOTE: negative values of CI are allowed. Compute the open loop subframe
weighted error energy corresponding to that lag at the current subframe, and
add the result to the frame weighted error accumulator corresponding to the
trajectory being evaluated.
* * *
           STEP 4e                                                                                                                                                                                               If the current subframe index is \> 1, decrement the pointer to the current subframe, and go to step 4a.
STEP 5 Store the lags defining the frame lag trajectory derived and the open
loop LTP frame weighted error energy which this trajectory yields. Increment
the counter of evaluated frame lag trajectories.  
STEP 6 Go to step 2.  
STEP 7 If m \ \frac{\left( C_{\text{best}}
\right)^{2}}{G_{\text{best}}}$ (125)
Evaluating equation (125) directly from Ci and Gi requires one multiply, one
divide and one compare operation. By cross multiplying equation (117) can be
expressed as:
$\left( C_{i} \right)^{2}G_{\text{best}} > \left( C_{\text{best}}
\right)^{2}G_{i}$ (126)
Using equation (126) requires only three multiplies and a compare per
evaluation (and no divides) where (Cbest)2 and Gbest are updated throughout
the search to reflect the running best codeword.
### 4.1.11 Multimode gain vector quantization
A separate GSP0 vector quantizer is derived for each of the four voicing
modes. Once the frame voicing mode is selected, the vector quantizer,
corresponding to that mode, is searched to select the excitation gains at each
subframe of the frame.
Although the interpretation of what the excitation sources are differs between
MODE=0 and the remaining MODE values, the procedure for searching the gain
vector quantizer is identical. In each case, the P0 term specifies the
relative contribution of the first of the two excitation vectors to the total
excitation energy at the subframe, where the first excitation vector is the
long term prediction vector for MODE=1, 2 or 3, while the vector selected from
the first of the two VSELP codebooks is used in the MODE=0 case.
#### 4.1.11.1 Coding GS and P0
Define ex(n) to be the excitation function at a given subframe. For MODE=1, 2
or 3, ex(n) is a linear combination of the pitch prediction vector scaled by
β, the long term predictor coefficient, and of the codevector scaled by γ, its
gain. In equation form
$\text{ex}\left( n \right) = \text{βc}_{0}\left( n \right) +
\text{gc}_{1}\left( n \right)$ 0 ≤ n ≤ Ns‑1 (127)
where for MODE≠0
c0(n) is the unweighted long term prediction vector, bL(n)
c1(n) is the unweighted codevector selected, uI(n)
and for MODE=0
c0(n) is the unweighted codevector selected from the first VSELP codebook,
uI,1(n)
c1(n) is the unweighted codevector selected from the second VSELP codebook,
uH,2(n)
The variable c\'j(n) is a weighted version of cj(n). The power in each
excitation vector is given by
$R_{x}(k) = \sum_{n = 0}^{N_{s} - 1}{c^{2_{k}}\left( n \right)}$ 0 ≤ k ≤1
(128)
Let R be the total power in the coder subframe excitation
$R = \beta^{2}R_{x}\left( 0 \right) + g^{2}R_{x}\left( 1 \right)$ (129)
P0, the power contribution of the pitch prediction vector as a fraction of the
total excitation power at a subframe,
$P0 = \frac{\beta^{2}R_{x}\left( 0 \right)}{R}$ where 0 ≤ P0 ≤ 1 (130)
Define R\'q(0) to be the quantized value of R(0) to be used for the current
subframe and Rq(0) to be the quantized value of R(0). Then:
R\'q(0) = Rq(0)previous frame for subframe 1 (131a)
R\'q(0) = Rq(0)current frame for subframes 2, 3, 4 (131b)
Let RS be
$\text{RS} = N_{s}R_{q}^{'}\left( 0 \right)\prod_{i = 1}^{N_{p}}\left( 1 -
r_{i}^{2} \right)$ (132)
The term GS is the energy tweak parameter defined as
(133)
P0 represents the fraction of the total subframe excitation energy which is
due to the first codebook vector, and GS, the energy tweak factor which
bridges the gap between R, the actual energy in the coder excitation, and RS,
its estimated value.
The gain bias factor χ, formulated to force a better energy match between p(n)
and the weighted synthetic excitation, is given below where.
(134)
The weighted error equation is
$E = c^{2}R_{\text{pp}} - a\sqrt{\text{GS}P0} - b\sqrt{\text{GS}\left( 1 - P0
\right)} + c\text{GS}\sqrt{P0\left( 1 - P0 \right)} + d\text{GS}P0 +
e\text{GS}\left( 1 - P0 \right)$ (135)
where
$a = 2\text{cR}_{\text{pc}}\left( 0 \right)\sqrt{\frac{\text{RS}}{R_{x}\left(
0 \right)}}$ (136)
$b = 2\text{cR}_{\text{pc}}\left( 1 \right)\sqrt{\frac{\text{RS}}{R_{x}\left(
1 \right)}}$ (137)
$c = \frac{2R_{\text{cc}}\left( 0,1 \right)\text{RS}}{\sqrt{R_{x}\left( 0
\right)R_{x}\left( 1 \right)}}$ (138)
$d = \frac{\text{RS}R_{\text{cc}}\left( 0,0 \right)}{R_{x}\left( 0 \right)}$
(139)
$e = \frac{\text{RS}R_{\text{cc}}\left( 1,1 \right)}{R_{x}\left( 1 \right)}$
(140)
k=0,1 (141)
k=0,1, j=k,1 (142)
(143)
$R_{\text{pp}} = \sum_{n = 0}^{N_{s} - 1}{p^{2}\left( n \right)}$ (144)
Four separate vector quantizers for jointly coding P0 and GS are defined, one
for each of the four voicing modes. The first step in quantizing of P0 and GS
consists of calculating the parameters required by the error equation:
Rcc(k,j) k = 0, 1, j = k, 1
Rx(k) k = 0, 1
RS
Rpc(k) k = 0, 1
a, b, c, d, e
Next equation (135) is evaluated for each of the 32 vectors in the {P0,GS}
codebook, corresponding to the selected voicing mode, and the vector which
minimizes the weighted error is chosen. Note that in conducting the code
search may be ignored in equation (135), since it is a constant. βq, the
quantized long term predictor coefficient, and γq, the quantized gain, are
reconstructed from
$\beta_{q} =
\sqrt{\frac{\text{RS}\text{GS}_{\text{vq}}P0_{\text{vq}}}{R_{x}\left( 0
\right)}}$ (145)
$g_{q} = \sqrt{\frac{\text{RS}\text{GS}_{\text{vq}}\left( 1 - P0_{\text{vq}}
\right)}{R_{x}\left( 1 \right)}}$ (146)
where P0vq and GSvq are the elements of the vector chosen from the {P0,GS}
codebook.
A special case occurs when the long term predictor is disabled for a certain
subframe, but voicing MODE≠0. This will occur when the state of the long term
predictor is populated entirely by zeroes.
For that case, the following error equation is used:
(147)
For this case the quantized codevector gains are:
(148)
$g_{q} = \sqrt{\frac{\text{RS}\text{GS}_{\text{vq}}\left( 1 - P0_{\text{vq}}
\right)}{R_{x}\left( 1 \right)}}$ (149)
## 4.2 GSM half rate speech decoder
Figure 5: The GSM half rate speech decoder for MODE = 1, 2 or 3
A block diagram of the GSM half rate speech decoder for MODE=1, 2 or 3 is
given in figure 5. The speech decoder creates the combined excitation signal,
ex(n), from the long term filter state and the VSELP codevector. For MODE=0,
the long term filter state is replaced by another VSELP codebook and the pitch
prefilter is not used. The combined excitation is then processed by an
adaptive pitch prefilter and gain. The prefiltered excitation is applied to
the LPC synthesis filter. After reconstructing the speech signal with the
synthesis filter, an adaptive spectral postfilter is applied followed by an
automatic gain control which is the final processing step in the speech
decoder.
### 4.2.1 Excitation generation
The combined excitation, ex(n), shall be computed as shown in equation (127)
The combined excitation, ex(n), is filtered by the synthesis filter to
generate the speech signal. The synthesis filter is a tenth order all pole
filter. The filter coefficients for the subframe are the αi\'s defined in
subclause 4.1.6. The filter coefficients will change from subframe to
subframe. The filter state shall be preserved from subframe to subframe. A
direct form filter shall be used for the synthesis filter.
### 4.2.2 Adaptive pitch prefilter
Given ex(n) as the input, exp(n), the pitch prefiltered output, is defined by
;for 0 ≤ n ≤ Ns‑1 (150)
where
$x = \left{ \begin{matrix} 0,3\text{Min}\left\lbrack \beta,\sqrt{P0}
\right\rbrack & ;\text{MODE}¹0 \ 0 & ;\text{MODE} = 0 \ \end{matrix} \right.\
$ (151)
Since L can be fractional in value, an interpolating filter is used. This is
the same interpolating filter which is used for the open loop lag search. A
gain scale factor is computed and is used to scale the pitch prefiltered
excitation, prior to applying it to the LPC synthesis filter. Pscale, the gain
scale factor, is
$P_{\text{scale}} = \sqrt{\frac{\sum_{n = 0}^{N - 1}{\text{ex}^{2}\left( n
\right)}}{\sum_{n = 0}^{N - 1}{\text{ex}_{p^{2}}\left( n \right)}}}$ (152)
Thus exps(n), the gain corrected pitch prefiltered excitation which drives the
LPC synthesis filter, is given by
$\text{ex}_{\text{ps}}\left( n \right) = P_{\text{scale}}\text{ex}_{p}\left( n
\right)$ ;for 0 ≤ n ≤ Ns‑1 (153)
### 4.2.3 Synthesis Filter
A direct form synthesis filter is used:
,0 ≤ n ≤ Ns‑1 (154)
### 4.2.4 Adaptive spectral postfilter
The perceptual quality of the synthetic speech is enhanced by using an
adaptive postfilter as the final processing step. The general form of the
postfilter is given by:
,0 ≤ n ≤ Ns‑1 (155)
$\overset{\sim}{s}(n) = \overline{s}(n) + \sum_{i = 1}^{Np}{\left( 0,\text{75}
\right)^{i}\alpha_{i}\overset{\sim}{s}(n - i)}$ ,0 ≤ n ≤ Ns‑1 (156)
0 ≤ n ≤ Ns‑1 (157)
The adaptive spectral postfilter numerator polynomial equation (155) is
replaced by a spectrally smoothed version of the adaptive spectral postfilter
denominator polynomial equation (156). To derive the coefficients of the
numerator polynomial, the denominator polynomial coefficients are converted to
the autocorrelation coefficients R(i). The SST bandwidth expansion function is
then applied to the autocorrelation sequence,
, 0 ≤ i ≤ Np (158)
and the numerator polynomial coefficients are calculated from the modified
autocorrelation sequence via the AFLAT recursion.
From Rsst(i) the reflection coefficients which define the combined spectrally
noise weighted synthesis filter are computed using the AFLAT recursion once
per frame.
+--------+------------------------------------------------------------+ | STEP 1 | Define the initial conditions for the AFLAT recursion: | | | | | | ,0 ≤ i ≤ Np (159) | | | | | | $V_{ | | | o}(i) = R_{\text{sst}}\left( \left| i + 1 \right| \right)$ | | | ,1-Np ≤ i ≤ Np‑1 (160) | +--------+------------------------------------------------------------+ | STEP 2 | Initialize j, the index of the lattice stage, to point to | | | the first lattice stage: | | | | | | j=1 (161) | +--------+------------------------------------------------------------+ | STEP 3 | Compute rj, the j-th reflection coefficient, using: | | | | | | (162) | +--------+------------------------------------------------------------+ | STEP 4 | Given rj, update the values of Vj and Pj arrays using: | | | | | | $P_{j}(i) = \le | | | ft( 1 + r_{j}^{2} \right)P_{j - 1}\left( i \right) + r_{j} | | | \left\lbrack V_{j - 1}(i) + V_{j - 1}( - i) \right\rbrack$ | | | .0 ≤ i ≤ Np - j - 1 (163) | | | | | | $V_{j}(i) = V_{j - 1}\ | | | left( i + 1 \right) + r_{j}^{2}V_{j - 1}\left( - i - 1 \ri | | | ght) + 2r_{j}P_{j - 1}\left( \left| i + 1 \right| \right)$ | | | ,1+j-Np≤i≤Np-j‑1 (164) | +--------+------------------------------------------------------------+ | STEP 5 | Increment j: | | | | | | j = j +1 | +--------+------------------------------------------------------------+ | STEP 6 | If j ≤ Np go to step 3, otherwise all Np reflection | | | coefficients have been obtained. | +--------+------------------------------------------------------------+ | STEP 7 | The reflection coefficients, rj, are then converted to i, | | | the direct-form LP filter coefficients for use in the | | | adaptive spectral postfilter numerator polynomial. | +--------+------------------------------------------------------------+
The resultant adaptive spectral postfilter is derived from equations 155, 156
and 157:
,0 ≤ n ≤ Ns‑1 (165)
,0 ≤ n ≤ Ns‑1 (166)
,0 ≤ n ≤ Ns‑1 (167)
In order to reduce the computations needed to compute the spectrally smoothed
numerator coefficients, the spectral smoothing operation is performed once per
frame on the denominator coefficients corresponding to the uninterpolated
coefficients. This will yield the coefficients for the numerator of the
spectral postfilter for subframe four. The numerator coefficients for
subframes one, two, and three are interpolated using the same interpolation
scheme that is used for the LPC synthesis coefficients (see subclause 4.1.6).
As in the case of the pitch prefilter, a means of automatic gain control is
needed to ensure unity gain through the spectral postfilter. A scale factor,
Sscale, is given by:
S\'scale(n) = (0,9875 S\'scale(n‑1) ) + (0,0125 Sscale ) (168)
Scale factor, Sscale, is the square root of the ratio of the input signal
energy to the output signal energy over the subframe.
The output of the spectral postfilter is then multiplied by S\'scale as the
last step in reconstructing the speech signal in the speech decoder.
### 4.2.5 Updating decoder states
The long term predictor state, r(n), is updated by:
r(n) = r(n+40) for ‑146 ≤ n ≤‑41 (169)
r(n) = ex(n+40) for ‑40 ≤ n ≤ ‑1 (170)
# 5 Homing sequences
## 5.1 Functional description
The half rate speech codec as well as the DTX system and comfort noise
generator are described in a bit exact arithmetic to allow for easy type
approval as well as general testing purposes of the half rate speech codec.
The response of the codec to a predefined input sequence can only be foreseen
if the internal state variables of the codec are in a predefined state at the
beginning of the experiment. Therefore, the codec has to be put in a so called
home state before a bit exact test can be performed. This is usually done by a
reset.
To allow a reset of the codec in remote locations, special homing frames have
been defined for the encoder and the decoder, thus enabling a codec homing by
inband signalling.
The codec homing procedure is defined in such a way, that on either direction
(encoder or decoder), the homing functions are called after processing the
homing frame that is input. The output corresponding to the first homing frame
is therefore dependent on the codec state when receiving that frame and hence
usually not known. The response to any further homing frame in one direction
is by definition a homing frame of the other direction. This procedure allows
homing of both, the encoder and decoder from either side, if a loop back
configuration is implemented, taking proper framing into account.
## 5.2 Definitions
**encoder homing frame:** The encoder homing frame consists of 160 identical
samples, each 13 bit long, with the least significant bit set to \"one\" and
all other bits set to \"zero\". When written to 16 bit long words with left
justifications, the samples have a value of 0008 hex. Test sequence SEQ05.INP
described in GSM 06.07 [3] defines the encoder homing frame. The speech
decoder has to produce this frame as a response to the second and any further
decoder homing frame if at least two decoder homing frames were input to the
decoder consecutively.
**decoder homing frame:** The decoder homing frame has a fixed set of speech
parameters as defined in test sequence SEQ05.INP described in GSM 06.07 [3].
It is the natural response of the speech encoder to the second and any further
encoder homing frame if at least two encoder homing frames were input to the
encoder consecutively.
## 5.3 Encoder homing
Whenever the half rate speech encoder receives at its input an encoder homing
frame exactly aligned with its internal speech frame segmentation, the
following events take place:
Step 1: The speech encoder performs its normal operation including VAD and DTX
and produces a speech parameter frame at its output which is in general
unknown. But if the speech encoder was in its home state at the beginning of
that frame, then the resulting speech parameter frame is identical to the
decoder homing frame (this is the way how the decoder homing frame was
constructed).
Step 2: After successful termination of that operation, the speech encoder
provokes the homing functions for all submodules including VAD and DTX and
sets all state variables into their home state. On the reception of the next
input frame, the speech encoder will start from its home state.
NOTE: Applying a sequence of N encoder homing frames will cause at least N‑1
decoder homing frames at the output of the speech encoder.
## 5.4 Decoder homing
Whenever the speech decoder receives at its input a decoder homing frame, then
the following events take place:
Step 1: The speech decoder performs its normal operation including comfort
noise generation and produces a speech frame at its output which is in general
unknown. But if the speech decoder was in its home state at the beginning of
that frame, then the resulting speech frame is replaced by the encoder homing
frame. This would not naturally be the case but is forced by this definition
here.
Step 2: After successful termination of that operation, the speech decoder
provokes the homing functions for all submodules including the comfort noise
generator and sets all state variables into their home state. On the reception
of the next input frame, the speech decoder will start from its home state.
NOTE 1: Applying a sequence of N decoder homing frames will cause at least N‑1
encoder homing frames at the output of the speech decoder.
NOTE 2: By definition the first 58 bits of the decoder homing frame must
differ in at least one bit position from the first 58 bits of any of the
decoder test sequences. Therefore, if the decoder is in its home state, it is
sufficient to check only these first 58 bits to detect a subsequent decoder
homing frame. This definition ids made to support a delay optimised
implementation in the TRAU uplink direction.
## 5.5 Encoder home state
In GSM 06.06 [2], a listing of all the encoder state variables with their
predefined values when in the home state is given.
## 5.6 Decoder home state
In GSM 06.06 [2], a listing of all the decoder state variables with their
predefined values when in the home state is given.
###### ## Annex A (normative): Codec parameter description
# A.1 Codec parameter description
The following is a list of all the parameters which are coded for each 20 ms
speech frame. The basic data rate of the speech coder is 5,6 kbps. Therefore
each 20 ms speech frame consists of 112 bits. These bits are given in table
A.1.
Table A.1: Codec parameter description
* * *
Parameter No. of bits Description Frame bits:  
MODE 2 voicing mode R0 5 frame energy LPC1 11 reflection coefficient vector
r1-r3 LPC2 9 reflection coefficient vector r4-r6 LPC3 8 reflection coefficient
vector r7-r10 INT_LPC 1 the soft interpolation bit for the frame Subframe bits
(MODE = 1,2 or 3):  
LAG_1 8 lag for first subframe LAG_2 4 lag delta code for second subframe
LAG_3 4 lag delta code for third subframe LAG_4 4 lag delta code for fourth
subframe CODE_1 9 codebook, I, for first subframe CODE_2 9 codebook, I, for
second subframe CODE_3 9 codebook, I, for third subframe CODE_4 9 codebook, I,
for fourth subframe GSP0_1 5 {P0,GS} code for first subframe GSP0_2 5 {P0,GS}
code for second subframe GSP0_3 5 {P0,GS} code for third subframe GSP0_4 5
{P0,GS} code for fourth subframe Subframe bits (MODE=0):  
CODE1_1 7 codebook code, I, for first subframe CODE2_1 7 codebook code, H, for
first subframe CODE1_2 7 codebook code, I, for second subframe CODE2_2 7
codebook code, H, for second subframe CODE1_3 7 codebook code, I, for third
subframe CODE2_3 7 codebook code, H for third subframe CODE1_4 7 codebook
code, I, for fourth subframe CODE2_4 7 codebook code, H, for fourth subframe
GSP0_1 5 {P0,GS} code for first subframe GSP0_2 5 {P0,GS} code for second
subframe GSP0_3 5 {P0,GS} code for third subframe GSP0_4 5 {P0,GS} code for
fourth subframe
* * *
## A.1.1 MODE
The speech coder is defined by 4 voicing modes. MODE is a two bit code which
specifies which of the four voicing modes is used at the current frame. The
MODE indicates which definition of the frame bits to apply to the current
frame.
## A.1.2 R0
R0 is a code which represents the average signal power of the input speech for
the frame. The average signal power is computed using an analysis window which
is centered over the last 100 samples of the frame.
## A.1.3 LPC1 - LPC3
The 10 reflection coefficients are vector quantized in three vector segments.
The first vector segment codes reflection coefficients r1 - r3, the second
vector segment codes coefficients r4-r6, the third vector segment codes
coefficients r7 - r10.
## A.1.4 LAG_1 - LAG_4
LAG_1, the lag for the first subframe, can take on the value in the range of
21 to 142. Eight bits are used to encode the lag which may be fractional in
value. Each of the remaining lag values ( LAG_2 through LAG_4) is delta coded
relative to the preceding subframe\'s coded value of the lag, with a deviation
of ‑8 to +7 allowable lag value levels specified by a four bit code.
## A.1.5 CODEx_1 - CODEx_4
If MODE ≠ 0, the code value for the VSELP codebook is the codeword I as
derived by the codebook search procedure. If MODE=0, two VSELP codebooks are
sequentially searched, with codeword I, specifying the codevector from the
first VSELP codebook, assigned onto CODE1_x, and codeword H, specifying the
codeword selected from the second VSELP codebook, assigned onto CODE2_x, where
x is the subframe number.
## A.1.6 GSP0_1 - GSP0_4
The {P0,GS} codebook contains the values needed to determine the gain factors
for the excitation vectors of a given subframe. The index of the corresponding
codebook entry is assigned to GSP0_x.
The speech coder is a multimode speech coder, defined by four voicing modes:
* * *
MODE = 0 unvoiced MODE = 1 slightly voiced MODE = 2 moderately voiced MODE = 3
strongly voiced
* * *
If MODE=0, the adaptive codebook (long-term predictor) and the VSELP codebook
are replaced by two other VSELP codebooks.
# A.2 Basic coder parameters
The following are the basic parameters for the 5 600 bps GSM half rate speech
codec system.
* * *
       sampling rate                8 kHz
NF frame length 160 samples (20 ms) Ns subframe length 40 samples (5 ms) Np
short term predictor order 10
* * *
###### ## Annex B (normative): Order of occurrence of the codec parameters
over Abis
The order of occurrence of the codec parameters over the Abis is defined for
unvoiced speech (MODE = 0) and voiced speech (MODE = 1, 2 or 3) in tables B.1
and B.2 respectively.
Table B.1: Occurrence of the codec parameters over Abis for unvoiced speech
(MODE = 0)
* * *
Parameter No. of bits Bit No. (MSB - LSB) R0 5 b1 - b5 LPC1 11 b6 - b16 LPC2 9
b17 - b25 LPC3 8 b26 - b33 INT_LPC 1 b34 MODE 2 b35 - b36
CODE1_1 7 b37 - b43 CODE2_1 7 b44 - b50 GSP0_1 5 b51 - b55
CODE1_2 7 b56 - b62 CODE2_2 7 b63 - b69 GSP0_2 5 b70 - b74
CODE1_3 7 b75 - b81 CODE2_3 7 b82 - b88 GSP0_3 5 b89 - b93
CODE1_4 7 b94 - b100 CODE2_4 7 b101 - b107 GSP0_4 5 b108 - b112
* * *
Table B.2: Occurrence of the codec parameters over Abis for voiced speech
(MODE = 1, 2 or 3)
* * *
Parameter No. of bits Bit No. (MSB - LSB) R0 5 b1 - b5 LPC1 11 b6 - b16 LPC2 9
b17 - b25 LPC3 8 b26 - b33 INT_LPC 1 b34 MODE 2 b35 - b36
LAG_1 8 b37 - b44 CODE1 9 b45 - b53 GSP0_1 5 b54 - b58
LAG_2 4 b59 - b62 CODE2 9 b63 - b71 GSP0_2 5 b72 - b76
LAG_3 4 b77 - b80 CODE3 9 b81 - b89 GSP0_3 5 b90 - b94
LAG_4 4 b95 - b98 CODE4 9 b99 - b107 GSP0_4 5 b108 - b112
* * *
###### ## Annex C (informative): Bibliography
M. R. Schroeder and B. S. Atal, \"Code-Excited Linear Prediction (CELP): High
Quality Speech at Very Low Bit Rates\", **Proc. IEEE Int. Conf. on Acoustics,
Speech and Signal Processing** , pp. 937‑940, March 1985.
G. Davidson and A. Gersho, \"Complexity Reduction Methods for Vector
Excitation Coding\", **Proc. IEEE Int. Conf. on Acoustics, Speech and Signal
Processing** , pp. 3055‑3058, April 1986.
I. Gerson and M. Jasiuk, \"Vector Sum Excited Linear Prediction (VSELP) Speech
Coding at 8 kbps\", **Proc. IEEE Int. Conf. on Acoustics, Speech and Signal
Processing** , pp. 461‑464, April 1990.
P. Kroon and B. S. Atal, \"Pitch Predictors with High Temporal Resolution\",
**Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing** , pp.
661‑664, April 1990.
I. A. Gerson, \"Method and Means of Determining Coefficients for Linear
Predictive Coding\", U. S. Patent #4,544,919, Oct. 1985.
A. Cumani, \"On a Covariance-Lattice Algorithm for Linear Prediction\",
**Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing** , pp.
651‑654, May 1982.
M. McLaughlin, I. Gerson, F. Hudziak, and K. Kloker, \"High Performance
Processor for Real-Time Speech Applications\", **Proc. IEEE Int. Conf. on
Acoustics, Speech and Signal Processing** , pp. 859‑863, April 1980.
Y. Tohkura, F. Itakura and S. Hashimoto, \"Spectral Smoothing Technique in
PARCOR Speech Analysis-Synthesis\", **IEEE Trans. Acoustics, Speech and Signal
Processing** , vol. ASSP‑26, pp. 591‑596, Dec. 1978.
W. Kleijn, D. Krasinski, and R. Ketchum, \"Improved Speech Quality and
Efficient Vector Quantization in SELP\", **Proc. IEEE Int. Conf. on Acoustics,
Speech and Signal Processing** , pp. 155‑158, April 1988.
Y. Linde, A. Buzo, and R. M. Gray, \"An Algorithm for Vector Quantizer
Design\", **IEEE Trans. Comm.** , vol. COM‑28, pp. 84‑95, Jan. 1980.
Juin-Hwey Chen and Allen Gersho, \"Real-Time Vector APC Speech Coding at 4800
bps with Adaptive Postfiltering\", **Proc. IEEE Int. Conf. on Acoustics,
Speech and Signal Processing,** pp. 2185‑2188, 1987.
#