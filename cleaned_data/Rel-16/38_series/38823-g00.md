# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
In the present document, modal verbs have the following meanings:
**shall** indicates a mandatory requirement to do something
**shall not** indicates an interdiction (prohibition) to do something
The constructions \"shall\" and \"shall not\" are confined to the context of
normative provisions, and do not appear in Technical Reports.
The constructions \"must\" and \"must not\" are not used as substitutes for
\"shall\" and \"shall not\". Their use is avoided insofar as possible, and
they are not used in a normative context except in a direct citation from an
external, referenced, non-3GPP document, or so as to maintain continuity of
style when extending or modifying the provisions of such a referenced
document.
**should** indicates a recommendation to do something
**should not** indicates a recommendation not to do something
**may** indicates permission to do something
**need not** indicates permission not to do something
The construction \"may not\" is ambiguous and is not used in normative
elements. The unambiguous constructions \"might not\" or \"shall not\" are
used instead, depending upon the meaning intended.
**can** indicates that something is possible
**cannot** indicates that something is impossible
The constructions \"can\" and \"cannot\" are not substitutes for \"may\" and
\"need not\".
**will** indicates that something is certain or expected to happen as a result
of action taken by an agency the behaviour of which is outside the scope of
the present document
**will not** indicates that something is certain or expected not to happen as
a result of action taken by an agency the behaviour of which is outside the
scope of the present document
**might** indicates a likelihood that something will happen as a result of
action taken by some agency the behaviour of which is outside the scope of the
present document
**might not** indicates a likelihood that something will not happen as a
result of action taken by some agency the behaviour of which is outside the
scope of the present document
In addition:
**is** (or any other verb in the indicative mood) indicates a statement of
fact
**is not** (or any other negative verb in the indicative mood) indicates a
statement of fact
The constructions \"is\" and \"is not\" do not indicate requirements.
# 1 Scope
The present document is related to the technical report of the study item \"
Study on Enhancement for Disaggregated gNB \" [2].
This activity involves the Radio Access work area of the 3GPP studies and has
impacts on the Access Network of the 3GPP systems.
The present document gathers all technical outcome of the study item, and
draws a conclusion on the way forward.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] RP-191975, Revised SID: Enhancement for disaggregated gNB architecture,
CATT
[3] 3GPP TS 38.300: \"NR; Overall description; Stage-2\"
[4] 3GPP TS 38.401: \"NG-RAN; Architecture description\"
[5] 3GPP TS 38.425:\"NG-RAN; NR user plane protocol\"
[6] R3-197333, pCR for TR 38.823: Transport Network Delay Compensation in
Split gNB Architecture, Ericsson
[7] R3-197241, Evaluation of solutions for user plane enhancements, Huawei,
CATT
[8] R3-197714, pCR for TR 38.823: Evaluation of flow control enhancements,
Ericsson
[9] R3-197733, TP for TR 38.823: On reported DBS, Nokia, Nokia Shanghai Bell
[10] R3-197793, Solution on data compensation for transport network delay,
Huawei
[11] R3-197736, pCR for TR 38.823: Evaluation of Solution 2 for Scenario 2,
Ericsson
[12] R3-197738, Conclusion for Disaggregated gNB enhancement SI, CATT, China
Telecom
[13] R3-194746, TP to TR 38.823 on user plane enhancement, CATT, CAICT, China
Telecom
[14] R3-193694, Discussion on user plane enhancement, CATT, CAICT, China
Telecom
[15] R3-194448, Considerations on retransmitted PDCP PDUs issue, Huawei
# 3 Definitions of terms, symbols and abbreviations
## 3.1 Terms
For the purposes of the present document, the terms given in 3GPP TR 21.905
[1] and the following apply. A term defined in the present document takes
precedence over the definition of the same term, if any, in 3GPP TR 21.905
[1].
**gNB:** as defined in 3GPP TS 38.300 [3]
**gNB Central Unit (gNB-CU):** as defined in 3GPP TS 38.401 [4]
**gNB Distributed Unit (gNB-DU):** as defined in 3GPP TS 38.401 [4]
**gNB-CU-Control Plane (gNB-CU-CP):** as defined in 3GPP TS 38.401 [4]
**gNB-CU-User Plane (gNB-CU-UP):** as defined in 3GPP TS 38.401 [4]
## 3.2 Symbols
Void.
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
DDDS Downlink Data Delivery Status
NR NR Radio Access
TN Transport Network
# 4 General
**The objective of this study item is to investigate enhancements to
disaggregated gNB scenario. At least the following topics should be studied:**
1\. Identifying detailed solutions for further enhancements on current flow
control mechanism with the following aspects considered.
\- PDCP PDUs may be delivered in the Uu interface out of sequence.
\- The re-transmitted PDCP PDUs may arrive at DU out of order.
\- In DC scenario, data transmitted to UE from two legs may arrive out of
order which in turn may result in out-of-order delivery to higher layer in
case of re-ordering timer expiration.
Note1: The solution was required to be backward compatible (i.e. carefully
consider the fact no criticality handling defined in U-plane protocol
specification).
2\. Identifying detailed solutions to support the scenario that one UE
connects to several gNB-CU-UPs which belong to different security domains.
Note2: SA3 should be involved in this SI.
Note3: CP/UP separation and CU/DU split should be invisible to other nodes
(especially UE should not be impacted).
# 5 Further Enhancements on Flow Control Mechanism
## 5.1 Scenario
### 5.1.1 Scenario 1
In Rel-15, fast retransmission was introduced. For this case, data
unsuccessfully transmitted in one leg would be re-transmitted in another leg
based on the DDDS from the corresponding node. The current DDDS reports the
sequence number of the in-sequence successfully delivered PDCP PDUs, which may
lead to re-transmission in another leg of some already delivered PDCP PDUs.
For example, Figure 5.1-1 depicts the transmission status for one specific UE
in gNB-DU1, i.e. all PDCP PDU with sequence number below 207 are successfully
sent to UE except for PDCP PDU with SN 201. In this case, the gNB-DU1 would
only report to gNB-CU-UP that its highest in-sequence successful transmitted
PDCP SN as 200 and gNB-CU would request gNB-DU2 to re-transmit the PDCP PDU
whose SN is above 200, among which some are already delivered to the UE.
Figure 5.1-1: PDCP PDU transmission status in gNB-DU1 for Scenario 1
### 5.1.2 Scenario 2
For re-transmission, there may be two kinds of re-transmissions, i.e.
retransmission because of the data missing on F1/Xn interface and fast re-
transmission mechanism. When the two kinds of re-transmission data arrive at
corresponding node, the corresponding node may do re-ordering while sending
them to UE. At the same time, the data sent from hosting node may arrive at
corresponding node out of order. In this case, the hosting node could not get
the accurate information on the status of re-transmission packets.
In Rel-15, DDDS for retransmitted packets relies on reporting PDCP SN
corresponding to the highest in-sequence NR-U SN. This was decided mainly due
to backward compatibility and inter-operability.
For retransmitted packets, \"retransmission\" is flagged by CU. This is for
prioritization at DU (i.e. re-ordering based on PDCP SN). Although not
mandated, DU\'s re-ordering is critical to minimize service interruptions.
However, the current Rel-15 solution is suboptimal when DU performs re-
ordering. For example, suppose that DU re-orders lower PDCP SN packets after
successfully delivering SN #103 as in Figure 5.1.2-1 (assuming that SN #1, #2,
arrives at DU before transmitting SN #104):
Figure 5.1.2-1: DU\'s re-ordering makes the current Rel-15 solution sub-
optimal
\- Reporting a PDCP SN corresponding to the highest in-sequence NR-U SN
(current Rel-15) will be fixed to #103, until a next NR-U SN (i.e. corresponds
to #104) is successfully delivered.
\- In other words, there will not be any new feedback until all the
retransmitted packets with lower PDCP SN than #104 (and higher NR-U SN than
\"B\") are delivered successfully.
\- If they are in large volume (e.g. the Centralized Retransmission scheme),
this could result in a suboptimal behaviour for CU, because those large number
of already delivered retransmitted packets cannot be freed up in a timely
fashion.
In summary, the main issue with the current Rel-15 solution is as follows:
\- DU\'s reordering based on PDCP SN could result in earlier NR-U SN packets
(with higher PDCP SN) to be kept de-prioritized.
\- Such de-prioritization could lead DDDS feedback sluggish and inefficient
buffer management for CU.
### 5.1.3 Scenario 3
Typical delays on transport links between the node hosting the PDCP entity and
the corresponding node may be up to several tens of milliseconds. Such large
delays may lead to a discontinuity of packet arrivals at the corresponding
node, meaning that the corresponding node buffer may often be empty because
the packets transmitted by the node hosting the PDCP entity will spend
significant amount of time traversing the transport network (Refer to [6]).
## 5.2 Possible Solutions
### 5.2.1 Solution for Scenario 1
For scenario 1, the possible solutions are listed as below:
Solution1: The corresponding node reports the highest successfully delivered
PDCP SN in order and at the same time also reports all the other PDCP SN
delivered successfully out of order. The corresponding node reports all PDCP
SN which are delivered to UE successfully based on the request from hosting
node (Refer to [14]). The update to DDDS and DL USER DATA is as follows:
{width="5.53125in" height="9.53125in"}
Figure 5.2.1-1: Impact to DDDS for Solution 1
{width="5.71875in" height="5.666666666666667in"}
Figure 5.2.1-2: Impact to DL USER DATA for Solution 1
Solution 2: The corresponding node reports the highest successfully delivered
PDCP SN in order and the highest successfully delivered PDCP SN. At the same
time, it reports the PDCP SN which is not delivered successfully between them.
The corresponding node reports all PDCP SN which are delivered to UE
successfully based on the request from hosting node (Refer to [14]). The
update to DDDS and DL USER DATA is as follows:
{width="5.59375in" height="9.604166666666666in"}
Figure 5.2.1-3: Impact to DDDS for Solution 2
{width="5.645833333333333in" height="5.739583333333333in"}
Figure 5.2.1-4: Impact to DL USER DATA for Solution 2
Solution 3: The indication of successfully delivered PDCP SN range(s) is
introduced to indicate the status of the PDU after the highest successfully
delivered PDCP PDU, where the successfully delivered PDCP SN range is defined
by two parameters, i.e., start of successfully delivered PDCP SN and end of
successfully delivered PDCP SN (Refer to [15]).
{width="5.645833333333333in" height="4.197916666666667in"}
Figure 5.2.1-5: Impact to DDDS for Solution 3 to scenario 1
Solution 4: The existing DL discard mechanism from TS 38.425 is used [5].
Solution 5: The corresponding node was required to, if supported, send the
report of out-of-sequence delivered PDCP PDU SNs when the node hosting the
PDCP entity has set the _Full delivered PDCP PDU SN report flag_.
{width="5.697916666666667in" height="5.708333333333333in"}
Figure 5.2.1-6: Impact to DL User Data for Solution 5
{width="5.5279811898512685in" height="9.5465124671916in"}
Figure 5.2.1-7: Impact to DDDS for Solution 5
### 5.2.2 Solution for Scenario 2
Solution 1-5: Solutions for Scenario 1 could be reused for Scenario 2 with
similar information introduced for re-transmission packets.
Solution 6: Highest PDCP SN approach with up to which NR-U SN. To mitigate
this problem, the following solution is proposed for DDDS in TS 38.425 [5].
{width="5.690623359580052in" height="9.581395450568678in"}
Figure 5.2.2-1: Impact to DDDS for Solution 6
For Solution 6, the definition of the coding of information elements in frames
are as follows:
**Highest Delivered Retransmitted NR PDCP SN Ind**
\- **Description:** This parameter indicates the presence of highest
successfully delivered retransmitted PDCP Sequence Number.
\- **Value range:** {0= Highest Successfully delivered retransmitted NR PDCP
Sequence Number not present, 1= Highest Successfully delivered retransmitted
NR PDCP Sequence Number}.
\- **Field length:** 1 bit.
**Highest Delivered Retransmitted End NR-U SN Ind**
\- **Description:** This parameter indicates the presence of End of NR-U
Sequence Number for Highest successfully delivered retransmitted NR PDCP
Sequence Number.
\- **Value range:** {0= End of NR-U Sequence Number for Highest Successfully
delivered retransmitted NR PDCP Sequence Number not present, 1= End of NR-U
Sequence Number for Highest Successfully delivered retransmitted NR PDCP
Sequence Number}.
\- **Field length:** 1 bit.
**Highest Retransmitted NR PDCP SN Ind**
\- **Description:** This parameter indicates the presence of highest
retransmitted PDCP Sequence Number.
\- **Value range:** {0= Highest Retransmitted NR PDCP Sequence Number not
present, 1= Highest Retransmitted NR PDCP Sequence Number present}.
\- **Field length:** 1 bit.
**Highest Retransmitted End NR-U SN Ind**
\- **Description:** This parameter indicates the presence of End of NR-U
Sequence Number for Highest retransmitted NR PDCP Sequence Number.
\- **Value range:** {0= End of NR-U Sequence Number for Highest Successfully
delivered retransmitted NR PDCP Sequence Number not present, 1= End of NR-U
Sequence Number for Highest Successfully delivered retransmitted NR PDCP
Sequence Number}.
\- **Field length:** 1 bit.
**Highest Successfully delivered retransmitted NR PDCP Sequence Number**
\- **Description:** This parameter indicates highest successfully delivered NR
PDCP SN in-sequence among retransmission NR PDCP PDUs.
\- **Value range:** {0..218-1}.
\- **Field length:** 3 octets.
**End of NR-U Sequence Number for Highest successfully delivered retransmitted
NR PDCP Sequence Number**
\- **Description:** This parameter indicates a NR-U sequence number up to
which the reported Highest successfully delivered retransmitted NR PDCP
Sequence Number should be applied for retransmission NR PDCP PDUs.
\- **Value range:** {0..218-1}.
\- **Field length:** 3 octets.
**Highest retransmitted NR PDCP Sequence Number**
\- **Description:** This parameter indicates highest transmitted NR PDCP SN
in-sequence among retransmission NR PDCP PDUs.
\- **Value range:** {0..218-1}.
\- **Field length:** 3 octets.
**End of NR-U Sequence Number for Highest successfully delivered retransmitted
NR PDCP Sequence Number**
\- **Description:** This parameter indicates a NR-U sequence number up to
which the reported Highest retransmitted NR PDCP Sequence Number should be
applied for retransmission NR PDCP PDUs.
\- **Value range:** {0..218-1}.
\- **Field length:** 3 octets.
The proposed solution has the following principles:
\- Relying on \"highest\" PDCP SN feedback can embrace the advantage of
freeing up CU\'s buffer for what has been successfully delivered based on PDCP
SN.
\- By giving \"up to which NR-U SN\" retransmitted packets have been already
delivered to the UE and can be freed up by the reported \"highest\" SN, CU can
confine a range of retransmitted packets for which the reported \"highest\" SN
should be applied.
\- The proposed solution is a generalized version of the current Rel-15
solution, where \"up to which NR-U SN\" is always fixed to that of the PDCP SN
reported, thus cannot be worse than Rel-15.
For example, in Figure 5.2.2-2\'s scenario, CU is now able to know that \"OK,
among all the retransmitted packets whose PDCP SN lower than or equal to #103,
only those up to NR-U SN \"G\" are successfully delivered\", and thus free up
#1, #2, #3, #4, #5, and #103 from its buffer as exactly intended:
Figure 5.2.2-2: Proposed solution applied to the Figure 5.1.2-1\'s scenario
### 5.2.3 Solution for Scenario 3
Solution 1: According to TS 38.425, the amount of data per bearer that the
node hosting the PDCP entity send to the corresponding node is upper-bounded
by desired buffer size [5]. One way to address the problem in Scenario 3 and
compensate for transport network delay is to allow the node hosting the PDCP
entity to send additional amount of data on top of desired buffer size. This
could be accommodated by introducing the following statement in clause 5.4.2.1
of TS 38.425: \"_The hosting node may send additional amount of data to
compensate for transport link delays.\"_
Solution 2: In this solution, the corresponding node takes the transport
network delay into account when it calculates the desired buffer size. That
is, the corresponding node estimates the size of the additional amount of data
to compensate for link delays, according to the transmission rate over air
interface and the transport network delay which is received from the control
plane message sent by the node hosting the PDCP entity. Subsequently, the
corresponding node calculates the desired buffer size by considering the
estimated size of the additional amount of data to compensate for link delays.
## 5.3 Evaluations
### 5.3.1 Overhead of message size evaluation
Regarding to the cost of the F1/Xn-U in case of Solution 1, Solution 2,
Solution 3 and Solution 5 for scenario 1 from a message size perspective, the
extra cost of the DDDS are listed as follows.
\- Solution 1: For DDDS report, the cost is (1bit + 3 octets + _Number of NR
PDCP successfully delivered out of order_ * 3 octets), where the _Number of NR
PDCP successfully delivered out of order_ is (2^SN\ length^ -- 2) at most.
\- Solution 2: For DDDS report, the cost is (1bit + 3 octets + Number of
reported _missing NR PDCP_ * 3 octets), where the _Number of missing NR PDCP_
is (2^SN\ length^ -- 2) at most.
\- Solution 3: For DDDS report, the cost is (1bit + 3 octets + _Number of
successfully delivered PDCP SN range_ * 6 octets), where the _Number of
successfully delivered PDCP SN range_ is (2^SN\ length-1^ -- 1) at most.
\- Solution 5: For DDDS report, the cost is (1bit + 3 octets + _Number of
successfully delivered NR PDCP PDU SN blocks_ * 4 octets), where the _Number
of successfully delivered NR PDCP PDU SN blocks_ is (2^SN\ length-1^ -- 1) at
most.
Note: to align among the above Solutions 1-3 when compare the cost, the field
length of the number of the successfully delivered PDCP SN range is set to 3
octets as well, which is different from the Solution 3 and Solution 5 captured
in the present document.
In the worst case, for all the above solutions, the extra cost of the F1/Xn-U
is about 0.75MB and 12KB in case of SN-18 and SN-12, respectively, whereas for
Solution 5, the extra cost is about 0.5MB and 8KB in case of SN-18 and SN-12
respectively. However, the worst case is normally rare, and the extra cost on
the F1-U/Xn-U interface could be reduced and limited by the following
mechanisms:
\- Limit the reported size, i.e., the reported number of NR PDCP successfully
delivered out of order for Solution 1, the reported number of missing NR PDCP
Sequence for Solution 2, and the reported number of the successfully delivered
PDCP SN range for Solution 3. For example, if the value rang of the number of
the successfully delivered PDCP SN range is limited to 2^8^ with field length
1 octet as captured in [13], then the cost of the Solution 3 could be reduced
to 1.5KB, which is acceptable over the F1/Xn-U.
\- As described in Solution1/2, the corresponding node could report all PDCP
SN which are delivered to UE successfully based on the request from hosting
node.
Regarding the selection of solution, it depends on the transmission status,
e.g.,
\- Case 1: if the _successfully delivered PDCP SN range_ includes more than
two PDU SNs, then the Solution 3 is better than Solution 1, i.e., the extra
cost of the F1/Xn-U of Solution 3 is smaller than the Solution 1.
\- Case 2: if the _successfully delivered PDCP SN range_ includes two PDU SNs,
then the extra cost of the F1/Xn-U of Solution 3 is equal to the Solution 1.
\- Case 3: if the _successfully delivered PDCP SN range_ includes only one PDU
SN, then the extra cost of the F1/Xn-U of Solution 3 is larger than the
Solution 1.
\- Case 4: if the _successfully delivered NR PDCP PDU SN block size_ for a
certain block is larger than 256, then the Solution 5 is worse than Solution
3, i.e., the extra cost of the F1/Xn-U of Solution 5 is larger than the
Solution 3.
\- Case 5: if the _successfully delivered NR PDCP PDU SN block size_ for a
certain block is smaller than (or equal to) 256, then the extra cost of the
F1/Xn-U of Solution 5 is smaller than the Solution 3.
\- Case 6: if the _successfully delivered NR PDCP PDU SN block size_ for a
certain block is one, then the Solution 5 is worse than Solution 1, i.e., the
extra cost of the F1/Xn-U of Solution 5 is larger than the Solution 1.
\- Case 7: if the _successfully delivered NR PDCP PDU SN block size_ for a
certain block is larger than one, then the extra cost of F1/Xn-U of Solution 5
is better than Solution 1.
In conclusion, the cost of extra cost on the F1-U/Xn-U interface is
acceptable, and the solutions for DDDS enhancement have to be adopted, and
which one is chosen depends on the evaluation of the transmission status.
Considering the Case 6 and Case 7, it seems that in the most case, the
_successfully delivered NR PDCP PDU SN block size_ is larger than one. Hence,
compared with Solution 1 and Solution 2, Solution 5 is recommended [7].
With regards to Solution 4, since it reuses the existing DL discard mechanism,
no extra signalling cost needs to be considered.
Regarding to the cost of the F1/Xn-U in case of solution for Scenario 2 as
described in clause 5.2.2, the extra cost of the DDDS 2bit + 6 octets.
### 5.3.2 Practical relevance of the Scenarios 1 and 2
The changes to DDDS proposed in solutions 1-5 for Scenario 1 and Solutions 1-2
for Scenario 2 significantly change the current DDDS structure. Moreover,
regarding the claimed benefits of the solution for duplication and fast
retransmission, some properties of RLC need to be considered. First, when a
packet is handed over to the RLC, its transmission cannot be recalled. Second,
once a PDU is lost on RLC level, a meaningful RLC implementation will not
attempt to send new PDUs (or at least not more than an extremely small number
of new PDUs) to the UE until the missing PDU has been successfully delivered.
One claimed use case for detailed reporting of out-of-sequence delivered PDUs
is centralized (i.e. fast) retransmission. The essence of fast retransmission
feature is to temporarily suspend delivery in a leg that experiences delivery
problems, where the benefit of (only) temporary suspension is that RLC context
removal/reestablishment is avoided. In that respect, it is crucial that the
RLC recognizes early that the problems with delivery are likely to occur (i.e.
after one or two lost RLC PDUs) and initiates fast retransmission in the other
leg. Since the DU will not wait for long to take action, this means that the
number of out-of-sequence delivered PDUs to the UE is small. In other words,
the number of out-of-sequence delivered PDUs to the UE will be extremely
small, and any eventual retransmission in another leg will comprise an
extremely small number of PDUs.
Regarding the use of aforementioned solutions for revoking packet
transmissions in duplication, some companies expressed the following concern :
it is expected that the duplicates are delivered to the UE within a reasonably
short time period, meaning that, by the time an out-of-sequence delivery of a
PDU from one leg is reported, the transmission of its duplicates in other legs
cannot be recalled because the duplicates will most likely have entered the
RLC on other legs and their transmission in these other legs cannot be
recalled (i.e. discarded).
Having in mind the above, the benefits of the Solutions 1-5 for Scenario 1 and
Solutions 1-2 for Scenario 2, compared with their inherent complexity are
questioned by some companies.
The Solution 2 for Scenario 2 does not support the reporting for the scenario
where multiple sets of retransmission blocks (caused by e.g. TN loss or poor
conditions in the other leg) are sent along with first-time transmissions
[11].
The DU may perform full or partial reordering, where the CU cannot know if and
how much reordering has been done. The Solution 2 for Scenario 2 does not take
this into account (refer to [8]).
The Solution 2 for Scenario 2 is rather costly because not only that it
requires the use of 4 spare bits + up to 12 octets in the DDDS, but this
alternative also requires storage of NR-U SNs at the DU until their respective
PDUs are acknowledged, which may heavily load the memory.
The fundamental trait of fast retransmission is the ability to predict that
the link is bound to fail, which implies that fast retransmission usually
deals with small number of packets. Hence, it is concluded that the benefits
of the solution are marginal since the scenario in question will likely
involve a small number of retransmitted PDUs.
For the reasons explained above, the solution is not recommended for normative
work.
### 5.3.3 Evaluation of Solutions for Scenario 3
The essence of Scenario 3 is transport network (TN) delay compensation.
Accurate compensation requires accurate estimation of DL TN delay. Although DL
TN delay estimation is not an integral part of the Scenario 3, it is worth
mentioning that this delay can be measured in several different ways:
\- A proprietary method
\- One possibility would be to consider using the GTP-U echo to measure the
RTT and divide it by 2 or some other number calculated in a proprietary way.
\- Another option would be to use timestamps and report from the DU the PDU
reception time.
\- Yet another option could be to measure RTT for a poll (i.e. time between
sending a request and receiving a reply).
\- RAN3 recently approved SA5 measurements for F1-U DL based on RTT. The RTT
measurements are based on DDDS, where it is assumed that total internal DU
delay is known and that is subtracted from the RTT. The remainder is divided
by 2 to get the DL estimation. In case the DDDS refers to multiple packets,
the measurement starts from the last packet that pertains to the DDDS [9].
Although a portion of a buffer size at a receiver may be spent to account for
network delay as described in Scenario 3, a solution which disregards DBS
(e.g., Solution 1) is likely to incur interoperability issues. For such
mechanism to operate, there is an underlying assumption that a reliable way to
determine network delay between transmitter and receiver is accurate and
available. However, this cannot be guaranteed. Therefore, situations in which
a transmitter node estimates a delay that is not representative, or which
fluctuates, will make the estimation at the transmitter no longer
deterministic or accurate. Hence, it will result in sending an amount of data
that the receiver cannot handle, leading to buffer overflow, lost packets and
retransmissions. Thus, for a multi-vendor scenario to properly operate, it is
more appropriate for the transmitter has to respect the upper limit determined
by the DBS (as defined in TS 38.425 [5]) and not to exceed it based on an
estimation of the network delay over the interface.
Likewise, by means of implementation it is still possible to have the network
delay accounted for in the DBS value provided by the receiver without changes
to the existing TS 38.425 specification [5].
Compared to Solution 1, Solution 2 can be considered more accurate, since the
corresponding node (e.g., gNB-DU) obtains the channel state information and
knows the transmission rate over the air interface for each TTI (e.g., 1ms),
whereas the node hosting the PDCP entity can only speculate the transmission
rate over the air interface by DDR (which indicates the expected data rate of
the corresponding node in 1s). Moreover, in Solution 2 the corresponding node
can also use the transport network delay for scheduling to meet the QoS
requirements, especially for the TSN [10].
# 6 Support for UE Connection to Several gNB-CU-UPs from Different Security
Domains
## 6.1 Scenario
The support for CU-UPs located in different security domains can be useful for
certain deployment scenarios in which there may be a security concern.
\- An operator may not wish to share the same key with 3rd party application
providers (e.g., applications used in specific slices or CU-UPs). This
security concern exists irrespective of whether the CU-UPs are in the same
location or not. For example, consider Figure 6.1-1, In this example CU-UP1,
and CU-UP2 are located in the same virtualized centralized environment.
However, the level of trust for CU-UP1 and CU-UP2 is not the same. This may be
due to having a 3rd party application provider handling specific slices at the
CU-UP2 or even controlling the whole CU-UP2. Thus, a security breach in CU-UP2
would compromise CU-UP1. In Figure 6.1-2, a similar scenario is depicted, in
which CU-UP1 and CU-UP2 are both still in centralized environments, however,
at different location. The security concern for this scenario is the same.
Thus, to address this security concern, it is beneficial to have CU-UP1 and
CU-UP2 belong to different security domains.
{width="3.2805555555555554in" height="2.1944444444444446in"}
Figure 6.1-1: gNB with gNB-CU-UP centralized
{width="3.2729166666666667in" height="2.188888888888889in"}
Figure 6.1-2: gNB with gNB-CU-UP centralized at different locations
\- The location of certain CU-UP under a gNB may be a security concern.
Consider Figure 6.1-3, in which CU-UP2 is located at a distributed location
and CU-UP1 at a centralized one. If the distributed location is not well
secured, tampering at the site will compromise CU-UP1. This security concern
exists irrespective of whether CU-UP2 is handled by the same operator or a 3rd
party.
{width="3.313888888888889in" height="2.216666666666667in"}
Figure 6.1-3: gNB with gNB-CU-UP centralized and gNB-CU-UP distributed
## 6.2 Possible Solutions
void
## 6.2 Evaluations
void
# 7 Conclusion
RAN3 analysed various scenario and solutions as per the objectives described
in [2] and the conclusions and recommendations are provided below for each of
these objectives respectively.
Enhancements on Flow Control Mechanism:
\- During the discussion, 4 scenarios are proposed among which 3 scenarios are
identified in clause 5.1 and one scenario are precluded. Possible solutions
for the 3 scenarios are provided in clause 5.2. There has been evaluation on
different solutions from several aspects including Overhead of message size,
Radio resources efficiency, relevance of the scenario which is captured in
clause 5.3.
\- RAN3 acknowledged that Solution 5 can be beneficial in at least some
scenarios, e.g. Industrial IoT (packet duplication). This solution is
currently being discussed in the scope of an ongoing Rel-16 Work Item on
Industrial IoT and is considered beneficial in this latter scope. For this
reason, it is recommended to pursue this solution for scenario 1 in that
scope.
\- Further enhancements of Solution 5 targeting Scenario 2 may be specified
during normative phase, provided that gains can be confirmed with a reasonable
complexity. Some companies see the benefits of solutions for Scenario 3, but
there is no consensus on this issue in RAN3 [12].
Support for UE Connection to Several gNB-CU-UPs from Different Security
Domains:
\- The scenario was identified and agreed as useful to be supported. Likewise,
an LS was sent to SA3 requesting feedback on solutions for this scenario.
Therefore, a solution could be specified during normative phase based on the
feedback from SA3 [12].
###### ##
#