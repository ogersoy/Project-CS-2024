# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# Introduction
Mobile telephony devices and voice services continue to develop and evolve and
their associated minimum performance requirements and test methodologies also
need to stay relevant and representative of quality demands.
While many advances were made in Release 11 to the acoustic requirements and
test specifications in TS 26.131 [13] and TS 26.132 [8] many items therein
were left marked \"for further study\" and require a final decision by SA4.
Additionally, there are new acoustic requirements and emerging tests worth
considering in a future release, but that require further study before
incorporation into specifications.
This technical report will, first and foremost, address the remaining items
presently designated as \"for further study\" in TS 26.131 [13] and TS 26.132
[8].
The present document will also examine opportunities for new acoustic tests
and requirements that help us to better characterize the UE acoustic
experience, opportunities to replace existing test methods with others that
are more accurate or more efficient and make specific recommendations for
their inclusion in existing or new specifications.
# 1 Scope
The scope of the present document is to investigate, first and foremost, the
existing items presently designated as \"for further study\" in TS 26.131 [13]
and TS 26.132 [8].
The investigation will additionally identify, examine and evaluate
opportunities for new acoustic tests and requirements that better help
characterize the UE acoustic experience, opportunities to replace existing
test methods with others that are more accurate or more efficient and to make
specific recommendations for their inclusion in existing or new
specifications.
While many advances were made in Release 11 to the acoustic requirements and
test specifications in TS 26.131 [13] and TS 26.132 [8] many items therein
were left marked \"for further study\" and require a final disposition by SA4
including:
\- NB & WB Stability loss, Headset UE (TS 26.131 [13], subclauses 5.6 & 6.6).
\- NB & WB Delay, Wireless Headset (TS 26.131 [13], subclauses 5.12.2.2 &
6.11.2.2).
\- NB & WB Echo control (\"double-talk\") characteristics (TS 26.131 [13],
subclauses 5.13 & 6.12, TS 26.132 [8], subclause 8.11).
\- Handset, Headset, Handheld hands-free, Desktop and vehicle mounted hands-
free are all marked FFS.
\- NB& WB Free-field measurements for vehicle-mounted hands-free (TS 26.132
[8], subclauses 7.2.3 & 8.2.3).
\- NB & WB Idle Channel Noise, Sending/Receiving of test signal (TS 26.132
[8], subclauses 7.3.1, 7.3.2, 8.3.1 & 8.3.2).
Additionally, there are new acoustic requirements and emerging tests that may
be considered in a future release, but require further study before
incorporation to our specifications. It has been anticipated that topics in
this area would include, but would not be limited to, an evaluation of:
\- Time-variant user behaviour.
\- Additional UE usage environments.
\- New or refined test methods for existing requirements.
\- Acceptance of updates (if any) to existing ETSI and ITU-T dependencies.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] Recommendation ITU-T P.862 (02/2001): \"Perceptual evaluation of speech
quality (PESQ): An objective method for end-to-end speech quality assessment
of narrow-band telephone networks and speech codecs\".
[2] Recommendation ITU-T P.800 (08/1996): \"Methods for subjective
determination of transmission quality\".
[3] Recommendation ITU-T P.862.3 (11/2007): \"Application guide for objective
quality measurement based on Recommendations P.862, P.862.1 and P.862.2\".
[4] Recommendation ITU-T P.835 (11/2003): \"Subjective test methodology for
evaluating speech communication systems that include noise suppression
algorithm\".
[5] ETSI TS 103 106 (V1.3.1): \"Speech quality performance in the presence of
background noise: Background noise transmission for mobile terminals -
objective test methods\".
[6] Recommendation ITU-T P.863 (09/2014): \"Perceptual objective listening
quality assessment\".
[7] ETSI ES 202 396-1 (V1.4.1): \"Speech quality performance in the presence
of background noise; Part 1: Background noise simulation technique and
background noise database\".
[8] 3GPP TS 26.132: \"Technical Specification Group Services and System
Aspects; Speech and video telephony terminal acoustic test specification\".
[9] Recommendation ITU-T P.862.1 (11/2003): \"Mapping function for
transforming P.862 raw result scores to MOS-LQO\".
[10] Recommendation ITU-T P.862.2 (11/2007): \"Wideband extensions to
Recommendation P.862 for the assessment of wideband telephone networks and
speech codecs\".
[11] ETSI EG 202 396-3 (V1.5.1): \"Speech quality performance in the presence
of background noise; Part 3: Background noise transmission - Objective test
methods\".
[12] Recommendation ITU-T P.64, Annex E (11/2007): \"Determination of
sensitivity/frequency characteristics of local telephone systems\".
[13] 3GPP TS 26.131: \"Technical Specification Group Services and System
Aspects; Terminal acoustic characteristics for telephony\".
[14] ETSI TS 103 224 (V1.3.1): \"Speech and multimedia Transmission Quality
(STQ); A sound field reproduction method for terminal testing including a
background noise database\".
[15] Recommendation ITU-T P.58: \"Head and Torso simulator for
Telephonometry\".
[16] Recommendation ITU-T P.502 (05/2000): \"Objective test methods for speech
communication systems using complex test signals\".
[17] Recommendation ITU-T P.863.1 (09/2014): \"Application guide for
Recommendation ITU-T P.863\".
[18] Recommendation ITU-T P.1401 (07/2012): \"Methods, metrics and procedures
for statistical evaluation, qualification and comparison of objective quality
prediction models\".
[19] Recommendation ITU-T P. 79 (11/2007): \"Calculation of loudness ratings
for telephone sets\".
[20] ETSI TS 103 281 (V1.1.1): \"Speech quality in the presence of background
noise: objective test methods for SWB and FB terminals\".
[21] Recommendation ITU-T P.501: \"Test signals for use in telephonometry\".
[22] ETSI TS 103 557 (V1.1.1): \"Methods for reproducing reverberation for
communication device measurements\".
[23] Recommendation ITU-T P.862 (2001) Corrigendum 1 (10/2017).
_[24]_ Recommendation _ITU-T P.831:_ \"**Subjective performance evaluation of
network echo cancellers\"** (12/1998)**.**
# 3 Definitions and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
TR 21.905 [1] and the following apply.\ A term defined in the present document
takes precedence over the definition of the same term, if any, in TR 21.905
[1].
## 3.2 Abbreviations
For the purposes of the present document, the abbreviations given in TR 21.905
[1] and the following apply.\ An abbreviation defined in the present document
takes precedence over the definition of the same abbreviation, if any, in TR
21.905 [1].
HHS Hand-held speakerphone (= Hand-held hands-free)
# 4 Release 11 \"For Further Study\" Items
## 4.1 Stability loss, Headset UE
Void
## 4.2 UE Delay, NB & WB Wireless Headset
Void
## 4.3 NB & WB Echo control (\"double-talk\") characteristics
### 4.3.1 Results from a study on NB Echo control (\"double-talk\")
characteristics using P.835 methodology
#### 4.3.1.1 Background
In Release 11 of TS 26.132 [8], new methods for evaluation of echo control
characteristics were introduced in Clauses 7.11 and 8.11. However,
corresponding requirements were not defined in TS 26.131 [13].
A subjective listening test based on methods from Recommendation ITU-T P.835
[4] was conducted in order to provide some data for purposes of investigating
possible requirements.
Instead of a conversational test, or talking and listening test, the present
document provides results from listening only test, so participants did not
experience echo while talking, only while passively listening. Below are
presented results of the subjective evaluation of real speech double talk
test, for 12 devices, in both handset and handheld speakerphone for narrow
band.
#### 4.3.1.2 Test Method & Results
##### 4.3.1.2.1 Methods
The categories defined in Clauses 7.11, Figure 17b5, (copied below in Figure 1
for convenience) and Table 1 (Table 2c, and 8.11, Figure 19b5, and Table 2g),
are described in perceptually-relevant terms.
Figure 1: Classification of echo canceller performance
Table 1: Categories for echo canceller performance classification
* * *
Category Level difference (ΔL) Duration (D) Description **A1** -4 dB ≤ ΔL \ a) Position I: Handset | > b) Position II: Alternative | | > position for flat handsets | > \'Vertical\' position (see | | > (see text) | > text) | +----------------------------------+----------------------------------+ | Figure 21: Mounting of handset | | +----------------------------------+----------------------------------+
Figure 21a shows the mockup phone with a handset positioning for flat handsets
(0°, 0°, 5°) denoting the positioning delta from the standard HATS position
for (A, B, C) in ITU-T P.64 [12].
Position I:
Table 7a
* * *
MECRP (delta from actual ECRP)  
Axis Delta [mm] y~e~ 0 z~e~ 0
* * *
Table 7b
* * *
Angle settings  
Angle Delta from standard angle [°] A 0 B 0 C 5
* * *
This mounting is named \"norm\" in the following clauses.
Figure 21b shows an alternative version of mounting. The handheld positioner
was set to the delta angles (A, B, C) = (45°, 0°, 5°) . Additionally, a larger
distance between mouth and DUT was simulated; this was realized by shifting
the device 1 cm higher than the default mounting. This shift takes into
account that the dimensions of HATS as defined in [15] are felt to be too
small compared to the head size of many people today and such the distance
from mouth to microphone and the cheek shadow effect might not be properly
taken into account in tests. To some extent this shadowing effect can be
compensated in sending by shifting the DUT. In order to provide a better
separation to the existing positions, this new alternative position is named
\"vertical\" in the following clauses.
Position II:
Table 7c
* * *
MECRP (delta from actual ECRP)  
Axis Delta [mm] y~e~ 0 z~e~ 10
* * *
Table 7d
* * *
Angle settings  
Angle Delta from standard angle [°] A 45 B 0 C 5
* * *
For both mountings, an application force of 8N was used.
#### 5.3.2.2 Background Noise Systems
##### 5.3.2.2.0 General
For the generation of background noise during the measurements two different
simulation approaches were used: the new simulation technique described in
ETSI TS 103 224 [14] and the present industry standard described in ETSI ES
202 396-1 [7]. Both systems were set up and equalized in a small, mostly non-
reverberant room (RT60 \ 2 kHz). Device D at least tries to compensate the absolute
level difference, the lower frequency content almost matches in both
positions.
* * *
{width="3.1493055555555554in" height="1.9909722222222221in"}
{width="3.1493055555555554in" height="1.9909722222222221in"}
{width="3.1493055555555554in" height="1.9909722222222221in"}
{width="3.1493055555555554in" height="1.9909722222222221in"}
* * *
Figure 24: Frequency Responses for different devices and positioning
**Table 8** shows some more typical metrics for measurements under silence
conditions for each device which can describe these differences by single
values:
\- Sending Loudness Rating (acc. to Recommendation ITU-T P. 79 [19])
\- TOSQA 2001 (WB mode, electrical recording)
\- POLQA according to Recommendation ITU-T P.863 [6], Version 2.4 (fixed
active speech level of 73 dB SPL)
The absolute values are given in the column \"norm\", the difference to the
vertical position is given as \"vert. - norm.\".
Table 8: Metrics for sending direction per device
* * *
                                      DUT A   DUT B         DUT C   DUT D                                       
                                      norm.   vert.-norm.   norm.   vert.-norm.   norm.   vert.-norm.   norm.   vert.-norm.
Sending Loudness Rating [dB] 10,15 +4,43 7,44 +3,31 7,36 +4,62 8,64 +3,14
TOSQA2001 (WB) [MOS] 3,61 -0,12 3,61 -0,37 3,74 -0,22 3,37 -0,23 P.863 (POLQA)
[MOS] 3,90 -0,23 3,89 -0,07 3,75 -0,24 3,79 +0,06
* * *
All loudness ratings increase by at least 3,1 dB (up to 4.6), which is mainly
caused by the modified frequency responses shown in Figure 24. The large
differences in the spectral domain are not leading to huge differences in the
speech quality measures TOSQA and POLQA. In fact, all MOS scores decrease for
POLQA as well as for TOSQA when comparing normal vs. vertical position. The
maximum difference for POLQA is -0,24 for Device C, whereas the largest
difference for TOSQA is found for device B (-0,37). Please note that the
effect of decreased loudness is not captured by TOSQA and POLQA, because a
constant listening level of 73 dB (A) SPL was set.
#### 5.3.3.2 Measurements with Ambient Noise
The following tables provide the results according to ETSI TS 103 106 [5] for
each device and each positioning. Each MOS value is determined as the average
over 16 American English test sentences taken from annex C of [5]. Note that
MOS values as well as the calculated differences are round to one decimal
place.
Table 9: TS 103 106 S-/N-/G-MOS values for device A
{width="4.945138888888889in" height="2.9319444444444445in"}
Table 10: TS 103 106 S-/N-/G-MOS values for device B
{width="4.945138888888889in" height="2.9319444444444445in"}
Table 11: TS 103 106 S-/N-/G-MOS values for device C
{width="4.945138888888889in" height="2.9319444444444445in"}
Table 12: TS 103 106 S-/N-/G-MOS values for device D
{width="4.945138888888889in" height="2.9319444444444445in"}
The decrease of S-/N-/G-MOS for the vertical position is observable for all
devices. The minimum and maximum differences between vertical and normal
position for each category is shown in Table **13**. In overall, scores
decreases at least by 0,1 and up to 1,0 MOS for S-, N- and G-MOS.
When using the two different background noise simulation systems very similar
scores are obtained for S-, N- and G‑MOS in the normal position with a
tendency to slightly bigger differences in the vertical position. An exception
here is device D. This device shows significant differences between the
playback systems, for both positions. N-MOS scores increase up to 1,0 for the
background noise simulation according to ETSI TS 103 224 [14]. Since the sound
field reproduction system according to ETSI TS 103 224 [14] provides an
accurate sound field reproduction at the location of the hand-held terminal
(in contrast to an almost diffuse noise field generated when using ETSI ES 202
396-1 [7] which does not reproduce the physical characteristics of the real
sound field at the location of the terminal) it can be assumed that these
results might represent more accurately the \"real life\" behaviour of this
device.
Table 13: Minimum/maximum difference
* * *
          Min. Diff.   Device   BGN           Max. Diff   Device   BGN
G-MOS -0,3 A Car -0,9 B Road N-MOS -0,2 A Train Stat. -0,9 D Cafeteria S-MOS
-0,1 C Car -1,0 B Train Stat.
* * *
### 5.3.4 Summary
The study shows that degradations of device performance can be expected when
using different positioning as used in the study. The degradations depend on
device implementations. Different behaviour can be observed for some devices
with different background noise simulations.
## 5.4 Results from a study on objective measures with noise suppression and
background noise
### 5.4.1 Comparison of P.862 to subjective results for noise suppression
Recommendation ITU-T P.862, _Perceptual Evaluation of Speech Quality_ (PESQ)
[1], was published in 2001 to predict subjective scores as obtained in
Recommendation ITU-T P.800 Absolute Category Rating (ACR) tests of Overall
Speech Quality [2]. P.862 [1] is a very useful tool for assessing the speech
quality of devices in many situations; however it has significant limitations
for assessing speech quality when noise suppression is used, primarily because
the model was developed and trained before modern UE noise suppression
evolved. Since almost all modern UE\'s contain some form of noise suppression
algorithm, P.862 [1] should not be used for testing UE\'s in background noise
as it produces misleading results as demonstrated in the following clauses.
The inadequacy of P.862 [1] for devices incorporating noise suppression is
well documented. ITU-T Recommendation P.862.3 [3], _Application Guide for
Objective Quality Measurement Based on Recommendations ITU-T P.862 [1],
P.862.1 [9], and P.862.2 [10]_ provides unambiguous guidance regarding usage
with noise suppression as can be seen in the following excerpt [p3-4]:
{width="6.502777777777778in"
height="1.4916666666666667in"}{width="6.504166666666666in"
height="0.40069444444444446in"}
Figure 24a: See Figure 1 from ITU-T P.862.3 [3]
ITU-T Recommendation P.835 is used for subjective evaluation of systems with
noise suppression [4]. P.835 [4] evaluations use three rating scales: SIG
assessing the amount of speech distortion; BAK assessing the degree of
intrusiveness of any background noise; OVRL providing an overall speech
quality assessment. ETSI TS 103 106 [5] was designed specifically to predict
the three ratings from a P.835 [4] test and was explicitly trained on noise
reduction. In contrast, both P.862 [1] and P.863 [6] were designed to predict
results from P.800 [2] listening tests, which only have one rating scale,
overall speech quality, MOS-LQS. In fact, P.835 [4] was developed partly in
reaction to a high degree of uncertainty observed in P.800 [2] tests on
conditions with noise reduction. Studies directly comparing P.800 [2] MOS-LQS
scores to P.835 [4] OVRL scores are predominantly proprietary, but experience
has shown that there is generally good correlation between these two metrics.
An objective quality predictor is normally trained on a wide variety of
conditions, while a single subjective experiment includes a more limited set
of conditions which potentially changes the experimental context. Therefore
results from a specific subjective experiment may deviate from objective
predictions, hence the results below should be considered as case studies, not
as exhaustive and definitive results. However, these case studies can be
considered as indicative of the nature of issues that could arise when
predictors are applied outside their scope.
### 5.4.2 Experiment 1 - NB P.835 versus P.862.1
#### 5.4.2.1 Setup
In Experiment 1, a recording of American English speech consisting of four
sentences from each of two male and two female native talkers, as used in ETSI
TS 103 106 [5], was reproduced through an equalized HATS artificial at 92,3 dB
SPL active speech level at the MRP of HATS. The background noise generation
method described in ETSI ES 202 396‑1 [7] was used to reproduce eight noises
described in Table 2d of Clause 7.12 of 3GPP TS 26.132 [8]. Six handsets were
used, denoted as A, B, C, D, E, and F in the following plots. Each device was
mounted on the HATS in standard position and recordings made of clean speech,
and speech mixed with the eight noises described above, at the output of a
UMTS base-station simulator with AMR speech encoding at 12.2 kbit/s.
Recommendation ITU-T P.835 [4] is the recommended methodology for assessing
the listening quality of systems incorporating noise suppression. A group of
32 naïve listeners, all native speakers of American English, using the P.835
[4] methodology, rated all sentences in all conditions in a partially balanced
randomized blocks design, resulting in 128 votes per condition. Results were
used as training data for ETSI TS 103 106 [5] with further details in Clause
7.2.1 of that document.
For computing metrics, all recordings were taken at 48 kHz sample rate. For
P.862.1 [9], the clean source file was filtered to NB for use as reference and
the scores were computed separately on sentence pairs then averaged to obtain
per-condition values. For ETSI TS 103 106 [5], the NB operational mode was
selected and scores were computed on individual sentences and then averaged to
obtain per-condition values.
#### 5.4.2.2 Results
The results of this experiment are shown below, for four noise types.
{width="6.5in" height="3.886111111111111in"}
Figure 24b: Results of Experiment 1: comparing scores from P.835 [4] and
P.862.1 [9] in 4 noise types
It can be seen from these graphs that P.862.1 [9] significantly underestimates
the performance of the various handsets when compared to the results obtained
from the P.835 [4] test with human listeners. In addition the crossing of the
lines shows that the results obtained using P.862.1 [9] do not preserve the
rank order that is obtained with human listeners. For example handset D is the
top or almost top performing handset for all noise types when human listeners
are used, with a score of fair to good, however when tested with P.862.1 [9],
it is the 4^th^ or 5^th^ ranking handset in 3 of the noise types with a score
of only poor.
Figure 25 shows a scatter plot of the subjective P.835 [4] OVRL ratings
against objective scores. The red-coloured symbols are for P.862.1 [9] while
the blue-coloured symbols are for the GMOS output from the P.835 [4] predictor
of TS 103 106 [5]. As noted above, the range of the P.862.1 [9] predictions is
compressed relative to the range of subjective ratings. For example,
subjective ratings in the range of 3.5, or mid-way between 3 \"Fair\" and 4
\"Good\" are predicted by P.862.1 [9] in the region of 2 \"Poor\". In
contrast, for GMOS, the predicted scores span the full range of the subjective
ratings, and fall very close to the diagonal line of slope 1.
{width="5.998611111111111in" height="4.7625in"}
Figure 25: Results of Experiment 1 - correlation of P.835 [4] with P.862.1
[9]\ and ETSI TS 103 106 [5] (NB). Absolute maximum error for P.862.1 [9]\ is
1.630, absolute maximum error for ETSI TS 103 106 [5] is 0,880.\ Spearman
rank-order correlation, accounting for 95 % confidence interval,\ for P.862.1
[9] is 0.914 and for ETSI TS 103 106 [5] is 0,984
### 5.4.3 Experiment 2 - Problems with tuning for P.862.1
#### 5.4.3.1 Setup
In Experiment 2, a recording of American English speech consisting of four
sentences from each of two male and two female native talkers, as used in ETSI
TS 103 106 [5], was reproduced through an equalized artificial mouth. The
active speech level was -1.7 dBPa at the MRP of HATS. The background noise
generation method described in ETSI ES 202 396-1 [7] was used to reproduce
eight noises described in Table 2d of Clause 7.12 of 3GPP TS 26.132 [8]. In
this case, a single handset was used, but with noise suppression parameters
adjusted in two ways. The tuning labelled \"Tuned for P.862.1\" was defined so
as to provide high values of Recommendation ITU-T P.862.1 [9]. The tuning
labelled \"Alternative Tuning\" was defined in general accordance with the
requirements of the marketplace, based on network operator requirements. The
device was mounted on the HATS in standard position, and recordings made of
clean speech, and speech mixed with the eight noises described above, at the
output of a UMTS base-station simulator with AMR speech encoding at 12.2
kbit/s.
A group of 32 naïve listeners, all native speakers of American English, using
the Recommendation ITU-T P.835 [4] methodology, rated all sentences in all
conditions in a partially balanced randomized blocks design, resulting in 128
votes per condition.
#### 5.4.3.2 Results
{width="3.884027777777778in" height="2.5215277777777776in"}
Figure 26: Results of Experiment 2 - P.835 [4] Overall Score
{width="3.9159722222222224in" height="2.786111111111111in"}
Figure 27: Results of Experiment 2 - P.835 [4] Signal Score
{width="3.963888888888889in" height="2.5215277777777776in"}
Figure 28: Results of Experiment 2 - P.835 [4] Background Score
The results for the overall performance in the P.835 [4] listening test of
figure 26 show that tuning an algorithm to get the best P.862.1 [9] score does
not produce an optimum result. The version of the algorithm tuned for P.862.1
[9] significantly underperforms in 6 of the 9 noise types. The graphs in
Figures 27 and 28 break down the performance in terms of the signal and
background noise scores. These show that while tuning an algorithm to maximize
the P.862.1 [9] score slightly improves the perceived quality of the speech
signal, Figure 27, it significantly degrades the perception of the background
noise signal, figure 28, leading to the degraded overall score as shown Figure
26.
### 5.4.4 Experiment 3: WB P.835 v P.862.2, P.863 and TS 103 106
#### 5.4.4.1 Setup
The method used was very similar to the one described for narrow-band in
Clause 5.4.2.1. However, the UMTS base-station simulator was set to use speech
encoding with AMR-WB at 12.65 kbit/s.
For computing metrics, all recordings were taken at 48 kHz sample rate. For
P.862.2 [10] the clean source file was filtered to WB for use as reference and
the scores were computed separately on sentence pairs then averaged to obtain
per-condition values. For P.863 [6], version 2.4 was used; the clean source
was filtered to SWB for use as reference and the scores were computed using
the SWB mode, separately on sentence pairs then averaged to obtain per-
condition values. For ETSI TS 103 106 [5], scores were computed on individual
sentences and then averaged to obtain per-condition values.
#### 5.4.4.2 WB Correlation Results
Figure 29 shows a scatter plot of the subjective P.835 OVRL [4] ratings
against objective scores. The red-coloured (+) symbols are for P.862.2 (MOS-
LQOw) [10], while the blue-coloured (x) symbols are for the GMOS output from
the P.835 [4] predictor of [5] and the green-coloured (o) symbols are for
P.863 Version 2.4 [6].
As for narrowband, the range of the P.862.2 [10] predictions is compressed
relative to the range of the subjective ratings. Subjective ratings of about
3.5, or midway between \"Fair\" and \"Good\" are scored by P.862.2 [10] at
about 1.7, or below \"Poor\", and the RMSE is 1,659.
For P.863 [6] (MOS-LQOs), there is some compression and offset of the
predictions relative to the subjective ratings, but the compression is not as
severe as for P.862.2 [10]. Subjective ratings of about 3.5 are predicted as
about 2.0 by P.863, and the RMSE is 1.108.
The ETSI TS 103 106-WB [5] scores generally span the same range as the
subjective ratings, and fall close to the reference line, without the
compression observed in the P.862.2 [10] predictions. The RMSE is 0.196;
however for some cases, particularly at lower scores, the error can again be
large. These larger errors are not unexpected, since during the training phase
of ETSI TS 103 106 [5] there was relatively little data available with low
scores.
{width="6.406944444444444in" height="5.075in"}
Figure 29: Correlation of P.835 Overall with P.862.2 [10] (MOS-LQOw), ETSI TS
103 106 [5] (WB)\ GMOSw and P.863 [6] (MOS-LQOs). Maximum error of P.862.2
[10] is 2,192,\ of P.863 [6] is 1,459, and of ETSI TS 103 106 [5] is 0,424.\
Spearman rank-order correlation, accounting for 95% confidence interval,\ for
P.862.2 [10] is 0,890, for P.863 [6] is 0,897, and for ETSI TS 103 106 [5] is
0,975
#### 5.4.4.3 WB Rank Order Results
The graphs in figure 30 compare the scores of the various measures for each of
the six phones (A-F), in each noise type. Figure 31 then shows the number of
absolute rank order errors for each metric in each noise type when compared to
the results from the listening test. These results do not take account of
overlapping confidence intervals; hence the errors may be exaggerated,
especially for the clean condition where the listening tests results were very
similar.
For P.862.2 [10] the rank order is not preserved, again there are frequent
shifts of one and two positions, as well as shifts of three positions in
cafeteria and car noise. For P.863 [6] rank order errors are observed, but not
as many as for P.862.2 [10]. There are still frequent single rank switches,
but fewer two-rank switches, although there are larger errors observed in the
clean condition where the confidence intervals overlap. TS 103 106 [5] has the
best performance; however single rank switches are still common and occasional
two and three-rank switches also occur in clean, cafeteria and pub noise.
{width="6.504166666666666in" height="7.711805555555555in"}
Figure 30: Scores per device and noise type for P.835 Overall [4], P.862.
2[10] (MOS-LQOw),\ ETSI TS 103 106 [5] (WB) GMOSw and P.863 [6] (WB) (MOS-
LQOw)
{width="6.905555555555556in" height="5.019444444444445in"}
Figure 31: Rank Order Errors for each Objective Measure in WB
### 5.4.5 Experiment 4 SWB P.835 v P.862.2, P.863 and TS 103 106
#### 5.4.5.1 Setup
The method used was similar to the one described in Clause 5.4.2.1. However,
the following differences should be noted. As commercial super-wideband
terminals are not generally available, a mock- up of a handset was used. The
mock-up was the size and shape of a typical mobile handset, and was equipped
with several microphones, as in some current commercially available wideband
terminals. The same speech and background noise generation as for NB and WB
was used, but recordings were made from the microphones on the mock-up. The
signals were processed with offline processing to produce the noise-reduced
signals. No speech encoding was used.
For computing metrics, all recordings were taken at 48 kHz sample rate. For
P.862.2 [10], the source file was filtered to WB and the scores were computed
separately on sentence pairs then averaged to obtain per-condition values. For
P.863 [6] version 2.4 was used; the source was filtered to SWB and the scores
were computed separately on sentence pairs then averaged to obtain per-
condition values. For ETSI TS 103 106 [5], the source file was used as SWB and
scores were computed on individual sentences using the WB mode of the tool,
and then averaged to obtain per-condition values.
#### 5.4.5.2 SWB Correlation Results
Figure 32 shows a scatter plot of the subjective P.835 [4] OVRL ratings
against objective scores. The red-coloured (+) symbols are for P.862.2 (MOS-
LQOw) [10], while the blue-coloured (x) symbols are for the GMOS output from
the P.835 predictor of [5] and the green-coloured (o) symbols are for P.863
(ITU-T P.863) V2.4 [6].
As expected the P.862.2 [10] results show a poor correlation with the SWB
listening scores with an RMSE of 1.458. SWB P.863 [6] scores are more
consistent and have an RMSE of 0.815, however they show a similar compression
of the range of scores as was observed for NB and WB. Also as expected, the
ETSI TS 103 106-WB [5] scores are less well correlated in SWB than in WB with
an RMSE of 0.345.
{width="5.073611111111111in" height="3.7270833333333333in"}
Figure 32: Correlation of P.835 Overall with P.862.2 [10](MOS-LQOw),\ ETSI TS
103 106 [5] (WB) GMOSw and P.863 [6] (SWB) (MOS-LQOs).\ Maximum absolute error
for P.862.2 [10] is 2,463, for P.863 [6] is 1,326,\ and for ETSI TS 103 106
[5] is 0,842. Spearman rank-order correlation, accounting\ for 95 % confidence
interval, for P.862.2 [10] is 0,755, for P.863 [6] is 0,855,\ and for ETSI TS
103 106 [5] is 0,956
#### 5.4.5.3 SWB Rank Order Results
The graphs in figure 33 compare the scores of the various measures for the
mock-up phones with various levels of noise suppression (0-15), in each noise
type. Figure 34 then shows the number of absolute rank order errors for each
metric in each noise type when compared to the results from the listening
test.
None of the objective measures preserve the rank order of the listening tests
for SWB. All three measures have frequent shifts of up to three ranks and
occasional larger shifts. P.863 [6] also commonly shifts by four positions.
It can also be seen from the graphs in figure 33 that if these scores were
used to try and tune the noise suppression parameter in this algorithm,
different results would be obtained depending on which objective measure was
used, and in addition none of the measures would reliably select the same
optimization as that determined by the human listeners.
{width="6.670138888888889in" height="7.992361111111111in"}
Figure 33: Scores per device and noise type for P.835 [4] Overall, P.862.2
[10] (MOS-LQOw),\ ETSI TS 103 106 [5] (WB) GMOSw and P.863 [6] (SWB) (MOS-
LQOs)
{width="6.677083333333333in" height="3.595138888888889in"}
Figure 34: Rank Order Errors for each Objective Measure in SWB
### 5.4.6 Conclusions
The use of P.862.1 [9] and P.862.2 [10] for assessing the performance of
handsets in noise should be avoided. Almost all modern UEs now provide noise
suppression as part of their default operation and it is shown that P.862.1
[9] and P.862.2 [10] produce misleading results when used in conjunction with
noise suppression algorithms. Using P.862.1 [9] and P.862.2 [10] to compare
UE\'s is unreliable since a comparison of the results with actual listening
tests shows a different rank order between the two tests, i.e. the best
P.862.1 [9] and P.862.2 [10] score does not always produce the best overall
score from a listening test. The P.862.1 [9] and P.862.2 [10] scores (MOS_LQO)
also substantially underpredict the P.835 [4] OVRL scores obtained from the
listening test. In addition, in Annex B of ETSI EG 202 396‑3 [11], results for
P.835 [4] listening tests are compared to predictions from P.862.1 [9] and
P.862.2 [10] and are shown to not correlate well with the subjective results.
Finally, the use of P.862.1 [9] and P.862.2 [10] for comparing handsets may
steer manufacturers to tune their algorithms to maximize the P.862.1 [9] and
P.862.2 [10] score. For the reasons exposed, such tuning may actually degrade
the speech quality as perceived by human listeners.
For WB it is not too surprising that the objective tools that are intended to
predict the perceived quality of telephone speech with noise reduction (e.g.
ETSI TS 103 106 [5]) perform that task better than tools which were not
initially designed to do so. However there is still room for improvement, as
even ETSI TS 103 106 [5] does not consistently preserve the rank order, which
can make comparative evaluations unreliable.
For SWB none of the three predictors performed particularly well. Again this
is to be expected since P.862.2 [10] and ETSI TS 103 106 [5] were not designed
to be used on SWB speech, and P.863 [6] was not designed for use with modern
terminal noise suppression algorithms.
Further work has since been done to develop more effective objective measures
especially for wider bandwidths ETSI TS 103 281 [20]. It is particularly
important to ensure that maximum error and rank order are taken into account
as well as just RMSE, which would enable more reliable comparative evaluations
of solutions across a range of operation scenarios including different
background noises and noise suppression technologies.
## 5.5 Validation results for combination of model A and B according to ETSI
TS 103 281
### 5.5.1 Introduction
In ETSI TS 103 281 [20], two models for predicting results of ITU-T P.835 [4]
evaluations of the sending speech quality in noise are described. Due to a
desire by 3GPP SA4 to reference a single model in 3GPP TS 26.132 [8], a model
consisting of the combination of the predictions from Model A and Model B of
[20] was proposed in [8].
Below are described the combination of the models and an analysis of the
performance of the combined model on three validation databases of [20] based
on the input from ETSI TC STQ.
### 5.5.2 Description of combination of model predictions
As defined in [8], the predictions from Model A and Model B of [20] are
combined as follows:
S-MOS-LQO~fb~ = (S-MOS-LQO~fb_modelA~ + S-MOS-LQO~fb_modelB~)/2
N-MOS-LQO~fb~ = (1.438*N-MOS-LQO~fb_modelA~ -- 1.959 + N-MOS-LQO~fb_modelB~)/2
G-MOS-LQO~fb~ = (G-MOS-LQO~fb_modelA~ + G-MOS-LQO~fb_modelB~)/2
Except for a linear post-mapping of N-MOS from Model A, the combination is
simply the average of the corresponding predictions from each Model. The
linear post-mapping of N-MOS from Model A was derived from validation
databases 3 (DES-25) and 4 (DES-26). Figure 35 shows a scatter plot of
unmapped model N-MOS predictions and subjective BAK ratings for both databases
separately. In addition, linear regression lines are also shown separately for
each database.
{width="4.698611111111111in" height="4.021527777777778in"}
Figure 35: Scatter plot of N-MOS from Model A versus subjective BAK ratings
for validation databases DES-25 and DES-26
Note that the scatter plots for both databases are nearly the same, as are the
linear regression lines. From this, it was proposed to combine the results
from both databases and compute a single regression line, as shown in Figure
36.
{width="4.731944444444444in" height="4.054166666666666in"}
Figure 36: Scatter plot of N-MOS from Model A versus subjective BAK ratings
for combined validation databases DES-25 and DES-26
The regression equation obtained from the combined databases was then used as
post-mapping for the N-MOS predictions from Model A. Using the combined model,
comparisons to validation databases 3, 4, and 5 are shown in the following
clauses.
### 5.5.3 Validation database 3 (DES-25): Results for combined model
Results are shown as scatter plots, comparing instrumental predicted ratings
to subjective ratings. Results from the combined model on validation database
3 for each of the three ratings, SIG, BAK, and OVRL, are shown in Figure 37.
For each rating (rows), two scatter plots are shown, one before a monotonic
mapping is applied (right column) and one after a monotonic 3^rd^ order
mapping is applied (left column).
{width="5.8590277777777775in" height="8.709027777777777in"}
Figure 37: Scatter plots from combined model for validation database 3
(DES-25)
The rmse* and maximum absolute error* (maxabs*) after mapping are shown on all
figures, with and orange-coloured symbol indicating the condition with the
largest overall maximum absolute error. The mapping polynomial is shown in the
upper left corner of each panel. The dashed green lines show error of ± 0.5
MOS. The error bars indicate the 95% confidence interval before mapping (left
column) and after mapping (right column).
Additional performance metrics, including Pearson\'s ρ correlation
coefficient, Spearman\'s ρ rank order correlation, and Kendall\'s τ are shown
in Table 14.
Table 14: Performance metrics for combined model on validation database 3
(DES-25)
* * *
Dimension Metric Raw Mapped d* Mapped & d* SIG Rmse 0,299 0,256 0,194 0,142
Max Abs Error 0,572 0,450 0,452 0,331 Pearson\'s ρ 0,941 0,942 0,972 0,980
Spearman\'s rank order ρ 0,902 0,902 0,942 0,978 Kendall\'s τ 0,740 0,740
0,821 0,869 BAK Rmse 0,210 0,207 0,111 0,095 Max Abs Error 0,504 0,377 0,333
0,238 Pearson\'s ρ 0,975 0,974 0,992 0,995 Spearman\'s rank order ρ 0,968
0,968 0,987 0,988 Kendall\'s τ 0,854 0,854 0,926 0,932 OVRL Rmse 0,195 0,168
0,094 0,079 Max Abs Error 0,480 0,359 0,325 0,246 Pearson\'s ρ 0,972 0,972
0,991 0,993 Spearman\'s rank order ρ 0,965 0,965 0,989 0,993 Kendall\'s τ
0,854 0,854 0,940 0,952
* * *
### 5.5.4 Validation database 4 (DES-26): Results for combined model
Results are shown as scatter plots, comparing instrumental predicted ratings
to subjective ratings. Results from the combined model on validation database
4 for each of the three ratings, SIG, BAK, and OVRL, are shown in Figure 38.
As in the previous figure, for each rating (rows), two scatter plots are
shown, one before a monotonic mapping is applied (right column) and one after
a monotonic mapping is applied (left column).
{width="5.667361111111111in" height="8.391666666666667in"}
Figure 38: Scatter plots from combined model for validation database 4
(DES-26)
The rmse* and maximum absolute error* (maxabs*) after mapping are shown on all
figures, with and orange-coloured symbol indicating the condition with the
largest overall maximum absolute error. The mapping polynomial is shown in the
upper left corner of each panel. The dashed green lines show error of ± 0.5
MOS. The error bars indicate the 95% confidence interval before mapping (left
column) and after mapping (right column).
Additional performance metrics, including Pearson\'s ρ correlation
coefficient, Spearman\'s ρ rank order correlation, and Kendall\'s τ are shown
in Table 15.
Table 15: Performance metrics for combined model on validation database 4
* * *
Dimension Metric Raw Mapped d* Mapped & d* SIG Rmse 0,345 0,276 0,224 0,144
Max Abs Error 0,858 0,488 0,669 0,345 Pearson\'s ρ 0,938 0,945 0,957 0,976
Spearman\'s rank order ρ 0,945 0,945 0,955 0,962 Kendall\'s τ 0,758 0,758
0,783 0,881 BAK Rmse 0,139 0,147 0,069 0,064 Max Abs Error 0,434 0,347 0,305
0,218 Pearson\'s ρ 0,985 0,985 0,996 0,997 Spearman\'s rank order ρ 0,988
0,988 0,998 0,997 Kendall\'s τ 0,917 0,917 0,982 0,973 OVRL Rmse 0,183 0,188
0,102 0,080 Max Abs Error 0,538 0,363 0,405 0,232 Pearson\'s ρ 0,967 0,963
0,991 0,993 Spearman\'s rank order ρ 0,968 0,968 0,992 0,989 Kendall\'s τ
0,863 0,863 0,954 0,932
* * *
### 5.5.5 Validation database 5 (DES-27): Results for combined model
Results are shown as scatter plots, comparing instrumental predicted ratings
to subjective ratings. Results from the combined model on validation database
5 for each of the three ratings, SIG, BAK, and OVRL, are shown in Figure 39.
As in the previous figures, for each rating (rows), two scatter plots are
shown, one before a monotonic mapping is applied (right column) and one after
a monotonic mapping is applied (left column).
{width="5.879166666666666in" height="8.577777777777778in"}
Figure 39: Scatter plots from combined model for validation database 5
(DES-26)
The rmse* and maximum absolute error* (maxabs*) after mapping are shown on all
figures, with and orange-coloured symbol indicating the condition with the
largest overall maximum absolute error. The mapping polynomial is shown in the
upper left corner of each panel. The dashed green lines show error of ± 0.5
MOS. The error bars indicate the 95% confidence interval before mapping (left
column) and after mapping (right column).
Additional performance metrics, including Pearson\'s ρ correlation
coefficient, Spearman\'s ρ rank order correlation, and Kendall\'s τ are shown
in Table 16.
Table 16: Performance metrics for combined model on validation database 5
* * *
Dimension Metric Raw Mapped d* Mapped & d* SIG Rmse 0,870 0,351 0,737 0,214
Max Abs Error 1,383 0,648 1,260 0,453 Pearson\'s ρ 0,849 0,888 0,867 0,960
Spearman\'s rank order ρ 0,849 0,849 0,855 0,955 Kendall\'s τ 0,672 0,672
0,681 0,835 BAK Rmse 0,358 0,242 0,248 0,130 Max Abs Error 0,713 0,388 0,616
0,244 Pearson\'s ρ 0,971 0,971 0,984 0,992 Spearman\'s rank order ρ 0,962
0,962 0,974 0,989 Kendall\'s τ 0,857 0,857 0,890 0,940 OVRL Rmse 0,343 0,217
0,233 0,116 Max Abs Error 0,902 0,421 0,760 0,305 Pearson\'s ρ 0,965 0,970
0,972 0,991 Spearman\'s rank order ρ 0,975 0,975 0,973 0,994 Kendall\'s τ
0,884 0,884 0,878 0,950
* * *
### 5.5.6 Conclusions
The provided data indicated that the combined model A and B performs better
than the individual models on their own. The results support the use of the
combined model in TS 26.132 [8].
# 6 Conclusions
The present document presented several further analyses and studies related to
the terminal testing specification TS 26.132 [8].
A large auditory evaluation was conducted to investigate the relation between
human perception and echo control characteristics (\"double talk performance"
according to clauses 7.11 and 8.11 of [8]). However, even though extensive
analyses on instrumental and auditory data were carried out, adequate and
reasonable requirements for TS 26.131 [13] could still not be derived for this
measurement method.
Clause 5 of the present document presented several studies regarding new
and/or advanced acoustic testing of terminals.
The usage of alternative and more challenging handset positions as well as the
background noise simulation system in ETSI TS 103 224 [14] were evaluated for
handset devices. Results on both methods are presented in this document.
Another study investigated the usage of several speech quality prediction
models for noise-suppressed speech. Even though the methods according to ITU-T
P.862 [9] and P.862.2 [10] explicitly excluded this application in their
scope, they are widely used for this purpose. The systematic score under-
prediction of P.862.2 was analysed in ITU-T SG12 and the incorrect
transformation of the sound pressure level was found as a reason of the bias;
the Corrigendum in [23] improves the performance. Substantial amounts of
auditory tests were compared with such metrics, concluding that they provide
poor correlation with the subjective data. Even the more recent speech quality
prediction method according ITU-T P.863 [6] does not perform well for noise-
suppressed speech.
The recently introduced method for assessing the quality of noise-suppressed
SWB/FB speech according to ETSI TS 103 281 provides two models (A and B). In
order to benefit from the performance of both models, a combined approach is
presented as a separate analysis here. The data of two validation listening
test databases indicate that the performance of an average model performs
better than the single ones and confirms the usage of this approach in TS
26.132 [8]. Further terminal investigations based on ETSI TS 103 281 is
expected to provide the basis for agreement on adequate and reasonable
requirements/objectives for TS 26.131 [13].
#