# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
In the present document, modal verbs have the following meanings:
**should** indicates a recommendation to do something
**should not** indicates a recommendation not to do something
**may** indicates permission to do something
**need not** indicates permission not to do something
**can** indicates that something is possible
**cannot** indicates that something is impossible
**will** indicates that something is certain or expected to happen as a result
of action taken by an agency the behaviour of which is outside the scope of
the present document
**will not** indicates that something is certain or expected not to happen as
a result of action taken by an agency the behaviour of which is outside the
scope of the present document
**might** indicates a likelihood that something will happen as a result of
action taken by some agency the behaviour of which is outside the scope of the
present document
**might not** indicates a likelihood that something will not happen as a
result of action taken by some agency the behaviour of which is outside the
scope of the present document
**is** (or any other verb in the indicative mood) indicates a statement of
fact
**is not** (or any other negative verb in the indicative mood) indicates a
statement of fact
# Introduction
# 1 Scope
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TS 28.550: \"Management and orchestration; Performance assurance\".
[3] 3GPP TS 28.533: \"Management and orchestration; Architecture framework\".
[4] 3GPP TS 28.530: \"Management and orchestration; Concepts, use cases and
requirements\".
[5] 3GPP TR 28.861: \"Study on the Self-Organizing Networks (SON) for 5G
networks\".
[6] 3GPP TR 28.805: \"Study on management aspects of communication services\".
[7] 3GPP TS 28.554: \"5G end to end Key Performance Indicators (KPI)\".
[8] 3GPP TS 28.552: \"Management and orchestration; 5G performance
measurements\".
[9] 3GPP TS 22.101: \"service aspects; service principles\".
[10] 3GPP TS 32.500: \"Telecommunication management; Self-Organizing Networks
(SON); Concepts and requirements\".
[11] 3GPP TS 37.816: \"Study on RAN-centric data collection and utilization
for LTE and NR\".
[12] 3GPP TS 37.320: \"Radio measurement collection for Minimization of Drive
Tests (MDT); Overall description\".
[13] 3GPP TS 23.501: \"System Architecture for the 5G System (5GS); Stage 2\".
[14] 3GPP TS 28.310: \"Energy efficiency of 5G\".
[15] 3GPP TR 21.866: \"Study on Energy Efficiency Aspects of 3GPP Standards\".
[16] 3GPP TS 26.247: \"Transparent end-to-end Packet-switched Streaming
Service (PSS); Progressive Download and Dynamic Adaptive Streaming over HTTP
(3GP-DASH)\".
[17] 3GPP TS 26.114: \"IP Multimedia Subsystem (IMS); Multimedia Telephony;
Media handling and interaction\".
[18] 3GPP TS 23.288: \"Architecture enhancements for 5G System (5GS) to
support network data analytics services\".
[19] 3GPP TS 28.313: \"Self-Organizing Networks (SON) for 5G networks\".
[20] 3GPP TS 28.541: \"Management and orchestration; 5G Network Resource Model
(NRM); Stage 2 and stage 3\".
[21] 3GPP TS 38.304 NR: \"User Equipment (UE) procedures in idle mode and in
RRC Inactive state\".
[22] 3GPP TS 28.545: \" Management and orchestration; Fault Supervision (FS)
\".
# 3 Definitions of terms, symbols and abbreviations
## 3.1 Terms
For the purposes of the present document, the terms given in 3GPP TR 21.905
[1] and the following apply. A term defined in the present document takes
precedence over the definition of the same term, if any, in 3GPP TR 21.905
[1].
**\ :** \.
## 3.2 Symbols
For the purposes of the present document, the following symbols apply:
\ \
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
AI Artificial Intelligence
MDA Management Data Analytics
MDAS Management Data Analytics Service
ML Machine Learning
# 4 Concepts and overview
Editor's note: this clause is to accommodate the concepts and overview of
MDA/MDAS.
## 4.1 Overview
The Management Data Analytics is defined in TS 28.550 [2] and has also been
mentioned by various other technical specifications and reports including for
example TS 28.533 [3], TS 28.530 [4], TR 28.861 [5] and TR 28.805 [6].
The MDA provides a capability of processing and analysing the raw data related
to network and service events and status (e.g., performance measurements,
Trace/MDT/RLF/RCEF reports, QoE reports, alarms, configuration data, network
analytical data, and service experience data from AFs, etc.) to provide
analytics report (including recommended actions) to enable the necessary
actions for network and service operations.
The MDA, in conjunction with Artificial Intelligence (AI) and Machine Learning
(ML) techniques, brings intelligence and automation to the network service
management & orchestration.
MDA can help to perform management tasks in preparation, commissioning,
operation as well as in the termination phases. For example, MDA can support
service provisioning by preparing service catalogues, evaluating network
requirements for a new service and carrying out feasibility check. During
operation phase, the MDA can identify ongoing issues impacting the performance
of the network and service, and discover in advance the potential issues that
would cause potential failure and/or performance degradation. The MDA can also
assist to predict the network and service demand to enable the timely resource
provisioning and deployments which would allow fast time-to-market network and
service deployment.
The MDAS can be consumed by various consumers, for instance the MFs (i.e., MnS
service producers/consumers for network and service management), NFs (e.g.,
NWDAF), SON functions, network and service optimization tools/functions, SLS
assurance functions, human operators, and AFs, etc.
The MDA is an enabler for the automation and cognition of the network and
service management & orchestration.
## 4.2 MDA functionality
Figure 4.2.1 illustrates the functionality provided by MDA. Depending on the
scenario, MDA may collect data for analysis by acting as an MDAS Consumer,
and/or as an MnS Consumer, and/or as an NWDAF subscriber. After analysis, MDA
acts as an MDAS Producer to expose the analysis results to MDAS Consumers.
Figure 4.2.1: Functional overview of MDA
# 5 MDA process and role
Editor's note: this clause is to accommodate the MDA process (in connection
with AI/ML techniques), relation between MDA and SON, relation between MDA and
NWDAF, position of MDAS producer in SBMA, etc.
## 5.1 MDA role in management loop
The MDA forms a part of the management loop (which can be open loop or closed
loop, see TS 32.500 [10]), and it brings intelligence and generates value by
_processing and analysis of management and network data, where the AI and ML
techniques may be utilized._
The MDA plays the role of Analytics in the management loop illustrated in
figure 5.1-1 below.
Figure 5.1-1: Analytics in management loop
**Observation** : The observation of the managed networks and services. The
observation involves monitoring and collection of events, status and
performance of the managed networks and services, and providing the
observed/collected data (e.g., performance measurements, Trace/MDT/RLF/RCEF
reports, network analytics reports, QoE reports, alarms, etc).
**Analytics** : The data analytics for the managed networks and services. The
MDA described in the TR plays the role of Analytics in the management loop.
The MDA prepares, processes and analyzes the data related to the managed
networks and services, and provides the analytics reports for root cause
analysis of ongoing issues, prevention of potential issues and prediction of
network or service demands. The analytics report contains the description of
the issues or predictions with optionally a degree of confidence indicator,
the possible causes for the issue and the recommended actions. Techniques such
as AI and ML (e.g., ML model) may be utilized with the input data including
not only the observed data of the managed networks and services, but also the
execution reports of actions (taken by the execution step). The MDA classifies
and correlates the input data (current and historical data), learn and
recognize the data patterns, and makes analysis to derive inference, insight
and predictions.
**Decision** : The decision making for the management actions for the managed
networks and services. The management actions are decided based on the
analytics reports (provided by MDA) and other management data (e.g.,
historical decisions made) if necessary. The decision may be made by the
consumer of MDAS (in the closed management loop), or a human operator (in the
open management loop). The decision includes what actions to take, and when to
take the actions.
**Execution** : The execution of the management actions according to the
decisions. During the execution step, the actions are carried out to the
managed networks and services, and the reports (e.g., notifications, logs) of
the executed actions are provided.
## 5.2 Management interaction with NWDAF and gNB
There are two types of data analytics services, one is the network data
analytics service provided by NWDAF, another is the MDAS provided by 3GPP
management system. The MDAS producer provides the analytics data for
management purposes based on the data related to different types of NFs, e.g.,
data reported from gNB and other core network functions. The MDAS producer may
use the analytics result of NWDAF as input.
> Figure 5.2-1 shows an example of the coordination between NWDAF, gNB and
> MDAS producer for data analytics purpose.
>
> 1\. The NWDAF may consume the MDAS for identified scenarios and provide
> analytics service for 5GC NF for control purpose.
>
> 2\. The CN Domain MDAS producer may consume the service provided by NWDAF
> and other 5GC NFs and provide analytics data for management purpose.
>
> 3\. The gNB many consume the MDAS for identified scenarios for RAN control
> purpose.
>
> 4\. The RAN Domain MDAS producer may consume the service provided by gNB and
> provide analytics data for management purpose.
{width="4.766666666666667in" height="4.3in"}
Figure 5.2-1: Example of coordination between NWDAF, gNB and MDAS producer for
data analytics
Figure 5.2-2 shows another example of the coordination between NWDAF and MDAS
producer for data analytics purpose.
> 1\. The NWDAF may consume the MDAS for identified scenarios and provide
> analytics service for 5GC NF for control purpose.
>
> 2\. The gNB may consume the MDAS for identified scenarios for RAN control
> purpose
>
> 3\. The Domain MDAS producer may consume the service provided by NWDAF,
> other 5GC NFs and gNB, provide analytic data for management purpose.
{width="3.85in" height="3.225in"}
Figure 5.2-2: Example of coordination between NWDAF, gNB and MDAS producer for
data analytics
## 5.3 MDA process
The MDA may rely on ML technologies, which may need the consumer to be
involved to optimize the accuracy of the MDA results.
The MDA process in terms of the interaction with the consumer, when utilizing
ML technologies, is described in the figure below.
Figure 5.3-1: MDA process
There are two kinds of processes for MDA, the process for ML model training
and the process for management data analysis. In the process for ML model
training, the MDA producer classifies the input data for training purpose,
trains the ML model and provides the ML training report. The process for ML
model training may also get the consumer involved, i.e., allowing the consumer
to provide input for ML model training. The ML model training may be performed
on an un-trained ML model or a trained ML model. In the process for management
data analysis, the MDA producer classifies the analytics input for management
data analysis purpose, analyses the data by the trained ML model, and provides
the analytics report to the consumer.
**Data classification** : The data input to the MDA producer could be used for
ML model training or for the actual management data analysis. The MDA producer
classifies the input data into the category for ML data training and the
category for management data analysis, and passes the classified data along to
corresponding step for further processing.
**ML model training** : The MDAS producer trains the ML model, i.e., to train
the algorithm of the ML model to be able to provide the expected training
output by analysis of the training input. The data for ML model training may
be the training data (including the training input and the expected output)
and/or the validation data provided by the consumer. After the ML model
training, the MDAS producer provides an ML model training report.
**Management data analysis** : The trained ML model analyses the classified
data and generates the management data analytics report(s). Analytics reports
were presented in Section 5.1.
**Validation** : The consumer may validate the output data provided by the
MDAS producer. The output data to be validated may be the analytics report
and/or the ML model training report as described above. The consumer may
provide the validation data as feedback to the MDAS producer, and the MDAS
producer will use the validation data for further ML model training with the
historical data that are used to generate the validated output data.
# 6 Use cases, potential requirements and possible solutions
## 6.1 Coverage related issues
### 6.1.1 Coverage issue analysis
#### 6.1.1.1 Use case
The coverage issue may cause various UE and network failures and degrade the
network performance offered the UEs.
The coverage issue could be a weak coverage, a coverage hole, a pilot
pollution, an overshoot coverage, or a DL and UL channel coverage mismatch as
described in clause 5.1.1, 3GPP TS 37.816 [11]. The weak coverage may result
in low success rate of random access, paging, RRC connection establishment and
handover, low data throughput, more abnormal releases of RRC connection, DRB
retainability, QoS flow and/or PDU session resources, and dissatisfied QoE.
The coverage hole is a more severe problem and would further lead to the UE
out of service in the area.
The 5G related coverage issue may exist only in 5G (i.e., 5G issue only with
good coverage provided by other RATs) or exist in all RATs (i.e., no RAT
provides good coverage in the area).
Coverage performance should be assured to guarantee user service experience.
It is desirable that the coverage issue can be detected by MDA from the
various symptoms, together with the geographical and terrain data and the
configuration parameters of the RAN.
Once the coverage issue is detected, the MDAS producer provides the analytics
report that precisely describes the coverage issue, and the analytics report
needs to contain sufficient information to enable the MDAS consumer (e.g., SON
CCO function) to take the remedy actions. The MDAS producer may also provide
the recommended actions to solve the identified coverage issue in the
analytics report, so that the MDAS consumer can execute the actions
accordingly or by taking the recommended actions into account.
The MDAS producer is informed when the actions are taken by the MDAS producer
consumer to solve the coverage issue described in the analytics report, so
that the MDAS producer can start evaluating the result of the executed
actions.
The MDAS producer gets the execution reports describing the actions taken by
the MDAS consumer, and takes the execution reports into account to fine-tune
the accuracy of the future (new or updated) analytics report.
The MDAS producer also provide update(s) of the analytics report to indicate
the status change (e.g., solved, mitigated or deteriorated) of the coverage
issue.
#### 6.1.1.2 Potential requirements
**REQ-COV_ANA-CON-1** The MDAS producer should have a capability to provide
the analytics report describing the coverage issue.
**REQ-COV_ANA-CON-2** The analytics report describing the coverage issue
should contain the following information:
> \- The identifier of the coverage issue described in the analytics report;
>
> \- Indication of whether the coverage issue is weak coverage or coverage
> hole, a pilot pollution, an overshoot coverage, or a DL and UL channel
> coverage mismatch;
>
> \- The start time and end time of the coverage issue;
>
> \- The geographical area and location where the coverage issue exists;
>
> \- Root cause of the coverage issue;
>
> \- Whether the coverage issue exists in 5G only or in all RATs;
>
> \- The cells affected by the coverage issue;
>
> \- The severity level (e.g., critical, medium, or cleared) of the coverage
> issue;
>
> \- The recommended actions to solve the coverage issue.
#### 6.1.1.3 Possible solutions
##### 6.1.1.3.1 Solution description
The MDAS producer correlates, processes and analyzes the data described in the
following subclause within a time period on a regular basis or trigged by
events (e.g., the RLF reports) to identify the coverage issue, and provide the
analytics reports to describe the identified coverage issues (which could be
new issues or the updates of existing issues).
##### 6.1.1.3.2 Data required for coverage issue analysis
The following table describes the data required for coverage issue analysis:
+----------------------------------+----------------------------------+ | **Data category** | **Required data** | +==================================+==================================+ | Performance measurements | > \- Average/distribution of UE | | | > reported RSRPs/RSRQs/SINRs of | | | > the serving cell when the TA | | | > (Timing Advance) or UE rx-tx | | | > applied to the UEs is in a | | | > specific range; | | | > | | | > \- Average/distribution of UE | | | > reported RSRPs/RSRQs/SINRs of | | | > each neighbour cell when the | | | > UE reported RSRPs/RSROs of the | | | > serving cell is in a specific | | | > range, measured per NCR | | | > (neighbour cell relation), per | | | > SSB index and per CSI-RS index | | | > of each NCR; | | | > | | | > \- Number of abnormal releases | | | > of DRBs, QoS flows, PDU | | | > sessions, and UE contexts in | | | > the serving cell measured per | | | > SSB index and per CSI-RS index | +----------------------------------+----------------------------------+ | MDT reports | MDT reports containing RSRPs and | | | RSRQs of the serving cell and | | | neighbour cells reported by each | | | UE with anonymous id (e.g., | | | C-RNTI) and location | | | information. | +----------------------------------+----------------------------------+ | RLF reports | RLF reports containing RSRP(s) | | | and RSRQ(s) of the serving cell | | | and neighbour cells reported by | | | each UE with anonymous id (e.g., | | | C-RNTI) and location | | | information. | +----------------------------------+----------------------------------+ | RECF reports | RCEF reports containing RSRP(s) | | | and RSRQ(s) of the serving cell | | | and neighbour cells reported by | | | each UE with anonymous id (e.g., | | | C-RNTI) and location | | | information. | +----------------------------------+----------------------------------+ | UE location reports | UE location information provided | | | by the LCS with the anonymous id | | | (e.g., C-RNTI) which can be used | | | to correlate with the | | | MDT/RLF/RCEF reports. | +----------------------------------+----------------------------------+ | QoE reports | Editor's note: the level of | | | details of QoE reports required | | | in this solution for FFS. | +----------------------------------+----------------------------------+ | Geographical data and terrain | > \- The geographical | | data of the RAN | > information (longitude, | | | > latitude, altitude) of the | | | > deployed RAN (gNBs and | | | > eNodeBs, antennas, sector | | | > carrier equipments, etc.). | | | > | | | > \- The terrain data for the | | | > area of the deployed RAN. | | | | | | Editor's note: which MnS | | | provides this kind of data is | | | FFS. | +----------------------------------+----------------------------------+ | Configuration data | > \- The current NRMs containing | | | > the attributes affecting the | | | > RAN coverage, such as maximum | | | > transmission power of the | | | > cell, directions and tilts of | | | > the antennas or beams, etc. | | | > | | | > \- The NRM update reports | | | > (notifications or logs) | | | > containing the creations or | | | > changes of the MOIs (Managed | | | > Object Instance) affecting the | | | > RAN coverage. | +----------------------------------+----------------------------------+
##### 6.1.1.3.3 Analytics report for coverage issue
The analytics report describing the coverage issue contains the following
information:
> \- Coverage issue identifier: The identifier of the coverage issue;
>
> \- Coverage issue type indication: Indication that the coverage issue is
> weak coverage or coverage hole, pilot pollution, overshoot coverage, or DL
> and UL channel coverage mismatch;
>
> \- Start time: The start time of the coverage issue;
>
> \- Stop time: The stop time of the coverage issue;
>
> \- Location: The geographical area and location where the coverage issue
> exists;
>
> \- Root cause: Root cause of the coverage issue, e.g., weak transmission
> power, blocked by constructions, restricted by terrain, etc;
>
> \- RAT indication: Indication that the coverage issue exists in 5G only or
> in all RATs;
>
> \- Affected objects: The MOIs of the cells affected by the coverage issue;
>
> \- Severity level: The severity level (e.g., critical, medium, cleared) of
> the coverage issue;
>
> \- Recommended actions: The recommended actions to solve the coverage issue.
> The recommended action could be re-configurations of coverage related
> attributes, creation of new cells or beams, or manual operations to add or
> change the physical units.
>
> Editor's Note: Quantification of severity levels is FFS.
## 6.2 Resource related issues
### 6.2.1 RAN user plane congestion analysis
#### 6.2.1.1 Use case
With the development of diverse communication services and the increasing
number of connections, user data volume demanded by end users grows rapidly
which may not be satisfied by the current deployed 5G network.
In clause 3.1 of TS 22.101 [9], the _RAN user plane congestion is defined as
the situation where the demand for RAN resources to transfer user data exceeds
the available RAN capacity to deliver the user data for a significant period
of time in the order of few seconds or longer. The case where_ a short-
duration burst of user plane traffic is not identified as RAN congestion.
Due to the complexity of 5G network and wireless environment, multiple types
of performance deteriorate are related with RAN user plane congestion, e.g.,
high drop rate of PDCP PDU, the full PRB utilisation, inappropriate mobility
parameters configuration or inefficient usage of radio resources. The root
causes should be analysed and identified to help to resolve the RAN user plane
congestion and improve the end users' experience, e.g., the issue of lack of
physical or virtual resources or unsuitable resources allocation, unsuitable
mobility parameters. The recommended actions may also be provided, e.g.,
recommended policies of physical and virtual resources allocation, possible
means to improve the radio condition, load balancing mechanisms etc.
The producer of MDAS is able to, from the perspective of the management
aspects, provide the user plane data congestion analytics report related to a
specific cell, specific network slicing instance or subnetwork. This analytics
report can be considered as an input to support SLS assurance to perform
further evaluation.
Editor's Note: The more detailed descriptions of user plane congestion are
FFS.
#### 6.2.1.2 Potential requirements
**REQ-CONG_ANA-CON-1** : The MDAS producer shall be able to provide the
analytics report describing the RAN user plane congestion problem.
**REQ-CONG_ANA-CON-2** : The analytics report describing the RAN user plane
congestion problem should contain the following information:
> \- The identifier of the RAN user plane congestion;
>
> \- Indication of the RAN user plane congestion type;
>
> \- The start time and end time of the RAN user plane congestion;
>
> \- The geographical area and location where the RAN user plane congestion
> affects;
>
> \- Root cause of the RAN user plane congestion;
>
> \- The objects affected by the RAN user plane congestion;
>
> \- The severity level of the RAN user plane congestion;
>
> \- The recommended actions to solve the RAN user plane congestion problem.
#### 6.2.1.3 Possible Solutions
##### 6.2.1.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to identify the RAN user plane congestion problems. As the
table in 6.2.1.3.3 shows, the analytics report is able to be provided by the
MDAS producer to describe the root causes and recommendations of identified
RAN user plane problem. This procedure may be triggered by the request or
periodically.
##### 6.2.1.3.2 Data required for RAN user plane congestion problem
Following table shows the potential data required to analyse the RAN user
plane congestion problem.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | UE throughput: The IP throughput of end | | | users, see clause 5.1.1.3 of TS 28.552 | | | [8]; | | | | | | Radio resource utilization: The usage of | | | physical radio resource utilization of | | | the network, see clause 5.1.1.2 of TS | | | 28.552[8]; | | | | | | PDCP Data Volume: The transmitted PDCP | | | data volume, see clause 5.1.2.1 and | | | 5.1.3.6 of TS 28.552 [8]; | | | | | | TB related measurements: The TB | | | transmitted in a cell, see clause | | | 5.1.1.7 of TS 28.552 [8]; | | | | | | CQI related measurements: the | | | distribution of Wideband CQI (Channel | | | Quality Indicator) reported by UEs in | | | the cell, see clause 5.1.1.11 of TS | | | 28.552 [8]; | | | | | | MCS related Measurements: the | | | distribution of the MCS scheduled for | | | PDSCH RB by NG-RAN, the distribution of | | | the MCS scheduled for PUSCH RB by | | | NG-RAN, see clause 5.1.1.12 in TS 28.552 | | | [8]; | | | | | | RAN UE throughput: A KPI that shows how | | | NG-RAN impacts the service quality | | | provided to an end-user, see clause | | | 6.3.6 of TS 28.554 [7]; | | | | | | Throughput for network slice instance: | | | Upstream/Downstream throughput for | | | network and Network Slice Instance, see | | | clause 6.3.2 and clause 6.3.3 of TS | | | 28.554 [7]; | | | | | | Throughput at N3 interface: | | | Upstream/Downstream GTP data throughput | | | at N3 interface, see clause 6.3.4 and | | | clause 6.3.5 of TS 28.554 [7]; | +--------------------------+------------------------------------------+ | MDT Data | UE measurements related to RSRP, RSRQ, | | | SINR and UE location information. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs related | | | with RAN user plane congestion. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.2.1.3.3 Analytics report for RAN user data congestion
Following table shows the potential information carried in the analytics
report of RAN user plane congestion.
**Analytics Report of RAN user plane congestion** **Attribute Name**
**Description**
* * *
                                                      Resource issue identifier                   The identifier of the RAN user plane congestion
                                                      RAN user plane congestion type indication   Indicator of the root cause of the RAN user plane congestion, e.g., PRB resources shortage, unsuitable resource allocation, inappropriate mobility parameters configuration, inefficient usage of radio resources
                                                      Start time                                  The start time of the RAN user plane congestion problem
                                                      Stop time                                   The end time of the RAN user plane congestion problem
                                                      Location                                    The geographical area or the cells where the RAN user plane congestion exists
                                                      Root cause                                  The root cause of the UP congestion issue, e.g. poor radio condition, inappropriate radio resource allocation, bad handover parameters etc
                                                      Affected objects                            The MOIs of the cells or subnetworks or network slices affected by the RAN user plane congestion problem
                                                      Severity level                              The severity level (e.g., critical, medium, not important) of the RAN user plane congestion
                                                      Recommended actions                         The recommend actions to solve the RAN user plan congestion problem. The recommended actions could be to update the policies of physical and virtual resources allocation, improve the radio condition quality, or optimize load balancing mechanisms.
Editor's Note: Quantification of severity levels is FFS.
### 6.2.2 Resource utilization analytics
#### 6.2.2.1 Use case
The network is a resource limited system, it is therefore quite imperative to
ensure an optimum resource utilization for the network so that the required
resources can be efficiently allocated while ensuring no wastage or under
allocation of resources to cause additional CapEx and OpEX.
The resources usage for a network, a portion of network or a network slice
could be higher or lower during different time periods depending on the
traffic patterns. The traffic patterns could also vary in different
geographical locations (e.g., business area, entertainment area and
residential area) of the network, and could vary for different network slices.
It could happen that at some point in some areas or network slices the
resources are in shortage status while in some other areas or network slices
there are abundant resources. This may result in that the users cannot be
satisfactorily served in some areas or network slices due to lack of resources
even though the overall maximum capacity is sufficient. Resource shortage may
affect the QoS and potentially impact user quality of service experience,
e.g., lowering down the user data throughput, prolong the user data delay,
raise the rejections and failures for establishment of new connections (e.g.,
RRC connection), sessions (e.g., PDU session) and resources (e.g., QoS flows,
DRBs, etc.) and increase the drops of the existing connections, sessions and
resources and deteriorates user quality of service experience. Especially in
shared scenarios, it is usually that network slices may share the same RAN
resources, TN resources and/or some CN network resources. When resources
become limited, the suddenly high increase in resource usage by one network
slice may potentially affect the performance of other network slices. If
resources are not limited but one network slice is in relatively higher
resource usage and the others are in lower resource usage, the proportion of
resource distribution may need to be reallocated without provisioning
additional spare resources in order to achieve efficient and optimum network
resource usage, which can effectively reduce the CapEx and OpEx.
Therefore, it would be desirable that the spare resource of the under-utilized
usage areas or network slices can be re-allocated to areas or network slices
that requires more resources within the same period of time to prevent the
resource shortage from happening.
The MDA can analyze the current and historical performance data related to
resource usage, network traffic and user quality of service experience for the
network or network slices, and identify the ongoing issues on resource
utilization and predict potential issues.
The MDAF may provide analytical report on capacity planning, resource
requirements, resource utilization, resource availability and resource
reservation proposals to assist the feasibility check by network and network
slice management system before the provisioning of the communication service.
The MDAS producer provides analytics report describing the ongoing and/or
potential resource utilization issues to the authorized consumers. The issues
need to be described precisely, including (but not limited to) the information
about which part of the network or network slice has encountered or is going
to encounter the resource utilization issue, it is resource shortage or
resource excess, over which time period, etc. The MDAS producer may also
provide the recommendations to solve the resource utilization issues
identified by the analytics report. The recommended actions may be for example
to schedule the "scale-in" and "scale out" of VNFs to dynamically
(re-)allocate the virtualized resources to where they are needed, or to
create/update the resource allocation policy for different network slices to
allow the network slices getting different percentage of resources in
different time periods according the traffic patterns and user quality of
service experience. In case of sharing scenario, the MDAS producer should also
weighs the resource usages of the shared network resources which belong to
different network slices. If reallocating the already allocated network
resource can solve the resource utilization issues, no other newly allocated
network resource is needed.
The MDAS producer gets the execution reports of the actions taken by the MDAS
consumer to solve the resource utilization issue, and takes the execution
reports into account in the following analysis.
The MDAS producer continue analyzing the reported issue and provides update(s)
if there is any status change (e.g., solved, mitigated or deteriorated) till
it is solved.
#### 6.2.2.2 Potential requirements
**REQ-RES-ANA-1** The MDAS producer should have a capability to provide the
analytics report describing the resource utilization issue.
**REQ-RES-ANA-2** The analytics report describing the resource utilization
issue should contain the following information:
> \- The identifier of the resource utilization issue;
>
> \- Indication that it is an ongoing issue or potential issue;
>
> \- The time period(s) during which the resource utilization issue has
> happened or is potentially going to happen;
>
> \- Indication that resource issue is shortage or excess over each time
> period;
>
> \- Percentage of resource shortage or excess in each time period;
>
> \- The network entities involved in the resource utilization issue;
>
> \- The network slices involved in the resource utilization issue;
>
> \- The recommended actions to solve the resource utilization issue.
**REQ-RES-ANA-3** The MDAS producer should have a capability to weigh the
allocation of shared network resource when providing the analytics report
describing the resource utilization issue.
#### 6.2.2.3 Possible solutions
##### 6.2.2.3.1 Solution description
_The MDAS producer correlates and analyzes_ the ongoing and/or potential
resource utilization issues based on the the current and historical
performance data related to resource usage and network traffic for the network
or network slices. The required data can be from RAN domain or CN domain or
both. Based on the analysis above, the MDAS producer is able to provide the
domain specific or cross domain analytics report as defined in 6.2.2.3.4
related with resource utilization analytics triggered by event or
periodically.
_To assist the feasibility check, the MDAS producer_ may consider the
following information: e.g., capacity planning of the network slice instance
and/or network slice subnet instance, existing active or non-active network
slice instance and/or network slice subnet instance resource information,
slice provisioning requirements, etc.
##### 6.2.2.3.2 Required data for resource utilization analysis for RAN domain
The management data required to analyze the RAN related resource utilization
are defined as the following table.
+----------------------+----------------------+----------------------+ | **Input data** | **Data type** | **Description** | +======================+======================+======================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [2]. MDAS | | | | uses this | | | | information to | | | | identify target | | | | network slices for | | | | resource utilization | | | | analytics and may | | | | derive network | | | | topology information | | | | according to | | | | S-NSSAI. | +----------------------+----------------------+----------------------+ | Performance | Measurement data | UE throughput: The | | measurement | | IP throughput of end | | | | users, see clause | | | | 5.1.1.3 of TS 28.552 | | | | [3]; | | | | | | | | RAN UE throughput: A | | | | KPI that shows how | | | | NG-RAN impacts the | | | | service quality | | | | provided to an | | | | end-user, see clause | | | | 6.3.6 of TS 28.554 | | | | [4]; | | | | | | | | Throughput for | | | | network slice | | | | instance: | | | | Upstream/Downstream | | | | throughput for | | | | network and Network | | | | Slice Instance, see | | | | clause 6.3.2 and | | | | clause 6.3.3 of TS | | | | 28.554 [4]; | | | | | | | | Throughput at N3 | | | | interface: | | | | Upstream/Downstream | | | | GTP data throughput | | | | at N3 interface, see | | | | clause 6.3.4 and | | | | clause 6.3.5 of TS | | | | 28.554 [4]; | | | | | | | | Radio resource | | | | utilization: The | | | | usage of physical | | | | radio resource | | | | utilization of the | | | | network, see clause | | | | 5.1.1.2 of TS | | | | 28.552[3]; | +----------------------+----------------------+----------------------+ | MDT Data | Measurement data | UE measurements | | | | related to RSRP, | | | | RSRQ, SINR and UE | | | | location | | | | information, see TS | | | | 37.320 [12]. | +----------------------+----------------------+----------------------+ | Capacity planning | Use case and | Capacity management | | data | procedures | use case and | | | | procedure, see | | | | clause 5.4.15 of | | | | TS28.530 [5] and | | | | clause 7.15 of | | | | TS28.531[6]. | +----------------------+----------------------+----------------------+ | Network topology | Network topology | The topology of the | | | data | network for resource | | | | utilization | | | | analytics. | +----------------------+----------------------+----------------------+ | User service | Analysis data | User service | | experience | | experience relevant | | | | attributes and/or | | | | analytics analysis | | | | obtained from NWDAF | | | | or AF, see clause | | | | 6.4 of TS 23.288 | | | | [18]. | +----------------------+----------------------+----------------------+
Note: The above parameters may not be the complete list.
##### 6.2.2.3.3 Required data for resource utilization analysis for CN domain
The management data required to analyze the CN related resource utilization
are defined as the following table.
+----------------------+----------------------+----------------------+ | **Input data** | **Data type** | **Description** | +======================+======================+======================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [2]. MDAS | | | | uses this | | | | information to | | | | identify target | | | | network slices for | | | | resource utilization | | | | analytics and may | | | | derive network | | | | topology information | | | | according to | | | | S-NSSAI. | +----------------------+----------------------+----------------------+ | Performance | Measurement data | User subscription | | measurement | | data by performance | | | | measurement for AMF | | | | as defined in clause | | | | 5.2 of TS 28.552 | | | | [3]; | | | | | | | | Performance | | | | measurement data for | | | | SMF as defined in | | | | clause 5.3 of TS | | | | 28.552 [3]; | | | | | | | | Performance | | | | measurement data for | | | | UPF as defined in | | | | clause 5.4 of TS | | | | 28.552 [3]; | | | | | | | | Performance | | | | measurement data for | | | | NF as defined in | | | | clause 5.7 of TS | | | | 28.552 [3]; | | | | | | | | Throughput for | | | | network slice | | | | instance: | | | | Upstream/Downstream | | | | throughput for | | | | network and Network | | | | Slice Instance, see | | | | clause 6.3.2 and | | | | clause 6.3.3 of TS | | | | 28.554 [4]; | | | | | | | | Throughput at N3 | | | | interface: | | | | Upstream/Downstream | | | | GTP data throughput | | | | at N3 interface, see | | | | clause 6.3.4 and | | | | clause 6.3.5 of TS | | | | 28.554 [4]; | | | | | | | | PDU sessions for | | | | network slice | | | | instance: number of | | | | PDU sessions and PDU | | | | session | | | | establishment time | | | | of network slice | | | | instance, see clause | | | | 6.4.1 and clause | | | | 6.4.3 of TS 28.554 | | | | [4]; | | | | | | | | Virtualised resource | | | | utilization: | | | | Virtualised resource | | | | utilization of | | | | Network Slice | | | | Instance, see clause | | | | 6.4.2 of TS 28.554 | | | | [4]; | +----------------------+----------------------+----------------------+ | Capacity planning | Use case and | Capacity management | | data | procedures | use case and | | | | procedure, see | | | | clause 5.4.15 of | | | | TS28.530 [5] and | | | | clause 7.15 of | | | | TS28.531[6]. | +----------------------+----------------------+----------------------+ | Network topology | Network topology | The topology of the | | | data | network for resource | | | | utilization | | | | analytics. | +----------------------+----------------------+----------------------+
Note: The above parameters may not be the complete list.
##### 6.2.2.3.4 Analytics report for resource utilization analysis
Following table provides the potential contents of the domain specific or
cross domain analytics report of resource utilization analysis based on the
required data received as described in 6.2.2.3.2 and 6.2.2.3.3.
**Analytics Report of resource utilization analysis** **Attribute Name**
**Description**
* * *
                                                          Resource utilization issue Identifier           The identifier indicates the resource utilization issue
                                                          Indication of resource utilization issue type   Indicates the type of the resource utilization issue, e.g., ongoing or potential resource utilization issue
                                                          Time period                                     Describes the time period(s) during which the resource utilization issue has happened or is going to happen
                                                          Indication of resource usage demand             Indicates that resource issue is shortage or excess in each time period
                                                          Percentage of resource usage demand             Describes percentage of resource shortage or excess in each time period
                                                          List of network entities                        Lists the network entities involved in the resource utilization issue
                                                          A List of network slices                        List of the network slices involved in the resource utilization issue
                                                          Recommended actions                             Describes the recommended actions to solve the resource utilization issue
### 6.2.3 Cross-slice resource optimization
#### 6.2.3.1 use case
In TR 28.861 [5], SON use case of cross-slice network resource optimizations
described. The resource allocated for each network slice instance may vary
considering the network resource utilization, traffic patterns, network
bandwidth and the demand of resources for each NSI, the priorities of NSI,
etc.
The MDAS producer is expected to have the capability to provide analytics
report of resource optimization for multiple network slices. Resource
optimizations for multiple network slices may be dependent on each other.
Resource scale out / in of one slice may impact resource allocation strategy
of the other network slices considering the overall resource availability
constraints. Aspects to be considered by MDAS include network slice type,
priority, resource availability, traffic load, QoS requirements and QoS flow
related measurements etc. The recommendations of the most optimal resource
allocation for each network slice and the predictions of the resource demand
for each NSI may aslo be provided. This analytics report can be consumed by
SON function to help the optimization of cross-slice resource optimization.
#### 6.2.3.2 Potential requirements
**REQ-Multi-SLICE-Resource_MDA-1** : MDAS producer shall have the capability
to provide analytics report describing resource optimization across multiple
network slices.
**REQ-Multi-SLICE-Resource_MDA-2** : The analytics report describing the
resource optimization across multiple network slices should include the
following information:
> \- Resource optimization threshold for each network slice;
>
> \- Recommendations of resource allocation for each NSI;
>
> \- The predictions of resource demand for each NSI
#### 6.2.3.3 Possible Solution
##### 6.2.3.3.1 Solution description
_The MDAS producer correlates and analyzes_ the resource optimization
strategies across multiple network slices based on the current and historical
resource utilization measurements and network traffic for each network slice
instances. Based on the analysis above, the MDAS producer is able to provide
the analytics report as defined in 6.2.3.3.3 related with cross slice resource
optimization analytics triggered by event or periodically.
##### 6.2.3.3.2 Required data for cross-slice resource optimization analysis
The input data in clause 6.2.2.3.2 and 6.2.2.3.3 can be reused as the required
management data to analyze the resource optimization across multiple network
slices.
##### 6.2.3.3.3 Analytics report for cross-slice resource optimization
Following table provides the potential contents of the analytics report of
cross-slice resource optimization.
**Analytics Report of cross-slice resource optimization analysis** **Attribute
Name** **Description**
* * *
                                                                       Cross-slice resource optimization Identifier   The identifier indicates the Cross-slice resource optimization
                                                                       Resource optimization threshold                Indicates the thresholds to trigger network resource optimizations for each network slice;
                                                                       Resource allocation recommendation             Describes the recommendations of resource allocation (e.g. increase or decrease NSI capacities like storage, computing, network bandwidth and radio resources) for each NSI;
                                                                       Resource demand prediction                     Describes the predictions of resource demand for each NSI
### 6.2.4 NAS level congestion control optimization
#### 6.2.4.1 Use case
The current NAS level congestion control as described in TS 23.501 [13] uses
back-off timer to avoid AMF receiving large amounts of NAS messages from UEs
including Mobility Registration Update request. The AMF will accept or rejects
the request depending on various aspects. In virtualized environment, the
Mobility Registration Update request may be rejected due to inadequacy of
available resources with the target AMF. The resource may include virtual
resource (e.g., compute, memory and disk). If the Mobility Registration Update
request is rejected by the AMF, UE will receive the reject message with a
Mobility Management back off time and send a new Mobility Registration Update
request after the timer. It is possible that the new Mobility Registration
Update request will be rejected again because of the load of the AMF. This
mechanism results in wastage of UE and network resources. It also brings
inefficiency in network procedures.
It is desirable to use MDAS (Management data analytic service) to assist
congestion control in order to avoid too many rejections of NAS messages at
the AMF. MDAS producer provides analytical report containing the current and
future/predicted resource consumption status for the target AMF. The
analytical report also provides recommended actions to optimize the target AMF
for congestion control. Based on the report MDAS consumer adjusts (e.g.,
scale-out/up the virtual resource, set the suitable timer) the resources
before continuing processing the received messages.
#### 6.2.4.2 Potential requirements
**REQ-NAS_OPT_CON-1** MDAS producer shall have the capability to provide
analytics report describing the NAS level congestion issue at AMF.
**REQ-NAS_OPT_CON-2** The analytics report describing the NAS level congestion
issue should contain the following information:
> \- The identifier of the NAS level congestion issue described in the
> analytics report;
>
> \- The start time and end time of the NAS level congestion issue;
>
> \- Affected AMF;
>
> \- Root cause of the NAS level congestion issue;
>
> \- The recommended actions to solve NAS level congestion issue.
#### 6.2.4.3 Possible solutions
##### 6.2.4.3.1 Solution Description
The MDAS producer correlates and analyses the management data described in the
following subclause to provide AMF resource consumption
statistics/predictions, identification of NAS level congestion issues and the
root cause as the table in clause 6.2.4.3.3 shows. This procedure may be
triggered by the request or periodically
##### 6.2.4.3.2 Data required for NAS level congestion control analysis
The management data required to analyze the NAS level congestion issue are
defined as the following table.
+--------------------------+------------------------------------------+ | **Data category** | **Required data** | +==========================+==========================================+ | Performance Measurements | Performance measurement for AMF: | | | registration and service related | | | measurement for AMF as defined in clause | | | 5.2 of TS 28.552 [3]. | | | | | | Virtual resource usage measurement for | | | AMF as defined in clause 5.7 of TS | | | 28.552 [3]. | +--------------------------+------------------------------------------+ | QoE Data | > The details information of QoE data | | | > required by this case is FFS. | +--------------------------+------------------------------------------+
##### 6.2.4.3.3 Analytics report
The NAS level congestion issue analytics report contains the following
information.
+----------------------+---------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of NAS level | | | | congestion issue** | | | +======================+=====================+======================+ | | Issue identifier | The identifier of | | | | the NAS level | | | | congestion. | +----------------------+---------------------+----------------------+ | | Start Time | > The start time of | | | | > the issue | | | | > happened. | +----------------------+---------------------+----------------------+ | | Stop Time | The end time of the | | | | issue has been | | | | solved. | +----------------------+---------------------+----------------------+ | | Affected AMF | The MOI of the AMF | | | | that affected by the | | | | NAS level congestion | | | | issue. | +----------------------+---------------------+----------------------+ | | Root cause | The root cause of | | | | the NAS level | | | | congestion issue, | | | | e.g. increased | | | | resource | | | | consumption. | +----------------------+---------------------+----------------------+ | | Recommended actions | Recommendation for | | | | AMF in order to make | | | | it optimal for NAS | | | | level congestion | | | | control e.g. | | | | scale-out AMF, | | | | Increase or adjust | | | | back-off time to | | | | avoid large amounts | | | | of UEs initiate | | | | deferred requests | | | | simultaneously. | +----------------------+---------------------+----------------------+
## 6.3 SLS assurance related issues
### 6.3.1 E2E latency analysis
#### 6.3.1.1 Use case
Latency is one of the SLA parameters for URLLC services. User data packets
should be successfully delivered within certain time constraints to satisfy
the end users requirements.
Latency could be impacted by the network capability and network
configurations, e.g. configuration of service priority, RAN capacity, network
load, number of re-transmissions, Wireless channel environment and the
processing time of the network functions, etc. These factors may be the root
cause if the latency requirements cannot be achieved. Packet transmission
latency may dynamically change if one or multiple of these factors change. The
latency requirement should be assured even if some of the network conditions
may degrade. There are some mechanisms to assure latency, e.g. to upgrade the
service priority, allocate or reserve more network resource, prepare backups.
With regard to latency analysis for URLLC services, the performance data and
fault data are required to be collected, reported and analysed in near real
time. Distributed MDAS deployment architecture should be applied for this
scenario. The domain MDAS Providers located in the edge network provides
latency analysis or predictions for local services in near real time. E.g. for
latency and other related QoS evaluation or prediction for V2X application,
user location and user trajectory may need to be analyzed in near-real time.
The analytical report can be consumed by edge AFs to perform actions in time.
The centralized MDAS Providers analyzes integrate latency performance for
cross domain. It may provide more comprehensive analytical report to the
centralized AF. AI/ML models or analytical data may need to be exchanged
between the neighbouring domain MDAS Providers, or between domain MDAS
Providers and the centralized MDAS Providers.
From the management perspective, resource configuration and allocation
algorithms or policies should support latency assurance. E2E latency is the
latency across multiple domains, e.g. RAN domain, core network domain and
transport network domain, each domain should ensure its own latency
requirement to achieve the total E2E latency goal. The domain specific MDAS
can be utilized to provide the domain specific latency analysis, and together
with the cross-domain MDAS to provide E2E latency analysis to support SLS
assurance.
#### 6.3.1.2 Potential requirements
**REQ-LATENCY_ASS-CON-1** : MDAS producer should have the capability to
provide analytics report describing the latency problem.
**REQ-LATENCY_ASS-CON-2** : The MDAS producer should have the capability to
provide the latency analytics report in time for URLLC services according to
the corresponding latency requirement.
**REQ-LATENCY_ASS-CON-3** : Distributed MDAS deployment and exchange of
analytical data between MDAS producers should be supported.
**REQ-LATENCY_ASS-CON-4** : The analytics report describing the latency
problem should include the following information:
> \- The identifier of the latency issue;
>
> \- Indication of latency issue type;
>
> \- The start time and end time of the latency issue;
>
> \- The geographical area and location where the latency issue exists;
>
> \- Root cause of the latency issue;
>
> \- The objects affected by the latency issue;
>
> \- The severity level of the latency issue;
>
> \- The recommended actions to solve the latency issue.
#### 6.3.1.3 Possible solutions
##### 6.3.1.3.1 Solution description
_The performance measurements, e.g., network latency, UE throughput, network
resource utilization and packet loss can be utilized for E2E latency analysis.
To support E2E latency assurance_ in order to satisfy the latency requirements
from the vertical users, MDAS producer is able to provide the analytics report
as defined in 6.3.1.3.5 related with E2E latency analytics triggered by event
or periodically.
##### 6.3.1.3.2 Required data for latency analysis for RAN domain
The management data required to analyze the latency are defined as the
following table.
+------------------------+------------------+------------------------+ | **Input data** | **Data type** | **Description** | +========================+==================+========================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [13]. MDAS | | | | may derive network | | | | topology information | | | | according to S-NSSAI | +------------------------+------------------+------------------------+ | Performance | Measurement data | Packet delay: "packet | | measurement | | delay" measurement as | | | | defined in clause | | | | 5.1.1.1, clause | | | | 5.1.3.3, TS 28.552 | | | | [8]; | | | | | | | | IP Latency | | | | measurements: "IP | | | | Latency measurements" | | | | as defined in clause | | | | 5.1.3.4, TS 28.552 | | | | [8]; | | | | | | | | UE throughput: The IP | | | | throughput of end | | | | users, see clause | | | | 5.1.1.3 of TS 28.552 | | | | [8]; | | | | | | | | RAN UE throughput: A | | | | KPI that shows how | | | | NG-RAN impacts the | | | | service quality | | | | provided to an | | | | end-user, see clause | | | | 6.3.6 of TS 28.554 | | | | [7]; | | | | | | | | Throughput at N3 | | | | interface: | | | | Upstream/Downstream | | | | GTP data throughput at | | | | N3 interface, see | | | | clause 6.3.4 and | | | | clause 6.3.5 of TS | | | | 28.554 [7]; | | | | | | | | Radio resource | | | | utilization: The usage | | | | of physical radio | | | | resource utilization | | | | of the network, see | | | | clause 5.1.1.2 of TS | | | | 28.552[8]; | | | | | | | | CQI related | | | | measurements: the | | | | distribution of | | | | Wideband CQI (Channel | | | | Quality Indicator) | | | | reported by UEs in the | | | | cell, see clause | | | | 5.1.1.11 of TS 28.552 | | | | [8]; | | | | | | | | MCS related | | | | Measurements: the | | | | distribution of the | | | | MCS scheduled for | | | | PDSCH RB by NG-RAN, | | | | the distribution of | | | | the MCS scheduled for | | | | PUSCH RB by NG-RAN, | | | | see clause 5.1.1.12 in | | | | TS 28.552 [8]; | +------------------------+------------------+------------------------+ | MDT Data | Measurement data | UE measurements | | | | related to RSRP, RSRQ, | | | | SINR and UE location | | | | information, see TS | | | | 37.320 [12]. | +------------------------+------------------+------------------------+ | QoE Data | Measurement data | The details | | | | information of QoE | | | | data required by this | | | | case is FFS. | +------------------------+------------------+------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.1.3.3 Required data for latency analysis for CN domain
The management data required to analyze the latency are defined as the
following table.
+------------------------+------------------+------------------------+ | **Input data** | **Data type** | **Description** | +========================+==================+========================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [13]. MDAS | | | | may derive network | | | | topology information | | | | according to S-NSSAI | +------------------------+------------------+------------------------+ | Performance | Measurement data | Round-trip GTP Data | | measurement | | Packet Delay: | | | | "Round-trip GTP Data | | | | Packet Delay" as | | | | defined in clause | | | | 5.4.1.9, TS 28.552 | | | | [8]; | | | | | | | | GTP packets delay in | | | | UPF: "GTP packets | | | | delay in UPF" as | | | | defined in clause | | | | 5.4.5, TS 28.552 | | | | [8]; | | | | | | | | Round-trip GTP Data | | | | Packet Delay on N9 | | | | interface: "Round-trip | | | | GTP Data Packet Delay | | | | on N9 interface" as | | | | defined in clause | | | | 5.4.4.1, TS 28.552 | | | | [8]; | | | | | | | | Throughput at N3 | | | | interface: | | | | Upstream/Downstream | | | | GTP data throughput at | | | | N3 interface, see | | | | clause 6.3.4 and | | | | clause 6.3.5 of TS | | | | 28.554 [7]; | +------------------------+------------------+------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.1.3.4 Required data for E2E latency analysis for cross domain
For cross domain analysis, the RAN and CN domain required data as described in
6.3.1.3.2 and 6.3.1.3.3 may be also needed, as well as the potential data
described in the following table.
+----------------------+----------------------+----------------------+ | **Input data** | **Data type** | **Description** | +======================+======================+======================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [13]. MDAS | | | | may derive network | | | | topology information | | | | according to S-NSSAI | +----------------------+----------------------+----------------------+ | Performance | Measurement data | End-to-end Latency | | measurement | | of 5G Network: | | | | "End-to-end Latency | | | | of 5G Network" as | | | | defined in clause | | | | 6.3.1, TS 28.554 | | | | [7]; | | | | | | | | Throughput for | | | | network slice | | | | instance: | | | | Upstream/Downstream | | | | throughput for | | | | network and Network | | | | Slice Instance, see | | | | clause 6.3.2 and | | | | clause 6.3.3 of TS | | | | 28.554 [7]; | +----------------------+----------------------+----------------------+ | QoE Data | Measurement data | The details | | | | information of QoE | | | | data required by | | | | this case is FFS. | +----------------------+----------------------+----------------------+ | "Required data for | Measurement data | Raw data in | | latency analysis for | and/or analytical | "6.3.1.3.2 Required | | RAN domain" or RAN | data | data for latency | | domain "Analytics | | analysis for RAN | | report for latency | | domain", or | | analysis" | | analytical data of | | | | RAN domain in | | | | "6.3.1.3.5 Analytics | | | | report for latency | | | | analysis" | +----------------------+----------------------+----------------------+ | "Required data for | Measurement data | Raw data in | | latency analysis for | and/or analytical | "6.3.1.3.3 Required | | CN domain" or CN | data | data for latency | | domain "Analytics | | analysis for CN | | report for latency | | domain", or | | analysis" | | analytical data of | | | | CN domain in | | | | "6.3.1.3.5 Analytics | | | | report for latency | | | | analysis" | +----------------------+----------------------+----------------------+
Note: The above parameters may not be the complete list.
##### 6.3.1.3.5 Analytics report for latency analysis
Following table shows the potential information of the domain specific or
cross domain E2E analytics report for latency analysis based on the required
data received as described in 6.3.4.3.2, 6.3.4.3.3 and 6.3.4.3.4.
**Analytics Report of E2E latency analysis** **Attribute Name**
**Description**
* * *
                                                 SLS assurance issue Identifier           The identifier indicates the SLS assurance issue
                                                 Indication of SLS assurance issue type   Indicates the type of the SLS assurance issue, e.g., RAN latency issue, CN latency issue, TN latency issue.
                                                 Location                                 The geographical area and location where the latency issue exists
                                                 Start time                               The start time of the latency issue
                                                 Stop time                                The stop time of the latency issue
                                                 Root cause                               The root cause of the E2E latency degradation, e.g. coverage issue, load issue in RAN, load issue in CN, low throughput in RAN, low throughput in CN etc.
                                                 Affected objects                         The MOIs of cells, subnetwork or network slices affected by the latency issue;
                                                 Severity level                           The severity level (e.g., critical, medium, not important) of the latency issue;
                                                 Recommended actions                      The recommended actions to solve the latency issue, e.g., resource radio resources re-allocation in gNB, scaling the VNF.
Editor's Note: Quantification of severity levels is FFS.
### 6.3.2 Network slice load analysis
#### 6.3.2.1 Use case
Network slice load may vary over time. Therefore, network resources allocated
initially could not always satisfy the traffic requirements, for example, the
network slice may be overloaded or underutilized. Various factors may impact
the network slice load, e.g. number of UEs accessing the network, number of
PDU sessions, service types and the end users distribution. Overload of
signalling in control plane and/or user data congestion in user plane will
lead underperforming network. Besides, allocating excessive resources for
network slice with light load will decrease resource efficiency.
The analysis of network slice load should consider the load of services with
different characteristics (e.g., QoS information, service priority), load
distribution to derive the corresponding resource requirements. Load level and
detailed load distribution analytic result may be provided, e.g. load
distribution for different applications (probably coming from respective AFs),
different frequency layers, different RATs, different locations and/or time
periods, different NFs etc. Proportion of high loaded/light loaded cells,
NSSI, NFs etc can also be provided.
The analysis of network slice load should consider the network slice capacity,
so that the number of users and the numbers of PDU sessions setup can be
further supported by certain network slice could be analysed and predicted.
_"maxNumberofUEs"_ and _"maxNumberofConns"_ are two capacity related
requirements in the ServiceProfile in [20]. In addition, from end to end
network slice perspective, the capacity related requirements and the actual
network performance measurements also help to reflect the slice load and slice
capacity headroom.
Traffics and resources related performance measurements and UE measurements
can be utilized by MDAS producer to identify degradation of the performance
measurements and KPI documented in an SLS due to load issues and provide the
analytic reports of load analysis. For example, the analytic report for a RAN
NSSI, slice load related information may include load of DRBs and SRBs, radio
resource utilization and availability, virtual resources of RAN CU, etc. MDAS
may provide statistic or predictive results of the above load related
information and their correlations for multiple cells in certain coverage
areas and time periods. MDAS may further provide recommendations of slice RRM
Policy ratio for the analysed cells. In addition, MDAS may utilize the
analytical data of slice load analysis (as appropriate), NF load analysis, UE
mobility statistics/predictions and UE communication statistics/predictions
from NWDAF [18] to assist its network slice load analysis. The producer of
MDAS is able to, from the perspective of the management aspects, provide the
network slice load analytics report related to an NSI, a specific RAN NSSI, a
specific CN NSSI. This analytics report can be considered as an input to
support SLA assurance to perform further evaluation.
#### 6.3.2.2 Potential requirements
**REQ-NS_LOAD_ANA-1** : MDAS producer shall have the capability to provide
analytics report describing the network slice load problem.
**REQ-NS_LOAD_ANA-2** : MDAS producer shall have the capability to analyse and
predict the network slice load based on the slice capacity including the
number of users and the numbers of PDU sessions setup supported by certain
network slice.
**REQ-NS_LOAD_ANA-3** : The analytics report describing the network slide load
problem should include the following information:
> \- The identifier of the network slice load problem;
>
> \- Indication of the network slice load problem;
>
> \- The start time and end time of the network slice load problem;
>
> \- The type of network slice load problem (overloaded or underutilized);
>
> \- The geographical area, location (UE, gNB, or UPF), domain (RAN, CN) where
> the network slice load problem exists;
>
> \- The cause(es) of network slice problem (e.g., number of UEs accessing the
> network, number of PDU sessions, service types and the end user's
> distribution);
>
> \- Root cause of the network slice load problem;
>
> \- The applications affected by the network slide load problem
>
> \- The severity level of the network slice load problem;
>
> \- The recommended actions to solve the network slice load problem.
#### 6.3.2.3 Possible solutions
##### 6.3.2.3.1 Solution description
_The MDAS_ producer correlates and analyzes the ongoing and/or potential
network slice load problem based on the the current and historical performance
data related to resource usage and network traffic for the target network
slice. The slice load is a comprehensive result. Various factors may impact
the network slice load, e.g. number of UEs accessing the network, number of
QoS flows, the resource utilizations of different NFs which is related with
the network slice instance. The analysis of network slice load should consider
the load of services with different characteristics (e.g., QoS information,
service priority), load distribution to derive the corresponding resource
requirements. To identify degradation of the KPIs documented in an SLS due to
load issues, traffics and resources related performance measurements and UE
measurements can be utilized. Note that this solution covers both domain
specific and cross-domain load problem analysis scenarios. Based on the
analysis above, the MDAS producer is able to provide the analytics report as
defined in 6.3.2.3.5 related with the network slice load analytics triggered
by event or periodically.
##### 6.3.2.3.2 Required data for network slice load analysis for cross domain
For cross domain analysis, the RAN and CN domain required data as described in
6.3.2.3.3 and 6.3.2.3.4 may be also needed, as well as the potential data
described in the following table.
+----------------------+----------------------+----------------------+ | **Input data** | **Data type** | **Description** | +======================+======================+======================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [2]. MDAS | | | | uses this | | | | information to | | | | identify target | | | | network slices for | | | | network slice load | | | | analytics and may | | | | derive network | | | | topology information | | | | according to | | | | S-NSSAI. | +----------------------+----------------------+----------------------+ | Performance | Measurement data | End-to-end Latency | | measurement | | of 5G Network: | | | | "End-to-end Latency | | | | of 5G Network" as | | | | defined in clause | | | | 6.3.1, TS 28.554 | | | | [4]; | | | | | | | | UE throughput: The | | | | IP throughput of end | | | | users, see clause | | | | 5.1.1.3 of TS 28.552 | | | | [3]; | | | | | | | | Throughput for | | | | network slice | | | | instance: | | | | Upstream/Downstream | | | | throughput for | | | | network and Network | | | | Slice Instance, see | | | | clause 6.3.2 and | | | | clause 6.3.3 of TS | | | | 28.554 [4]; | | | | | | | | Virtualised resource | | | | utilization of | | | | Network Slice | | | | Instance, see clause | | | | 6.4.2 of TS 28.554 | | | | [4] | +----------------------+----------------------+----------------------+ | MDT Data | Measurement data | UE measurements | | | | related to RSRP, | | | | RSRQ, SINR and UE | | | | location | | | | information, see TS | | | | 37.320 [12]. | +----------------------+----------------------+----------------------+ | Capacity planning | Use case and | Capacity management | | data | procedures | use case and | | | | procedure, see | | | | clause 5.4.15 of | | | | TS28.530 [5] and | | | | clause 7.15 of | | | | TS28.531[6]. | +----------------------+----------------------+----------------------+ | Network topology | Network topology | The topology of the | | | data | network for network | | | | slice load | | | | analytics. | +----------------------+----------------------+----------------------+
Note: The above parameters may not be the complete list.
##### 6.3.2.3.3 Required data for network slice load for RAN domain
The management data required to analyze the network slice load for RAN domain
are defined as the following table.
+----------------------+----------------------+----------------------+ | **Input data** | **Data type** | **Description** | +======================+======================+======================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [2]. MDAS | | | | uses this | | | | information to | | | | identify target | | | | network slices for | | | | network slice load | | | | analytics and may | | | | derive network | | | | topology information | | | | according to | | | | S-NSSAI. | +----------------------+----------------------+----------------------+ | Performance | Measurement data | RAN domain | | measurement | | measurement data: | | | | | | | | RAN UE throughput: A | | | | KPI that shows how | | | | NG-RAN impacts the | | | | service quality | | | | provided to an | | | | end-user, see clause | | | | 6.3.6 of TS 28.554 | | | | [4]; | | | | | | | | Radio resource | | | | utilization: The | | | | usage of physical | | | | radio resource | | | | utilization of the | | | | network, see clause | | | | 5.1.1.2 of TS | | | | 28.552[3]; | | | | | | | | Performance | | | | measurement data for | | | | gNB as defined in | | | | clause 5.1 of TS | | | | 28.552 [3]; | +----------------------+----------------------+----------------------+ | MDT Data | Measurement data | UE measurements | | | | related to RSRP, | | | | RSRQ, SINR and UE | | | | location | | | | information, see TS | | | | 37.320 [12]. | +----------------------+----------------------+----------------------+ | Capacity planning | Use case and | Capacity management | | data | procedures | use case and | | | | procedure, see | | | | clause 5.4.15 of | | | | TS28.530 [5] and | | | | clause 7.15 of | | | | TS28.531[6]. | +----------------------+----------------------+----------------------+ | Network topology | Network topology | The topology of the | | | data | network for network | | | | slice load | | | | analytics. | +----------------------+----------------------+----------------------+
Note: The above parameters may not be the complete list.
##### 6.3.2.3.4 Required data for network slice load for CN domain
The management data required to analyze the network slice load for CN domain
are defined as the following table.
+----------------------+----------------------+----------------------+ | **Input data** | **Data type** | **Description** | +======================+======================+======================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [2]. MDAS | | | | uses this | | | | information to | | | | identify target | | | | network slices for | | | | network slice load | | | | analytics and may | | | | derive network | | | | topology information | | | | according to | | | | S-NSSAI. | +----------------------+----------------------+----------------------+ | Performance | Measurement data | CN domain | | measurement | | measurement data | | | | | | | | User subscription | | | | data by performance | | | | measurement for AMF | | | | as defined in clause | | | | 5.2 of TS 28.552 | | | | [3]; | | | | | | | | Performance | | | | measurement data for | | | | SMF as defined in | | | | clause 5.3 of TS | | | | 28.552 [3]; | | | | | | | | Performance | | | | measurement data for | | | | UPF as defined in | | | | clause 5.4 of TS | | | | 28.552 [3]; | | | | | | | | Performance | | | | measurement data for | | | | NF as defined in | | | | clause 5.7 of TS | | | | 28.552 [3]; | | | | | | | | Throughput at N3 | | | | interface: | | | | Upstream/Downstream | | | | GTP data throughput | | | | at N3 interface, see | | | | clause 6.3.4 and | | | | clause 6.3.5 of TS | | | | 28.554 [4]; | +----------------------+----------------------+----------------------+ | Capacity planning | Use case and | Capacity management | | data | procedures | use case and | | | | procedure, see | | | | clause 5.4.15 of | | | | TS28.530 [5] and | | | | clause 7.15 of | | | | TS28.531[6]. | +----------------------+----------------------+----------------------+ | Network topology | Network topology | The topology of the | | | data | network for network | | | | slice load | | | | analytics. | +----------------------+----------------------+----------------------+
Note: The above parameters may not be the complete list.
##### 6.3.2.3.5 Analytics report for network slice load analysis
Following table provides the potential information of the domain specific or
cross domain analytics report for network slice load analysis based on the
required data received as described in 6.3.2.3.2, 6.3.2.3.3 and 6.3.2.3.4.
**Analytics Report of resource utilization analysis** **Attribute Name**
**Description**
* * *
                                                          Network slice load problem identifier     The identifier indicates the network slice load problem
                                                          Type of network slice load problem        Indicates the type of the network slice load problem, e.g., ongoing/potential or overload/underutilized network slice load problem
                                                          Time period                               Describes the time period(s) during which the network slice load problem has happened or is going to happen
                                                          Slice load level and distribution         Describes the detailed load distribution e.g., load distribution for different applications (probably coming from respective AFs), different frequency layers, different RATs, different locations and/or time periods, different NFs etc.
                                                          Slice load information                    Describes the load of the following resources in the network slice: DRBs and SRBs, radio resource utilization and availability, virtual resources of RAN CU, etc
                                                          Slice load statistics                     Describes the load statistics of the above resources and their correlated results in terms of coverage and time periods
                                                          Slice load predictive results             Describes the load predictive results of the above resources and their correlations in terms of coverage and time periods
                                                          Indication of network slice load demand   "Indicates, for each time period, that the network slice is overutilized (load is too high) or underutilized (load is too low)
                                                          Percentage of network slice load demand   Describes how much of the slice load capacity is either overloaded or underutilized in each time period
                                                          List of network entities                  Lists the network entities involved in the network slice load problem
                                                          Recommended actions                       Describes the recommended actions to solve the network slice load problem
### 6.3.3 Service experience analysis
#### 6.3.3.1 Use case
In 5G network, the variety of the services provided to the verticals is an
important feature. The network requirements which support different services
may vary a lot. For example, the users who require URLLC service have high
requirements on the network latency and reliability, while the users who
require NB-IoT service considers the maximum access UE numbers as the first
priority for network requirement. The analysis of service experience of
different vertical consumers is important to support the SLA assurance from
the network aspect.
The UE level's experience analysis based on the information from AF provided
by NWDAF, e.g., the service MOS may be utilized by MDAS producer as one of the
service performance inputs. The network performance measurements from RAN,
e.g., the UE IP throughput, coverage, latency, successful handover ratio, etc.
and network performance measurements from core network could also be used by
MDAS producer for the analysis of service fulfilment by the network. Resource
utilization efficiency may impact the user quality of service experience as
described in clause 6.2.2. The analytics information from combining the user
quality of service experience and, network performance and network resource
utilisation analysis could be made available to operators or verticals for
further action and analysis. For example, root cause for service deteriorating
and recommendation actions may be provided by MDAS producer if some of the SLA
requirements cannot be achieved, operators could perform the network
optimization actions when needed. The MDAS producer may also coordinate with
other management services producer to perform close loop SLA assurance of the
network under the operator configured policies.
#### 6.3.3.2 Potential requirements
**REQ-Ser_Exp_CON-1** The MDAS producer should have a capability to provide
the analytics report on service experience analysis
**REQ- Ser_Exp _CON-2** The analytics report describing the service experience
should contain the following information describing the service experience
aspects and potentially future prediction:
> \- The predictive service experience or observed service experience
> statistics, may split into subcounters in different levels, e.g. per
> S-NSSAI, per 5QI, per UE etc;
>
> \- Service experience indication and root cause analysis;
#### 6.3.6.3 Possible solutions
##### 6.3.6.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to provide service experience analysis and identify the
root cause. As the table in 6.3.6.3.3 shows, the analytics report is able to
be provided by the MDAS producer to describe the service experience issue,
root causes and recommendations. This procedure may be triggered by the
request or periodically.
##### 6.3.6.3.2 Data required for service experience analysis
Following table shows the potential data required to analyse the service
experience analysis.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Packet delay: The average and | | | distribution of DL/UL packet delay | | | between UPF and UE, see clause 5.4.9 of | | | TS 28.552[8] | | | | | | UE throughput: Average and distribution | | | of DL/UL UE throughput in gNB, see | | | clause 5.1.1.3 of TS 28.552[8]; | | | | | | RAN UE throughput: A KPI that shows how | | | NG-RAN impacts the service quality | | | provided to an end-user, see clause | | | 6.3.6 of TS 28.554 [7]. | | | | | | Throughput for network slice instance: | | | Upstream/Downstream throughput for | | | network and Network Slice Instance, see | | | clause 6.3.2 and clause 6.3.3 of TS | | | 28.554 [7]; | +--------------------------+------------------------------------------+ | MDT Data | UE measurements related to RSRP, RSRQ, | | | SINR, packet delay and UE location | | | information. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | | | | | | The App data which shows the end user | | | experience. | +--------------------------+------------------------------------------+ | Analytics Data | NWDAF analytical data: Slice QoE, see | | | clause 6.3 of TS 23.288 [18] | | | | | | NWDAF analytical data: Observed Service | | | Experience and/or observed Service MoS, | | | see clause 6.4 of TS 23.288 [18] | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.6.3.3 Analytics report for service experience analysis
Following table shows the potential information of the domain specific or
cross domain analytics report for service experience analysis based on the
required data received as described in 6.3.6.3.2.
**Analytics Report of service experience** **Attribute Name** **Description**
* * *
                                               Service experience identifier           The identifier indicates the analytics report is related with service experience analysis.
                                               Managed Objects of service experience   The object instances where the service experience is applicable, e.g., SubNetwork Instance, NetworkSlice Instance, S-NSSAI.
                                               Service experience level                The level of service experience, e.g. there are five levels which represented by 1, 2, 3, 4, 5 where level 1 represents the users are endures bad experience while level 5 represent the users requirements are perfectly satisfied.
                                               Info of service experience              Statistics or predictions of the service experience, may be analysed in different levels, e.g. per S-NSSAI, per network slice, per network slice subnet, per 5QI, per UE etc.
                                               Root cause                              The root cause of the service experience issues, e.g., unstable handover successful rate, high latency, low QoS retainability etc.
### 6.3.4 Network slice throughput analysis
#### 6.3.4.1 Use case
Throughput is of great importance which represents the end users' experiences
and also reflects the network problems, e.g., low UE throughput may be caused
by the resource shortage.
In order to satisfy the requirements of _dL/ulThptPerSlice_ in the
_ServiceProfile_ , MDAS may be utilized for throughput related
analysis/predictions for, network slice instance. The related performance
measurements in 28.552 [2] and KPIs in 28.554 [3] are utilized as the input
data for analysis.
MDAS producer should have the capability to detect potential throughput issues
and identify the root cause to assist throughput assurance. Network slice
throughput analysis can be for a specific domain or for cross-domain. It is
expected that 3GPP Cross Domain MDAS producer provides the federated
throughput analytics report and Domain MDAS producer provides the domain
specific throughput analysis. These two levels of MDAS producers worked in a
coordinated way to assure the throughput performance.
The CSC concerns the statistics or predictions of subscribers' DL/UL
throughput for the network slice, e.g. average percentage of users, for which
the required SLS throughput is met or the average percentage of time, during
which the required SLS throughput is, or could be, met. The 3GPP Cross Domain
MDAS producer may indicate whether the problem is caused by NG-RAN or CN. In
general, NG-RAN is the bottleneck because of the limited radio resources and
complicated wireless radio conditions. In this case, resource reconfigurations
may be needed to resolve the throughput degradation issue. To identify the
root causes, RAN Domain MDAS Producer may collect radio resource related
configurations and measurements, radio condition related measurements and
throughput related measurements.
The producer of MDAS is able to, from the perspective of the management
aspects, provide the network slice throughput analytics report. This analytics
report can be considered as an input to support SLS assurance to perform
further evaluation.
#### 6.3.4.2 Potential requirements
**REQ-THP_CON-1** The MDAS producer should have a capability to provide the
analytics report on network slice throughput.
**REQ-THP_CON-2** The analytics report of the network slice throughput should
contain the following information:
> \- Network slice throughput statistics/predictions;
>
> \- Root cause analysis of network slice throughput degradation;
#### 6.3.4.3 Possible solutions
##### 6.3.4.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to provide network slice throughput
statistics/predictions, identification of throughput degradation issues and
the root cause as the table in 6.3.4.3.5 shows. This procedure may be
triggered by the request or periodically.
##### 6.3.4.3.2 Data required for network slice throughput
statistics/predictions for RAN domain
Following table shows the potential data required to analyse the network slice
throughput for RAN domain.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Packet Delay, see clause 5.1.1.1.1 in TS | | | 28.552 [8]; | | | | | | UE throughput, see clause 5.1.1.3 of TS | | | 28.554 [7]; | | | | | | RAN UE throughput, KPI shows how NG-RAN | | | impacts the service quality provided to | | | an end-user, see clause 6.3.6 of TS | | | 28.554 [7]; | | | | | | Throughput at N3 interface, | | | Upstream/Downstream GTP data throughput | | | at N3 interface, see clause 6.3.4 and | | | clause 6.3.5 of TS 28.554 [7]; | | | | | | Radio resource utilization, the usage of | | | physical radio resource utilization of | | | the network, see clause 5.1.1.2 of TS | | | 28.552[8]. | +--------------------------+------------------------------------------+ | MDT Data | UE measurements related to RSRP, RSRQ, | | | SINR and UE location information. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. The | | | data comes from the provisioning MnS | | | provider, e.g., the configured | | | ServiceProfile. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.4.3.3 Data required for network slice throughput
statistics/predictions for CN domain
Following table shows the potential data required to analyse the network slice
throughput for CN domain.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Throughput at N3 interface, | | | Upstream/Downstream GTP data throughput | | | at N3 interface, see clause 6.3.4 and | | | clause 6.3.5 of TS 28.554 [7]; | | | | | | Number of incoming/outgoing GTP data | | | packets on the N3 interface, see clause | | | 5.4.1.1 and 5.4.1.2 of TS 28.552 [8]. | | | | | | Number of octets of incoming/outgoing | | | GTP data packets on the N3 interface, | | | see clause 5.4.1.3 and 5.4.1.4 of TS | | | 28.552 [8]. | | | | | | Virtualised resource usage measurement, | | | see clause 6.2 of TS 28.552 [8]. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. The | | | data comes from the provisioning MnS | | | provider, e.g., the configured | | | ServiceProfile. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.4.3.4 Data required for network slice throughput
statistics/predictions for cross domain
For cross domain analysis, the RAN and CN domain required data as described in
6.3.4.3.2 and 6.3.4.3.3 may be also needed, as well as the potential data
described in the following table.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Latency of 5G Network, see clause 6.3.1 | | | of TS 28.554 [7]; | | | | | | Throughput for network slice instance, | | | see clause 6.3.2 of TS 28.554 [7]; | | | | | | Upstream/Downstream throughput for | | | network and Network Slice Instance, see | | | clause 6.3.3 of TS 28.554 [7]. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. The | | | data comes from the provisioning MnS | | | provider, e.g., the configured | | | ServiceProfile. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.4.3.5 Analytics report for network slice throughput analysis
Following table shows the potential information of the domain specific or
cross domain analytics report for network slice throughput analysis based on
the required data received as described in 6.3.4.3.2, 6.3.4.3.3 and 6.3.4.3.4.
+----------------------+----------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of network slice | | | | throughput** | | | +======================+======================+======================+ | | Network slice | The identifier of | | | throughput issue | the network slice | | | identifier | throughput issues; | +----------------------+----------------------+----------------------+ | | Network slice | Average percentage | | | throughput | of users, for which | | | st | the required SLS | | | atistics/predictions | throughput is, or | | | | could be, met. | | | | | | | | Average percentage | | | | of time, during | | | | which the required | | | | SLS throughput is, | | | | or could be, met. | +----------------------+----------------------+----------------------+ | | Root cause | The root cause of | | | | the network slice | | | | throughput | | | | degradation issues, | | | | e.g. PRB resource | | | | shortage; | +----------------------+----------------------+----------------------+ | | Recommended actions | The recommend | | | | actions to solve the | | | | network slice | | | | throughput | | | | degradation issues. | +----------------------+----------------------+----------------------+
### 6.3.5 Uplink/downlink throughput per UE in network slice analysis
#### 6.3.5.1 Use case
Uplink/downlink throughput per UE in network slice is one of the SLA
parameters. Data rate in uplink and downlink should be guaranteed to assure
quality experience of UE using specific network slice.
UE uplink/downlink throughput could be impacted by the network capability and
network configurations, e.g. configuration of service priority, RAN capacity,
network load, number of UE in one TA, Wireless channel environment and the
processing time of the network functions, etc. These factors may be the root
cause if the UE uplink/downlink throughput requirements cannot be achieved.
There are some mechanisms to assure UE uplink/downlink throughput, e.g. to
upgrade the service priority, allocate or reserve more network resource.
From the management perspective, resource configuration and allocation
algorithms or policies should support UE uplink/downlink throughput assurance.
MDAS can be utilized to provide UE uplink/downlink throughput analysis to
support SLS assurance.
#### 6.3.5.2 Potential requirements
**REQ-UETHROUGHPUT_ASS-CON-1** : MDAS producer shall have the capability to
provide analytics report describing the UE uplink/downlink throughput problem.
**REQ-UETHROUGHPUT_ASS-CON-2** : The analytics report describing the UE
uplink/downlink throughput problem should include the following information:
> \- The identifier of the UE uplink/downlink throughput issue;
>
> \- Indication of UE uplink/downlink throughput issue type;
>
> \- The start time and end time of the UE uplink/downlink throughput issue;
>
> \- The geographical area and location where the UE uplink/downlink
> throughput issue exists;
>
> \- Root cause of the UE uplink/downlink throughput issue;
>
> \- The objects affected by the UE uplink/downlink throughput issue;
>
> \- The severity level of the UE uplink/downlink throughput issue;
>
> \- The recommended actions to solve the UE uplink/downlink throughput issue.
#### 6.3.5.3 Possible solutions
##### 6.3.5.3.1 Solution description
_The performance measurements, e.g., UE throughput, network resource
utilization can be utilized for_ UE uplink/downlink throughput _analysis. To
support_ UE uplink/downlink throughput _assurance_ in order to satisfy the
throughput per UE requirements from the vertical users, MDAS producer is able
to provide the analytics report as defined in 6.3.5.3.3 related with UE
uplink/downlink throughput analytics triggered by event or periodically.
##### 6.3.5.3.2 Required data for UE uplink/downlink throughput analysis
The management data required to analyze the UE uplink/downlink throughput are
defined as the following table.
+------------------------+------------------+------------------------+ | **Input data** | **Data type** | **Description** | +========================+==================+========================+ | S-NSSAI | Service data | "S-NSSAI" as defined | | | | in clause 5.15.2, TS | | | | 23.501 [13]. MDAS | | | | may derive network | | | | topology information | | | | according to S-NSSAI | +------------------------+------------------+------------------------+ | Performance | Measurement data | UE throughput: The IP | | measurement | | throughput of end | | | | users, see clause | | | | 5.1.1.3 of TS 28.552 | | | | [8]; | | | | | | | | RAN UE throughput: A | | | | KPI that shows how | | | | NG-RAN impacts the | | | | service quality | | | | provided to an | | | | end-user, see clause | | | | 6.3.6 of TS 28.554 | | | | [7]; | | | | | | | | Throughput for network | | | | slice instance: | | | | Upstream/Downstream | | | | throughput for network | | | | and Network Slice | | | | Instance, see clause | | | | 6.3.2 and clause 6.3.3 | | | | of TS 28.554 [7]; | | | | | | | | Throughput at N3 | | | | interface: | | | | Upstream/Downstream | | | | GTP data throughput at | | | | N3 interface, see | | | | clause 6.3.4 and | | | | clause 6.3.5 of TS | | | | 28.554 [7]; | | | | | | | | Radio resource | | | | utilization: The usage | | | | of physical radio | | | | resource utilization | | | | of the network, see | | | | clause 5.1.1.2 of TS | | | | 28.552[8]; | | | | | | | | CQI related | | | | measurements: the | | | | distribution of | | | | Wideband CQI (Channel | | | | Quality Indicator) | | | | reported by UEs in the | | | | cell, see clause | | | | 5.1.1.11 of TS 28.552 | | | | [8]; | | | | | | | | MCS related | | | | Measurements: the | | | | distribution of the | | | | MCS scheduled for | | | | PDSCH RB by NG-RAN, | | | | the distribution of | | | | the MCS scheduled for | | | | PUSCH RB by NG-RAN, | | | | see clause 5.1.1.12 in | | | | TS 28.552 [8]; | +------------------------+------------------+------------------------+ | MDT Data | Measurement data | UE measurements | | | | related to RSRP, RSRQ, | | | | SINR and UE location | | | | information, see TS | | | | 37.320 [12]. | +------------------------+------------------+------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.5.3.3 Analytics report for UE uplink/downlink throughput analysis
Following table provides the potential contents of the analytics report of UE
uplink/downlink throughput analysis.
**Analytics Report of UE uplink/downlink throughput analysis** **Attribute
Name** **Description**
* * *
                                                                   SLS assurance issue Identifier           The identifier indicates the SLS assurance issue
                                                                   Indication of SLS assurance issue type   Indicates the type of the SLS assurance issue, e.g.,
                                                                   Location                                 The geographical area and location where the UE uplink/downlink throughput issue exists
                                                                   Start time                               The start time of the UE uplink/downlink throughput issue
                                                                   Stop time                                The stop time of the UE uplink/downlink throughput issue
                                                                   Root cause                               The root cause of the UE uplink/downlink throughput degradation, e.g. coverage issue, load issue in RAN, load issue in CN, low throughput in RAN, low throughput in CN etc.
                                                                   Affected objects                         The MOIs of cells, subnetwork or network slices affected by the UE uplink/downlink throughput issue;
                                                                   Severity level                           The severity level (e.g., critical, medium, not important) of the UE uplink/downlink throughput issue;
                                                                   Recommended actions                      The recommended actions to solve the UE uplink/downlink throughput issue, e.g.,
Editor's Note: Quantification of severity levels is FFS.
### 6.3.6 KPI anomaly analysis
#### 6.3.6.1 Use case
KPI(s) are of great importance for network operators to monitor the key
performance of the network. For 5G and beyond, a large amount of KPIs are
defined in TS 28.554 [7]. The correlations between different KPIs are
complicated and it is hard to monitor the KPI(s) manually. Also, how to assign
each KPI threshold is a big challenge for network operators, since each KPI
threshold should not be a fixed value considering many factors such as network
capacity, service types, end user's experiences, etc. In addition, the
criteria to determine whether a KPI is anomalous also depends on a variety of
requirements.
MDAS is expected to have the capability to analyze KPI(s) for both cross
domain and single domain. 3GPP Cross Domain MDAS producers may coordinate with
domain MDAS producer to identify the anomalous KPI(s) and the corresponding
root cause(s). The KPI anomaly analysis should consider both a single KPI and
KPI correlations of different domains. For cross domain KPI anomaly analysis,
KPIs or KPI analytical report from each domain should be collected. The MDAS
producer should also be able to identify anomalous network situations. A
network situation can be characterized as a combination of KPIs with respect
to a predefined context that includes time, location, amount of traffic, user
characteristics, etc.
MDAS is also expected to have the capability to detect and predict the
anomalous KPI(s) and anomalous network situations in different levels e.g. per
S-NSSAI, per NSI or per NSSI, etc. The detection and prediction of single KPI
anomaly and in relation with multiple correlated KPIs anomaly may be involved.
The detection and prediction may also involve a single or multiple KPIs in
relation with a network situation. By utilizing Machine learning technology,
historical KPI data and performance data may also be used as the input to
perform the ML model training. Besides, along with the KPI or network
situation anomaly identification and root cause analysis, MDAS may also
recommend more appropriate network configurations to optimize and resolve the
KPI anomaly issue and improve the slice QoE.
The KPI anomaly analysis is also expected to have the capability to analyse
the correlations between SLS and KPIs or network situations according to
service model and identify the most relevant anomalous KPIs and network
situations, which cause the SLS degradation, this corresponding analytics
report can be considered as an input to support further SLS assurance.
#### 6.3.6.2 Potential requirements
**REQ-KPI_ANOMALY_CON-1** The MDAS producer should have a capability to
provide the analytics report on KPIs anomaly analysis.
**REQ- KPI_ANOMALY_CON-2** The analytics report describing the KPIs anomaly
should contain the following information describing the KPI anomaly aspects
and potentially future prediction:
> \- The predictive anomaly KPI(s) or observed anomaly KPI(s), may split into
> subcounters in different levels, e.g. per S-NSSAI, per NSI, per NSSI, per
> 5QI, per UE etc;
>
> \- KPI anomaly indication and root cause analysis;
>
> \- Cross domain and domain KPI anomaly analysis;
>
> \- The recommendations for the configurations of network resource and KPI
> threshold.
**REQ- KPI_ANOMALY_CON-3** The MDAS producer should have a capability to
provide the analytics report that identifies a possible anomalous KPIs with
respect to network situations for a particular network location and network.
#### 6.3.6.3 Possible solutions
##### 6.3.6.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to provide KPI anomaly analysis and identify the root
cause. The required data can be from RAN domain or CN domain or both. As the
table in 6.3.6.3.4 shows, the analytics report is able to be provided by the
MDAS producer to describe the KPI anomaly issue, root causes and
recommendations. This procedure may be triggered upon request or periodically.
##### 6.3.6.3.2 Data required for KPI anomaly analysis for RAN domain
Following table shows the potential data required to analyse the RAN domain
KPI anomaly.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Radio resource utilization: The usage of | | | physical radio resource utilization of | | | the network, see clause 5.1.1.2 of TS | | | 28.552[8]; | | | | | | Performance Measurements for gNB: for | | | example, for RRC connection related KPI | | | anomaly analysis, see clause 5.1, TS | | | 28.552[8], e.g., RRC connection | | | number, RRC connection establishment, | | | RRC connection re-establishment, RRC | | | connection resuming; | | | | | | RAN UE throughput: A KPI that shows how | | | NG-RAN impacts the service quality | | | provided to an end-user, see clause | | | 6.3.6 of TS 28.554 [7]. | +--------------------------+------------------------------------------+ | MDT Data | UE measurements related to RSRP, RSRQ, | | | SINR and UE location information. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration data | The execution data including the changes | | | or the configuration of the MOIs. | +--------------------------+------------------------------------------+ | Context data | The information on the conditions | | | applicable to the data considered for | | | analytics, e.g. time of day, season or | | | event in relation to location. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.6.3.3 Data required for KPI anomaly analysis for CN domain
Following table shows the potential data required to analyse the CN domain KPI
anomaly.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Performance Measurements for AMF: for | | | example, for number of registered | | | subscribers related KPI anomaly | | | analysis, see clause 5.2.1, TS | | | 28.552[8]; | | | | | | Performance Measurements for SMF: for | | | example, for PDU session management | | | related KPI anomaly analysis, see clause | | | 5.3.1, TS 28.552[8]; | | | | | | Throughput at N3 interface: KPI related | | | to Upstream/Downstream GTP data | | | throughput at N3 interface, see clause | | | 6.3.4 and clause 6.3.5 of TS 28.554 | | | [7]; | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.6.3.4 Data required for KPI anomaly analysis for cross domain
For cross domain analysis, the RAN domain and CN domain required data as
described in 6.3.6.3.2 and 6.3.6.3.3 may be needed, as well as the potential
data described in the following table.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | Throughput for network slice instance: | | | Upstream/Downstream throughput for | | | network and Network Slice Instance, see | | | clause 6.3.2 and clause 6.3.3 of TS | | | 28.554 [7]; | | | | | | NWDAF analytical data: Slice QoE, see | | | clause 6.4 of TS 23.288 [18]. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration data | The execution data including the changes | | | or the configuration of the MOIs. | +--------------------------+------------------------------------------+ | Context data | The information on the conditions | | | applicable to the data considered for | | | analytics, e.g. time of day, season or | | | event in relation to location. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.3.6.3.5 Analytics report for KPI anomaly analysis
Following table shows the potential information of the domain specific or
cross domain analytics report for KPI anomaly analysis based on the required
data received as described in 6.3.6.3.2, 6.3.6.3.3 and 6.3.6.3.4.
**Analytics Report of network slice KPI anomaly** **Attribute Name**
**Description**
* * *
                                                      KPI anomaly identifier             The identifier of the KPI anomaly;
                                                      Anomalous KPI Name                 The name of the KPI(s) which is identified or predicted as anomalous, the KPI name refers to bullet a) in TS28.554 (7);
                                                      Managed Objects of anomalous KPI   The object instances where the KPI is applicable, e.g., SubNetwork Instance, NetworkSlice Instance
                                                      Info of KPI anomaly                Statistics or predictions of the anomalous KPIs, may concern single KPI or multiple correlated KPIs, and may split into subcounters at different levels, e.g. per S-NSSAI, per NSI, per NSSI, per 5QI, per UE etc.
                                                      Root cause                         The root cause of the network slice KPI anomaly issues, e.g., unstable handover successful rate, low PRB utilization, low QoS retainability.
##### 6.3.6.3.6 Analytics report for network situation analysis
Following table shows the potential information of the domain specific or
cross domain analytics report based on the required data received as described
in 6.3.6.3.2, 6.3.6.3.3, and 6.3.6.3.4.
**Analytics Report on network situations** **Attribute Name** **Description**
* * *
                                               Network situation identifier           The identifier of the possible network situations .
                                               Network situation description          The network performance, QoE and UE location and context data that describe a network situation .
                                               Network situations anomaly status      The status of a network situation. This may be a simple binary function that indicates a normal or anomalous status.
                                               Severity level                         Describes the degree of anomaly (low, medium, high).
                                               Location                               Geographical location of anomalous network situations
                                               Managed Objects of network situation   The object instances, e.g., cell, carrier.
                                               Type of analytics                      Statistics or predictions of the anomalous situation.
### 6.3.7 Jitter analysis
#### 6.3.7.1 Use case
In addition to E2E latency, some new network services have extra new demands
for SLA parameters. In extreme business scenarios such a V2X and telemedicine,
network jitter also needs to be satisfied. Jitter assurance with high
certainty becomes a new dimension of end-to-end delay-sensitive service
quality.
The analysis of jitter does not cover the entire network, but the analysis
should consider the whole process of data frame and also the definition of
different network layers. It could be impacted by the configuration of clock
synchronization, traffic forwarding, bandwidth reservation and latency etc. In
some circumstances, it will also be affected by the external environment,
which can only be resolved non-automatically.
The performance measurements and measurements related to data forwarding
mechanisms can be used by the MDAS producer to generate a jitter analysis
report. For example, in some network node, one particular data flow can have
bandwidth competition with normal data flow which causes high network jitter.
The MDAS will first analyse the bandwidth resource and provide bandwidth
reservation modification so that it can satisfy network performance
requirement of this particular data flow. Jitter is also related to E2E
latency parameter, the jitter analysis will then need to be cross-domain, e.g.
RAN domain, core network domain transport network domain. The jitter analysis
from the multiple domains may be combined to calculate the end-to-end jitter,
which can be checked against end-to-end SLA requirements. The jitter analysis
will reference the E2E analysis result to support SLS assurance. In case of
excessive end-to-end jitter, the jitter analysis from each domain may be used
to identify the likely source of problems.
#### 6.3.7.2 Potential requirements
**REQ-JITTER_ASS-CON-1** : MDAS producer shall have the capability to provide
analytics report describing the jitter problem.
**REQ-JITTER_ASS-CON-2** : The analytics report describing the jitter problem
should include the following information:
> \- The identifier of the jitter issue;
>
> \- Indication of jitter issue type;
>
> \- The start time and end time of the jitter issue;
>
> \- The geographical area and location where the jitter issue exists;
>
> \- Root cause of the jitter issue;
>
> \- The objects affected by the jitter issue;
>
> \- The severity level of the jitter issue;
>
> \- The recommended actions to solve the jitter issue.
## 6.4 Fault management related issues
### 6.4.1 Alarm incident analysis
#### 6.4.1.1 Use case
In 5G network, millions of alarms are generated due to the network complexity.
Since the topological relations between different network elements and logical
relations between different generated alarms, a series of alarms caused by a
same root cause should be correlated with each other. In addition, the same
root causes may give rise to the network performance deterioration. For
example, an alarm in a lower layer of the communication protocol stack or an
alarm related to virtualized resource in the virtualization deployment
environment may cause multiple alarms in higher layers. Sequence of alarms may
be generated in multiple domains along a communication link if one fault in
the source domain occurs.
Large amount of alarms brings difficulties in network operation and
maintenance. Therefore, the alarms and deteriorated performance measurements
of same root cause should be correlated and analysed. Some ML models and
algorithms may be used to group or filter the correlated alarms and indicate
the root cause. Also, the historical alarms, performance measurements and
network topology data can be utilized as the foreknowledge.
To improve the efficiency of network operation and maintenance, the MDAS
producer is able to provide the analytics result including the root alarm or
root cause by correlate and group the related alarms and performance
measurements into an alarm incident.
#### 6.4.1.2 Potential requirements
**REQ-ALARM_MDA-01:** The MDAS producer shall have a capability to provide the
analytics report describing the alarm incident analysis.
**REQ-ALARM_MDA-02:** The analytics report describing the alarm incident
should include the following information:
> \- Alarm incident Identifier
>
> \- List of Correlated Alarms, performance measurements
>
> \- The start time and end time of the Alarm incident
>
> \- The root cause or root alarm of the Alarm incident
>
> \- Severity level
>
> \- Affected objects
>
> \- Recommended actions
#### 6.4.1.3 Possible Solutions
##### 6.4.1.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to identify the alarm incident. The required data can be
from RAN domain or CN domain or both. As the table in 6.4.1.3.4 shows, the
analytics report is able to be provided by the MDAS producer to describe the
root causes and recommendations of identified alarm incident. It can be a
domain specific or cross domain analytics report. This procedure may be
triggered by the request or periodically.
##### 6.4.1.3.2 Data required for alarm incident analysis for RAN domain
Alarm data and performance measurements from correlated logical and physical
resources are able to be utilized to perform the alarm incident analysis. The
data listed in following table are the potential management data for RAN
domain used to construct the alarm incident.
Table 6.4.1.3.2-1: Potential data required for alarm incident analysis
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Alarm Data | The alarm information, e.g., the alarm | | | of NG-U, the alarm of radio frequency | | | unit, the alarm of cell outage. | | | | | | The alarm information related to | | | virtualized resource, see clause 8 of TS | | | 28.545 [22]. | | | | | | The types of alarms are FFS. | +--------------------------+------------------------------------------+ | Performance measurements | The deteriorated performance or the | | | abnormal performance measurements based | | | on certain performance monitoring | | | threshold. Following performance | | | measurements may be used. | | | | | | UE throughput: The IP throughput of end | | | users, see clause 5.1.1.3 of TS 28.552 | | | [8]; | | | | | | PDCP Data Volume: The transmitted PDCP | | | data volume, see clause 5.1.2.1 and | | | 5.1.3.6 of TS 28.552 [8]; | | | | | | TB related measurements: The TB | | | transmitted in a cell, see clause | | | 5.1.1.7 of TS 28.552 [8]; | | | | | | CQI related measurements: the | | | distribution of Wideband CQI (Channel | | | Quality Indicator) reported by UEs in | | | the cell, see clause 5.1.1.11 of TS | | | 28.552 [8]; | | | | | | MCS related Measurements: the | | | distribution of the MCS scheduled for | | | PDSCH RB by NG-RAN, the distribution of | | | the MCS scheduled for PUSCH RB by | | | NG-RAN, see clause 5.1.1.12 in TS 28.552 | | | [8]; | | | | | | RAN UE throughput: A KPI that shows how | | | NG-RAN impacts the service quality | | | provided to an end-user, see clause | | | 6.3.6 of TS 28.554 [7]; | | | | | | Throughput for network slice instance: | | | Upstream/Downstream throughput for | | | network and Network Slice Instance, see | | | clause 6.3.2 and clause 6.3.3 of TS | | | 28.554 [7]; | | | | | | Throughput at N3 interface: | | | Upstream/Downstream GTP data throughput | | | at N3 interface, see clause 6.3.4 and | | | clause 6.3.5 of TS 28.554 [7]; | | | | | | Inter-gNB handovers: Number of | | | requested/successful handover/failed | | | handover preparations/resource | | | allocations/executions, see clause | | | 5.1.1.6.1 of TS 28.552 [8]. | | | | | | Intra-gNB handovers: Number of | | | requested/successful handover | | | executions, see clause 5.1.1.6.2 of TS | | | 28.552 [8]. | | | | | | RRC connection establishment related | | | measurements: Attempted/ successful RRC | | | connection establishments, see clause | | | 5.1.1.15 of TS 28.552 [8]. | | | | | | RRC connection Re-establishment and RRC | | | connection Resuming related measurement, | | | see clause 5.1.1.17 and 5.1.1.18 of TS | | | 28.552 [8]. | | | | | | Packet loss rate, Packet drop rate and | | | Packet delay including the average delay | | | and distribution of delay in CU-UP, | | | F1-U, gNB-DU, CU-UP both of downlink and | | | uplink. | | | | | | Virtualised resource usage measurement, | | | see clause 6.2 of TS 28.552 [8]. | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. | +--------------------------+------------------------------------------+ | Network topology | The topology of the network deployment. | +--------------------------+------------------------------------------+
Editor's Notes: The data above may not be the complete list for alarm incident
detection, other types of management data may also be utilized.
##### 6.4.1.3.3 Data required for alarm incident analysis for CN domain
Alarm data and performance measurements from correlated logical and physical
resources are able to be utilized to perform the alarm incident analysis. The
data listed in following table are the potential management data for CN domain
used to construct the alarm incident.
Table 6.4.1.3.3-1: Potential data required for alarm incident analysis
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Alarm Data | The alarm information, e.g., the alarm | | | of AMF, the alarm of UPF. | | | | | | The types of alarms are FFS. | +--------------------------+------------------------------------------+ | Performance measurements | The deteriorated performance or the | | | abnormal performance measurements based | | | on certain performance monitoring | | | threshold. Following performance | | | measurements may be used. | | | | | | Mobility related measurements for AMF: | | | Number of requested/failed PDU | | | sessions/QoS flows for inter-AMF | | | handovers and number of | | | attempted/successful/failed handover | | | between 5GS and EPC, see clause 5.2.5.1, | | | 5.2.5.3 and 5.2.5.4 of TS 28.552 [8]. | | | | | | Session related measurements for SMF: | | | Number of successful/failed PDU session | | | creation and number of | | | requested/successful/failed PDU session | | | modifications, see clause 5.3.1 of TS | | | 28.552 [8]. | | | | | | QoS flow monitoring for SMF: Number of | | | requested/successful/failed QoS flows to | | | create/modify, see clause 5.3.2 of TS | | | 28.552 [8]. | | | | | | Session related measurements for UPF: | | | Number of requested/failed N4 session | | | establishments, see clause 5.4.3.1 of TS | | | 28.552 [8]. | | | | | | Throughput for network slice instance: | | | Upstream/Downstream throughput for | | | network and Network Slice Instance, see | | | clause 6.3.2 and clause 6.3.3 of TS | | | 28.554 [7]; | | | | | | Throughput at N3 interface: | | | Upstream/Downstream GTP data throughput | | | at N3 interface, see clause 6.3.4 and | | | clause 6.3.5 of TS 28.554 [7]; | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. | +--------------------------+------------------------------------------+ | Network topology | The topology of the network deployment. | +--------------------------+------------------------------------------+
Editor's Notes: The data above may not be the complete list for alarm incident
detection, other types of management data may also be utilized.
##### 6.4.1.3.4 Analytics report for alarm incident analysis
Following table provides the potential information of the domain specific or
cross domain analytics report for alarm incident analysis based on the
required data received as described in 6.4.1.3.2 and 6.4.1.3.3.
**Analytics Report of alarm incident** **Information** **Description**
* * *
                                           Alarm Incident Identifier                          The alarm incident id or name for correlated alarms and performance measurements, e.g., NgU transmission alarm incident, Xn transmission alarm incident.
                                           List of Correlated AlarmInfo                       List of Alarm name or alarm ID, e.g., alarm of NgU setup, alarm of user plane link failure, alarm of user plane failure, alarm of cell outage.
                                           List of Correlated performance measurements info   Performance measurements and the corresponding value, e.g., NgU handover failure rate, NgU setup failure rate.
                                           Location                                           The geographical area or the cells where the alarm incident exists
                                           Start Time                                         The start time of alarm incident
                                           Stop Time                                          The end time of alarm incident
                                           Affected objects                                   The MOIs, e.g., the MOIs of cells or subnetworks or network slices affected by the alarm incident
                                           Root cause or Root alarm                           Root alarm identified or predicted by root cause decision model, e.g. alarm of NgU setup, alarm of virtualized resource failure.
                                           Severity level                                     The severity level (e.g., critical, medium, not important) of the alarm incident
                                           Recommended actions                                The recommend actions to clear the alarm incident. The recommended actions could be to replace the hardware unit, reconfigure the protocol, e.g., Xn application protocol
### 6.4.2 Fault prediction analysis
#### 6.4.2.1 Use case
In 5G network, millions of alarms are generated every day. The causes of these
alarms are usually the faults or abnormal states of the network. The current
treatment method is generally based on the alarm information analysis, to find
out the cause of the faults or abnormal states, and then determine the fault
repair method and solve the problems, so as to eliminate the alarms. Because
the amount of alarms is so large, it is a big challenge to deal with these
alarms in a timely and efficient manner.
One the other hand, when we look at it the other way, if the network can be
maintained very well so that it has fewer faults and abnormal states, then
there will be fewer alarms. This requires the system to be able to predict the
potential faults or abnormal states before they occur, and to recommend
appropriate handling actions to prevent the fault or abnormal state really
occur. In 5G network, MDAS is adopted, which is in conjunction with AI and ML
techniques. The MDAS producer may train the ML model of the MDAS by using the
historical alarms, performance measurements, configuration data and network
topology information to obtain the basic health maintenance knowledges (e.g.
the relationship between the faults or potential faults and the related
maintenance actions).
The MDAS producer monitors and analyses the performance measurements and KPIs
continuously, and provides the analytics report which includes the predictive
information of potential faults or abnormal states and corresponding
recommendation of maintenance actions to prevent the fault or abnormal state
really occur, so that the MDAS consumer can execute the recommended actions
accordingly or by taking the recommended actions into account.
The MDAS producer is informed when the recommended actions are taken by the
MDAS consumer to maintain the network health, so that the MDAS producer can
evaluate the result of the executed actions and update its basic health
maintenance knowledges.
The MDAS producer also periodically does the ML training based on the new
collected alarms, performance measurements and KPIs, configuration data, and
updates its basic health maintenance knowledges.
#### 6.4.2.2 Potential requirements
**REQ-HEALTH_MDA-01:** The MDAS producer shall have a capability to provide
the analytics report describing the fault prediction analysis results.
**REQ-HEALTH_MDA-02:** The analytics report describing the results from the
fault prediction analysis should include the detailed advice on how to
eliminate the cause of potential fault(s).
Note: The detailed advice described in the fault prediction analytics report
may include but not limited the follows:
  * List of potential faults and severity levels
  * Affected objects
  * Recommended actions
#### 6.4.2.3 Possible solutions
##### 6.4.2.3.1 Solution description
The MDAS producer analyses the management data described in the following
subclauses to identify the potential faults or abnormal states and
corresponding recommended actions. The required data can be from RAN domain or
CN domain or both.
As the table in 6.4.2.3.4 shows, the analytics report is able to be provided
by the MDAS producer to describe the analytics result and recommendations of
network health maintenance. It can be a domain specific or cross domain
analytics report. This procedure may be triggered by the request or
periodically.
##### 6.4.2.3.2 Data required for fault prediction analysis for RAN domain
Following table shows the potential data required to perform the fault
prediction analysis for RAN domain.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | RAN related performance measurements and | | | KPIs, see TS 28.552 [8] and TS | | | 28.554[7]; | | | | | | The detailed types of performance | | | measurements and KPIs are FFS | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. | +--------------------------+------------------------------------------+ | Network topology | The topology of the network deployment. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.4.2.3.3 Data required for fault prediction analysis for CN domain
Following table shows the potential data required to perform the fault
prediction analysis for CN domain.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | CN related performance measurements and | | | KPIs, see TS 28.552 [8] and TS | | | 28.554[7]; | | | | | | The detailed types of performance | | | measurements and KPIs are FFS | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs. | +--------------------------+------------------------------------------+ | Network topology | The topology of the network deployment. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.4.2.3.4 Analytics report for fault prediction analysis
Following table shows the potential information carried in the analytics
report of fault prediction analysis.
+----------------------+----------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of fault | | | | prediction** | | | +======================+======================+======================+ | | Fault prediction | The identifier of | | | analytics report | the fault prediction | | | identifier | analytics report | +----------------------+----------------------+----------------------+ | | List of potential | List of potential | | | faults | faults, including: | | | | | | | | - Fault type | | | | | | | | - Location | | | | | | | | - Severity level | | | | | | | | - Affected objects | +----------------------+----------------------+----------------------+ | | Recommended actions | The recommend | | | | actions to eliminate | | | | the causes of the | | | | potential faults | +----------------------+----------------------+----------------------+
Note: The above parameters carried in the analytics report may not be the
complete list.
## 6.5 Mobility management related issues
### 6.5.1 Handover optimization
#### 6.5.1.1 Use case
Current handover procedures are mainly based on radio conditions for selecting
the target gNB upon a handover. The target gNB accepts or rejects the handover
(HO) request depending on various conditions. In virtualized environment, the
HO may be rejected due to inadequate available resources within the target
gNB. The notion of resources may include virtual resources (e.g., compute,
memory) and/or radio resources (e.g., PRB, RRC connected users). If the HO
request is rejected, a UE will try to connect to a different gNB until the
request is successfully accepted. Several target gNBs can be tried until the
request is successfully accepted. This process can result in wastage of UE and
network resources, while it may also introduce service disruption due to
increased latency and radio link failures (RLFs). It also introduces
inefficiency in the HO or other network procedures.
To address this handover optimization issue, it is desirable to use MDAS
(Management data analytic service) to provision and/or select a particular
target gNB for handover in order to reduce or even avoid HO rejections. The
MDAS producer provides a HO optimization analytics report containing the
current and future/predicted resource consumption, resources capabilities and
other KPIs' status for the available target gNB(s). The analytics report also
provides recommended actions to optimize the target gNB for handover. This may
include resource re-configuration or the updated selection criteria for target
gNB. Based on the report, the MDAS consumer adjusts (e.g., scale-out/up the
virtual resource, re-schedule/optimize radio resource) the resources before
continuing with the handover and/or adjusts the selection criteria of the
target gNB by also considering the overlapping coverages of inter-frequency
and inter-RAT deployments.
#### 6.5.1.2 Potential requirements
**REQ-HO_OPT_CON-1** The MDAS producer should have a capability to provide the
analytics report describing the resource consumption to authorized consumers
based on the current and future virtual resource consumption of gNB.
**REQ-HO_OPT_CON-2** The MDAS producer should have a capability to provide the
analytics report describing the resource consumption to authorized consumers
based on the current and future radio resource consumption of gNB.
**REQ-HO_OPT_CON-3** The analytics report describing the resource consumption
should contain the following information describing the current and future
resource consumption:
> \- Assigned virtual, radio, and transport resources for target gNB.
>
> \- Consumed virtual, radio, and transport resources for target gNB.
>
> \- Projected virtual, radio and transport resource usage in near future for
> target gNB.
>
> \- Indication on whether the target gNB is optimal for handover.
>
> \- Recommended action to optimize the target gNB and/or the selection of the
> target gNB for handover.
**REQ-HO_OPT_CON-4** The MDAS producer should have a capability to provide an
analytics report indicating a selection priority for the target cell, among a
set of candidate inter-frequency cells.
**REQ-HO_OPT_CON-5** The MDAS producer should have a capability to provide an
analytics report indicating a list of target cells to spare, i.e. avoid, a
handover for an indicated time period.
**REQ-HO_OPT_CON-6** The analytics report describing inter-frequency target
cell selection for handover may provide information for provisioning or
selecting a target gNB with respect to a specific service or slice, if the
same Network Slice Instance (NSI) is available in both the current and target
gNB.
**REQ-HO_OPT_CON-7** The analytics report describing inter-frequency target
cell selection for handover should provide indication of current and expected
QoE (for the UE) at the current and target gNB.
#### 6.5.1.3 Possible solutions
##### 6.5.1.3.1 Solution description
The solution considers resource consumption both in terms of virtual and radio
resource for the target gNB. The current resource consumption is analysed with
the future/predicative resource consumption to decide if the target gNB is
optimal for handover or not.
_The MDAS producer can correlate and analyze_ the ongoing and/or potential
handover optimization issues based on the current and historical performance
data related to handover performance considering intra-gNB and inter-gNB
handover measurements as well as other performance measurements including
network load, E2E latency, retainability and radio conditions, UE measurements
including MDT, location and QoE for the network or network slices. The MDAS
producer can provide the analytics report as defined in Clause 6.5.1.3.3
related with resource utilization analytics triggered by an event or
periodically.
##### 6.5.1.3.2 Data required
The following data is required to do the required analysis.
Table 6.5.1.3.2-1: Potential data required for handover optimization
+----------------------------+----------------------------------------+ | **Data category** | **Required data** | +============================+========================================+ | Performance Measurements | Average/distribution of UE reported | | | RSRPs/RSRQs/SINRs of each neighbour | | | cell; | | | | | | Packet delay related to neighbour | | | cells as defined in clause | | | 5.1.1.1/5.1.3.3, TS 28.552 [8]; | | | | | | IP Latency to neighbour cells as | | | defined in clause 5.1.3.4, TS 28.552 | | | [8]; | | | | | | Round-trip GTP Data Packet Delay to | | | neighbour cells as defined in clause | | | 5.4.1.9, TS 28.552 [8]; | | | | | | End-to-end Latency of 5G Network to | | | neighbour cells as defined in clause | | | 6.3.1, TS 28.554 [7]; | | | | | | CQI related measurements: The | | | distribution of Wideband CQI reported | | | by UEs, clause 5.1.1.11 of TS 28.552 | | | [8]; | | | | | | Intra-gNB handovers: Number of failed | | | handovers in terms of handover | | | preparation/resource | | | allocation/execution and the mean time | | | of handover execution, clause 5.1.1.6 | | | of TS 28.552 [8]; | | | | | | Inter-gNB handovers: Number of failed | | | handovers in terms of handover | | | preparation/resource preparation | | | clause 5.1.1.6.2, TS 28.552 [8]; | | | | | | Frequency Priority Information (i.e., | | | based on deployment) set by the MNOs: | | | Absolute priorities for different NR | | | frequencies or inter-RAT frequencies, | | | clause 5.2.4.1, TS 38.304 [21]; | | | | | | Throughput at N3 interface: | | | Upstream/Downstream GTP data | | | throughput at N3 interface, clause | | | 6.3.4/6.3.5 of TS 28.554 [7]; | | | | | | Data packet loss: Data volume of | | | outgoing GTP data packets per QoS | | | level on the N3 interface, from UPF to | | | (R)AN and via versa clause 5.4.1.6 TS | | | 28.552 [8] | +----------------------------+----------------------------------------+ | Allocated Virtual Resource | Allocated Compute: This describes the | | | number of vCPUs allocated to the | | | virtual machine on which the gNB VNF | | | is hosted. | | | | | | Allocated Memory: This describes the | | | number of vMemory allocated to the | | | virtual machine on which the gNB VNF | | | is hosted. | | | | | | Allocated Storage: This describes the | | | number of vStorage allocated to the | | | virtual machine on which the gNB VNF | | | is hosted. | +----------------------------+----------------------------------------+ | Consumed Virtual Resource | Consumed Compute: This describes the | | | number of total aggregated compute | | | resource consumption at a particular | | | point of time. | | | | | | Consumed Memory: This describes the | | | number of total aggregated memory | | | consumption at a particular point of | | | time. | | | | | | Consumed Storage: This describes the | | | number of total aggregated storage | | | consumption at a particular point of | | | time. | +----------------------------+----------------------------------------+ | Consumed Radio Resource | Radio resource utilization: The | | | physical radio resource utilization of | | | the target gNB, see clause 5.1.1.2 of | | | TS 28.552[8]; | +----------------------------+----------------------------------------+ | MDT Data | UE measurements related to RSRP, RSRQ, | | | SINR (serving cell and neighbour | | | cells) and UE location information, TS | | | 37.320 [12]. | +----------------------------+----------------------------------------+ | UE location reports | UE location information provided by | | | the LCS with the anonymous ID, which | | | can be used to correlate with MDT | | | reports. | +----------------------------+----------------------------------------+ | QoE Data | Detailed measurements are FFS. | +----------------------------+----------------------------------------+ | S-NSSAI | S-NSSAI as defined in clause 5.15.2, | | | TS 23.501 [13]. MDAS uses this | | | information to identify target gNBs or | | | inter-RAT cells associated with a | | | network slice performing handover | | | optimization and may derive resource | | | utilization and network performance | | | analytics. | +----------------------------+----------------------------------------+ | Configuration Data | Resource configuration data including | | | RAN and virtualized NFs. | | | | | | The current policy configured in the | | | RAN related to the handover | | | optimization. | +----------------------------+----------------------------------------+
##### 6.5.1.3.3 Analytics report on gNB resource consumption
The resource analytics report contains the following information per gNB.
+----------------------+----------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of gNB resource | | | | consumption** | | | +======================+======================+======================+ | | Allocated Virtual | Allocated Compute: | | | Resource | This describes the | | | | number of vCPUs | | | | allocated to the | | | | virtual machine on | | | | which the gNB VNF is | | | | hosted. | | | | | | | | Allocated Memory: | | | | This describes the | | | | number of virtual | | | | vMemory allocated to | | | | the virtual machine | | | | on which the gNB VNF | | | | is hosted. | | | | | | | | Allocated Storage: | | | | This describes the | | | | number of vStorage | | | | allocated to the | | | | virtual machine on | | | | which the gNB VNF is | | | | hosted. | +----------------------+----------------------+----------------------+ | | Consumed Virtual | Consumed Compute: | | | Resource | This describes the | | | | number of total | | | | aggregated compute | | | | resource consumption | | | | at a particular | | | | point of time. | | | | | | | | Consumed Memory: | | | | This describes the | | | | number of total | | | | aggregated memory | | | | consumption at a | | | | particular point of | | | | time. | | | | | | | | Consumed Storage: | | | | This describes the | | | | number of total | | | | aggregated storage | | | | consumption at a | | | | particular point of | | | | time. | +----------------------+----------------------+----------------------+ | | Projected Virtual | Projected Compute: | | | Resource consumption | This describes the | | | | number of total | | | | projected compute | | | | resource consumption | | | | at a particular | | | | point of time. | | | | | | | | Projected Memory: | | | | This describes the | | | | number of total | | | | projected memory | | | | consumption at a | | | | particular point of | | | | time. | | | | | | | | Projected Storage: | | | | This describes the | | | | number of total | | | | projected storage | | | | consumption at a | | | | particular point of | | | | time. | | | | | | | | Timestamp: Time for | | | | which the projection | | | | is made. | +----------------------+----------------------+----------------------+ | | Assigned radio | The physical radio | | | resources | resource assignment | | | | to the target gNB. | +----------------------+----------------------+----------------------+ | | Consumed radio | The physical radio | | | resource | resource utilization | | | | of the target gNB. | +----------------------+----------------------+----------------------+ | | Projected radio | The physical radio | | | resource | resource projected | | | | utilization of the | | | | target gNB. | +----------------------+----------------------+----------------------+ | | isOptimal | Indication on | | | | whether the target | | | | gNB is optimal for | | | | handover. This will | | | | include: | | | | | | | | isOptimal: | | | | TRUE/FALSE | | | | indication if it is | | | | optimal. | | | | | | | | Network slice | | | | Identifier: | | | | Indication of the | | | | target slice (or | | | | same slice type) at | | | | the target gNB. | +----------------------+----------------------+----------------------+ | | isFutureOptimal | Indication on | | | | whether the target | | | | gNB is optimal for | | | | handover at a future | | | | point of time | | | | (Timestamp). This | | | | will include: | | | | | | | | isFutureOptimal: | | | | TRUE/FALSE | | | | indication if it is | | | | optimal. | | | | | | | | TimeStamp: | | | | Indicating the | | | | timestamp at which | | | | the target gNB will | | | | be optimal | | | | | | | | Network slice | | | | Identifier: | | | | Indication of the | | | | target slice (or | | | | same slice type) at | | | | the target gNB. | +----------------------+----------------------+----------------------+ | | Priority | Priority of the | | | | target gNB for | | | | optimal HO, in case | | | | of multiple targets. | +----------------------+----------------------+----------------------+ | | Remedial Action | Recommendation for | | | | gNB modification in | | | | order to make it | | | | optimal for handover | | | | e.g., scale-out gNB, | | | | increase radio | | | | resource. | +----------------------+----------------------+----------------------+
### 6.5.2 Inter-gNB Beam Selection Optimization
#### 6.5.2.1 Use case
The handover procedure specified in 5G is triggered based on UE measurements,
specifically considering the cell level radio quality of the source and target
cell(s). In case of beamformed access, one cell can make use of several beams
for serving residing users (SSB or CSI-RS) with each user served by a single
beam at a time. The cell level quality can be represented as an aggregated
metric over one or more beams. So, although handover is performed between two
5G cells, the granularity of handover can be further broken down to beam
level.
The target cell provides RACH resources to the UE, which are linked with
specific beams. Currently, the target cell can do this, based on beam level
measurements performed and reported by the UE. Picking the wrong beam for
performing RACH on the target cell could easily result in RLF for the UE and
should be avoided.
To address this beam level handover optimization issue, it is desirable to use
MDAS to prioritize and/or select a beam in case of handover for a specific
target cell, in order to minimize or even avoid RLF.
The MDAS producer provides a beam level HO optimization analytics report
considering information about the handover performance of different beam
combinations between specific source and target cell pairs. In particular, the
MDAS producer considers the beam of the current cell and the selected beam
(out of several available beams) of the target cell to keep statistics
regarding the handover performance in order to avoid RLF. Beams of the target
cell with a successful handover are preferred in the selection.
In other words, the analytics report also provides recommended actions to
optimize the beam selection at the target gNB as a function of serving beam on
the source cell side. Based on the recommended actions, the MDAS consumer
adjusts the priorities for the beam selection at HO, i.e. the beam
combinations that are likely to succeed are prioritized, less optimal beam
combinations are down prioritized. The analytics report may also be used to
aid the target cell to allocate RACH resources in a way that ensures HO
success.
#### 6.5.2.2 Potential requirements
**REQ-HO_BEAM_OPT_CON-1** The MDAS producer should have a capability to
provide the analytics report describing the handover performance of beam
combinations between cell pairs to authorized consumers based on previously
recorded HOs.
**REQ-HO_BEAM_OPT_CON-2** The analytics report describing the performance of
beam combinations between cell pairs should contain the following information:
> \- Number of successful HOs between a given beam pair
>
> \- Number of failed HOs between a given beam pair
>
> \- Indication if a beam pair is to be prioritized or down prioritized
#### 6.5.2.3 Possible solutions
##### 6.5.2.3.1 Solution description
_The MDAS producer can analyze_ the ongoing and/or potential beam handover
optimization based on the current and historical beam selection
success/failure rate for an inter-gNB handover. The MDAS producer can provide
the analytics report as defined in Clause 6.5.2.3.3 triggered by an event or
periodically.
##### 6.5.2.3.2 Data required
The following data is required to do the required analysis.
+--------------------------+------------------------------------------+ | **Data category** | **Required data** | +==========================+==========================================+ | Performance Measurements | Inter-gNB handover: Number of | | | success/failed handovers in terms of | | | handover preparation/resource | | | preparation; | | | | | | Beam level measurements: CSI-RS, SSB | | | beam related measurements clause | | | 5.1.1.28, TS 28.552 [8]; | | | | | | Success/failure handover rate per beam | | | pair, i.e. serving beam Id in source gNB | | | and selected beam Id in target gNB. | +--------------------------+------------------------------------------+ | MDT Data | UE measurements related to radio | | | conditions and UE location information. | +--------------------------+------------------------------------------+ | Beam selection policy | The current policy configured in the RAN | | | related to beam selection for inter-gNB | | | handover optimization. | +--------------------------+------------------------------------------+
##### 6.5.2.3.3 Analytics report
The gNB resource analytics report contains the following information.
**Analytics Report of gNB resource consumption** **Attribute Name**
**Description**
* * *
                                                     Beam level Inter-gNB Handover performance   Handover success rate perÂ beam ID pair. This can be quantified as high, medium or low success rate.
                                                     Time period                                 Time period, in the future, for the handover success rate perÂ beam ID pair
                                                     List of gNBs                                Objects involved: gNB(s) and cells of gNBs,
### 6.5.3 Load Balancing optimization
#### 6.5.3.1 Use case
The rapid traffic growth and multiple frequency bands utilized in a commercial
network make it challenging to steer the traffic in a balanced distribution.
To address the problem, load balancing had been proposed. The objective of
load sharing and load balancing is to distribute cell load evenly among cells
or to transfer part of the traffic from congested cell, or to offload users
from one cell or carrier or RAT to improve the network resource utilization
efficiency and achieve network energy saving. This can be done by means of
optimization of cell reselection/handover parameters and handover actions.
To ensure the service performance and user experience, the load balancing
action based on handovers highly depends on the measurement report (MR) from
the UE. For example, the inter-frequency scenarios with the deployment of
multiple different frequency bands, the MR configuration and UE MR reports may
cause amount of signalling overhead over Uu interface. The frequent inter-
frequency measurement will cause huge UE power consumption and severely impact
on running service by the data interruption for inter-frequency measurement
gap, e.g. the gap time in LTE is number of frequency*60ms per 480ms period and
the gap time in NR also depends on SMTC period. The gap assistant inter-
frequency measurements mechanism will bring delay of the measurement and
decrease the data transmission rate. Solutions are desired to improve the
effectiveness of the MR configuration and report, which may help to greatly
reduce the MR signalling overhead, UE power consumption and data interruption
of running service, and improve the convergence speed of the load balancing.
The MDA can help to predict the measurement results of cell on neighboring
frequencies for each UE without the GAP assisted measurement. Via analyzing
the historical intra-frequency and inter-frequency measurement from both the
serving cell and the neighbour cell, the MDA can construct the network "radio
finger print", which characterize the network intra-frequency and inter-
frequency coverage quality. The "radio finger print" information is composed
of multiple virtual grid. The grid index is to identify a specific virtual
grid and this index consists of cell ID and corresponding coverage quality,
e.g., RSRP, of at least three intra-frequency cells. The attributes of the
grid are used to describe the wireless characteristics of the grid, such as
coverage of inter-frequency neighbor cells, including RSRP, reference signal
receiving quality (RSRQ), received signal strength indication (RSSI), channel
quality indicator (CQI), modulation and coding scheme (MCS), beam ID, etc.
The MDA producer provides the analytics report on "radio finger print"
information to the gNB, gNB can directly predict the measurement values of
cells on neighboring frequencies for each UE based on the well-constructed
"radio finger print" and the real-time intra-frequency measurement. In this
case, the GAP assisted inter-frequency measurement is avoided, and the gNB can
make proper load balancing actions based on the predictions, which helps to
reduce the data interruption of running services and improve the load
balancing speed.
The MDA producer may also provide the traffic load prediction report to the
authorized consumers, e.g., gNB, to enable the proactive load balancing
actions. This would help to prevent the user experience degradation in advance
compared to the reactive optimizations based on the delayed load information
measurement and exchange.
#### 6.5.3.2 Potential requirements
**REQ-MLB_OPT_CON-1** The MDAS producer should have a capability to provide
the analytics report describing the radio measurement information to
authorized consumers , e.g., gNB.
**REQ-MLB_OPT_CON-2** The analytics report describing the radio measurement
information should contain the following information:
> \- the applied cell ID;
>
> \- the time period(s) of the original data used for deriving the analytics
> report;
>
> \- the serving cell and its inter-frequency/intra-frequency neighboring
> cell's cell ID and corresponding radio measurement information, e.g., CSI-
> RSRP, SS-RSRP, etc;
>
> \- Indication on whether the gNB is suitable to be selected as the target
> gNB for the MLB based handover based on the radio signal qualities.
**REQ-MLB_OPT_CON-3** The analytics report describing the predicted resource
utilization status of gNB should contain the following information:
> \- predicted virtual, radio, and transport resources utilizations for
> potential MLB source and target gNBs in the near future;
>
> \- Indication on whether the gNB is needed to activate the MLB operation;
>
> \- Indication on whether the gNB is suitable to be selected as the target
> gNB for the MLB based handover.
#### 6.5.3.3 Possible solutions
TBD
### 6.5.4 Mobility performance analysis
#### 6.5.4.1 Use case
The mobility performance related problems may be resulted from different
causes, e.g., too long mobility interruption time for latency sensitive
services, low handover successful rate due to poor coverage of the cell-edge,
handover failure due to lack of handover resources, too-early/too-
late/pingpong handovers due to inappropriate handover parameters.
In addition, there are different handover mechanisms, e.g. Dual Active
Protocol Stack (DAPS) to reduce service interruption time during handover,
Conditional Handover (CHO) to improve handover robustness, RACH-less handover
to reduce handover latency etc. SON MRO solutions can handle multiple handover
robustness issues such as too early handover, too late handover, handover to a
wrong cell etc. Furthermore, handover mechanisms are also related with NSA and
SA deployment architecture. In different scenarios, handover solutions will
have different impacts on the mobility performance. The analytics report to
identify the most optimal handover mechanism may be provided by MDAS producer.
For example, to satisfy the requirements of 0ms mobility interruption time for
some URLLC services, MDAS may propose to prioritize the usage of DAPS. If
handover successful rate is low due to coverage issue in the cell edge, MDAS
may recommend CHO instead of gNB triggered handover mechanisms. To provide
optimal handover mechanisms and the corresponding handover related parameters,
MDAS may consider multiple factors, e.g. radio conditions, cell load, service
requirements, handover successful rate, history performance data around
handover, UE RF finger prints etc. MDAS may compare performance of different
handover mechanisms and propose optimal handover mechanisms, e.g. the
prioritization of different handover mechanisms in different conditions.
MDAS can be used to analyse service experience and network performance during
handover period in different mobility scenarios. It may also be able to
provide the recommendations of optimal handover parameters, resource
configurations and mobility related policies. Mobility performance analysis
should cover the following aspects:
> \- Mobility scenarios in NSA and SA deployment architectures;
>
> \- Optimal handover mechanisms, e.g. DAPS, CHO, RACH-less handover etc;
>
> \- Optimal handover parameter and resource configurations;
>
> \- Coordination with SON MRO mechanisms to improve handover robustness;
>
> \- Mechanisms for fast handover failure recovery;
The MDAS producer is able to, from the perspective of the management aspects,
provide the mobility performance analytics report. This analytics report can
be considered as an input to support SLS assurance to perform further
evaluation.
#### 6.5.4.2 Potential requirements
**REQ-MOB_PMF_CON-1** The MDAS producer should have a capability to provide
the analytics report of mobility performance.
**REQ-MOB_PMF_CON-2** The analytics report describing the mobility performance
should contain the following information describing the mobility related
performance aspects:
> \- Optimal handover mechanism and the corresponding parameters for DAPS,
> CHO, RACH-less handover and NR SON MRO scenarios etc.
#### 6.5.4.3 Possible solutions
##### 6.5.4.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to provide optimal handover mechanisms and the
corresponding configurations regarding parameters and resources. As the table
in 6.5.4.3.3 shows, the analytics report is able to be provided by the MDAS
producer to describe the optimal handover mechanisms. This procedure may be
triggered by the request or periodically.
##### 6.5.4.3.2 Data required for mobility performance analysis
Following table shows the potential data required to analyse the mobility
performance.
+--------------------------+------------------------------------------+ | **Data Category** | **Required Data** | +==========================+==========================================+ | Performance Measurements | sNSSAIList; | | | | | | Inter-gNB handovers: see clause | | | 5.1.1.6.1 of TS 28.552[8]; | | | | | | Intra-gNB handovers: see clause | | | 5.1.1.6.2 of TS 28.552[8]; | | | | | | Handovers between 5GS and EPS: see | | | clause 5.1.1.6.3 of TS 28.552[8]; | | | | | | RRC Connection Re-establishment: see | | | clause 5.1.1.17 of TS 28.552[8]; | | | | | | Inter-AMF handovers: see clause 5.2.5.1 | | | of TS 28.552[8]; | | | | | | Handovers from 5GS to EPS: see clause | | | 5.2.5.3 of TS 28.552[8]; | | | | | | Handovers from EPS to 5GS: see clause | | | 5.2.5.4 of TS 28.552[8]; | | | | | | Number of handover events, Number of HO | | | failures, Number of too early HO | | | failures, Number of too late HO | | | failures, Number of HO failures to wrong | | | cell, Number of unnecessary HOs to | | | another RAT: see clause 4.3.5 of TS | | | 28.628[y]; | | | | | | Radio resource utilization: The usage of | | | physical radio resource utilization of | | | the network, see clause 5.1.1.2 of TS | | | 28.552[8]; | | | | | | RAN UE throughput: A KPI that shows how | | | NG-RAN impacts the service quality | | | provided to an end-user, see clause | | | 6.3.6 of TS 28.554 [7]; | | | | | | Throughput at N3 interface: | | | Upstream/Downstream GTP data throughput | | | at N3 interface, see clause 6.3.4 and | | | clause 6.3.5 of TS 28.554 [7]; | | | | | | NWDAF analytical data: UE mobility | | | analytics, UE Communication Analytics; | | | see 6.7.2 and 6.7.3 of TS 23.288 [y]; | +--------------------------+------------------------------------------+ | MDT Data | UE measurements related to RSRP, RSRQ, | | | SINR and UE location information. | +--------------------------+------------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +--------------------------+------------------------------------------+ | Configuration Data | The execution data including the changes | | | or the configuration of the MOIs related | | | with RAN user plane congestion. | +--------------------------+------------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.5.4.3.3 Analytics report for mobility performance analysis
Following table shows the potential information carried in the analytics
report of mobility performance analysis.
+----------------------+----------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of mobility | | | | performance** | | | +======================+======================+======================+ | | Mobility performance | The identifier of | | | issue identifier | the mobility | | | | performance issue | | | | analysis; | +----------------------+----------------------+----------------------+ | | Root cause of | The root cause of | | | mobility performance | mobility performance | | | issue | issues, e.g., too | | | | long mobility | | | | interruption time | | | | for latency | | | | sensitive services, | | | | low handover | | | | successful rate due | | | | to poor coverage of | | | | the cell-edge, | | | | too-ear | | | | ly/too-late/pingpong | | | | handovers due to | | | | inappropriate handover | | | | parameters | +----------------------+----------------------+----------------------+ | | Recommended handover | Recommended handover | | | mechanisms | mechanisms according | | | | to network | | | | conditions, e.g., | | | | DAPS, CHO, RACH-less | | | | handover; | | | | | | | | Note: The DAPS and | | | | CHO mechanism are | | | | mutually exclusive. | +----------------------+----------------------+----------------------+ | | Recommended handover | Corresponding | | | related parameters | configurations of | | | | handover related | | | | parameters, e.g., | | | | the range of | | | | handover offset. | +----------------------+----------------------+----------------------+ | | Time duration | The time duration | | | | the identified | | | | handover mechanism | | | | or handover related | | | | parameters are | | | | recommended to | | | | apply. | +----------------------+----------------------+----------------------+ | | Location | The geographical | | | | area or the cells | | | | where the identified | | | | handover mechanism | | | | and handover related | | | | parameters are | | | | applied. | +----------------------+----------------------+----------------------+
### 6.5.5 Handover optimization based on UE trajectory
#### 6.5.5.1 Use case
Handover optimization can benefit from knowledge about the trajectory on which
the user may be moving. A trajectory here is a sequence of location
coordinates, i.e. a vector that captures the sequences of coordinates within a
certain time interval, derived from historical UE location data, that
identifies the different directions which users may take starting at a given
point. At a city junction, for example, the probability of a handover success
for a user moving straight through the junction may be different from that for
a user who is turning left or turning right. So, at that junction, the
straight, left and right direction indicate three possible trajectories. The
MDAS producer should be able to analyse historical handover performance data
in combination with historical UE location and the radio characteristics like
RSRP and SINR considering the possible user trajectories to identify the
optimal handover configurations and target cell prioritization.
#### 6.5.5.2 Potential requirements
REQ-HO_OPT_TR_CON-1 The MDAS producer should have a capability to provide an
analytics report indicating the possible candidate user trajectories across
the cell boundaries and provide radio configuration and target gNB selection
specific to each trajectory.
#### 6.5.5.3 Possible solutions
##### 6.5.5.3.1 Solution description
The solution considers UE trajectories and radio conditions for selecting the
target gNB. The current resource consumption is analysed with the
future/predicative resource consumption to decide if the target gNB is optimal
for handover or not.
##### 6.5.5.3.2 Data required
The following data is required to do the required analysis.
+-------------------------+-------------------------------------------+ | **Data category** | **Required data** | +=========================+===========================================+ | Consumed Radio Resource | > Radio resource utilization: The | | | > physical radio resource utilization of | | | > the target gNB, see clause 5.1.1.2 of | | | > TS 28.552[8]; | +-------------------------+-------------------------------------------+ | MDT data | UE measurements related to RSRP, RSRQ, | | | SINR time-stamped and annotated with UE | | | location information. | +-------------------------+-------------------------------------------+
##### 6.5.5.3.3 Analytics report on user trajectory-based handover
optimization
The gNB trajectory-based handover optimization analytics report contains the
following information.
**Analytics Report of user trajectory-based handover** **Attribute Name**
**Description**
* * *
                                                           User trajectory                            The predicted UE location that identifies a trajectory across a cell boundary.
                                                           Radio characteristics on user trajectory   Radio parameters e.g. RSRP, SINR, on the predicted user trajectory across a cell boundary.
                                                           Recommended actions                        Recommendation for optimal gNB configuration and/or target gNB selection/prioritization based on the user trajectory information.
## 6.6 Energy efficiency related issues
### 6.6.1 MDA assisted energy saving
#### 6.6.1.1 Use case
Energy saving is a critical issue for the 5G operators. Energy saving is
achieved by activating the energy saving mode of the NR capacity booster cell
or 5GC NF (e.g. UPF etc.), and the energy saving activation decision making
may be based on the various information such as load information of the
related cells and the energy saving policies set by operators as specified in
TS 28.310 [14].
As the conclusion from clause 7.2 of the TR 21.866 [15], "The EE Control and
Coordination Function: a self-managed automated process to control and
coordinate system wide power saving operations including the access networks,
core network, backhaul/fronthaul transmission networks, backbone networks and
other subsystems", the management system has the overall view of network load
information and it could also take the inputs from the control plane analysis
(e.g. the analytics provided by NWDAF). The management system may provide the
network wide analytics and cooperate with Core and RAN domains and decide on
which network element should move into energy saving mode in a coordinated
manner.
There are various information could be used as inputs for management energy
saving analysis. For example, the MDAS provides the analytics report to assist
energy saving based on the EE related performance measurements, (e.g. PDCP
data volume, PNF temperature, and PNF power consumption etc.) from the gNBs.
The composition of the traffic load could be also considered as inputs for
energy saving analysis. (e.g., the percentage of high-value traffic in the
traffic load). The variation of traffic load may be related to the network
data (e.g., historical handover information of the UEs or network congestion
status). Collecting and analysing the network data with machine learning tools
may provide predictions related to the trends of traffic load. The composition
and the trend of the traffic load may be used as references for making
decision on energy saving.
MDAS may also obtain NF location or other resource information including
virtual resource consumption, while analyzing historical network information.
Based on the collected information, MDAS provides analysis and give
suggestions to network management in optimization suggestion for 5G Core NF
deployment options in high-value traffic region (e.g. location of VNF in
context of energy saving). The information from control plane data analysis
from NWDAF may also be used as input for energy saving analysis and decision.
The decision of core NF and RAN node energy saving should be coordinated by
management system to guarantee the overall network and service performance are
not affected as much as possible.
To achieve an optimized balance between the energy consumed and the serviced
performance provided by the network, MDAS can be used to provide an analytic
report by analyzing the above information comprehensively to assist the energy
saving related decision making.
#### 6.6.1.2 Potential requirements
TBD
#### 6.6.1.3 Possible solutions
##### 6.6.1.3.1 Solution description
The MDAS producer correlates and analyses the management data described in the
following subclause to assist the management energy saving function to make
energy efficiency decisions. As the table in 6.6.1.3.3 shows, the analytics
report is able to be provided by the MDAS producer to describe the analytics
result and recommendations of energy saving. This procedure may be triggered
by the request or periodically.
Energy saving activation decision making may be based on the various
information such as load information. The prediction result of these
information can be used by operators to make energy-saving policies. There are
many prediction models which may use ML algorithms for predicting these
information, such as energy-saving scenarios prediction models and traffic
load prediction models.
The prediction models are trained to be able to produce the expected training
output from the training input. The data for models training may include RRC
connection number, PRB utilization, energy consumption, service experience,
etc. After the training process, the pre-trained models for predicting
information used to make energy-saving policies can be obtained.
The more accurate the information prediction results are, the better the
energy-saving policies based on the information prediction results will be.
According to the result of information prediction and the energy-saving
benefit, the MDA service can assist the energy saving policy decision making
by recommending the optimal information prediction models which can provide
more accurate information prediction results for consumers.
For example, the MDA service may take base station energy saving scenarios
prediction model and the traffic load prediction model together as input.
Based on the results of energy saving scenarios prediction and traffic load
prediction, the MDA service may use the ML algorithms to calculate the energy-
saving benefit based on base station related information (e.g., service
experience changes), the traffic load changes as well as the prediction of the
energy saving scenarios. And by maximizing the expected sum of energy-saving
benefits, the MDA service may provide the optimal prediction models for making
recommendation of base station energy saving policies accordingly.
##### 6.6.1.3.2 Data required for MDA assisted energy saving
Following table shows the potential data required to analyse the energy saving
issue.
+-------------------------------+-------------------------------------+ | **Data Category** | **Required Data** | +===============================+=====================================+ | Performance Measurements | PNF Power Consumption: Power | | | consumed over the measurement | | | period, see clause 5.1.1.19.2 of TS | | | 28.552 [8]; | | | | | | PNF Energy consumption: The energy | | | consumed, see clause 5.1.1.19.3 of | | | TS 28.552[8]; | | | | | | PNF Energy Temperature: The | | | temperature over the measurement | | | period, see clause 5.1.1.19.4 of TS | | | 28.552[8]; | | | | | | PNF Voltage: The voltage, see | | | clause 5.1.1.19.5 of TS | | | 28.552[8]; | | | | | | PNF Current: The current, see | | | clause 5.1.1.19.6 of TS | | | 28.552[8]; | | | | | | PNF humidity consumption: The | | | percentage of humidity during the | | | measurement period, see clause | | | 5.1.1.19.7 of TS 28.552[8]; | | | | | | PDCP Data Volume: The transmitted | | | PDCP data volume, see clause | | | 5.1.2.1 and 5.1.3.6 of TS 28.552 | | | [8]; | | | | | | Virtual resource usage of NF: The | | | resource usage of virtual network | | | functions, see clause 5.7.1 of TS | | | 28.552 [8]. | +-------------------------------+-------------------------------------+ | QoE Data | The measurements that are collected | | | are DASH [16] and MTSI [17] | | | measurements. The detailed | | | information of QoE data required by | | | this case is FFS. | +-------------------------------+-------------------------------------+ | Analytics Data | The control plane analysis result | | | from the NWDAF defined in TS 23.288 | | | [18], e.g., observed service | | | experience related network data | | | analytics. | | | | | | The additional required analysis | | | result is FFS. | +-------------------------------+-------------------------------------+ | Pre-trained Prediction Models | The pre-trained models, which may | | | be based on ML algorithms and | | | trained to be able to produce the | | | expected training output for | | | consumers, e.g., pre-trained base | | | station energy-saving scenarios | | | prediction models, pre-trained | | | traffic load prediction models. | | | | | | The detailed information about | | | where to obtain the pre-trained | | | prediction models is FFS. | +-------------------------------+-------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.6.1.3.3 Analytics report for MDA assist energy saving
Following table shows the potential information carried in the analytics
report of MDA assist energy saving.
**Analytics Report of MDA assisted energy saving** **Attribute Name**
**Description**
* * *
                                                       Energy efficiency issue identifier   The identifier of the MDA assisted energy saving
                                                       Location                             The geographical area or the cells where the unreasonable energy consumption exists
                                                       Root cause                           The root cause of the part of the energy consumption that may be conserved, e.g., ultra-low traffic load area with energy consumption, excessive energy consumption
                                                       Recommended prediction models        The optimal prediction models which can provide more accurate information prediction results to assist the energy saving related decision making.
## 6.7 Paging performance related issues
### 6.7.1 Paging optimization
#### 6.7.1.1 Use case
As per the current procedures, if the UE goes out-of-coverage (OOC) the paging
which was initiated by the network Access and Mobility Management Function
(AMF) fails. The re-attempts continue to fail until UE comes in the coverage
and reacts to the paging attempts. This repetitive paging attempts result in
the wastage of network resources. As an example, the use case includes a user
or a group of users getting into an area, with no cellular coverage on a
regular basis for a considerably long duration, for e.g., the user gets into a
shielded room for some testing purpose every day for a defined period. The
Network initiated paging for such users will fail until they are back in the
area with cellular coverage. This would result in in-efficient network
resource usage.
It is desirable to use MDAS (Management data analytic service) to optimize the
current paging procedures in 5G networks. MDAS producer provides an analytical
report containing the user(s) paging analytics indicating the time window at
which the user is OOC on a regular basis at the particular location and hence
will not be able to respond on a network-initiated paging. Based on the report
MDAS consumer (e.g., AMF, gNB) decides on whether, when and where to initiate
or not to initiate the paging procedures, thereby ensuring the efficient
paging procedures and optimal network resource utilization, as paging can be
initiated only when there are more chances for it to be successful.
#### 6.7.1.2 Potential Requirements
**REQ-PA_OPT_CON-1:** The MDAS producer should have a capability allowing the
authorized consumer to get the paging analytics report describing paging
results for a particular user or a group of users.
**REQ-PA_OPT_CON-2:** The MDAS producer should have a capability to provide
the paging analytics report describing the paging results based on successful
and un-successful paging attempts at a particular time and duration.
**REQ-PA_OPT_CON-3:** The paging analytics report describing the paging
results should contain the following information:
> \- User Identification: Identification of the user or a group of users.
>
> \- Daily-OOC-Duration: Identifying the time window during which UE is out-
> of-coverage every day.
>
> \- Daily-OOC-Location: Identifying the last known location before UE going
> out-of-coverage every day.
>
> \- Recommended Action: The recommendation may suggest stopping paging the UE
> for Daily-OOC-Duration at Daily-OOC-Location.
#### 6.7.1.3 Possible Solutions
##### 6.7.1.3.1 Solution description
The solution requires MDAS producer to collect various data and provide the
paging analytics report. Daily-OOC-Duration and Daily-OOC-Location will be
included in the Paging Analytics Report mentioning the time window during
which UE is out-of-coverage every day at a particular location. The paging is
not initiated for the UE during the period provided as Daily-OOC-Duration if
the last know UE location is the location identified by Daily-OOC-Location.
##### 6.7.1.3.2 Data required
The consumer (e.g. AMF) can subscribe to obtain the paging analytics report
for a user or a group of the user from MDAS producer. The subscription request
may include identification for the target user or a group of the user,
reporting interval etc. The MDAS producer collects the following per UE per
day data from various sources.
**Data category** **Required data**
* * *
UE Paging Measurements Number of successful paging attempt. Successful
Timestamp: The timestamp for each successful paging attempt. Successful
Location: Last known location of UE. Number of un-successful paging attempt:
Total number of un-successful paging attempt. Un-Successful Timestamp: The
timestamp for each un-successful paging attempt. Un-Successful Location: Last
known location of UE.
##### 6.7.1.3.3 Analytics report
The paging analytics report contains the following information
**Paging Analytics Report** **Attribute Name** **Description**
* * *
                                User Identification   Identification of the user or a group of users.
                                Daily-OOC-Duration    Identifying the time window during which UE is out-of-coverage every day. This will be provided per UE.
                                Daily-OOC-Location    Identifying the last known location before UE going out-of-coverage every day. This will be provided per UE.
                                Recommended Action    The recommendation may suggest stopping paging the UE for Daily-OOC-Duration at Daily-OOC-Location. This will be provided per UE.
Based on the report and the recommendation, the consumer decides whether to
change the paging strategy for a particular UE or a group of UE. If the paging
policy needs to be changed, the AMF may decide whether, when and where to page
the UE. The AMF may not page the UE during the period provided as Daily-OOC-
Duration if the last know UE location is the location identified by Daily-OOC-
Location.
Editor's Note: This use may require MDAS to know UE Identifier. How that will
be done is FFS.
## 6.8 Software management related issues
### 6.8.1 RAN Node Software Upgrade
#### 6.8.1.1 Use case
As per the current mechanism of software upgrade at RAN node results in
service disruption or huge operational cost. Consider a scenario, when a RAN
Node is required to shut down manually to undergo critical maintenance for a
very short duration of time. Software upgrade can be one such critical
maintenance scenario. In such cases, all the resources (bearer, security
functions, mobility management) that are managed by this RAN Node need to be
purged and reconfigured at another RAN Node (standby RAN Node) or if another
RAN Node is not available then resources will be reconfigured again when
former RAN Node comes up after software upgrade. Both the situations lead to
additional operational expenses and data loss. Operational expense in terms of
all the resources to be released/attached again and data loss for all GBR
sessions/bearer.
It is expected to use MDAS to optimize the procedure of software upgrade at
RAN Node. The software upgrade should be automatically initiated by the OAM
system, once configured, at the time when the expected impacts are minimum i.e
at the Optimal Time when there would be minimum expected operational cost and
data loss. The Optimal Time (current or futuristic) can be derived by
collecting and analysing the data related to DRBs including GBR/non-GBR,
state, modification count, ongoing handover etc. MDAS can utilize historical
data and AI/ML (e.g., time series based) algorithm to derive the future
optimal time for software upgrade.
Note: RAN Node above refers to CU-CP in case of gNB split case.
#### 6.8.1.2 Potential Requirements
**REQ-SW_UPG_CON-1:** The MDAS producer should have a capability allowing the
authorized consumer to get the DRB info analytics report describing the DRBs
info at a particular RAN Node(s).
**REQ-SW_UPG_CON-2:** The MDAS producer should have a capability to provide
the DRB info analytics report describing the DRB info based on DRB
characteristics including GBR/non-GBR, state, modification count, handover
etc.
**REQ-SW_UPG_CON-3:** The DRB info analytics report describing the DRB info
should contain the following information:
> \- Timestamp: Time at which the report is generated
>
> \- CurrentUpgradeOptimal: Whether RAN Node is optimal for upgrade at present
>
> \- DRB status: Total number of GBR and non-GBR DRBs at present
>
> \- FutureUpgradeOptimal: Whether RAN Node will be optimal for upgrade at a
> future point of time. This will also provide a future timestamp.
>
> \- DRB status: Total number of GBR and non-GBR DRBs at future point of time.
> This will also provide a future timestamp.
#### 6.8.1.3 Possible Solutions
##### 6.8.1.3.1 Solution description
The solution requires MDAS producer to collect current DRB info as defined in
clause 6.8.1.3.2 and produce the report, as defined in clause 6.8.1.3.3,
providing the optimal time for software upgrade i.e. the time at which the
impact is minimal.
##### 6.8.1.3.2 Data required
The following table shows the data required to generate the DRB info analytics
report. The data is collected per DRB from gNB.
+-------------------+-------------------------------------------------+ | **Data Category** | **Required Data** | +===================+=================================================+ | Bearer Statistics | QCI: Indicates resource bearer type (GBR, | | | non-GBR). | +-------------------+-------------------------------------------------+ | | Radio bearer State: Radio bearer State (Idle, | | | Active) | | | | | | _The state indicates the status of bearer | | | connection. The state will be used to deduce | | | total number of idle/active connection. Based | | | on the number of idle/active connections | | | probable time for SW Upgrade can be decided._ | +-------------------+-------------------------------------------------+ | | Bearer Modification Count: This count indicates | | | number of times, this bearer has gone for | | | modification since its creation. | | | | | | _This count will be used to detect how frequent | | | this session has undergone bearer modification. | | | With history database, if this session is | | | vulnerable to many bearer modifications, the | | | upgrade can be differed._ | +-------------------+-------------------------------------------------+ | | Handover In Progress: This flag indicates | | | whether the bearer is undergoing handover or | | | not. | | | | | | _This flag will help to deduce number of | | | sessions which are undergoing handover. MDAS | | | may choose to defer SW upgrade based on number | | | of sessions which are undergoing handover. The | | | best practise is to go for SW upgrade, when | | | active handovers are minimum._ | +-------------------+-------------------------------------------------+ | | GTP Error Indication: This flag indicates GTP | | | Path has gone to error state and system is | | | waiting for recovery. | | | | | | _This flag will help to deduce number of | | | sessions which are recovering due to error in | | | GTP Path. MDAS may choose to defer SW upgrade | | | based on number of sessions which are in error | | | state. The best practise is to go for SW | | | upgrade, when number of sessions suffering from | | | this error are minimal._ | +-------------------+-------------------------------------------------+ | | Timestamp: This parameter indicates timestamp | | | during which this information has been | | | collected | +-------------------+-------------------------------------------------+
Editor's Note: Additional Input may be required, which are FFS.
##### 6.8.1.3.3 Analytics report
The DRB info analytics report shall contain the following
**DRB info Analytics Report** **Attribute Name** **Description**
* * *
                                  Timestamp               Time at which the report is generated
                                  CurrentUpgradeOptimal   Boolean attribute indicating whether RAN Node can be upgrade at present.
                                  No. of GBR DRB          Total number of GBR bearer
                                  No. of Non-GBR DRB      Total number of non-GBR bearer
                                  FutureUpgradeOptimal    Boolean attribute indicating whether RAN Node can be upgrade in future. This will provide the time duration in future.
                                  No. of GBR DRB          Total number of GBR bearer
                                  No. of Non-GBR DRB      Total number of non-GBR bearer
## 6.9 MDA assisted SON coordination
### 6.9.1 SON conflict prevention and resolution
#### 6.9.1.1 Use case
Some SON functions, such as the MRO function and the MLB function, may modify
the same parameters of an NR cell and potentially cause conflict. For
instance, the MRO function may need to modify the HO parameters causing a
handover to occur later (i.e., when the signal strength of the neighbour cell
become stronger). However, the MLB function may need to modify the same HO
parameters causing the HO to occur sooner, in order to offload some traffic
towards the same neighbour cell. Similarly, the conflict may arise between a
SON function and a non-SON function (e.g., eMIMO).
The potential SON conflict (which could be between SON functions or between a
SON function and a non-SON function) should be prevented from happening as
much as possible, and if the conflict happens it should be resolved as soon as
possible. The SON conflict prevention and resolution can be assisted by MDA.
The MDA could analyse the following data for identifying the potential SON
conflict or detecting whether a SON conflict occurred:
> \- historical and the most recent changes made by the SON functions and non-
> SON functions;
>
> \- the current network configurations;
>
> \- historical and current network performance data related to the SON
> function(s) and the relevant non-SON functions. For instance, load
> information of the NR cells, handover performance measurements (too early
> HOs, too late HOs, etc.);
>
> \- Policies and targets for the SON functions.
>
> \- historical and current MDT/RLF data.
>
> \- for a SON function or a non-SON function, considering potential affected
> parameters.
If a potential SON conflict is identified, the MDAS producer provides an
analytics report to describe the potential conflict and the recommended
actions to prevent such conflicts from happening.
If a SON conflict is defected, the MDAS producer provides an analytics report
to describe the conflict including the recommended actions to resolve it.
The recommended actions for SON conflict prevention and resolution may be one
or more of the following:
> \- modify the policies and targets for the SON function(s);
>
> \- change the priority of the SON function(s);
>
> \- set or change the range of the attributes value that the SON function(s)
> are allowed to modify;
>
> \- update the attributes value to correct the conflict (if already
> occurred);
>
> \- temporarily switch off one or more SON function(s) ;
>
> \- undo the most recent configuration undertaken by the SON function;
>
> \- provide a report that describes how SON function(s) can potentially
> affect the common parameters.
#### 6.9.1.2 Potential requirements
**REQ-MDA_SONCO-CON-1** The MDAS producer should have a capability to provide
the analytics report describing the identified potential conflict between SON
functions or between a SON function and a non-SON function with recommended
actions to prevent the conflict from happening.
**REQ-MDA_SONCO-CON-2** The MDAS producer should have a capability to provide
the analytics report describing the detected conflict between SON functions or
between a SON function and a non-SON function with recommended actions to
resolve the conflict.
**REQ-MDA_SONCO-CON-3** The MDAS producer should have a capability to provide
the analytics report that describes the relations (i.e. whether certain
conditions trigger conflicts) between observed conflicts and observed
conditions.
##### 6.9.1.3 Possible solutions 6.9.1.3.1 Solution description
The MDAS producer correlates and analyzes the data described in the following
subclause within a time period on a regular basis or trigged by events (e.g.,
the RLF report) to identify a potential SON conflict or a SON conflict already
occurred.
Once a potential or already occurred SON conflict is identified, the MDAS
producer provides the analytics report to describe the SON conflict as shown
in subclause 6.9.1.3.3.
##### 6.9.1.3.2 Data required for SON conflict analysis
The following table describes the data required for SON conflict analysis:
+-------------------------------+-------------------------------------+ | **Data Category** | **Required Data** | +===============================+=====================================+ | Performance Measurements | Radio Measurements for gNB: RRC | | | connection, see clause 5.1, TS | | | 28.552[8], e.g., RRC connection | | | number, RRC connection | | | establishment, RRC connection | | | re-establishment, RRC | | | connection resuming; | | | | | | RAN UE throughput: A KPI that shows | | | how NG-RAN impacts the service | | | quality provided to an | | | end-user, see clause 6.3.6 of TS | | | 28.554 [7]. | | | | | | Throughput for network slice | | | instance: Upstream/Downstream | | | throughput for network and Network | | | Slice Instance, see clause 6.3.2 | | | and clause 6.3.3 of TS 28.554 | | | [7]; | | | | | | Performance measurements related to | | | the SON functions, see TS 28.313 | | | [19]. | +-------------------------------+-------------------------------------+ | CM notification | Notifications of the NRM updates | | | made by SON functions and non-SON | | | functions. | | | | | | The notification needs to include | | | the Id (e.g., DN) of the SON | | | function or non-SON function who | | | made the NRM updates. | +-------------------------------+-------------------------------------+ | MDT/RLF Data | UE measurements related to RLF | | | containing RSRP, RSRQ, of the | | | serving cell and neighbour cells, | | | SINR with anonymous id (e.g., | | | C-RNTI) and UE location | | | information. | +-------------------------------+-------------------------------------+ | QoE Data | The details information of QoE data | | | required by this case is FFS. | +-------------------------------+-------------------------------------+ | Configuration Data (NRM) | The execution data including the | | | changes or the configuration of the | | | MOIs. This should include | | | historical UE configurations | | | | | | The attributes of the MOIs to be | | | analysed, see TS 28.541 [20]. | | | | | | The policy and targets of the SON | | | functions, see TS 28.313 [19]. | +-------------------------------+-------------------------------------+ | Potential affected parameters | SON functions parameters affected | | | including the degree of impact | | | (low, medium, high). | +-------------------------------+-------------------------------------+
Note: The above parameters may not be the complete list.
##### 6.9.1.3.3 Analytics report SON conflict prevention and resolution
Following table provides the potential contents of the analytics report for
SON conflict prevention and resolution:
+----------------------+----------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of SON conflict | | | | prevention and | | | | resolution** | | | +======================+======================+======================+ | | Conflicting | Indicates the Id of | | | Functions Id | the conflicting SON | | | | functions or non-SON | | | | functions. | +----------------------+----------------------+----------------------+ | | Conflict type | Indicates the | | | | conflict is a | | | | potential conflict | | | | or an already | | | | occurred conflict. | +----------------------+----------------------+----------------------+ | | Conflicting | The MOI and | | | attributes | attributes where the | | | | conflict occurred or | | | | is potentially to | | | | occur. | +----------------------+----------------------+----------------------+ | | Conflict reason | The description of | | | | the reason for the | | | | conflict. | +----------------------+----------------------+----------------------+ | | Conflicting metrics | The performance | | | | measurements and | | | | KPI(s) over which | | | | the SON or non-SON | | | | Functions conflict. | +----------------------+----------------------+----------------------+ | | Attribute conflict | The relative level | | | status | (low, medium, high) | | | | of impact of each | | | | conflicting | | | | attribute on the SON | | | | or non-SON | | | | functions. | +----------------------+----------------------+----------------------+ | | Recommended actions | The MOI and | | | | attributes | | | | recommended to be | | | | configured/changed: | | | | | | | | - The policy and | | | | targets of the SON | | | | functions, see TS | | | | 28.313 [19]; | | | | | | | | - The range of | | | | attributes value | | | | each conflicting SON | | | | function can change; | | | | | | | | - The priority of | | | | each conflicting SON | | | | function; | | | | | | | | - Value of the | | | | attributes of the | | | | affected MOIs (e.g., | | | | NRCellCU) where the | | | | conflict already | | | | occurred; | | | | | | | | - Switch off the | | | | conflicting SON | | | | functions, see TS | | | | 28.313 [19]. | +----------------------+----------------------+----------------------+
## 6.10 Security related issues
### 6.10.1 Security risk assessment
#### 6.10.1.1 Use case
Security risk assessment can detect anomalies in managed objects, e.g. NF,
identify potential security risks and propose countermeasures to mitigate
them. Security risks may originate from a variety of different sources and
target distinct network objects resulting in different abnormal behaviours,
e.g. sudden increase in computing and storage in a virtualization environment,
sudden increase of load in network links, abnormal communication patterns
between NFs, excessive latency in accessing a NF, relocating a NF in an
unexpected location or interrupting the relocation of a NF.
To assess security risks, the management plane can leverage the benefits of
MDAS. An MDAS producer can identify a security risk issue by correlating
different performance measurements and alarms, i.e. performing a root cause
analysis to locate the malicious source and the network objects affected. Such
activity can be triggered when certain performance measurements and KPIs
indicate an abnormal network behaviour, which is not related to another known
faults.
_The MDAS producer should correlate the usage, e.g. considering the NF
procedures for supporting a number of UEs or other events, with the
corresponding resource usage, e.g. in terms of CPU, storage and disk. If no
other fault alarms indicate another reason, an unexpected resource usage
should trigger a security risk analysis to identify the issue based on a
private security risk database that resides on the MDAS producer._ The MDAS
producer can notify the MDAS consumer, e.g. MnF or NE, and provide
recommendations to mitigate the identified security risk. The MDAS consumer
based on the recommendations can isolate the malicious network objects, e.g.
NF, and can also provide recommendations to harden the network in order to
avoid similar security risks in the future.
#### 6.10.1.2 Potential requirements
**REQ-SEC_CON-1** The MDAS producer should have a capability to provide the
analytics report describing the security risk to authorized consumers based on
the correlation of current and predicted performance measurements and alarms.
**REQ-SEC_CON-2** The analytics report describing the security issue should
contain the following information describing the current and future security
risk issue:
> \- Identify the type of security risk.
>
> \- Location and network objects affected by the security risk.
>
> \- Root cause analysis of the security risk issue.
>
> \- Recommended action to isolate and/or restrict the security risk issue and
> harden the network security.
#### 6.10.1.3 Possible solutions
##### 6.10.1.3.1 Solution description
The solution considers security risk assessment related to network. The MDAS
producer correlates and analyzes performance measurements and alarm data
considering the network topology and configuration data related to statistics
or predictions to identify the type of security risk.
##### 6.10.1.3.2 Data required
The following data is required to perform the corresponding security risk
assessment analysis.
+------------------------------+--------------------------------------+ | **Data category** | **Required data** | +==============================+======================================+ | **Alarm Data** | Alarm information - types of alarms | +------------------------------+--------------------------------------+ | **Service Data** | S-NSSAI as defined in clause 5.15.2, | | | TS 23.501 [13]. MDAS may derive | | | network topology information | +------------------------------+--------------------------------------+ | **Performance Measurements** | Failures and disruptions: | | | | | | > \- Number of abnormal releases: | | | > DRB, QoS flows, PDU sessions, UE | | | > context in serving cells as per TS | | | > 28.552 [8] | | | > | | | > \- Disruption measurements: | | | > CQI/MCS as per TS 28.552 [8] | | | > | | | > \- Excessive delay in accessing | | | > NFs (e.g. AMF or SMF) | | | > | | | > \- NF abnormal and excessive | | | > communication, e.g. AMF uses a | | | > different SMF without performing | | | > the expected selection process or | | | > it overloads an SMF unexpectedly. | | | > | | | > \- Intra/inter-gNB handover: | | | > failures - long handover time as | | | > per TS 28.552 [8] | | | | | | Virtualized resources/behaviour: | | | | | | > \- Virtual resource usage of NF: | | | > The resource usage of virtual | | | > network functions, see clause | | | > 5.7.1 of TS 28.552 [8] | | | > | | | > \- Virtual NF Re-location: | | | > Timing/duration and success rate | | | > | | | > \- Frequency of virtual NF | | | > Re-location: Rate of relocation | | | > | | | > \- Virtual NF location: NF | | | > location with respect to a data | | | > network | | | | | | NF context information as per TS | | | 28.552 [8]: | | | | | | > \- Number of UEs/periodic | | | > registration updates (AMF) | | | > | | | > \- Number of PDU | | | > sessions/modifications, QoS flows | | | > (SMF) | | | > | | | > \- N4/N6/N9 measurements or packet | | | > delay, traffic volume, link usage, | | | > packet loss (UPF) | | | > | | | > \- Number of application trigger | | | > requests rejected (NEF) | | | > | | | > \- Number of failed NF service | | | > registration/update, discoveries | | | > due to unauthorized NF/error (NRF) | +------------------------------+--------------------------------------+ | **Configuration Data** | NRM attributes affecting the | | | location and virtual NF resource | | | allocation and configuration | | | | | | NRM update reports (notification and | | | log) containing the creation or | | | changes of the MOIs affecting the | | | virtual NFs | +------------------------------+--------------------------------------+ | **Network Topology** | Topology of the network | +------------------------------+--------------------------------------+
##### 6.10.1.3.3 Analytics report
The MDAS producer offers a new Security Analytics service to the MDAS
consumer, which supports security risk assessment related providing the
following analytics results:
+----------------------+----------------------+----------------------+ | **Analytics Report |** Attribute Name**|** Description**| | of Security risk | | | | assessment** | | | +======================+======================+======================+ | | **Security Incident | Identifier that | | | Identifier** | indicates the | | | | security risk (e.g. | | | | DDoS, malicious NF, | | | | etc.) | +----------------------+----------------------+----------------------+ | | **Type of | Statistics or | | | Analytics** | Prediction of | | | | security risks | +----------------------+----------------------+----------------------+ | | **Location** | Geographical | | | | location that the | | | | security risk | | | | affects | +----------------------+----------------------+----------------------+ | | **Affected Objects** | NF, PDU session, QoS | | | | Flow, Slice | +----------------------+----------------------+----------------------+ | | **Start/Stop Time** | Starts/stop time of | | | | the security risk | | | | issue | +----------------------+----------------------+----------------------+ | | **Root Cause** | The originator of | | | | security issue to | | | | isolate fast the | | | | problem. | +----------------------+----------------------+----------------------+ | | **Severity Level** | The severity level | | | | (e.g. critical, | | | | medium, not | | | | important) of the | | | | security risk issue | +----------------------+----------------------+----------------------+ | | **Recommended | Recommendation | | | Actions** | actions to resolve | | | | the security risk | | | | issue: | | | | | | | | > \- | | | | > Isolate/terminate | | | | > NF, terminate PDU | | | | > session, throttle | | | | > signalling from NF | | | | > or UE, block UE, | | | | > etc. | | | | > | | | | > \- Harden security | | | | > on specific NF, | | | | > firewall update, | | | | > scaling resources, | | | | > load balancing, | | | | > admission control, | | | | > etc. | +----------------------+----------------------+----------------------+
### 6.11 Traffic projection
### 6.11.1 Network slice traffic projection
#### 6.11.1.1 Use case
Some of the requirements captured in SliceProfile need to be translated into
configurable parameter for various network entities including entities in 5G
Core Network (5GC), Radio Access Network (RAN) and Transport Network. One of
the example would be: the GST attribute Downlink throughput per slice
(dLThptPerSlice) can be translated into maximum downlink throughput per slice
(maxDlThptPerSlice) as a configuration parameter, for UPF. However, as one
slice may have multiple UPF instances, dividing the total quota available
among each UPF instance is critical. **The given requirements can be divided
among all the targeted NF instance based on the slice traffic analytics.** The
value for a particular configurable parameter (translated from a particular
ServiceProfile attribute) for a particular NF is crucial, especially if
multiple instance of that NFs is available in the network slice instance.
**It is desirable to use uses MDAS to get the network slice traffic
projections including individual traffic projections on each of the
constituent network functions instances present in the slice. The individual
traffic projections can be used to divide total available quota among the
constituent network functions instances which can then be configured for
network function(s), as required. For example, MDAS can provide total number
of projected terminal or subscription for each AMF instance in the slice.
Based on the projections the total available quota can be divided among the
multiple AMF instances in the slice. The AMF instance serving more users or
require to serve more users in future will have more quota then other AMF
instances in the slice.**
#### 6.11.1.2 Potential Requirements
**REQ-TRA_CON_CON-1: The MDAS producer should have a capability allowing the
authorized consumer to request the slice traffic analytics report describing
traffic projection of the slice including its constituent network functions.**
**REQ-TRA_CON_CON -2: The MDAS producer should have a capability to provide
the slice traffic analytics report describing the traffic projections for each
constituent network function instance in the slice.**
**REQ-TRA_CON_CON -3:** **The slice traffic analytics report providing traffic
projection for the slice may include the following information:**
> \- Projected uplink and downlink throughput requirement on each User Plane
> Function instance (UPF) present in the slice.
>
> \- Projected number of Packet Data Unit (PDU) session for each Session
> Management Function (SMF) instance present in the slice.
>
> \- Projected number of UE or Registered subscriptions for each AMF instance
> present in the slice.
>
> \- Projected maximum packet size for each UPF instance present in the slice.
>
> \- Projected UE uplink and downlink throughput requirement per slice on each
> gNodeB (gNB) instance present in the slice.
#### 6.11.1.3 Possible Solutions
##### 6.11.1.3.1 Solution description
The solution requires MDAS producer to produce slice traffic analytics report
providing traffic projections on NFs involved in the slice. Based on the
report, configuration for the NFs can be decided.
##### 6.11.1.3.2 Data required
The following table shows the data required to generate the traffic analytics
report.
+-------------------------------+-------------------------------------+ | **Data Category** | **Required Data** | +===============================+=====================================+ | Performance Measurements/KPIs | | +-------------------------------+-------------------------------------+ | | From each UPF instance in the slice | | | | | | > \- Current Uplink throughput. See | | | > 5.4.1.3 in TS 28.552. | | | > | | | > \- Current Downlink throughput. | | | > See 5.4.1.4 TS 28.552 | | | > | | | > \- Current Maximum packet size | +-------------------------------+-------------------------------------+ | | From each gNB instance in the slice | | | | | | > \- Current Uplink UE throughput. | | | > See 5.1.1.3 in TS 28.552. | | | > | | | > \- Current Downlink UE | | | > throughput. See 5.1.1.3 in TS | | | > 28.552. | +-------------------------------+-------------------------------------+ | | From each SMF instance in the slice | | | | | | > \- Current Number of PDU session. | | | > See 5.2.1 in TS 28.552. | +-------------------------------+-------------------------------------+ | | From each AMF instance in the slice | | | | | | > \- Current Number of registered | | | > subscriptions. See 5.2.1 in TS | | | > 28.552. | +-------------------------------+-------------------------------------+
##### 6.11.1.3.3 Analytics report
The slice traffic analytics report shall contain the following:
**Analytics Report of slice traffic projection** **Attribute Name**
**Description**
* * *
                                                     Slice Identifier            Identifier of the slice for which the report is provided
                                                     Projection Timestamp        Provide a particular time stamp for which the projections are provided
                                                     Projection Duration         Provides a time duration during which the average projections are provided
                                                     For each UPF in the slice   Projected Uplink throughput
                                                                                 Projected Downlink throughput
                                                                                 Projected Maximum packet size
                                                     For each gNB in the slice   Projected Uplink UE throughput.
                                                                                 Projected Downlink UE throughput
                                                     For each SMF in the slice   Projected Number of PDU session
                                                     For each AMF in the slice   Projected Number of registered subscriptions
## 6.99 MDA management aspects
Editor's Note: This sub-clause will be put to the end of clause 6 to separate
from other categories of issues. The sub-clause number will be revisited
before sending the TR for approval.
### 6.99.1 ML model training for MDA
#### 6.99.1.1 Use case
The MDA process may rely on ML technologies. To optimize the accuracy of MDA
result, the ML model of the MDA process may need to be trained.
For training the ML model of the MDA process, the consumer provides the
training data including training input and the desired output to the MDAS
producer. The MDAS producer classifies the training data and uses the training
input and the desired output to train the ML model, i.e., to train the
algorithm of the ML model to be able to provide the desired output by analysis
of the training input. The MDAS producer provides an ML model training report
as one kind of output data to the consumer.
With a trained ML model for MDA, the MDAS producer can analyze the analytics
input and generate the analytics report as output data of the analysis to the
consumer.
The consumer may validate the output data provided by the MDAS producer. The
output data to be validated may be the analytics report and/or the ML model
training report as described above. The consumer may provide the validation
data as feedback to the MDAS producer, and the MDAS producer will use the
validation data for further ML model training for MDA with the historical data
that are used to generate the validated output data.
#### 6.99.1.2 Potential requirements
**REQ-MDA_MGMT-CON-1** The MDAS producer should have a capability allowing the
consumer to train the ML model for MDA.
**REQ-MDA_MGMT-CON-2** The MDAS producer should have a capability to provide
ML model training report to the consumer.
**REQ-MDA_MGMT-CON-3** The MDAS producer should have a capability to receive
the validation data from the consumer and train the ML model for MDA based on
the received validation data.
### 6.99.2 Subscription to Management Data Analytics Reports
#### 6.99.2.1 Use case
MDAS Producer may provide several management data analysis reports. Multiple
users may wish to receive a selection of these reports.
The user submits a request to MDAS to subscribe to an MDA report. This request
may include a filter to specify which subset of management data should be
analysed. MDA activates the data collection if it is not already active.
For all reports, MDA collects data, analyses the data, and generates an
analysis report.
MDA notifies to subscribers when a new or updated analysis report is
available. The notification may contain the analytics report, or the
notification may contain a link to a location where the report may be
retrieved.
The user may send a request to MDAS to unsubscribe from an MDA report. If no
subscribers remain for an MDA report, MDA may decide to deactivate data
collection for this report.
#### 6.99.2.2 Potential requirements
**REQ-MDA_SUB-1** The MDAS producer should have a capability to allow an MDAS
consumer to subscribe to an analytics report. The subscription request should
optionally allow the MDAS consumer to filter the scope of data in the
analytics report.
**REQ-MDA_SUB-2** The MDAS producer should have a capability to provide the
analytics report to subscribed consumers.
**REQ-MDA_SUB-3** The MDAS producer should have a capability to allow an MDAS
consumer to unsubscribe to an analytics report.
#### 6.99.2.3 Possible solutions
Figure 6.99.2.3-1 shows a possible solution.
Figure 6.99.2.3-1: Management data analytics subscribe/unsubscribe
### 6.99.3 Request for Management Data Analytics Reports
#### 6.99.3.1 Use case
MDA may provide several management data analysis reports. A user may wish to
receive one of these reports.
The user submits a request to MDAS to receive an MDA report. This request may
include a filter to specify which subset of management data should be
analysed.
MDA collects data, analyses the data, and sends an analysis report to the
user.
#### 6.99.3.2 Potential requirements
**REQ-MDA_REQ-1** The MDAS producer should have a capability to allow an MDAS
consumer to request an analytics report. The request should optionally allow
the MDAS consumer to filter the scope of data in the analytics report.
**REQ-MDA_REQ-2** The MDAS producer should have a capability to provide the
analytics report to the MDAS consumer.
#### 6.99.3.3 Possible solutions
Figure 6.99.3.3-1 shows a possible solution.
Figure 6.99.3.3-1: Network management data analytics request
## 6.99.4 Confidence indicator in analysis results
A _consumer of MDAS should treat the results of Management Data Analytics with
caution. A decision based on analytics should take into account the degree of
confidence of the analysis result, especially in the case when multiple
analysis results are based on different models or different source data._
_Therefore it is proposed that the result of Management Data Analytics should
contain an attribute which indicates the degree of confidence of the
analysis._
NOTE: How to evaluate a degree of confidence and how it should be expressed as
an attribute are not addressed in this study. More work is needed in this
area.
# 7 Conclusions and recommendations
#