# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
The present document provides information on the performances of default
speech codecs in packet switched conversational multimedia applications. The
codecs under test are AMR-NB (Adaptive Multi-Rate Narrowband) and AMR-WB
(Adaptive Multi-Rate Wideband). In addition, several ITU-T codecs (G.723.1,
G.729, G.722 and G.711) are included in the testing. Experimental test results
from the speech quality testing are reported to illustrate the behaviour of
these codecs.
The results give information of the performance of PS conversational
multimedia applications under various operating and transmission conditions
(e.g., considering radio transmission errors, IP packet losses, end-to-end
delays, and several types of background noise). The performance results can be
used e.g. as guidance for network planning and to appropriately adjust the
radio network parameters.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
  * References are either specific (identified by date of publication, > edition number, version number, etc.) or non‑specific.
  * For a specific reference, subsequent revisions do not apply.
  * For a non-specific reference, the latest version applies. In the > case of a reference to a 3GPP document (including a GSM document), > a non-specific reference implicitly refers to the latest version > of that document _in the same Release as the present document_
[1] ITU-T Recommendation P.800: \"Methods for Subjective Determination of
Transmission Quality\".
[2] ITU-T Recommendation P.831: \"Subjective performance evaluation of network
echo cancellers\".
[3] ITU-T Recommendation G.711: \"Pulse code modulation (PCM) of voice
frequencies\".
[4] ITU-T Recommendation G.729: \"Coding of speech at 8 kbit/s using
conjugate-structure algebraic-code-excited linear-prediction (CS-ACELP)\".
[5] ITU-T Recommendation G.723.1: \"Dual rate speech coder for multimedia
communications transmitting at 5.3 and 6.3 kbit/s\".
[6] ITU-T Recommendation G.722: \"7 kHz audio-coding within 64 kbit/s\".
[7] IETF RFC 1889: \"RTP: A Transport Protocol for Real-Time Applications\".
[8] IETF RFC 3267: \"Real-Time Transport Protocol (RTP) Payload Format and
File Storage Format for the Adaptive Multi-Rate (AMR) Adaptive Multi-Rate
Wideband (AMR-WB) Audio Codecs\".
[9] 3GPP TS 34.121: \"Terminal Conformance Specification, Radio Transmission
and Reception (FDD)\" (downlink).
[10] 3GPP TS 25.141: \" Base Station (BS) conformance testing (FDD)\"
(uplink).
[11] 3GPP TR 25.853 \"Delay budget within the access stratum\".
[12] 3GPP TS 26.235: \"Packet switched conversational multimedia applications;
Default codecs\".
[13] 3GPP TS 26.071: \"AMR speech Codec; General description\".
[14] 3GPP TS 26.171: \"AMR speech codec, wideband; General description\".
[15] 3GPP TS 25.322: \"Radio Link Control (RLC) protocol specification\".
[16] IETF RFC 3095: \"RObust Header Compression (ROHC): Framework and four
profiles: RTP, UDP, ESP, and uncompressed\".
[17] 3GPP TS 34.108: \"Common test environments for User Equipment (UE)
conformance testing\".
[18] ETSI TR 101 112: \"Universal Mobile Telecommunications System (UMTS);
Selection procedures for the choice of radio transmission technologies of the
UMTS\" (UMTS 30.03 v3.1.0).
[19] 3GPP TS 26.114 : "IP Multimedia Subsystem (IMS); Multimedia Telephony;
Media handling and interaction"
[20] ITU-T Recommendation P.805 (P.CONV): "Subjective evaluation of
conversational quality"
# 3 Abbreviations
## 3.1 Abbreviations
For the purposes of the present document, the following abbreviations apply:
> AMR-NB (or AMR) Adaptive Multi-Rate Narrowband Speech Codec
>
> AMR-WB Adaptive Multi-Rate Wideband Speech Codec
>
> ANOVA Analysis of Variance
>
> ASY ASYmmetric conditions
>
> BLER Block Error Rate
>
> CDF Cumulative Distribution Function
>
> CMR Codec Mode Request
>
> COND Test CONDitions
>
> CN Core Network
>
> CQ Conversational Quality
>
> CRC Cyclic Redundancy Check
>
> DCH Dedicated Channel
>
> DL Downlink
>
> DMOS Degradation Mean Opinion Score
>
> DPCH Dedicated Physical Channel
>
> DTCH Dedicated Traffic Channel
>
> Eb/No Ratio of energy per modulating bit to the noise spectral density
>
> EID Error Insertion Device
>
> FER Frame Erasure Rate, Frame Error Rate
>
> GAL Global Analysis Laboratory
>
> GQ Global Quality (of the conversation)
>
> HM High Mobility
>
> HT High Traffic
>
> HSDPA/EUL High Speed Downlink Packet Access/Enhanced UpLink
>
> IA InterAction (with your partner)
>
> IP Internet Protocol
>
> ITU-T International Telecommunication Union - Telecommunications
> Standardization Sector
>
> JBM Jitter Buffer Management
>
> LAB Listening LABoratory
>
> LM Low Mobility
>
> LT LowTraffic
>
> MAC Medium access control
>
> MANOVA Multivariate Analysis of Variance
>
> Log-MAP Logarithmic Maximum A Posteriori
>
> MOS Mean Opinion Score
>
> NB Narrowband
>
> PC PerCeption of impairments (also: Personal Computer)
>
> PDCP Packet Data Convergence Protocol
>
> PDU Protocol Data Unit
>
> Pa Sound Pressure Level (in Pascal)
>
> PL Packet Loss
>
> plc Packet Loss Concealment
>
> RC Radio Conditions
>
> PS Packet Switched
>
> RB Radio Bearer
>
> RAB Radio Access Bearer
>
> RCV Receive
>
> RLC Radio Link Control
>
> ROHC Robust Header Compression
>
> RRM Radio Resource Management
>
> RTCP Real-Time Control Protocol
>
> RTP Real-time Transport Protocol
>
> SYM SYMmetric conditions
>
> TB size Transport Block size
>
> TF Transport Format
>
> ToC Table of Content
>
> TrCH Transmission Channel
>
> TTI Transmission Time Interval
>
> UDP User Datagram Protocol
>
> UE User Equipment
>
> UL Uplink
>
> UM Unacknowledged Mode
>
> UMD Unacknowledged Mode Data
>
> US difficulty UnderStanding (your partner)
>
> VOIP Voice over IP
>
> VQ Voice Quality (of your partner)
>
> WB Wideband
>
> XMIT Transmit
# 4 General Overview
## 4.1 Introduction
The performance of default speech codecs (AMR-NB and AMR-WB) for packet
switched conversational multimedia [12, 19] was characterised over DCH
channels and over HSDPA/EUL radio channels.
The testing over DCH channels was carried out from October 2003 until February
2004. Further subjective testing was carried out from June until October 2007
in order to characterize the performance over HSDPA/EUL radio channels. The
main purpose of the latter testing was to evaluate and verify adequate
performance of the AMR-NB and AMR-WB speech codecs used as defined in IMS
Multimedia Telephony TS 26.114 [19] with a specific focus on jitter buffer
management.
## 4.2 Tests over DCH radio channels
The tests over DCH channels were separated into two phases: Phase 1 considered
the default speech codecs AMR-NB [13] and AMR-WB [14] in various operating
conditions. Phase 2 considered also several other codecs including ITU-T
codecs G.723.1 [5], G.729 [4], G.722 [6] and G.711 [3].
In Phase 1, France Telecom R&D acted as host laboratory. The subjective
testing laboratories were ARCON for the North American English language,
France Telecom R&D for the French language and NTT-AT for the Japanese
language. Phase 1 tests consisted of 24 test conditions both for the AMR codec
(modes 6.7 and 12.2 kbit/s) and the AMR-WB codec (modes 12.65 and 15.85
kbit/s) with error conditions covering both IP packet loss of 0% and 3% and
radio conditions with 10--2, 10--3 and 5 10-4 BLER (Block Error Rate). End-to-
end delays of 300 and 500 ms were covered. Robust Header Compression (ROHC),
an optional UMTS functionality, was included for some test cases for AMR-WB.
Three types of background noise were used: car, street and cafeteria.
In Phase 2, France Telecom R&D acted as host and listening laboratory. Two
languages were used (French and Arabic). The following codecs were tested:
AMR-NB (modes 6.7 and 12.2 kbit/s), AMR-WB (modes 12.65 and 15.85 kbit/s),
ITU-T G.723.1 (mode 6.4 kbit/s), ITU-T G.729 (mode 8 kbit/s), ITU-T G.722
(mode 64 kbit/s) and ITU-T G.711 (64 kbit/s). Transmission error conditions
covered IP packet loss of 0% and 3%.
Siemens provided the real time air interface simulator for the Phase 1. France
Telecom provided the IP core network simulator and terminal simulator used in
both experiments Phase 1 and Phase 2. IPv6 was employed in the testing. (IPv6
is fully simulated over the radio interface. The CN simulator employs IPv4 but
since the only impact is a marginal difference in the end-to-end delay - of
the order of \~16 ìs - the use of a particular IP-version in CN part has no
impact on the performance results.)
These tests were the first ever conversational tests conducted in any
standardization body. Performance evaluation consisted of assessment of 5
aspects: 1) voice quality, 2) difficulty of understanding words, 3) quality of
interaction, 4) degree of impairments, and 5) global communication quality. A
5-category rating scale was used for each aspect.
Dynastat performed the global analysis for Phases 1 and 2. The results are
contained in Clause 7.
## 4.3 Tests over HSDPA/EUL radio channels
These listening-only tests characterized the performance of AMR-NB and AMR-WB
speech codecs over HSDPA/EUL channels when conducting buffer adaptation to the
network delay variations using a simple jitter buffer management (JBM)
algorithm. The tests focused on the effect of channel errors and channel
jitter to speech quality instead of the impact of overall end-to-end delay in
speech conversation. The end-to-end delay impact was considered separately by
conducting a delay analysis on the whole processed test material.
The subjective listening-only tests were conducted in Finnish and Swedish
languages at Nokia and Ericsson, respectively. The tests consisted of eight
different channel conditions in clean speech and in background noise
conditions. AMR-NB was tested in 12.2 and 5.9 kbit/s modes, and AMR-WB at
12.65 kbit/s. The outstanding issue was to evaluate the performance of
adaptive JBM operation in HSDPA/EUL channel conditions. The applied adaptive
jitter buffer was a simple implementation conducting buffer adaptation mainly
during discontinuous transmission, i.e. speech pauses, and not using any time
scaling operation. A non-implementable fixed jitter buffer with the full a
priori knowledge on the channel characteristics was used as a reference.
Although the average end-to-end delays of both adaptive and fixed jitter
buffers were the same, the number and locations of jitter buffer induced frame
losses were different depending on the channel conditions.
The results are contained in Clause 8A.
A program of Conversation Tests was organized to evaluate the performance of
AMR-NB and AMR-WB for UMTS over HSDPA/EUL. Three test labs were contracted to
conduct the conversation tests and deliver raw voting data to Dynastat, the
Global Analysis Lab (GAL), for processing and statistical analysis.
Three conversation tests were conducted in each of three test labs. The test
labs were FTRD, testing in the French language, BIT, testing in the Chinese
language, and Dynastat, testing in North American English. Each of the three
conversation tests involved a different speech codec:
  * Exp.1 - AMR operating at 5.9k bps
  * Exp.2 - AMR operating at 12.2k bps
  * Exp.3 - AMR-WB operating at 12.65k bps
The experiments were conducted according to specifications contained in the
ITU-T Recommendation for Conversation Testing, P.805 [20]. Alcatel-Lucent
provided the network impairment simulation test-bed. The raw voting data for
each test lab and each Experiment was delivered to the GAL. The GAL conducted
statistical analyses on the raw voting data and the results of those analyses
are contained in Clause 8B.
# 5 Test bed and test plan for Phase 1
This section describes the test plan for the Phase 1 of the conversation test
of the AMR-NB (AMR) and AMR-WB in PS networks. All the laboratories
participating to this conversation test phase used the same test plan, just
the language of the conversation changed. Even if the test rooms or the test
equipments are not exactly the same in all the laboratories, the calibration
procedures and the tests equipment characteristics and performance guaranteed
the similarity of the test conditions.
Annex B contains the instructions for the subjects participating to the
conversation tests.
## 5.1 Test methodology
The protocol described below evaluates the effect of degradation such as delay
and dropped packets on the quality of the communications. It corresponds to
the conversation-opinion tests recommended by the ITU-T P.800 [1]. First of
all, conversation--opinion tests allow subjects passing the test to be in a
more realistic situation, close to the actual service conditions experienced
by telephone customers. In addition, conversation-opinion tests are suited to
assess the effects of impairments that can cause difficulty while conversing
(such as delay).
Subjects participate to the test by couple; they are seated in separate sound-
proof rooms and are asked to hold a conversation through the transmission
chain performed by means of UMTS simulators, and communications are impaired
by means of an IP impairments simulator part of the CN simulator and by the
air interface simulator, as Figure 1 describes it.
The network configurations (including the terminal equipments) are symmetrical
(in the two transmission paths). The only dissymmetry will be due to presence
of background noise in one of the test rooms.
## 5.2 Test arrangement
### 5.2.1 Description of the testing system
Figure 1 describes the simulation system.
{width="6.309722222222222in" height="3.4583333333333335in"}
Figure 1: Packet switch audio communication simulator
The PS audio communication has been simulated using 5 PCs as shown in Figure
2.
{width="6.354861111111111in" height="2.9159722222222224in"}
Figure 2: Simulation Platform
PC 1 and PC 5 are running under Windows OS with the VOIP Terminal Simulator
Software of France Telecom R&D. PC 2 and PC 4 run under Linux OS with the Air
Interface Simulator coming from Siemens AG. And PC 3 runs under WinNT OS with
Network Simulator Software (NetDisturb).
The platform simulates a PS interactive communication between two users using
PC 1 and PC 5 as their relative VOIP terminals. PC 1 sends AMR (or AMR-WB)
encoded packets that are encapsulated using IP/UDP/RTP headers to PC 5. PC 1
receives IP/UDP/RTP audio packets from PC 5.
In fact, the packets created in PC 1 are sent to PC 2. PC 2 simulates the air
interface uplink (UL) transmission and then forwards the transmitted packets
to PC 4.
In the same way, PC 4 simulates the air interface downlink (DL) transmission
and then forwards the packets to PC 5. PC 5 decodes and plays the speech back
to the listener.
### 5.2.2 Network simulator
The core network simulator, as implemented, works under IPv4. However, as the
core network simulator acts only on packets (loss, delay,...) the use of IPv4
or IPv6 is equivalent for this test conversation context. Considering the
networks perturbations introduced by the simulator and the context of the
interactive communications, the simulation using IPv4 perturbation network
simulator is adapted to manage and simulate the behaviours of an IPv6 core
network.
Figure 3 shows the possible network simulator parameters that can be modified.
{width="6.574305555555555in" height="3.9138888888888888in"}
Figure 3: IP simulator interface
On both links, one can choose delay and loss laws. Both links can be treated
separately or in the same way. For example, delay can be set to a fixed value
but can also be set to another law such as exponential law.
Only loss law and delay law were given values, for delay law the values are 0
or 200 ms and for loss law the possible values: 0% or 3% under bursty law.
Both links were treated in the same way.
### 5.2.3 UMTS simulator choices
The transmission of IP/UDP/RTP/AMR (or AMR-WB) packets over the UMTS air
interface is simulated using the RAB described in Section 5.2.3.1. The
required functions of the RLC layer are implemented according to [15] and work
in real-time. The underlying Physical Layer is simulated offline. Error
patterns of block errors (i.e. discarded RLC PDUs) are inserted in the real-
time simulation as described in Section 5.2.3.2. For more details on the
parameter settings of the Physical Layer simulations see Section 5.2.3.3.
#### 5.2.3.1 RAB and protocols
For the narrowband conversational tests, the AMR is encoded with a maximum of
12.2 kbit/s. The bitstream is encapsulated using IP/UDP/RTP protocols. The air
interface simulator receives IPv4 packets from the CN simulator. The RTP
packets are extracted and before transmission over the air interface, IPv6/UDP
headers are inserted. Finally real IPv6 packets are transmitted over the air
interface simulator.
The payload format is the following:
− RTP payload format for AMR-NB (cf. [8]) is used;
− Bandwidth efficient mode is used;
− One speech frame is encapsulated in each RTP packet;
− Interleaving is not used;
The payload header consists of the 4 bits of the CMR (Codec Mode Request).
Then 6 bits are added for the ToC (Table of Content). For IPv4, this
corresponds to a maximum of 72 bytes per frame that is to say 28.8 kbit/s.
This goes up to 92 bytes (36.8 kbit/s) when using IPv6 protocol on the air
interface.
RTCP packets are sent. However, in the test conditions defined in the
conversation test plans, RTCP is not mandatory, as it is not in a multicast
environment (cf. [7]). RTCP reports were sent but not used.
ROHC is an optional functionality in UMTS. In order to reduce the size of the
tests and the number of conditions, the ROHC algorithm is not used for the
AMR-NB conversation test. This functionality is only tested in the wideband
condition.
For the WB conversational tests, the AMR-WB encodes speech at a maximum of
15.85 kbit/s. The bitstream is also encapsulated and transmitted in the same
way as for the NB case. For IPv4 a maximum of 81 bytes (41 bytes for the AMR
and its payload header plus the 40 bytes of the IP/UDP/RTP headers) per frame
are transmitted that is to say 32.4 kbit/s, this goes up to 101 bytes (40.4
kbit/s) when using IPv6 protocol on the air interface.
ROHC algorithm is supported in the AMR-WB conversation test, for the 12.65
kbit/s mode and the 15.85 modes. Header compression is done on the IP/UDP/RTP
headers (profile 1). ROHC starts in the unidirectional mode and switches to
bi-directional mode as soon as a packet has reached the decompressor and
replied with a feedback packet indicating that a mode transition is desired.
The Conversational / Speech / UL:46 DL:46 kbps / PS RAB coming from [17] was
used. It is not an optimal RAB for PS conversational test but it was the only
one available at the time the test bed and the air interface simulator were
designed. The RAB description is given in Table 1.
Table 1: RAB description
* * *
Higher layer RAB/Signalling RB RAB  
PDCP PDCP header size, bit 8  
RLC Logical channel type DTCH  
RLC mode UM  
Payload sizes, bit 920, 304, 96  
Max data rate, bps 46000  
UMD PDU header, bit 8  
MAC MAC header, bit 0  
MAC multiplexing N/A  
Layer 1 TrCH type DCH  
TB sizes, bit 928, 312, 104  
TFS TF0, bits 0x928 TF1, bits 1x104 TF2, bits 1x312 TF3, bits 1x928 TTI, ms 20  
Coding type TC  
CRC, bit 16  
Max number of bits/TTI after channel coding 2844  
Uplink: Max number of bits/radio frame before rate matching 1422  
RM attribute 180-220
* * *
#### 5.2.3.2 Description of the RLC implementation
The UMTS air interface simulator (implemented in PC 2 and 4) receives
IP/UDP/RTP/AMR (or AMR-WB) packets on a specified port of the network card
(see Figure 4). The IP/UDP/RTP/AMR (or AMR-WB) packets are given to the
transmission buffer of the RLC layer, which works in Unacknowledged Mode (UM).
The RLC segments or concatenates the IP bitstream in RLC PDUs, adding
appropriate RLC headers (sequence number and length indicators). It is assumed
that always Transport Format TF 3 is chosen on the physical layer, providing
an RLC PDU length including header of 928 bits. In the regular case, one IP
packet is placed into an RLC PDU that is filled up with padding bits. Due to
delayed packets from the network simulator it may also occur that there are
none or no more than one IP packet in the RLC transmission buffer to transmit
in the current TTI.
Each TTI of 20ms, an RLC PDU is formed. It is then given to the error
insertion block that decides if the RLC PDU is transmitted successfully over
the air interface or if it is discarded due to a block error after channel
decoding. The physical layer is not simulated in real time, but error pattern
files are provided. The error patterns of the air interface transmission are
simulated offline according to the settings given in Section 5.2.3.1. They
consist of binary decisions for each transmitted RLC PDU, resulting in a
certain BLER.
After the error pattern insertion, the RLC of the air interface receiver site
receives RLC PDUs in the reception buffer. The sequence numbers of the RLC
headers are checked to detect when RLC PDUs have been discarded due to block
errors. A discarded RLC PDU can result in one or more lost IP packets,
resulting in a certain packet loss rate of the IP packets and thereby in a
certain FER of the AMR (or AMR-WB) frames. The IP/UDP/RTP/AMR (or AMR-WB)
packets are reassembled and transmitted to the next PC. This PC is either the
network simulator (PC 3) in case of uplink transmission, or is one of the
terminals (PC 1 or PC 5) in case of downlink transmission.
{width="6.615277777777778in" height="4.749305555555556in"}
Figure 4: UMTS air interface simulation
#### 5.2.3.3 Physical Layer Implementation
The parameters of the physical layer simulation were set according to the
parameters for a DCH in multipath fading conditions given in [9] for the
downlink and [10] for the uplink. The TB size is 928 bits and the Turbo
decoder uses the Log-MAP algorithm with 4 iterations. The rake receiver has 6
fingers at 60 possible positions.
The different channel conditions given in Tables 2, 3 and 4 were extracted
from [18] (Selection procedures for the choice of radio transmission
technologies of the UMTS).
Table 2: Indoor Office Test Environment Tapped-Delay-Line Parameters
* * *
Tap Channel A Doppler  
Rel. Delay (nsec) Avg. Power (dB) Spectrum 1 0 0 FLAT 2 50 -3.0 FLAT 3 110
-10.0 FLAT 4 170 -18.0 FLAT 5 290 -26.0 FLAT 6 310 -32.0 FLAT
* * *
Table 3: Vehicular Test Environment, High Antenna, Tapped-Delay-Line
Parameters
* * *
Tap Channel A Doppler  
Rel. Delay (nsec) Avg. Power (dB) Spectrum 1 0 0.0 CLASSIC 2 310 -1.0 CLASSIC
3 710 -9.0 CLASSIC 4 1090 -10.0 CLASSIC 5 1730 -15.0 CLASSIC 6 2510 -20.0
CLASSIC
* * *
Table 4: Outdoor to Indoor and Pedestrian Test Environment Tapped-Delay-Line
Parameters
* * *
Tap Channel A Doppler  
Rel. Delay (nsec) Avg. Power (dB) Spectrum 1 0 0 CLASSIC 2 110 -9.7 CLASSIC 3
190 -19.2 CLASSIC 4 410 -22.8 CLASSIC 5 - - CLASSIC 6 - - CLASSIC
* * *
Table 5 (DL) and Table 6 (UL) show approximate results of the air interface
simulation for $\frac{\text{DPCH}_{}}{I_{\text{or}}}$ and Eb/N0 corresponding
to the considered BLERs.
Table 5: Downlink performance - approximate
$\frac{\text{DPCH}_{}}{I_{\text{or}}}$ for the different channels and BLER
* * *
                                       BLER
Channel 5*10-2 1*10-2 1*10-3 5*10-4 Indoor, 3 km/h (= 9 dB) -13.1 dB -8.9 dB
-3.4 dB -2.4 dB Outdoor to Indoor, 3 km/h (= 9 dB) -13.2 dB -9.7 dB -5.9 dB
-5.2 dB Vehicular, 50 km/h (= -3 dB) -9.35 dB -8.2 dB -6.9 dB -6.55 dB
Vehicular, 120 km/h (= -3 dB) -9.7 dB -8.95 dB -7.95 dB -7.55 dB
* * *
Table 6: Uplink performance - approximate Eb/N0 for the different channels and
BLER
* * *
Channel BLER  
5*10-2 1*10-2 1*10-3 5*10-4 Indoor, 3 km/h 3.9 dB 6.4 dB 9.2 dB 9.8 dB Outdoor
to Indoor, 3 km/h 3.7 dB 6.1 dB 8.6 dB 9.2 dB Vehicular, 50 km/h -0.9 dB -0.15
dB 0.55 dB 0.75 dB Vehicular, 120 km/h 0.2 dB 0.6 dB 1.1 dB 1.3 dB
* * *
Outdoor to Indoor channel was used for uplink and downlink in the simulations.
### 5.2.4 Headsets and Sound Card
To avoid echo problems headsets were used instead of handsets. The monaural
headsets are connected to the sound cards of the PCs supporting the speech
codec simulators.
The sound level in the earphones can be adjusted, if needed, by the users.
But, in practice, the original settings, defined during the preliminary tests,
and producing a comfortable listening level, are not modified. The microphones
are protected by a foam ball in order to reduce the \"pop\" effect. It is also
suggested to the user to avoid placing the acoustic opening of the microphone
in front of the mouth.
### 5.2.5 Test environment
Each of the two subjects participating to the conversations are installed in a
test room. They sit on an armchair, in front of a table. The test rooms are
acoustically insulated. All the test equipments are installed in a third room,
connected to the test rooms. When needed, the background noise is generated in
the appropriate test room through a set of 4 loudspeakers. The background
noise level is adjusted and controlled by a sound level meter. The measurement
microphone, connected to the Sound level meter is located at the equivalent of
the center of the subject\'s head. The noise level is A weighted.
### 5.2.6 Calibration and test conditions monitoring
#### 5.2.6.1 Speech level
Before the beginning of a set of experiment, the end-to-end transmission level
is checked subjectively, to ensure that there is no problem. If it is
necessary to check the speech level following procedure is applied. An
artificial mouth placed in front of the microphone of the Headset A, in the
LRGP position (see ITU-T Rec. P.64), generates in the artificial ear
(according to ITU-T Rec. P57), coupled to the earphone of the Headset B, the
nominal level. If necessary, the level is adjusted with the receiving volume
control of the headset. Similar calibration is done by inverting headsets A
and B.
#### 5.2.6.2 Delay
The overall delay (from the input of sound card A to the output of sound card
B) is calculated as shown: On the air interface side, the simulator only
receives packets on its network card, processes them and transmits every 20 ms
these packets to the following PC. Only processing delay and a possible delay
due to a jitter can be added (a packet arrives just after the sending window
of the air interface).
The delay is calculated as shown below:
> − Encoder side: delay due to account framing, look-ahead, processing and
> packetization = 45ms
>
> − Uplink delay between UE and Iu: 84.4 ms (see [11])
>
> − Core network delay: a few ms
>
> − Routing through IP: depending on the number of routers.
>
> − Downlink delay between Iu and UE: 71.8 ms (see [11])
>
> − Decoder side, taking into account jitter buffer, de-packetization and
> processing: 40 ms
The total delay to be considered is at least: 241.2 ms.
## 5.3 Test conditions for AMR-NB codec
Tables 7 - 9 summarise the test conditions used for AMR-NB testing.
For both AMR-NB and AMR-WB codecs two representative modes were chosen for the
testing. The lowest codec modes (such as AMR-NB 4.75) were not included since
these are intended to be used mainly temporarily to cope with poor radio
conditions. They were expected to provide insufficient quality for
conversational applications if used throughout the call (as done in these
characterisation tests).
Table 7: Test conditions for AMR-NB
* * *
Cond. Background noise in Room A Background noise in Room B Experimental
factors  
Radio cond. (BLER) IP cond. (Packet loss ratio) Mode + delay 1 No No 10 --2 0%
6.7 kbit/s (delay 300 ms) 2 No No 10 --2 0% 12.2 kbit/s (delay 500 ms) 3 No No
10 --2 0% 12.2 kbit/s (delay 300 ms) 4 No No 10 --2 3% 6.7 kbit/s (delay 300
ms) 5 No No 10 --2 3% 12.2kbit/s (delay 500 ms) 6 No No 10 --2 3% 12.2 kbit/s
(delay 300 ms) 7 No No 10-3 0% 6.7 kbit/s (delay 300 ms) 8 No No 10-3 0% 12.2
kbit/s (delay 500 ms) 9 No No 10-3 0% 12.2 kbit/s (delay 300 ms) 10 No No 10-3
3% 6.7 kbit/s (delay 300 ms) 11 No No 10-3 3% 12.2 kbit/s (delay 500 ms) 12 No
No 10-3 3% 12.2 kbit/s (delay 300 ms) 13 No No 5 10-4 0% 6.7kbit/s (delay 300
ms) 14 No No 5 10-4 0% 12.2kbit/s (delay 500 ms) 15 No No 5 10-4 0% 12.2
kbit/s (delay 300 ms) 16 No No 5 10-4 3% 6.7kbit/s (delay 300 ms) 17 No No 5
10-4 3% 12.2 kbit/s (delay 500 ms) 18 No No 5 10-4 3% 12.2 kbit/s (delay 300
ms) 19 Car No 5 10-4 3% 12.2 kbit/s (delay 300 ms) 20 No Car 5 10-4 3% 12,2
kbit/s (delay 300 ms) 21 Cafeteria No 5 10-4 0% 6.7 kbit/s (delay 300 ms) 22
No Cafeteria 5 10-4 0% 6.7 kbit/s (delay 300 ms) 23 Street No 5 10-4 0%
12.2kbit/s (delay 500 ms) 24 No Street 5 10-4 0% 12.2kbit/s (delay 500 ms)
* * *
Table 8: Noise types for AMR-NB
* * *
Noise type Level (dB Pa ) Car 60 Street 55 Cafeteria 50
* * *
Table 9: Test details for AMR-NB
* * *
Listening Level 1 79 dBSPL Listeners 32 Naïve Listeners Groups 16 2
subjects/group Rating Scales 5  
Languages 3 North American English, French, Japanese Listening System 1
Monaural headset (flat response in the audio bandwidth of interest:
50Hz-7kHz). The other ear is open. Listening Environment Room Noise: Hoth
Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section
A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1), except when background
noise is needed (see Table 8 of this TR).
* * *
## 5.4 Test conditions for AMR-WB codec
Tables 10 - 13 summarise the test conditions used for AMR-WB testing.
Table 10: Test conditions for AMR-WB
* * *
Cond. Experimental factors  
Radio conditions (BLER) IP conditions (Packet loss ratio) Mode 1 10--2 0%
12,65 kbit/s, ROHC 2 10--2 0% 12,65 kbit/s 3 10--2 0% 15,85 kbit/s, ROHC 4 10
--2 3% 12,65 kbit/s, ROHC 5 10--2 3% 12,65 kbit/s 6 10--2 3% 15,85 kbit/s,
ROHC 7 10--3 0% 12,65 kbit/s, ROHC 8 10--3 0% 12,65 kbit/s 9 10--3 0% 15,85
kbit/s, ROHC 10 10--3 3% 12,65 kbit/s, ROHC 11 10--3 3% 12,65 kbit/s 12 10--3
3% 15,85 kbit/s, ROHC 13 5. 10--4 0% 12,65 kbit/s, ROHC 14 5. 10--4 0% 12,65
kbit/s 15 5. 10--4 0% 15,85 kbit/s, ROHC 16 5. 10--4 3% 12,65 kbit/s, ROHC 17
5. 10--4 3% 12,65 kbit/s 18 5. 10--4 3% 15,85 kbit/s, ROHC
* * *
Table 11: Test conditions with noise for AMR-WB
+----------+----------+----------+----------+----------+----------+ | * | **Ad |** Ad | **Expe | | | | *Cond.** | ditional | ditional | rimental | | | | | Ba | Ba | f | | | | | ckground | ckground | actors**| | | | | noise** | noise**| | | | | | | | | | | | |** Room | **Room | | | | | | A** | B** | | | | +----------+----------+----------+----------+----------+----------+ | | | | Radio | IP | Mode | | | | | co | co | | | | | | nditions | nditions | | | | | | (BLER) | (Packet | | | | | | | loss | | | | | | | ratio) | | +----------+----------+----------+----------+----------+----------+ | 19 | Car | No | 5 10-4 | 3% | 12,65 | | | | | | | kbit/s, | | | | | | | ROHC | +----------+----------+----------+----------+----------+----------+ | 20 | No | Car | 5 10-4 | 3% | 12,65 | | | | | | | kbit/s, | | | | | | | ROHC | +----------+----------+----------+----------+----------+----------+ | 21 | C | No | 5 10-4 | 0% | 12,65 | | | afeteria | | | | kbit/s | +----------+----------+----------+----------+----------+----------+ | 22 | No | C | 5 10-4 | 0% | 12,65 | | | | afeteria | | | kbit/s | +----------+----------+----------+----------+----------+----------+ | 23 | Street | No | 5 10-4 | 0% | 15,85 | | | | | | | kbit/s, | | | | | | | ROHC | +----------+----------+----------+----------+----------+----------+ | 24 | No | Street | 5 10-4 | 0% | 15,85 | | | | | | | kbit/s, | | | | | | | ROHC | +----------+----------+----------+----------+----------+----------+
Table 12: Noise Types for AMR-WB
* * *
Noise type Level (dB Pa) Car 60 Street 55 Cafeteria 50
* * *
Table 13: Test details for AMR-WB
* * *
Listening Level 1 79 dBSPL Listeners 32 Naïve Listeners Groups 16 2
subjects/group Rating Scales 5  
Languages 3 North American English, French, Japanese Listening System 1
Monaural headset (flat response in the audio bandwidth of interest:
50Hz-7kHz). The other ear is open. Listening Environment Room Noise: Hoth
Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section
A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1),except when background
noise is needed (see Table 12 of this TR)
* * *
# 6 Test bed and test plan for Phase 2
The Phase 2 of the listening test was conducted by one listening test
laboratory (FT R&D). The different speech coders used in this test are:
\- Adaptive Multi-Rate Narrow-Band (AMR-NB), in modes 6.7 kbit/s and 12.2
kbit/s,
\- Adaptive Multi-Rate Wide-Band (AMR-WB), in modes 12.65 kbit/s and 15.85
kbit/s,
\- ITU-T G.723.1, in mode 6.4 kbit/s,
\- ITU-T G.729, in mode 8 kbit/s,
\- ITU-T G.722 (wideband codec), in mode 64 kbit/s, with packet loss
concealment and,
\- ITU-T G.711, with packet loss concealment.
As there is no standardized packet loss concealment for G.711 and G.722,
proprietary packet loss concealment algorithms were used for them. The
simulated network was tested under two values of IP packet loss (0% and 3%).
The testing was done in one test laboratory only, but in two different
languages (Arabic and French).
The IP packet contains 20 ms speech frames except for G.723.1 for which IP
packet contains 30 ms speech. For G.729 the 20 ms packet consists of two 10 ms
frames.
The test methodology was the same as the one applied in Phase 1.
Annex B contains the instructions for the subjects participating to the
conversation tests.
## 6.1 Test arrangement
### 6.1.1 Description of the proposed testing system
Figure 5 describes the system that was simulated.
{width="6.363888888888889in" height="3.5097222222222224in"}
Figure 5: Packet Switched audio communication simulator
This was simulated using 3 PCs as shown in Figure 6.
{width="6.354861111111111in" height="2.9069444444444446in"}
Figure 6: Simulation Platform
PC 1 and PC 5 run under Windows OS with VOIP Terminal Simulator Software of
France Telecom R&D. PC 3 run under WinNT OS with Network Simulator Software
(NetDisturb).
The platform simulates a packet switched interactive communication between two
users using PC 1 and PC 5 as their relative VOIP terminals. PC 1 sends encoded
packets that are encapsulated using IP/UDP/RTP headers to PC 5. PC 1 receives
these IP/UDP/RTP audio packets from PC 5.
### 6.1.2 Network simulator
The core network simulator is the same as the one presented in Section 5\. The
different parameters that can be modified are presented in Figure 3 (Section
5.2.2).
In this test, only \"loss law\" has two values, all the others settings are
fixed. On both links, one can choose delay and loss laws. Both links can be
treated separately or in the same way. For example, delay can be set to a
fixed value but it can also be set to another law such as exponential law.
Only loss law was given values: 0% or 3% under bursty law. Both links were
treated in the same way.
Headsets were here also used to reduce echo problems. The monaural headsets
are connected to the sound cards of the PCs supporting the different codecs.
The sound level in the earphones can be adjusted, if needed, by the users.
But, in practice, the original settings, defined during the preliminary tests,
and producing a comfortable listening level, are not modified. The microphones
are protected by a foam ball in order to reduce the \"pop\" effect. It is also
suggested to the user to avoid placing the acoustic opening of the microphone
in front of the mouth.
The same test environment as in test Phase 1 is used. Each of the two subjects
participating to the conversations are installed in a test room. They sit on
an armchair, in front of a table. The test rooms are acoustically insulated.
All the test equipments are installed in a third room, connected to the test
rooms. The background noise level is checked by a sound level meter. The
measurement microphone, connected to the Sound level meter is located at the
equivalent of the center of the subject\'s head. The noise level is A
weighted.
### 6.1.3 Calibration and test conditions monitoring
The speech level checking is done in the same way as for Phase 1 (see Section
5.2.6.1).
The overall delay (from the input of sound card A to the output of sound card
B) is adjusted for each test condition taking into account the delay of the
related codec in order to have a fixed delay around 250ms. This value of 250ms
is close to the hypothetical delay computed for AMR-NB and AMR-WB through the
UMTS network.
## 6.2 Test Conditions
The test conditions and details are described in Tables 14 and 15.
Table 14: Test conditions
* * *
Cond. Experimental factors  
IP conditions (Packet loss ratio) Mode
1 0% AMR-NB 6,7kbit/s 2 0% AMR-NB 12,2 kbit/s 3 0% AMR-WB 12,65 kbit/s 4 0%
AMR-WB 15,85 kbit/s 5 0% G. 723.1 6,4 kbit/s 6 0% G.729 8 kbit/s 7 0% G.722 64
kbit/s + plc 8 0% G.711 + plc 9 3% AMR-NB 6,7kbit/s 10 3% AMR-NB 12,2 kbit/s
11 3% AMR-WB 12,65 kbit/s 12 3% AMR-WB 15,85 kbit/s 13 3% G. 723.1 6,4 kbit/s
14 3% G.729 8 kbit/s 15 3% G.722 64 kbit/s + plc 16 3% G.711 + plc
* * *
Table 15: Test details
* * *
Listening Level 1 79 dBSPL Listeners 32 Naïve Listeners per language Groups 16
2 subjects/group Rating Scales 5  
Languages 2 French, Arabic Listening System 1 Monaural headset (flat response
in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
Listening Environment Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T
Recommendation P.800: Annex A, section A.1.1.2.2.1 Room Noise, with table A.1
and Figure A.1)
* * *
# 7 Analysis of test results for DCH channels for Phase 1 and 2
This section presents the Global Analysis of the results. The analysis work
was performed by Dynastat in its function as the Global Analysis Laboratory
(GAL). Annex G presents the GAL Test Plan for characterizing the results of
the conversation tests. (Detailed test plans are given in Annexes D and E for
Phase 1 and in Annex F for Phase 2).
It should be noted that this is the first instance in any standardisation body
of conversation tests being used to characterize the performance of
standardized speech codecs, and the first instance of codecs in 3GPP being
characterized for packet-switched networks. Moreover, the analyses reported in
this document represent a new approach to evaluating the results of
conversation tests.
## 7.1 Conversation Tests
The Phase 1 test plan describes the methodology for conducting the
conversation tests. In general, the procedure involved a pair of subjects
located in different rooms and communicating over a simulated packet-switched
network. The subjects were involved in a task, which required them to
communicate in order to solve a specific problem. At the end of their task,
each subject was required to rate various aspects of the quality of their
conversation. Each of these ratings involved a five-point scale with
descriptors appropriate to the aspect of the conversation being rated. Table
16 shows a summary of the five rating scales. (The first row in each column
shows the scale abbreviation that will be used throughout this report).
Table 16: Summary of Rating Scales used in the Conversation Tests
{width="6.409027777777778in" height="1.3125in"}
Since each subject makes five ratings for each condition, there are five
dependent variables involved in analyses of the response data. We would expect
the ratings on the scales in Table 16 to show some degree of inter-correlation
across test conditions. If, in fact, all five were perfectly correlated then
we would conclude that they were each measuring the same underlying variable.
In this scenario, we could combine them into a single measure (e.g., by
averaging them) for purposes of statistical analyses and hypothesis testing.
If, on the other hand, the ratings were uncorrelated, we would conclude that
each scale is measuring a different underlying variable and should be treated
separately in subsequent analyses. In practice, the degree of intercorrelation
among such dependent variables usually falls somewhere between these two
extremes. Multivariate Analysis of Variance (MANOVA) is a statistical
technique designed to evaluate the results of experiments with multiple
dependent variables and determine the nature and number of underlying
variables. MANOVA was proposed in the GAL test plan for the conversation tests
and was used extensively in the analyses presented in this report.
## 7.2 Experimental Design and Statistical Procedures
The two Phase 1 test plans, AMR Narrowband (AMR-NB) and AMR Wideband (AMR-WB),
described similar experimental designs, each experiment involving 24 test
conditions (_COND_) and 16 pairs of subjects. The test plans also specified
that the experiments would be conducted by three Listening Laboratories
(_LAB_), each in a different language: Arcon for North American English, NTT-
AT for Japanese, and France Telecom for French.
Of the 24 conditions in both the NB and WB experiments, 18 were described as
Symmetrical conditions (SYM), six as Asymmetrical (ASY). In the SYM conditions
all subjects were located in a Quiet room, i.e., with no introduced background
noise. The six ASY conditions were actually three pairs of conditions where
one subject in each conversation-pair was located in a noisy background and
the other subject was in the quiet. The data from these sets of paired
conditions were sorted to effect a comparison of _sender in noise/receiver in
quiet_ and s _ender in quiet/receiver in noise_ for the three conditions
involving noise in the rooms.
The Phase 2 test plan described a single experiment involving 16 conditions
conducted by one listening lab (France Telecom) but in two languages, French
and Arabic.
For purposes of the GAL, the data from the three experiments, Phase 1-NB,
Phase 1-WB, and Phase 2 were separated into five _Sets_ of conditions for
statistical analyses:
_Set 1._ Phase 1 - NB/SYM conditions (1-18)
_Set 2._ Phase 1 - NB/ASY conditions (19-24)
_Set 3._ Phase 1 - WB/SYM conditions (1-18)
_Set 4._ Phase 2 - WB/ASY conditions (19-24)
_Set 5._ Phase 2 - Ph2 conditions (1-16)
For each of these five set of conditions, a three-step statistical process was
undertaken to attempt to simplify the final analyses and arrive at the most
parsimonious and unambiguous statistical method for characterizing the results
of the conversation tests. These procedures involved the following steps:
Step 1) Compute an intercorrelation matrix among the dependent variables for
the _Set_ of conditions. Substantial inter-correlation among the dependent
variables (i.e., correlation coefficients > .50 or \ \- Radio conditions -- 10-2, 10-3, and 5x10-4
>
> \- Packet Loss -- 0% and 3%
>
> \- AMR-NB mode or bit rate -- 6.7 kbps and 12.2 kbps
>
> \- Delay -- 300 msec and 500 msec
These conditions are assigned to two factorial experimental designs for
analysing the effects of three of these factors. Table 20a shows the
allocation of the 12 conditions used to evaluate the effects of Radio
Conditions, Packet Loss, and Mode -- with Delay held constant at 300 msec.
Table 20b shows the allocation of the 12 conditions used to evaluate the
effects of Radio Conditions, Packet Loss, and Delay -- with Mode held constant
at 12.2 kbit/s.
Table 20a: NB/SYM: Factorial Design for Table 20b: NB/SYM: Factorial Design
for the Effects of Radio Cond., Packet Loss, and Mode Effects of Radio Cond.,
Packet Loss, and Delay
{width="6.002083333333333in" height="2.1875in"}
The composite dependent variable, NB/S-CTQ, was computed for the NB/SYM
conditions using the equation shown in Eq.1. These composite scores were
subjected to factorial ANOVA for the two experimental designs shown in Tables
20a and 20b. The results of those ANOVA's are shown in Tables 21 and 22,
respectively.
Table 21: Results of ANOVA of NB/S-CTQ for the Effects of Lab, Radio
Conditions (RC), Packet Loss (PL), and Mode
{width="5.519444444444445in" height="3.4881944444444444in"}
Table 21 shows that the main effects for _Radio Conditions_ , _Packet Loss_ ,
and _Mode_ are significant (p\B: | Hoth | Lm.LT.LM | | | | [1] | | | | | | | | LM.LT.Lm | | | | B->A: | | | | | | [1] | | | +-------------+-------------+-------------+-------------+-------------+ | 2 | Car | A->B: | Car | Hm.LT.HM | | | | [6] | | | | | | | | HM.LT.Hm | | | | B->A: | | | | | | [6] | | | +-------------+-------------+-------------+-------------+-------------+ | 3 | Car | A->B: | Hoth | Hm.LT.LM | | | | [5] | | | | | | | | HM.LT.Lm | | | | B->A: | | | | | | [2] | | | +-------------+-------------+-------------+-------------+-------------+ | 4 | Hoth | A->B: | Car | Lm.LT.HM | | | | [2] | | | | | | | | LM.LT.Hm | | | | B->A: | | | | | | [5] | | | +-------------+-------------+-------------+-------------+-------------+ | 5 | Cafeteria | A->B: | Cafeteria | Lm.LT.LM | | | | [1] | | | | | | | | LM.LT.Lm | | | | B->A: | | | | | | [1] | | | +-------------+-------------+-------------+-------------+-------------+ | 6 | Cafeteria | A->B: | Street | Lm.LT.HM | | | | [2] | | | | | | | | LM.LT.Hm | | | | B->A: | | | | | | [5] | | | +-------------+-------------+-------------+-------------+-------------+ | 7 | Street | A->B: | Cafeteria | Hm.LT.LM | | | | [5] | | | | | | | | HM.LT.Lm | | | | B->A: | | | | | | [2] | | | +-------------+-------------+-------------+-------------+-------------+ | 8 | Street | A->B: | Street | Hm.LT.HM | | | | [6] | | | | | | | | HM.LT.Hm | | | | B->A: | | | | | | [6] | | | +-------------+-------------+-------------+-------------+-------------+ | 9 | Hoth | A->B: | Hoth | Lm.HT.LM | | | | [3] | | | | | | | | LM.HT.Lm | | | | B->A: | | | | | | [3] | | | +-------------+-------------+-------------+-------------+-------------+ | 10 | Car | A->B: | Car | Hm.HT.HM | | | | [8] | | | | | | | | HM.HT.Hm | | | | B->A: | | | | | | [8] | | | +-------------+-------------+-------------+-------------+-------------+ | 11 | Car | A->B: | Hoth | Hm.HT.LM | | | | [7] | | | | | | | | HM.HT.Lm | | | | B->A: | | | | | | [4] | | | +-------------+-------------+-------------+-------------+-------------+ | 12 | Hoth | A->B: | Car | Lm.HT.HM | | | | [4] | | | | | | | | LM.HT.Hm | | | | B->A: | | | | | | [7] | | | +-------------+-------------+-------------+-------------+-------------+ | 13 | Cafeteria | A->B: | Cafeteria | Lm.HT.LM | | | | [3] | | | | | | | | LM.HT.Lm | | | | B->A: | | | | | | [3] | | | +-------------+-------------+-------------+-------------+-------------+ | 14 | Cafeteria | A->B: | Street | Lm.HT.HM | | | | [4] | | | | | | | | LM.HT.Hm | | | | B->A: | | | | | | [7] | | | +-------------+-------------+-------------+-------------+-------------+ | 15 | Street | A->B: | Cafeteria | Hm.HT.LM | | | | [7] | | | | | | | | HM.HT.Lm | | | | B->A: | | | | | | [4] | | | +-------------+-------------+-------------+-------------+-------------+ | 16 | Street | A->B: | Street | Hm.HT.HM | | | | [8] | | | | | | | | HM.HT.Hm | | | | B->A: | | | | | | [8] | | | +-------------+-------------+-------------+-------------+-------------+
On each test trial, the subjects evaluated the test connection using five
rating scales, where each rating scale involved five categories. In this
report the results and analyses for the rating scales are labeled by the
following conventions:
  * Question 1 -- **VQ** \-- Rate the **Voice Quality** of your partner.
  * Question 2 -- **UN** \-- Rate the difficulty of **Understanding** > your partner.
  * Question 3 -- **LE** \-- Rate the **Level of Effort** required to > communicate with your partner.
  * Question 4[^1] -- **DD** \-- Did you **Detect Disturbances** in the > conversation? If yes, how annoying were they.
  * Question 5 -- **OQ** \-- Rate the **Overall Quality** of the test > connection.
### 8.B.3 Cross-check of Test Lab Results
The three test labs delivered their raw voting data to the GAL in the Excel
spreadsheets provided by the GAL. Each of the test labs also provided test lab
reports containing summary results for the conversation tests. Dynastat
processed the raw voting data from the data delivery files and cross-checked
the resulting scores against those contained in the test lab reports. In all
cases the scores computed by Dynastat agreed with those reported by the test
labs. The GAL therefore confirms the integrity of the raw data delivery for
the three test labs.
### 8.B.4 Test Results
#### 8.B.4.1 Mean Scores by Experiment and by Test Lab
The GAL was instructed by 3GPP/SA4 to treat the results of individual
experiments from the test labs separately rather than making comparisons
across experiments or across labs. This approach is justified by the
experimental design of the conversation tests. Each experiment in each lab
involved a different codec and each used an independent panel of test
subjects. Comparisons of results across experiments within one lab are
confounded by both codecs and subject panels. Comparisons across labs are
further confounded by language and cultural differences in the subject panels.
Finally, there are no common conditions across experiments and therefore no
basis for transforming scores to a common origin and scale across experiments.
The results and analyses contained in this report are limited to the results
from a single experiment in a single Lab.
Figures 1-9 show the Mean scores for each of the five rating scales by
Experiment and by Test Lab -- Figs. 1-3 for Exp.1, Figs. 4-6 for Exp.2, and
Figs. 7-9 for Exp.3.
{width="5.002083333333333in" height="2.790277777777778in"}
Fig. 8.B.1 -- Mean Scores for Exp.1 - AMR-5.9 in Lab BIT
{width="5.002777777777778in" height="2.790277777777778in"}
Fig. 8.B.2 -- Mean Scores for Exp.1 - AMR-5.9 in Lab FTRD
{width="5.002777777777778in" height="2.813888888888889in"}
Fig. 8.B.3 -- Mean Scores for Exp.1 - AMR-5.9 in Lab Dynastat
{width="4.997222222222222in" height="2.779166666666667in"}
Fig. 8.B.4 -- Mean Scores for Exp.2 - AMR-12.2 in Lab BIT
{width="5.002777777777778in" height="2.779166666666667in"}
Fig. 8.B.5 -- Mean Scores for Exp.2 - AMR-12.2 in Lab FTRD
{width="5.002777777777778in" height="2.779166666666667in"}
Fig. 8.B.6 -- Mean Scores for Exp.2 - AMR-12.2 in Lab Dynastat
{width="5.002777777777778in" height="2.790277777777778in"}
Fig. 8.B.7 -- Mean Scores for Exp.3 - AMRWB-12.65 in Lab BIT
{width="5.002777777777778in" height="2.779166666666667in"}
Fig. 8.B.8 -- Mean Scores for Exp.3 - AMRWB-12.65 in Lab FTRD
{width="5.002777777777778in" height="2.8020833333333335in"}
Fig. 8.B.9 -- Mean Scores for Exp.3 - AMRWB-12.65 in Lab Dynastat
#### 8.B.4.2 Subject Consistency Measures for Test Labs
In most subjective tests there are repeated measures, which may be used to
evaluate the reliability of individual subject's performance in the subjective
task relative to that of other subjects in the test panel. Furthermore, in
those tests subjects hear and evaluate the same materials and there is a basis
to compare and evaluate their responses across trials. For conversation tests,
however, subjects don't have the same materials on which to base their
responses (i.e., each conversation is unique) and there are no repeated
measurers on which to evaluate reliability (i.e., there is only one trial per
test condition). The only performance measure available for individual
subjects within an experiment is the correlation of their responses across
trials with the responses of the other subjects in the experiment. Table 2
shows the average correlation (across subjects and across rating scales) for
each Test Lab and for each experiment within each lab. These values provide an
indication of the consistency of the responses across subjects within an
experiment. In general, the values are relatively low compared to values
typically obtained for other subjective tests --- for MOS tests conducted by
Dynastat, those average correlations are typically around 0.90.
Table 8.B.2 -- Consistency Measures by Lab and Experiment
{width="3.678472222222222in" height="0.6770833333333334in"}
Since the same 16 test conditions were tested in each of the three
experiments, though with a different codec, the results across experiments can
be expected to be positively correlated. Table 3 shows the intercorrelations
across experiments for each of the five rating scales for each of the three
Test Labs. The correlations are very high, especially for Labs Dynastat and
FTRD, less so for Lab BIT. This finding was encouraging but somewhat
unexpected considering the relatively narrow range of mean scores across test
conditions, i.e., most mean scores were between 3.0 and 4.5.
Table 8.B.3 -- Intercorrelations Across Experiments for the Five Rating Scales
for Each Lab
{width="6.502777777777778in" height="1.6972222222222222in"}
#### 8.B.4.3 Multivariate Analysis of Variance (MANOVA)
The multiple rating scales used in conversation tests are designed to capture
different aspects of the conversation task, e.g., voice quality, difficulty of
understanding, level of effort, overall quality. In a previous conversation
testing exercise conducted by 3GPP/SA4 [see clause 7] the rating scales were
found to be highly intercorrelated and multivariate analyses (i.e., **M**
ultivariate **An** alysis **o** f **Va** riance or **MANOVA**) revealed that
there was only one underlying variable that accounted for the significant
variance in the five rating scales. The MANOVA procedure also provides
coefficients for weighting the scores on the individual rating scales to
produce a composite score corresponding to the underlying variable. The use of
such composite scores makes it easier to compare test factors since the
multiple criterion variables often give ambiguous or even conflicting results.
Furthermore, the composite scores are more reliable than scores based on a
single criterion variable. For the results reported here, the GAL conducted a
MANOVA for each of the nine experiments involved in the conversation test,
where the independent variable was _Conditions_ (n=16) and the dependent
variables were the five rating scales --- VQ, UN, LE, DD, and OQ. The results
of the MANOVA's showed that there was more never than one significant
composite variable in any experiment. In five of the nine experiments (1F, 1D,
2F, 2D, 3D) there was a single significant underlying variable (criterion =
p\0.05). Nevertheless, in the interests
of a parsimonious solution, the GAL computed a composite variable for each of
the nine conversation tests based on results from the appropriate MANOVA.
Using the precedent set in the previous 3GPP conversation tests, the GAL has
labeled each composite variable as the measure of _Conversational Quality_ for
the appropriate experiment.
##### 8.B.4.3.1 MANOVA Results and Statistics
The raw voting data from Exp.1, conducted at BIT, was subjected to MANOVA to
determine whether the scores for the five rating scales could be represented
by a smaller number of underlying variables. Table 4 shows the results of that
MANOVA. The following description of Table 4 also applies to the MANOVA's for
each of the other eight experiments.
Table 8.B.4 -- Results of MANOVA for Exp.1 -- AMR-5.9 -- Lab BIT
{width="6.496527777777778in" height="1.3430555555555554in"}
The first step in the MANOVA process is to examine the intercorrelations among
the dependent variables for indications of underlying variables. The left-hand
side of Table 4 shows the intercorrelation matrix of the five dependent
variables across conditions for Exp.1 for Lab BIT. The table shows a high
degree of intercorrelation, indicating the presence of a reduced set of
underlying variables.
The right-hand side of Table 4 shows the results of the MANOVA for the effects
of _Conditions_ (independent variable) x _Rating Scales_ (dependent
variables). The top section of the table shows the statistical test for the
significance of the combination of dependent variables. The Pillai Trace[^2]
and the associated F-statistic is not significant in this MANOVA, though it's
probability (p=0.0801) is close to the criterion for significance, p\ a Pre-processing, including e.g. suitable pre-filtering and signal level
> control
>
> b AMR/AMR-WB encoder
>
> c RTP payload packetisation
II Error insertion device (EID) applying error-delay patterns to the
"transmitted" RTP stream
III VoIP Client/receiver (and Network interface) containing
> a RTP payload depacketisation
>
> b Jitter buffer management (JBM)
>
> c AMR/AMR-WB decoder
>
> d Post-processing
For the listening-only test, the simulator can be implemented as an off-line
tool. It includes Voice Encoding, RTP packetisation and error Insertion. Here,
the error insertion device reads input RTP stream stored into a file, applies
given error-delay pattern, and writes modified output RTP stream into a file.
For this purpose the following storage protocol is introduced:
The raw-data speech (linear PCM masked to 14 bits at 8 kHz sampling rate for
AMR-NB and at 16 kHz sampling rate for AMR-WB) is carried within VoIP client
and receiver. The encoder output is then stored with the AMR-NB/AMR-WB file
storage format according to media types audio/amr and audio/amr-wb, as
specified in sections 5.1 and 5.3 of RFC 3267. The data exchanged between RTP
packetization/depacketisation and error insertion device is a stream of
encapsulated RTP packets in the RTPdump format shown in Table 9 and Table 10.
Table H.9: RTPdump file header elements.
* * *
**Element** **Size** **Description** Start 32 bits ("struct timeval") Start
time (GMT) of the file Source 32 bits ("long") Source (IP) address Port 16
bits ("short") UDP port number Padding 16 bits ("short") Padding data to
provide 32-bit alignment
* * *
Table H.10: RTPdump packet header elements.
* * *
**Element** **Size** **Description** Length 16 bits ("short") Length of the
packet (in bytes), including this header Plen 16 bits ("short") Length of the
RTP packet (RTP header + RTP payload) Offset 32 bits ("long") Milliseconds
since the start of the file
* * *
Preparation of the evaluation speech material can be based on the following
pseudo code:
> Read in first speech packet
>
> receivedPktTime = time of first received speech packet,
>
> playoutTime = time of the first received speech packet.
>
> lastReceivedPkt = 0
>
> do {
>
> While (receivedPktTime \
> Deliver the received speech packet to the VoIP client
>
> Read in next speech packet
>
> Set receivedPktTime = time of next received speech packet
>
> If (no more packets) {
>
> lastReceivedPkt=1
>
> break;
>
> }
>
> }
>
> While (playoutTime \
> Request speech samples from VoIP client
>
> VoIP client returns Tp sec of speech samples
>
> Write out Tp sec to file output
>
> Set playoutTime = playoutTime + Tp
>
> }
>
> } While (VoIP client has PCM samples & lastReceivedPkt==1)
The VoIP client should, when requested speech samples, return short duration
of PCM samples, e.g., 1ms. To ensure fair testing and verify the de-jitter and
time warping aspects in a VoIP system, the network-decoder interface controls
(i) the delivery of encoded speech packets to the speech decoder and (ii)
controls the output of speech data from the speech decoder. However, to enable
more realistic operation, the VoIP client is given the freedom of deciding how
many speech samples it wants to output for each NCIM speech output request.
###### ### Annex I: Illustrative scheme for jitter buffer management
This annex describes an illustrative example on jitter buffer management (JBM)
solution. This illustrative example is described as pseudo code in Section
I.1, and Section I.2 provides a performance analysis of one particular
implementation according to the pseudo code.
## I.1 Pseudo code
The pseudo code consists of two main parts:
  1. Reception functionality, including the decapsulation of received RTP payload and storing the received speech frames into a buffer.
  2. Decoding functionality, taking care of reading the frames from the buffer and providing a frame of decoded speech (or error concealment data) upon request.
To illustrate the relationship between these two functional parts in a simple
way, the pseudo code is structured in a form of a simulation model in which a
main loop handles the reception and decoding functionalities:
  * The _main loop_ models the time line -- at each execution of this loop the simulated "wall clock time" is increased by one clock tick. Furthermore, the other two loops -- reception loop and the decoding loop -- are implemented inside the main loop.
  * The _reception loop_ is executed as many times as needed to process the new packets available at the packet input at/before current time.
  * The _decoding loop_ is executed as many times as needed to process all frames in the buffer scheduled for decoding at/before current time.
It is straightforward to implement the contents of the _reception loop_ in
function that is called each time a new RTP payload is received to provide the
reception functionality. Similarly, the operations in the _decoding loop_ can
be implemented in a function that is called each time the audio device
requests a new frame of speech to provide the decoding functionality.
Table I.1 describes the variables used in the pseudo code. Note that in
addition to variables introduced in the table, the pseudo code also uses the
constant FRAME_DURATION to indicate a frame duration as number of RTP clock
ticks (FRAME_DURATION = 160 for AMR, FRAME_DURATION = 320 for AMR-WB).
Furthermore, constants THR1 and THR2 are used to control the fine tuning of
the onset frame buffering time.
Table I.1: Variables used in the pseudo code.
* * *
**Variable** **Purpose** **Description / usage** current_time Current
simulation time as clock ticks at RTP time stamp clock rate The current time
is initialised to random value -- indicated by "NOW" in the pseudo code. The
value is increased by one at the each execution of the main loop to simulate
the passing of time. rx_time Reception time of the current/next RTP packet (as
clock ticks at RTP time stamp clock rate) The reception time is initialised to
the same value as current_time. The value is updated each time a new packet is
available in the packet input. dec_time Decoding time of the next frame (as
clock ticks at RTP time stamp clock rate) The value is initialised by adding
the value of desired buffering delay JBM_BUFFER_DELAY for the initial value of
the current_time. This variable is updated after each decoded frame by
increasing the value by number of RTP clock ticks corresponding to one frame
(160 ticks for 8 kHz clock rate used for AMR, 320 ticks for 16 kHz clock rate
used for AMR-WB). rtp_ts RTP timestamp of the current/next RTP packet (as
clock ticks at RTP time stamp clock rate) The value is updated each time a new
input packet is captured frame_ts RTP timestamp of the current (received)
frame (as clock ticks at RTP time stamp clock rate) The frame timestamp value
is set/updated when parsing a packet (containing several frames) Next_ts RTP
timestamp of the frame to be decoded next (as clock ticks at RTP time stamp
clock rate) The variable is used both to request the next frame in decoding
order from the buffer and to detect the frames that arrive late end_of_input
Indication of input speech data status A status variable that is initialised
to value FALSE -- the value is set to TRUE when the end of the input packet
file is encountered. buffer_occupancy Buffer fill level in number of frames A
variable that is used to indicate buffering status -- needed for detecting the
end of the simulation and to detect buffer overflows. loss_burst_len Number of
consecutive frames replaced by error concealment The value of this variable is
increased each time the decoder needs to invoke the error concealment
operation. In case the value exceeds a predetermined threshold
JBF_LOSS_PERIOD_THR, the re-synchronisation operation is initiated by setting
resync_flag to value 1. In case of normal decoding the value of loss_burst_len
is set to zero. resync_flag Flag to indicate that a re-synchronisation is
needed. See the description for the variable loss_burst_len above. onset_flag
Indication that we are currently on the buffering time period before decoding
the onset speech frame The value of this variable is set to one in the
reception loop when an onset frame (i.e. the first speech frame after a non-
speech period) is received. The decoding loop sets this value to zero when a
requested frame from a buffer has been found and decoded. keep_frame_alignment
Indication whether the decoding time of a speech onset frame must be aligned
with the current frame structure or not -- i.e. whether the decoding must take
place at time T + n * 20 ms, where T is the decoding time of the first frame
of the session and n is an integer number. Set to non-zero value to force
keeping the original frame alignment at speech onsets, i.e. to force rounding
the decoding time of the first frame of a talk spurt to occur at an integer
multiple of 20 ms since the beginning of the session
* * *
/* INITIALISATION */
_Read the first input frame, initialise variables based in received packet_
/* NOTE that time is measured in speech samples at RTP clock rate -- 8 kHz for
AMR, 16 kHz for AMR-WB */
rx_time = current_time = NOW
next_ts = rtp_ts
/* Set the desired initial buffering delay */
dec_time = current_time + JBF_INITIAL_DELAY
end_of_input = FALSE
buffer_occupancy = 0
loss_burst_len = 0
resync_flag = 0
onset_flag = 0;
keep_frame_alingment = 1
/* MAIN LOOP */
WHILE end_of_input == FALSE OR buffer_occupancy > 0
{
> /* RECEPTION LOOP */
>
> WHILE end_of_input == FALSE AND rx_time \
> {
>
> /* Set RTP timestamp for the frame */
>
> frame_ts = rtp_ts
>
> /* Loop over all frames in the packet */
>
> WHILE more frames in this packet
>
> {
>
> /* Possible NO_DATA frames are discarded */
>
> IF frame_type != NO_DATA
>
> {
>
> IF _speech onset detected_
>
> {
>
> _Find_ bt_min _and_ bt_max _, i.e. the minimum and maximum predicted
> buffering times over the period of_ JBF_HISTORY_LEN _most recent frames_
>
> /* Set new buffering time */
>
> buffer_delay = bt_max -- bt_min
>
> /* Set this as the next frame to be decoded */
>
> next_ts = frame_ts
>
> /* Set decoding time */
>
> dec_time = current_time + buffer_delay
>
> /* Apply frame alignment if selected */
>
> IF keep_frame_alignment == 1
>
> {
>
> _Move_ dec_time _forward to the next frame boundary_
>
> }
>
> /* Indicate for the decoder that we are buffering for speech onset */
>
> onset_flag = 1;
>
> }
>
> /* Check if the decoder has set the re-synchronisation flag */
>
> ELSE IF resync_flag == 1
>
> {
>
> /* Continue decoding from the first frame arriving after a loss period */
>
> next_ts = frame_ts
>
> /* Clear the re-synchronisation flag */
>
> resync_flag = 0
>
> }
>
> /* Check if received frame is late by less than one frame slot */
>
> ELSE IF frame_ts + FRAME_DURATION == next_ts AND _TS_ >= next_ts NOT _in the
> buffer_
>
> {
>
> /* Re-schedule this frame to be the next frame to be decoded */
>
> next_ts = frame_ts
>
> }
>
> _Compute predicted buffering time for the received frame and update
> buffering time history_
>
> /* Check frame arrival time */
>
> IF frame_ts \
> {
>
> _Discard the frame because it arrived late_
>
> Update RX log: TIME = rx_time; RTP_TS = frame_ts; RX_STATUS = late_loss
>
> }
>
> ELSE
>
> {
>
> /* Check buffer occupancy */
>
> IF buffer_occupancy == MAX_BUFFER_OCCUPANCY
>
> {
>
> _Discard the frame because the buffer is full_
>
> Update RX log: TIME = rx_time; RTP_TS = frame_ts; RX_STATUS = overflow
>
> }
>
> ELSE
>
> {
>
> _Store the frame into the buffer_
>
> Update RX log: TIME = rx_time; RTP_TS = frame_ts; RX_STATUS = ok
>
> buffer_occupancy++
>
> }
>
> }
>
> }
>
> /* Update RTP timestamp for the next frame */
>
> frame_ts += FRAME_DURATION
>
> }
>
> _Read the next input packet_
>
> IF _new packet available_
>
> {
>
> _Update variables_
>
> rx_time
>
> rtp_ts
>
> }
>
> ELSE
>
> {
>
> end_of_input = TRUE
>
> }
>
> } /* end of RECEPTION LOOP */
>
> /* DECODING LOOP */
>
> WHILE dec_time \
> {
>
> /* Fine tune onset buffering time */
>
> IF onset_flag == 1
>
> {
>
> first_ts = _TS of the first frame in the buffer_
>
> /* Early decoding of onset frame if buffer is filling too fast */
>
> IF buffer_occupancy * FRAME_DURATION -- THR1 >= buffer_delay
>
> {
>
> next_ts = first_ts
>
> }
>
> /* Postpone decoding of onset frame if buffer is filling too slowly */
>
> ELSE IF buffer_occupancy * FRAME_DURATION + THR2 \ == first_ts
>
> {
>
> next_ts -= FRAME_DURATION;
>
> }
>
> }
>
> _Request frame having the RTP timestamp value_ next_ts _from the buffer_
>
> IF _requested frame found_
>
> {
>
> _Decode speech or generate comfort noise (SID or SID_FIRST frame) normally_
>
> Update DEC log: TIME = dec_time; RX_TIME = rcv_time; RTP_TS = next_ts;
> DEC_STATUS = ok
>
> buffer_occupancy--
>
> /* Clear lost burst counter */
>
> loss_burst_len = 0
>
> /* Clear speech onset flag */
>
> onset_flag = 0
>
> }
>
> ELSE
>
> {
>
> IF _in speech state_
>
> {
>
> /* Increase lost burst counter */
>
> loss_burst_len++
>
> /* Check the loss period length */
>
> IF loss_burst_len > JBF_LOSS_PERIOD_THR
>
> {
>
> _Find the oldest frame in the buffer_
>
> IF _a frame having a time stamp value_ new_ts _found_
>
> {
>
> _Decode the frame found in the buffer (i.e. reset the decoding to continue
> from the oldest frame found in the buffer)_
>
> Update DEC log: TIME = dec_time; RX_TIME = rcv_time; RTP_TS = new_ts;
> DEC_STATUS = ok
>
> buffer_occupancy--
>
> /* Set the time stamp */
>
> next_ts = new_ts
>
> /* Clear lost burst counter */
>
> loss_burst_len = 0
>
> }
>
> ELSE
>
> {
>
> _Invoke error concealment_
>
> Update DEC log: TIME = dec_time; RX_TIME = N/A; RTP_TS = next_ts; DEC_STATUS
> = error_concealment
>
> /* Set the re-synchronisation flag to trigger the decoding to continue from
> the next arriving frame */
>
> resync_flag = 1
>
> }
>
> }
>
> ELSE
>
> {
>
> _Invoke error concealment_
>
> Update DEC log: TIME = dec_time; RX_TIME = N/A; RTP_TS = next_ts; DEC_STATUS
> = error_concealment
>
> }
>
> }
>
> ELSE
>
> {
>
> /* DTX */
>
> _Continue comfort noise generation_
>
> Update DEC log: TIME = dec_time; RX_TIME = N/A; RTP_TS = next_ts; DEC_STATUS
> = comfort_noise
>
> }
>
> }
>
> /* Update variables for decoding the next frame */
>
> dec_time += FRAME_DURATION
>
> next_ts += FRAME_DURATION
>
> } /* end of DECODING LOOP */
>
> /* CLOCK/TIMER UPDATE */
>
> current_time++
}
## I.2 Verification against the minimum performance requirements
This section provides a verification of an implementation of JBM according to
the pseudo code in Section I.1 against the minimum performance requirements
specified in Section 8.2.3 of TS 26.114 [19]. The verification was performed
by using the implemented JBM algorithm with the AMR codec. On each channel the
simulation was repeated 20 times, each time with different random starting
point on the channel. The results provided in the following subsections
indicate the observed worst-case results (i.e. measured delay CDF closest to
the delay requirement CDF and the highest jitter loss rate).
The constants used in the pseudo code are set to the values given in Table I.2
for the verification.
Table I.2: Constant values in pseudo code used in performance analysis.
* * *
Constant Value JBF_INITIAL_DELAY 160 [ticks at 8 kHz clock rate]
JBF_HISTORY_LEN 100 [frames] JBF_LOSS_PERIOD_THR 5 [frames]
* * *
### I.2.1 Delay performance
Figures from I.1 to I.6 below show the delay performance of the implemented
JBM and comparison against the minimum performance requirement specified in
Section 8.2.2.2.2 of TS 26.114 [19]. The solid blue curve denotes the delay
CDF for the implemented JBM, and the black dash-dotted curve indicates the
delay requirement CDF.
{width="5.833333333333333in" height="4.375in"}
Figure I.1: Delay performance of the implemented JBM on channel 1.
{width="5.833333333333333in" height="4.375in"}
Figure I.2: Delay performance of the implemented JBM on channel 2.
{width="5.833333333333333in" height="4.375in"}
Figure I.3: Delay performance of the implemented JBM on channel 3.
{width="5.833333333333333in" height="4.375in"}
Figure I.4: Delay performance of the implemented JBM on channel 4.
{width="5.833333333333333in" height="4.375in"}
Figure I.5: Delay performance of the implemented JBM on channel 5.
{width="5.833333333333333in" height="4.375in"}
Figure I.6: Delay performance of the implemented JBM on channel 6.
### I.2.2 JBM induced error concealment operations
Table I.3 summarizes the jitter loss rates of the implemented JBM for all test
channels, computed as specified in TS 26.114 Section 8.2.3.2.3.
Table I.3: The jitter loss for the tested JBM on test channels.
* * *
**Channel** **1** **2** **3** **4** **5** **6** **JBM loss rate** 0.07 % 0.40
% 0.15 % 0.72 % 0.95 % 0.57%
* * *
###### ### Annex J: Test processing for listening only tests
This section specifies the method for the processing of the speech material
for the VoIMS over HSDPA/EUL listening only tests. The processing steps are
illustrated by block diagrams for a clear understanding of the processing
step. The processing of the speech material will be performed using the
ITU-T's Software Tool Library Release 2000 (STL2000).
## J.1 Speech preparation
The processing steps required for generation of the speech samples are
described below.
## J.2 Pre-processing
The first step is concatenation where all available speech samples are merged
into one long speech file. This file is then pre-processed according to the
figure below.
{width="5.375in" height="1.007638888888889in"}
Figure J.1. Pre-processing of MIRS filtered speech file
**STL2000 syntax**
concat infile1 ... infileN outfile\ filter --mod IRS16 infile outfile\
sv56demo --lev -26 --sf 16000 infile outfile
## J.3 Processing of speech/background noise signal
Noise files are filtered by the MIRS filter. The noise files are then
converted to a near-field perception using the ∆SM filter.
Figure J.2. Noise processing
**STL2000 syntax**
filter --mod IRS16 infile outfile\ filter DSM infile outfile
Figure J.3. Background noise mixing
**STL2000 syntax**
sv56demo --rms --lev -26 --sf 16000 infile noisefile\ oper --gain dB 0
speechfile + AL noisefile 0 mixedfile
AL should be -15 for the car noise and -20 for the café noise.
## J.4 Up and Down-Sampling, Rounding and Scaling
Up- and down-sampling is needed because the sample rate of the original speech
files is 48 kHz, the processing is made with 8/16 kHz sampling and the
listening was made with 16 kHz. The figure below describes the up- and down-
sampling between 16 kHz and 8 kHz.
Figure J.4. Sample-rate conversion, rounding and scaling for narrow-band
filtered conditions
Figure J.5. Sample-rate conversion, rounding and scaling for wideband-band
filtered conditions
**STL2000 syntax (narrow-band)**
filter -down HQ2 infile outfile\ scaldemo -dB -gain 0 -bits 13 -round
-nopremask -blk 160 infile outfile
(Processing ...)
scaldemo -dB -gain 0 -bits 13 -round -nopremask -blk 160 infile outfile\
filter -up HQ2 infile outfile 160
**STL2000 syntax (wide-band)**
scaldemo -dB -gain 0 -bits 14 -round -nopremask -blk 320 infile outfile
(Processing ...)
scaldemo -dB -gain 0 -bits 14 -round -nopremask -blk 320 infile outfile
## J.5 Processing for Direct Conditions
The processing for 'direct' conditions is very simple.
Figure J.6. Processing of speech for \'direct\' conditions
13 bits 8 kHz for AMR-NB, 14 bits 16 kHz for AMR-WB
## J.6 Processing for MNRU conditions
MNRU conditions are generated as shown in the figure below.
Figure J.7. Processing of narrow-/wideband MNRU conditions.
For AMR-NB the format of the infile is 13 bits 8 kHz and the MNRU levels are
5, 13, 21, 29, 37 dBq. For AMR-WB the format of the infile is 14 bits 16 kHz
and the MNRU levels are 5, 13, 21, 29, 37, 45 dBq.
**STL2000 syntax (narrow-band)**
mnrudemo -Q x infile outfile 160 /* x = dBq level */
**STL2000 syntax (wide-band)**
mnrudemo -Q x infile outfile 320 /* x = dBq level */
## J.7 Processing of voice over IMS over HSPA
The reference conditions with fixed JBM and the test conditions with adaptive
JBM are processed as described below.
Figure J.8. Processing of voice over IMS over HSPA.
The output from the encoder/RTP packetization and the input to the JBM/decoder
is in RTP-dump format.
The fixed JBM initial buffering delay is set in such a way that the resulting
end-to-end delay (including channel delay and buffering delay) is similar to
the average end-to-end delay of the adaptive JBM in the same test condition.
**Command syntax for AMR/AMR-WB encoding & RTP packetization**
amr_enc --dtx -fpp 1 --mode x --if infile --of outfile /* x = 2 for 5.9 kbit/s
mode, x = 7 for 12.2 kbit/s mode */
amrwb_enc --dtx -fpp 1 --mode 2 --if infile --of outfile /* x = 2 for 12.65
kbit/s mode */
**Command syntax for EID processing**
EID_rtpdump --bs 24 --ps 128 --bl 20 --st x --df channelfile --if infile --of
outfile /* x = offset to the channel file */
**Command syntax for adaptive JBM & AMR/AMR-WB decoding**
amr_dec --bt 20 --bs 20 --if infile --of outfile\ amrwb_dec --bt 20 --bs 20
--if infile --of outfile
**Command syntax for fixed JBM & AMR/AMR-WB decoding**
amr_dec_fixed --bt x --bs 20 --if infile --of outfile /* x = buffering time
for the 1st received frame */
amrwb_dec_fixed --bt x --bs 20 --if infile --of outfile /* x = buffering time
for the 1st received frame */
## J.8 Post-processing
Figure J.8. Post processing.
A window of length 1600 samples was used in the file separation.
**STL2000 syntax**
sv56demo --lev -26 --sf 16000 infile outfile\ astrip -wlen 1600 -blk 128000
-start no -n 1 infile outfile_no /* no = file number i.e. 1 to 40 */
## J.9 Test conditions
The test conditions are described below:
Table J.1. Test conditions
* * *
Cond. Codec JBM Noise Type Frame Loss Rate Channel AMR-Modes (fixed RTP delay)
1 Direct NB Clean  
2 Direct WB Clean  
3 NB MNRU 5 dBq  
4 NB MNRU 13 dBq  
5 NB MNRU 21 dBq  
6 NB MNRU 29 dBq  
7 NB MNRU 37 dBq  
8 WB MNRU 5 dBq  
9 WB MNRU 13 dBq  
10 WB MNRU 21 dBq  
11 WB MNRU 29 dBq  
12 WB MNRU 37 dBq  
13 WB MNRU 45 dBq  
14 AMR-NB Fixed Clean Error free 5.9 kbit/s (150 ms) 15 AMR-NB Fixed Clean
Error free 12.2 kbit/s (150 ms) 16 AMR-NB Fixed Car Error free 5.9 kbit/s (150
ms) 17 AMR-NB Fixed Car Error free 12.2 kbit/s (150 ms) 18 AMR-NB Fixed
Cafeteria Error free 5.9 kbit/s (150 ms) 19 AMR-NB Fixed Cafeteria Error free
12.2 kbit/s (150 ms) 20 AMR-WB Fixed Clean Error free 12.65 kbit/s (150 ms) 21
AMR-WB Fixed Car Error free 12.65 kbit/s (150 ms) 22 AMR-WB Fixed Cafeteria
Error free 12.65 kbit/s (150 ms) 23 AMR-NB Fixed Clean 0.01 Ch1 5.9kbit/s (
150 ms) 24 AMR-NB Fixed Clean 0.01 Ch2 5.9kbit/s ( 150 ms) 25 AMR-NB Fixed
Clean 0.01 Ch3 12.2kbit/s ( 150 ms) 26 AMR-NB Fixed Clean 0.01 Ch4 12.2kbit/s
( 150 ms) 27 AMR-NB Fixed Car 0.01 Ch5 5.9kbit/s ( 150 ms) 28 AMR-NB Fixed
Cafeteria 0.01 Ch6 5.9kbit/s ( 150 ms) 29 AMR-NB Fixed Car 0.01 Ch7 12.2kbit/s
( 150 ms) 30 AMR-NB Fixed Cafeteria 0.01 Ch8 12.2kbit/s ( 150 ms) 31 AMR-WB
Fixed Clean 0.01 Ch1 12.65 kbit/s (150 ms) 32 AMR-WB Fixed Clean 0.01 Ch2
12.65 kbit/s (150 ms) 33 AMR-WB Fixed Clean 0.01 Ch3 12.65 kbit/s (150 ms) 34
AMR-WB Fixed Clean 0.01 Ch4 12.65 kbit/s (150 ms) 35 AMR-WB Fixed Car 0.01 Ch5
12.65 kbit/s (150 ms) 36 AMR-WB Fixed Car 0.01 Ch6 12.65 kbit/s (150 ms) 37
AMR-WB Fixed Cafeteria 0.01 Ch7 12.65 kbit/s (150 ms) 38 AMR-WB Fixed
Cafeteria 0.01 Ch8 12.65 kbit/s (150 ms) 39 AMR-NB Adaptive Clean 0.01 Ch1
5.9kbit/s ( 150 ms) 40 AMR-NB Adaptive Clean 0.01 Ch2 5.9kbit/s ( 150 ms) 41
AMR-NB Adaptive Clean 0.01 Ch3 12.2kbit/s ( 150 ms) 42 AMR-NB Adaptive Clean
0.01 Ch4 12.2kbit/s ( 150 ms) 43 AMR-NB Adaptive Car 0.01 Ch5 5.9kbit/s ( 150
ms) 44 AMR-NB Adaptive Cafeteria 0.01 Ch6 5.9kbit/s ( 150 ms) 45 AMR-NB
Adaptive Car 0.01 Ch7 12.2kbit/s ( 150 ms) 46 AMR-NB Adaptive Cafeteria 0.01
Ch8 12.2kbit/s ( 150 ms) 47 AMR-WB Adaptive Clean 0.01 Ch1 12.65 kbit/s (150
ms) 48 AMR-WB Adaptive Clean 0.01 Ch2 12.65 kbit/s (150 ms) 49 AMR-WB Adaptive
Clean 0.01 Ch3 12.65 kbit/s (150 ms) 50 AMR-WB Adaptive Clean 0.01 Ch4 12.65
kbit/s (150 ms) 51 AMR-WB Adaptive Car 0.01 Ch5 12.65 kbit/s (150 ms) 52 AMR-
WB Adaptive Car 0.01 Ch6 12.65 kbit/s (150 ms) 53 AMR-WB Adaptive Cafeteria
0.01 Ch7 12.65 kbit/s (150 ms) 54 AMR-WB Adaptive Cafeteria 0.01 Ch8 12.65
kbit/s (150 ms) 55 Direct NB Car  
56 Direct NB Cafeteria  
57 Direct WB Car  
58 Direct WB Cafeteria
* * *
###### ### Annex K: Radio network simulation for HSDPA/EUL performance
characterization
Two different radio network simulators were used to produce the radio network
conditions used in the HSDPA/EUL performance characterization tests. Although
both tests used the same RAB configurations, there were some subtle
differences beyond the downlink schedulers and the lengths of the resulting
channel profiles. The channel profiles used in the testing were constructed
based on results from both simulations.
The system simulation was dynamic and included explicit modelling of fast
fading, power control, CQI generation, scheduling of users, etc. Channels that
connected different transmit/receive antenna pairs were generated at the UMTS
slot rate (1500Hz). The instantaneous SINR seen at each receiver was computed
at the slot rate. Virtual decoders mapped a sequence of slot rate SINRs to
block error events at the TTI rate for each physical channel. The virtual
decoders must generate the same statistical block error events as the true
decoders operating on a bit by bit basis in a link level simulation for the
same TTI rate for each physical channel under consideration.
Inner and outer loop power control loops were explicitly modelled for the
associated DPCH. The OVSF code and transmit power resources consumed by the
associated DPCH and HS-SCCH channels were modelled dynamically. Errors made in
HS-SCCH decoding were taken into account in determining whether the
corresponding HS-DSCH transmission is decoded correctly.
The system simulation attempted to model sufficiently the MAC-d PDU flow and
performance from the NodeB to the UE. Thus, the system simulation was
considered an "over-the-air" model and did not capture impairments beyond the
NodeB to UE subsystem
The RAB configuration can be found in 3GPP TS 25.993, sections 7.5.3 and
7.5.4. The respective simulator parameters are shown in the tables later in
this section.
The results from each respective simulation were then assembled into channel
profiles in the following way.
  * The results from simulation 1 entailed 16 samples for down link and 16 samples for up link with paired channel conditions PedB_3km, PedB30km, VehA_30km and VehA_120km. The location of the reference user was fixed for all simulations.
  * **The results from simulation 2 entailed 22 samples, where 20 are for the down link and two for the up link, representing a paired channel PedB_3km. The difference between the 20 samples lied in the network load (number of users) and the location of the reference user (geometry).**
Table K.1: File attributes of the available data
* * *
**Attribute Name** **Details** **Number** **Link Direction** **Up-Link, Down-
link** **2** **Network Load** **40,45,60,80,100** **5** **Channel Model**
**PedA-3km, PedB-3km, PedB30km, VehA-30km, VehA-120 km.** **5**
* * *
The definition of the conditions follows the conventions given below.
Table K.2: Definition of the radio network conditions
+-----------------------------+-----------------+------------------+------------+ | **Radio Network Condition** | **Low Traffic** | **High Traffic** | **Uplink** | | | | | | | | **Down Link** | **Down Link** | | +-----------------------------+-----------------+------------------+------------+ | **Low Mobility Mobile** | **LM.LT** | **LM.HT** | **Lm** | +-----------------------------+-----------------+------------------+------------+ | **High Mobility Mobile** | **HM.LT** | **HM.HT** | **Hm** | +-----------------------------+-----------------+------------------+------------+
  * Low Traffic (LT): 40, or 45, or 60 mobile users per cell
  * High Traffic (HT): 80, or 100 mobile users per cell
  * Low Mobility (LM, Lm): ITU --Channel-Model: PedB3_km or PedA3_km
  * High Mobility (HM, Hm): ITU-Channel-Model: VehA30km or Veh120km or PedB30km
Table K.3: Simulation 1, radio network simulation parameters
+----------------------------------+----------------------------------+ | **Parameter** | | +----------------------------------+----------------------------------+ | UMTS BS Nominal TX Power [dBm] | **43** | +----------------------------------+----------------------------------+ | P-CPICH Tx Power [dBm] | **33** | +----------------------------------+----------------------------------+ | UMTS BS Overhead TX Power | **34** | | [dBm] including paging, sync | | | and P/S-CCPCH | | +----------------------------------+----------------------------------+ | UMTS UE TX Power Class [dBm] | **21** | +----------------------------------+----------------------------------+ | UMTS UE Noise Figure [dB] | **10** | +----------------------------------+----------------------------------+ | BS Antenna Gain [dBi] | **17.1** | +----------------------------------+----------------------------------+ | MS Antenna Gain [dBi] | **0** | +----------------------------------+----------------------------------+ | Shadowing Standard Deviation | **8** | | [dB] | | +----------------------------------+----------------------------------+ | Path Loss Model: COST 231 | **-136+35.22*log10(d), d in | | | km** | +----------------------------------+----------------------------------+ | Shadow Site to site Correlation | **50%** | +----------------------------------+----------------------------------+ | Other Losses [dB] | **8** | +----------------------------------+----------------------------------+ | UMTS BS Antenna | **per TR 25.896 v6.0.0 A.3.1.1** | | | | | pattern | **65** | | | | | beamwidth [degrees] | | +----------------------------------+----------------------------------+ | Number of MS Antennas | **2** | +----------------------------------+----------------------------------+ | Propagation Channel Mixture for | **25% AWGN** | | loading users | | | | **37% PedB 3 kph** | | | | | | **13% PedB 30 kph** | | | | | | **13% VehA 30 kph** | | | | | | **12% VehA 120 kph** | +----------------------------------+----------------------------------+ | Number of loading users | **E-DCH: 40 UEs per cell** | | simulated | | | | **HSDPA: 40/60/80/100 UEs per | | | cell** | +----------------------------------+----------------------------------+ | Propagation Channel for the | **Case 1: PedB 3 kph** | | Reference UE | | | | **Case 2: PedB 30 kph** | | | | | | **Case 3: VehA 30 kph** | | | | | | **Case 4: VehA 120 kph** | +----------------------------------+----------------------------------+ | Location for Reference UE | **Case 1: One cell in active | | | set, UE geometry = 3.3 dB** | | | | | | **Case 2: Soft handoff with 2 | | | cells in active set, UE geometry | | | = 3.0 dB, UE serving cell | | | geometry = -0.7 dB** | +----------------------------------+----------------------------------+ | Ec/Io Admission Threshold | **-18 dB** | +----------------------------------+----------------------------------+ | RSCP Admission Threshold | **-115 dBm** | +----------------------------------+----------------------------------+ | Number of Node Bs | **19 Node Bs/57 cells** | +----------------------------------+----------------------------------+ | Cell layout | **3-Cell Clover-Leaf** | +----------------------------------+----------------------------------+ | Inter-site Distance [m] | **2500** | +----------------------------------+----------------------------------+ | Frequency | **1990 MHz** | +----------------------------------+----------------------------------+
Table K.4 Simulation 1, traffic assumptions
+----------------------------------+----------------------------------+ | **Parameter** | | +----------------------------------+----------------------------------+ | User-Plane Traffic Model | **100% VoIP** | | | | | Vocoder Type | **AMR 12.2** | | | | | Vocoder Voice Model Loading | **Markov Process with 50% | | Users | activity (transition probability | | | = 0.01)** | | Vocoder Voice Model Reference UE | | | | **100% activity** | +----------------------------------+----------------------------------+ | VoIP Packet Overheads | **1 byte RLC UM header** | | | | | | **4 bytes ROHC header** | +----------------------------------+----------------------------------+ | ROHC dynamics | **Resynchronization ignored** | +----------------------------------+----------------------------------+ | RTCP | **Not modeled** | +----------------------------------+----------------------------------+ | SIP | **Not modeled** | +----------------------------------+----------------------------------+ | SID Frames | **Not transmitted** | +----------------------------------+----------------------------------+ | RTP layer aggregation | **None** | +----------------------------------+----------------------------------+ | MAC-d PDU Size | **296 bits** | +----------------------------------+----------------------------------+
**Table K.5 Simulation 1, other simulation assumptions**
+----------------------------------+----------------------------------+ | **Parameter** | | +----------------------------------+----------------------------------+ | UMTS Time Modelled [s] | **60** | +----------------------------------+----------------------------------+ | Training Time [s] | **5** | +----------------------------------+----------------------------------+ | UE Category | **5** | +----------------------------------+----------------------------------+ | Receiver Type | **Rake with Mobile Receive | | | Diversity from 2 Antennas** | | | | | | **(2 Rx correlation = 0.5, | | | mismatch 2 dB)** | +----------------------------------+----------------------------------+ | Downlink DCCH Traffic and | **DCCH mapped to HS-DSCH, F-DPCH | | Transport | used instead of assoc. DPCH. | | | DCCH traffic modeled as 3.4kbps | | | source with 5% activity | | | factor.** | +----------------------------------+----------------------------------+ | Max. HSDPA Transmit Power | **18 watt -- power allocated for | | (HS-SCCH + HS-PDSCH) | all common and dedicated | | | channels** | +----------------------------------+----------------------------------+ | HS-SCCH Channel Model | **Depends on loading** | | | | | Number | **Yes** | | | | | Errors Impact HS-DSCH Decoding | **Fixed Offset from F-DPCH** | | | | | Power Allocation | | +----------------------------------+----------------------------------+ | Downlink Over-the air Delay | **90** | | Budget [ms] (MAC-d to MAC-d) | | +----------------------------------+----------------------------------+ | Iub delay modelled | **No** | +----------------------------------+----------------------------------+ | HSDPA Scheduler Implementation | **Proprietary** | +----------------------------------+----------------------------------+ | Mobility Model | **Static UE locations** | +----------------------------------+----------------------------------+ | E-DCH Scheduling | **Non-scheduled transmission** | +----------------------------------+----------------------------------+ | E-DCH TTI length | **Both 10ms TTI and 2ms TTI** | +----------------------------------+----------------------------------+ | E-DCH max number of HARQ | **2 Tx for 10ms TTI** | | transmissions | | | | **4 Tx for 2ms TTI** | +----------------------------------+----------------------------------+ | E-DCH QoS | **Target 1% BLER post-HARQ** | +----------------------------------+----------------------------------+ | HS-DPCCH modeled for E-DCH | **Yes** | | simulation | | +----------------------------------+----------------------------------+
Table K.6 Simulation 2, simulation assumptions
+----------------------------------+----------------------------------+ | **Parameters** | | +----------------------------------+----------------------------------+ | Multipath channel models | **PA3 and PB3** | | | | | | **Fader type: JTC.** | +----------------------------------+----------------------------------+ | User path loss and setup | **PA3:** | | | | | | **Geometry from serving cell: | | | 1.65 dB** | | | | | | **Soft-handover geometry: 5.8 | | | dB** | | | | | | **Soft-handover legs: 2** | | | | | | **PB3:** | | | | | | **Geometry from serving cell: | | | 0.09 dB** | | | | | | **Soft-handover geometry: 5.22 | | | dB** | | | | | | **Soft-handover legs: 2** | | | | | | **Number of UE antennas: 1.** | +----------------------------------+----------------------------------+ | Node B resources | **DL power reserved for common | | | channels and DPCH for all users: | | | 7.5 Watt (30%)** | | | | | | **3 Watt for common channels + 1 | | | Watt / \~100 users for DPCH** | | | | | | **Remaining power for all | | | HS-SCCH and HS-PDSCH: 17.6 | | | Watt** | | | | | | **OVSF codes reserved for common | | | channels:** | | | | | | | | | ------------- --------- -------- | | | **Channel** **SF** **Nb** | | | **CPICH** **256** **1** | | | **P-CCPCH** **256** **1** | | | **S-CCPCH** **256** **1** | | | **E-AGCH** **256** **1** | | | **AICH** **256** **1** | | | **PICH** **256** **1** | | | | | | ------------- --------- -------- | | | | | | **OVSF code usage modeled for | | | dedicated channels:** | | | | | | **F-DPCH + AICH** | | | | | | **Soft-handover overhead: 1.8** | | | | | | **Up to 8 simultaneous HS-DSCH | | | transmissions allowed.** | +----------------------------------+----------------------------------+ | IMS VoIP packet format and | **AMR 12.2 kbps.** | | overheads | | | | **VoIP packet with payload | | | according to RFC3267.** | | | | | | **24-bit ROHC overhead.** | | | | | | **8-bit RLC overhead.** | | | | | | **No voice packet bundling.** | +----------------------------------+----------------------------------+ | VoIP traffic modelling | **Voice users' frame boundaries | | | are randomly time-staggered.** | | | | | | **SID transmitted every 160 ms | | | of silence.** | | | | | | **Voice activity model for | | | background users:** | | | | | | **ON and OFF periods of duration | | | exponentially distributed, of | | | average 3 seconds.** | | | | | | **50% voice activity.** | | | | | | **Voice activity model for | | | selected user : 100% voice | | | activity** | +----------------------------------+----------------------------------+ | Signaling traffic | **SRB, RTCP, and SIP not | | | modeled.** | +----------------------------------+----------------------------------+ | HSDPA scheduling | **VoIP traffic scheduler:** | | | | | | **Exponential scheduling rule | | | with** | | | {width="0.4166666666666667in" | | | height="0.25in"}**.** | | | | | | **SDU discarding in the MAC-HS | | | modeled.** | +----------------------------------+----------------------------------+ | HSDPA feedback delays | **CQI delay: 8 slots from time | | | of measure to start of HS-PDSCH | | | transmission.** | | | | | | **HARQ delay: minimum 15 slots | | | from end of a transmission to | | | start of a re-transmission.** | +----------------------------------+----------------------------------+ | HSDPA error modelling | **HS-PDSCH: threshold-based | | | decoder.** | | | | | | **HS-SCCH: threshold-based | | | decoder.** | | | | | | **CQI: perfect estimation and | | | with quantization errors.** | | | | | | **HS-DPCCH: HARQ feedback errors | | | modelled with ACK false alarm | | | probability of 10^-3^ and ACK | | | mis-detection probability of | | | 10^-2^.** | +----------------------------------+----------------------------------+ | RAB for HSDPA | **According to reference RAB | | | configuration for VoIP over | | | HSDPA in [5].** | +----------------------------------+----------------------------------+ | EUL format | **2 ms TTI, 3 transmissions** | +----------------------------------+----------------------------------+ | EUL scheduling | **Non-scheduled, autonomous | | | transmissions.** | | | | | | **Delay from received packet | | | re-ordering not modelled** | +----------------------------------+----------------------------------+ | EUL error modelling | **No errors on E-HICH** | | | | | | **4% independent errors on | | | F-DPCH** | | | | | | **E-DPCCH power modelled, but | | | assumed error-free** | | | | | | **HS-DPCCH not modelled** | +----------------------------------+----------------------------------+ | Simulation duration | **3,000 warm-up slots** | | | | | | **90,000 execution slots** | +----------------------------------+----------------------------------+ | RAB for EUL | **According to reference RAB | | | configuration for VoIP over EUL | | | in [5].** | +----------------------------------+----------------------------------+
###### ### Annex L: Test Plan for the AMR NB/WB Conversation Test in UMTS over
HSDPA/EUL
## L.1 Introduction
This document contains the test plan of a conversation test for the selected
speech codecs of Adaptive Multi-Rate Narrow-Band (AMR-NB) and Adaptive Multi-
Rate Wide-Band (AMR-WB) in Packet Switched networks with HSDPA/HSUPA radio
interface, where HSUPA is also referred to as EUL, or EDCH within the
terminology of 3GPP-TSG-RAN. All the laboratories participating in the
conversation test will use the same test plan, while each laboratory uses a
different test language. Even if the test rooms or the test equipments are not
exactly the same in all the laboratories, the calibration procedures and the
tests equipment characteristics will guarantee the similarity of the test
conditions. The details of the test plan is given in the following in 3
sections:
  * Section 2 gives the general information regarding the test.
  * Section 3 details the test design and test methodology
  * Section 4 provides procedure for the test arrangement and logistics
## L.2 General Information
### L.2.1 Permanent Documents
ITU-T Rec. P.800 Methods for Subjective Determination of Transmission Quality
ITU-T Rec. P.805 Conversational Tests
### L.2.2 Key Acronyms
* * *
AMR-NB Adaptive Multi-Rate Narrowband Speech Codec AMR-WB Adaptive Multi-Rate
Wide-band Speech Codec MOS Mean Opinion Score HSPA High Speed Packet Access
HSDPA High Speed Downlink Packet Access HSUPA High Speed Uplink Packet Access
* * *
### L.2.3 Contacts
The following persons should be contacted for questions related to the test
and test plan.
+-------------+-------------+-------------+-------------+-------------+ | Res | Contacts | Affiliation | Mail | Phon | | ponsibility | | | Address | e/Fax/Email | +-------------+-------------+-------------+-------------+-------------+ | C | Jim McGowan | Alc | 67 Whippany | Tel: +1 908 | | oordination | | atel-Lucent | Rd. Rm | 582 5667 | | | | | 2A-384, | | | Test Bed | | | | Fax: | | | | | Whippany, | +1-9 | | | | | NJ 07891, | 73-386-4555 | | | | | USA | | | | | | | mcgowan\ | | | | | | @lucent.com | +-------------+-------------+-------------+-------------+-------------+ | 3GPP-TSG-S | Paolo Usai | ETSI MCC | 650 Route | Tel:+33 -4 | | A4-SQ-Chair | | | des | 92 94 42 | | | | | Lucioles\ | 36\ | | | | | 06921 | Fax: + 33 4 | | | | | Sophia | 93 38 52 06 | | | | | Antipolis | | | | | | Cedex\ | paolo.usa | | | | | France | i\@etsi.org | +-------------+-------------+-------------+-------------+-------------+ | Background | Alan | Dynastat | 6850 Austin | Tel.:+1-5 | | Noise | Sharpley | | Center | 12-476-4797 | | Material | | | Blvd., | | | | | | Ste.150 | Fax:+1-5 | | | | | | 12-472-2883 | | | | | Austin, TX | | | | | | 78731 | a | | | | | | sharpley\@d | | | | | | ynastat.com | +-------------+-------------+-------------+-------------+-------------+
### L.2.4. Participants
Each test laboratory has the responsibility to organize its conversation
tests. The list of the participating test laboratories is the following:
+---------+------------------+------------------+------------------+ | **Lab** | **Company** | **Test |** Contact**| | | | Language** | | +---------+------------------+------------------+------------------+ | 1 | France Telecom | French | Catherine | | | | | Quinquis, | | | | | | | | | | France Telecom\ | | | | | RD/TECH/SSTP\ | | | | | Technopole | | | | | Anticipa\ | | | | | 2, Av P Marzin\ | | | | | 22307 Lannion, | | | | | Cédex, France | | | | | | | | | | Tel : +33-29605 | | | | | 1493 | | | | | | | | | | Fax : +33-29605 | | | | | 3530 | | | | | | | | | | cather | | | | | ine.quinquis\@or | | | | | ange-ftgroup.com | +---------+------------------+------------------+------------------+ | 2 | Dynastat | English | Alan Sharpley, | | | | | | | | | | 6850 Austin | | | | | Center Blvd., | | | | | Ste.150, Austin, | | | | | TX 78731, US | | | | | | | | | | Tel. | | | | | :+1-512-476-4797 | | | | | | | | | | Fax | | | | | :+1-512-472-2883 | | | | | | | | | |  | +---------+------------------+------------------+------------------+ | 3 | Beijing | Chinese | Prof. Xie Xiang, | | | Institute of | | | | | Technology | | No.5 South | | | | | Zhongguancun | | | | | Street, Haidian | | | | | District, | | | | | Beijing 100081, | | | | | China | | | | | | | | | | Phone: +86 10 | | | | | 68915838 | | | | | | | | | | xiex | | | | | iang\@bit.edu.cn | +---------+------------------+------------------+------------------+
## L.3. Test Methodology
### L.3.1 Introduction
The method evaluates the effect of degradation on the quality of the
communications through the conversation-opinion tests recommended by the ITU-T
P.800. The conversation--opinion tests allow subjects in the test to be in a
more realistic situation in terms of the actual service conditions experienced
by telephone customers. In addition, the conversation-opinion tests are suited
to assess the effects of impairments that can cause difficulty while
conversing. Subjects participate to the test in couple; they are seated in
separate sound-proof rooms and are asked to hold a conversation through the
transmission chain simulated by a computer that generates the impairment of
the communication link considered typical for the packet switched network with
HSDPA/HSUPA air-interface. The simulated network configurations (including the
terminal equipments) will be symmetrical (in the two transmission paths as
shown in Figure L.1, but the link conditions in each direction can be
asymmetrical (to be elucidated later).
{width="5.760416666666667in" height="1.386111111111111in"}
Figure L.1: Test Arrangement
### L.3.2 Test Design
#### L.3.2.1 Description of the Test Bed
The test bed intends to provide an emulated transmission system that resembles
the UMTS with HSDPA/HSUPA, as shown by Figure L.2. The real situation to be
tested is a process in which a bit-stream is encoded by AMR packet-wise and
transmitted through a HSUPA and HSDPA air-interfaces, so that it reaches the
receiver, where it is decoded by AMR decoder packet-wise. The bit-stream
encounters impairments while traversing through the system. The impairment is
simulated by the simulator off-line and played into the test bed during the
test.
{width="5.9944444444444445in" height="1.25625in"}
Figure L.2: UMTS system under test
Simulated transmission links are implemented in hardware through two
computers, each being responsible for one direction, as shown in Figure L.3.
The Internet Protocol is implemented in both computers. Each AMR frame
generated by the AMR encoder is wrapped in a unique RTP packet every 20 ms. At
the receiver the RTP packets are buffered and delayed according to the lower
layer simulated receive time.
{width="6.002777777777778in" height="2.352777777777778in"}
Figure L.3: Implementation of the Test Bed
The radio access bearer (RAB) represents the performance of the HSDPA/HSUPA of
the physical layer. During the test, the test bed uses the delay-error
profiles generated by the off-line simulation of the RAB. A software unit that
inserts the off-line generated delays and errors into the RTP flows is
implemented in each computer and allows selections of different network and
channel conditions.
#### L.3.2.2 Transmission System
The transmission system is configured as a mobile-to-mobile connection within
an IMS with HSDPA downlink and an HSUPA uplink. The protocol stack of the
radio interface is shown in Figure L.4. The simulation of the performance of
the radio interface simulator is based on a network layout of 19 cells and 57
sectors, while the output of the simulation is a sequence of RLC packet
reception status. A RLC packet is transmitted from the mobile to the
origination RNC, and from the destination RNC to the destination RNC via the
core network, before reaching the receive mobile. The recorded traces include
the delay and the error event of the received RLC packets.
{width="5.499305555555556in" height="1.9993055555555554in"}
Figure L.4: Transmission path through a UMTS
The transmission of IP/UDP/RTP/AMR packets over the core network is not
further simulated in details besides a static end-to-end delay.
#### L.3.2.3 Radio Access Bearers
The AMR-NB/AMR-WB will encode speech at a 5.9 kbps, 12.2 kbps, and 12.65 kbps,
respectively. The bit-stream will be encapsulated using IP/UDP/RTP protocols
and sent to the air-interface emulator located in the origination computer.
The output of the air-interface is the payload of the IP packets, which are
then sent through an RJ-45 port of the origination computer and received by
the destination computer, where the RTP packets will be extracted and the AMR-
NB/AMR-WB frames are buffered and decoded.
The RABs underlying the test are specified in TS 25.993 in the following
sections:
"
  1. RB for Conversational / unknown UL: [max bitrate depending on UE category and TTI] on E-DCH DL: [max bitrate depending on UE category] on HS-DSCH / PS RAB\
     * RB for interactive or background / UL : [max bitrate depending on UE category and TTI] on E-DCH DL : [max bitrate depending on UE category] on HS-DSCH / PS RAB\
     * RB for interactive or background / UL : [max bitrate depending on UE category and TTI] on E-DCH DL : [max bitrate depending on UE category] on HS-DSCH / PS RAB\
     * UL : [max bitrate depending on UE category and TTI] on E-DCH DL : [max bit rate depending on UE category] on HS-DSCH SRBs for DCCH"
  2. RB for Conversational / Unknown UL: [max bitrate depending on UE category and TTI] on E-DCH DL: [max bitrate depending on UE category] on HS-DSCH / PS RAB\
     * RB for interactive or background / UL : [max bitrate depending on UE category and TTI] on E-DCH DL : [max bitrate depending on UE category] on HS-DSCH / PS RAB\
     * UL : [max bitrate depending on UE category and TTI] on E-DCH DL : [max bit rate depending on UE category] on HS-DSCH SRBs for DCCH"
\"
#### L.3.2.4 Test environment
An external sound card will be used for each computer of the test bed. To
avoid echo problems, headsets, instead of handsets will be used. The monaural
supra-aural headsets, the other ear uncovered, are connected to the sound
cards. But, in practice, the original settings, defined during the preliminary
tests, and producing a comfortable listening level, will not be modified. A
foam ball protects the microphones in order to reduce the \"pop\" effect. The
user should avoid to place the acoustic opening of the microphone in front of
the mouth
Each of the two subjects participating in the conversations is installed in a
test room. They sit in an armchair in front of a table. The test rooms are
acoustically insulated. All the test equipments are installed in a third room,
connected to the test rooms. When needed, the background noise is generated in
the appropriate test room through a set of 4 loudspeakers. The background
noise level is adjusted and controlled by a sound level meter. The measurement
microphone, connected to the sound level meter is located at the equivalent of
the center of the subject\'s head. The noise level is A weighted.
Before the beginning of a set of experiments, the end-to-end transmission
level is checked subjectively, to ensure that there is no problem. The speech
level is checked by the following procedure: An artificial mouth placed in
front of the microphone of the Headset A, in the LRGP position -See ITU-T Rec.
P.64-, generates in the artificial ear (according to ITU-T Rec. P57) coupled
to the earphone of the Head set B the nominal level defined in section 4.3.
The level is adjusted according to the bandwidth to -15 dB Pa for NB and to
-18 dB Pa for WB , when necessary, with the receiving volume control of the
headset. Inverting headsets A and B does a similar calibration.
At each test laboratory the test bed must be calibrated, so that the given
value of fixed delay for the speech transmission is the same for all labs.
### L.3.3 Test Conditions
Three codec rates will be tested: AMR-NB 5.9 kbps and 12.2 kbps, as well as
AMR-WB 12.65 kbps. Two different categories of test conditions are defined and
their combination makes the actual test conditions.
_Network Condition_
Table L.1: Definition of the radio network conditions
+-------------------------+-------------+--------------+--------+ | Radio Network Condition | Low Traffic | High Traffic | Uplink | | | | | | | | Down Link | Down Link | | +-------------------------+-------------+--------------+--------+ | Low Mobility Mobile | LM.LT | LM.HT | Lm | +-------------------------+-------------+--------------+--------+ | High Mobility Mobile | HM.LT | HM.HT | Hm | +-------------------------+-------------+--------------+--------+
In specifics:
  * [Low]{.underline} Traffic (LT): 40, or 45, or 60 mobile users per cell
  * [High]{.underline} Traffic (HT): 80, or 100 mobile users per cell
  * [Low]{.underline} Mobility (LM, Lm): ITU --Channel-Model: PedB3_km or PedA3_km
  * [High]{.underline} Mobility (HM, Hm): ITU-Channel-Model: VehA30km or Veh120km or PedB30km
The uplinks are simulated as dedicated channel, hence the traffic conditions
apply only to the downlinks. From a mobile-to-mobile connection, the order of
the uplink and downlink plays no role. Therefore, we have the following 8
possible construction of channel conditions:
Table L.2 Notation for the mobile-to-mobile radio network conditions
* * *
**_Number_** **_Notation_** **_Meaning_** [1] Lm.LT.LM Lm + LT.LM [2] Lm.LT.HM
Lm+LT.HM [3] Lm.HT.LM Lm+HT.LM [4] Lm.HT.HM Lm+HT.HM [5] Hm.LT.LM Hm+LT.LM [6]
Hm.LT.HM Hm+LT.HM [7] Hm.HT.LM Hm+HT.LM [8] Hm.HT.HM Hm+HT.HM
* * *
_Acoustic Noise Condition_
The condition refers the characteristic background noise of the subjects; four
classes of noise will be deployed:
* * *
Noise type Level (dB Pa ) Car -30 Street -35 Cafeteria -35 Hoth Spectrum at 30
dBA as defined by ITU-T, Recommendation P.800, Annex A, section A.1.1.2.2.1
Room Noise, with table A.1 and Figure
* * *
The production of background noise follows the guide lines of ETSI EG 202
396-1 (clause 6).
_Combined Test Conditions_
Each test condition is assigned a unique number defined as following:
* * *
x-y.z.c x y Z C e.g. 1-1.3a AMR-Mode Network Load Experiment Swap subjects
* * *
_Following conditions will be used for the tests:_
AMR-Mode 5.9 kbps (x=1): 8 conditions (y=1), 8 conditions (y=2)
+---------+----------+----------+----------+----------+----------+ | _Cond._ | _Noise |_ Radio | _Noise |_ Desc | _Cond. | | | in Room | Network_ | in Room | ription _| Number_ | | _Label_ | A _| | B_ | | | | | | _Co | | | | | | | ndition_ | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.1 | Hoth | A->B: | Hoth | Lm.LT.LM | 1 | | | | [1] | | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.2 | Car | A->B: | Car | Hm.LT.HM | 2 | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.3a | Car | A->B: | Hoth | Hm.LT.LM | 3 | | | | [5] | | | | | | | | | HM.LT.Lm | | | | | B->A: | | | | | | | [2] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.3b | Hoth | A->B: | Car | Lm.LT.HM | 4 | | | | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.4 | C | A->B: | C | Lm.LT.LM | 5 | | | afeteria | [1] | afeteria | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.5a | C | A->B: | Street | Lm.LT.HM | 6 | | | afeteria | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.5b | Street | A->B: | C | Hm.LT.LM | 7 | | | | [5] | afeteria | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [2] | | | | +---------+----------+----------+----------+----------+----------+ | 1-1.6 | Street | A->B: | Street | Hm.LT.HM | 8 | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.1 | Hoth | A->B: | Hoth | Lm.HT.LM | 9 | | | | [3] | | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.2 | Car | A->B: | Car | Hm.HT.HM | 10 | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.3a | Car | A->B: | Hoth | Hm.HT.LM | 11 | | | | [7] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [4] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.3b | Hoth | A->B: | Car | Lm.HT.HM | 12 | | | | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.4 | C | A->B: | C | Lm.HT.LM | 13 | | | afeteria | [3] | afeteria | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.5a | C | A->B: | Street | Lm.HT.HM | 14 | | | afeteria | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.5b | Street | A->B: | C | Hm.HT.LM | 15 | | | | [7] | afeteria | | | | | | | | HM.HT.Lm | | | | | B->A: | | | | | | | [4] | | | | +---------+----------+----------+----------+----------+----------+ | 1-2.6 | Street | A->B: | Street | Hm.HT.HM | 16 | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +---------+----------+----------+----------+----------+----------+
AMR-Mode 12.2 kbps (x=2): 8 conditions (y=1), 8 conditions (y=2)
+---------+----------+----------+----------+----------+----------+ | _Cond._ | _Noise |_ Radio | _Noise |_ Desc | _Cond. | | | in Room | Network_ | in Room | ription _| Number_ | | _Label_ | A _| | B_ | | | | | | _Co | | | | | | | ndition_ | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.1 | Hoth | A->B: | Hoth | Lm.LT.LM | 1 | | | | [1] | | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.2 | Car | A->B: | Car | Hm.LT.HM | 2 | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.3a | Car | A->B: | Hoth | Hm.LT.LM | 3 | | | | [5] | | | | | | | | | HM.LT.Lm | | | | | B->A: | | | | | | | [2] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.3b | Hoth | A->B: | Car | Lm.LT.HM | 4 | | | | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.4 | C | A->B: | C | Lm.LT.LM | 5 | | | afeteria | [1] | afeteria | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.5a | C | A->B: | Street | Lm.LT.HM | 6 | | | afeteria | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.5b | Street | A->B: | C | Hm.LT.LM | 7 | | | | [5] | afeteria | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [2] | | | | +---------+----------+----------+----------+----------+----------+ | 2-1.6 | Street | A->B: | Street | Hm.LT.HM | 8 | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.1 | Hoth | A->B: | Hoth | Lm.HT.LM | 9 | | | | [3] | | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.2 | Car | A->B: | Car | Hm.HT.HM | 10 | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.3a | Car | A->B: | Hoth | Hm.HT.LM | 11 | | | | [7] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [4] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.3b | Hoth | A->B: | Car | Lm.HT.HM | 12 | | | | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.4 | C | A->B: | C | Lm.HT.LM | 13 | | | afeteria | [3] | afeteria | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.5a | C | A->B: | Street | Lm.HT.HM | 14 | | | afeteria | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.5b | Street | A->B: | C | Hm.HT.LM | 15 | | | | [7] | afeteria | | | | | | | | HM.HT.Lm | | | | | B->A: | | | | | | | [4] | | | | +---------+----------+----------+----------+----------+----------+ | 2-2.6 | Street | A->B: | Street | Hm.HT.HM | 16 | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +---------+----------+----------+----------+----------+----------+
AMR-WB-Mode 12.65 kbps (x=3): 8 conditions (y=1), 8 conditions (y=2)
+---------+----------+----------+----------+----------+----------+ | _Cond._ | _Noise |_ Radio | _Noise |_ Desc | _Cond. | | | in Room | Network_ | in Room | ription _| Number_ | | _Label_ | A _| | B_ | | | | | | _Co | | | | | | | ndition_ | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.1 | Hoth | A->B: | Hoth | Lm.LT.LM | 1 | | | | [1] | | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.2 | Car | A->B: | Car | Hm.LT.HM | 2 | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.3a | Car | A->B: | Hoth | Hm.LT.LM | 3 | | | | [5] | | | | | | | | | HM.LT.Lm | | | | | B->A: | | | | | | | [2] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.3b | Hoth | A->B: | Car | Lm.LT.HM | 4 | | | | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.4 | C | A->B: | C | Lm.LT.LM | 5 | | | afeteria | [1] | afeteria | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.5a | C | A->B: | Street | Lm.LT.HM | 6 | | | afeteria | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.5b | Street | A->B: | C | Hm.LT.LM | 7 | | | | [5] | afeteria | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [2] | | | | +---------+----------+----------+----------+----------+----------+ | 3-1.6 | Street | A->B: | Street | Hm.LT.HM | 8 | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.1 | Hoth | A->B: | Hoth | Lm.HT.LM | 9 | | | | [3] | | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.2 | Car | A->B: | Car | Hm.HT.HM | 10 | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.3a | Car | A->B: | Hoth | Hm.HT.LM | 11 | | | | [7] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [4] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.3b | Hoth | A->B: | Car | Lm.HT.HM | 12 | | | | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.4 | C | A->B: | C | Lm.HT.LM | 13 | | | afeteria | [3] | afeteria | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.5a | C | A->B: | Street | Lm.HT.HM | 14 | | | afeteria | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.5b | Street | A->B: | C | Hm.HT.LM | 15 | | | | [7] | afeteria | | | | | | | | HM.HT.Lm | | | | | B->A: | | | | | | | [4] | | | | +---------+----------+----------+----------+----------+----------+ | 3-2.6 | Street | A->B: | Street | Hm.HT.HM | 16 | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +---------+----------+----------+----------+----------+----------+
Preliminary training conditions are 1-1.1 and 1-1.2 (colored within red and
blue, respectively, in the table)
_[Miscellaneous Conditions]{.underline}_
[]{.underline}
* * *
Listening Level 1 79 dBSPL or 76 dBSPL (-15 dB Pa or -18 dB Pa)
Listeners/Speakers 32 Naïve Listeners/Native Speakers Groups 16 2
subjects/group Rating Scales 5 see section 4.2 Languages 3 French, English,
Chinese Listening System 2 Monaural headset (flat response in the audio
bandwidth of interest: 50Hz-7kHz). The other ear is open. Microphone 2
Frequency range: 100Hz-10kHz
* * *
## L.4 Test Procedure
The procedure and logistic of the test across test laboratories are given in
the following:
### L.4.1 Time Projection
The following numbers characterizes the entire test:
* * *
#acoustic/radio conditions 8 2 subjects swapping #network load conditions 2
Light, heavy #codecs=#experiments per lab 3 5.9kbps, 12.2kbps, 12.65kbps
#languages 3 English, French, Chinese #subjects per experiment 32 16 pairs
* * *
Each lab tests only one language. Each experiment covers 16 test conditions.
Each group has to perform 16 conversations, each of ca. 3 minutes. A session
consists of 4 consecutive conversations, corresponding to ca. 20 minutes test
time. The subject panels for the three experiments shall be independent, i.e.
no subject will participate in more than one experiment. The order of the
presentation of test conditions are provided in Appendix 2.
The test time projection is the following:
  * Practice and Training per group: 30 minutes
  * Conversation plus setup and data collection: 5 minutes
  * Break between sessions: 10 minutes
  * Number of breaks per experiment: 3
  * Work hours per day: 8 hours
  * Work days per week: 5 days
This results in 3 groups per day, i.e. 6 working days per experiment, and 18
working days per laboratory, plus 1 day for system setup. In total, one month
per laboratory is estimated as the minimum
The project plan can be envisioned as the following:
* * *
Test Month Laboratories Duration Starting Date Month 1 France Telecom 4 weeks
May 15, 2007 Month 2 BIT 4 weeks June 19, 2007 Month 3 Dynastat 4 weeks July
28, 2007 Month 4 Dynastat (GAL) >1 week August 28, 2007
* * *
The actual time will be adapted to the specific situation of the individual
labs. The entire test is expected to take 3+ months.
### L.4.2 Instructions to the Subjects
The following instruction shall be given to the subjects in each lab in the
respective native language during the training phase prior to the tests.
"You are going to have a conversation with another user. The test situation is
simulating communications between two mobile phones. The most of the
situations will correspond to silent environment conditions, but some other
will simulate more specific situations, as in a car, or in a railway station
or in an office environment, when other people are discussing in the
background.
After the completion of each call conversation, you will have to give your
opinions on the quality, by answering to the following questions that will be
displayed on the screen of the black box in front of you. Your judgment will
be stored. You have 8 seconds to answer to each question. After \"pressing\"
the button on the screen, another question will be displayed. You continue the
procedure for the 5 following questions.
{width="6.709722222222222in" height="6.631944444444445in"}
From then on you will have a break approximately every 30 minutes. The test
will last a total of approximately 60 minutes.
Please do not discuss your opinions with other listeners participating in the
experiment."
### L.4.3 Test Materials
The pretexts used for conversation test are those developed by ITU-T SG12.
These scenarios have been elaborated to allow a conversation well balanced
within both participants and lasting approximately 2'30 or 3', and to
stimulate the discussion between persons that know each other to facilitate
the naturalness of the conversation. They are derived from typical situations
of every day life: railways inquiries, rent a car or an apartment, etc. Each
condition should be given a different scenario. Each lab is responsible for
developing the actual conversation materials to be used.
The examples are extracted from ITU-T rec. P.805 (2007) Appendices 4, 5 and 6.
Following the examples and the spirit given by this reference, the actual
materials should be developed and adapted to the language being tested, the
cultural specifics of the country of the lab and the local situations,
depending on where the test lab is located.
### L.4.4 Deliverables
The information required from each test laboratory is a table containing the
\"Opinion Score (OS)\", in ASCII file or in spreadsheet, obtained from every
subject for each conversation. No post processing is required from the labs.
The original data are provided by each lab using a template that includes the
following information:
Table L.3: Template for the raw data
* * *
Subject ID Test Condition Test Material _Rating_ Conversation Partner ID
Time/Date Comments
* * *
Raw data deliverable spreadsheet will be provided to the test labs by the
Global Analysis Lab prior to the beginning of the tests.
### L.4.5 Data Analysis
Two statistical analyses should be conducted on the data obtained with these
subjective scales. The first analysis consists in a MANOVA, which globally
indicates the possible effect of the experimental factors (_i.e._ , different
conditions). Then, a specific ANOVA should be run on each dependent variable
to test if there is an effect of a specific experimental factor for a given
subjective variable. In other words, these statistical analyses indicate if
the differences observed between the MOS obtained for the different conditions
are significant, for any given dependant variable (ANOVA) or for the entirety
of all the dependant variables (MANOVA). Finally, Pearson\'s linear
correlations should be computed between the results of all subjective
variables, to find out the specific dependent relations.
## L.5 Working Document for the Performance Characterization of VoIMS over
HSDPA/EDCH
### L.5.1 Introduction
TR 26.935 provides information on the performance of default speech codec in
packet switched conversational multimedia applications. The transmission of
IP/UDP/RTP/AMR packets over the UMTS air interface (DCHs) wass simulated using
the Conversational / Speech / UL:46 kbit/s / PS RAB coming from TS 34.108 v.
4.7.0.
During TSG SA#27 Tokyo [SP-050089], the new work item of "Performance
Characterization of VoIMS over HSDPA/EUL" was approved. The goal of the work
item is to test the codec performance when VoIP is supported by HS-DSCH in the
DL and EDCH in the UL.
### L.5.2 System Overview
The goal of the test system is to enable MOS tests of mobile-to-mobile
conversational voice services in a representative UMTS system supporting VoIP
over HSDPA/EDCH. The test system includes two independent links in opposite
directions, used by the two parties of an active conversation, respectively.
The two parties of the conversation are referred to as A and B, respectively.
Thus, the entities of the test system occur always in pair, and the
configuration of the link A-to-B and B-to-A are identical, reflecting the
symmetry of the conversational connection.
The principle of the design of the test system is the balance of the fidelity
to the reality and the feasibility of the implementation. The UMTS system and
the IP network with the designated channel types and protocols will be
simulated by means of digital computers. It is therefore important that a
design of the test system allows for the verifications and repetitions, so
that the correct implementation in software can be achieved with the highest
probability. To this end, a modular design is taken.
Considering the fact that HARQ and ROHC introduce sources of delay jitters for
the packets in both directions, it is necessary to implement them in two
modules. Besides, the speech lab and the IP/Core network are both independent
of RAN in nature, it is reasonable to divide the entire test system into 4
separate entities:
  * RN simulator,
  * IP/Core network simulator,
  * VoIP simulator and
  * Test Environment
This division results in 6 interfaces in each direction, as shown in Fig.1. On
the high level, each entity has the following respective function:
  * Radio Network (RN) Simulator: This simulates the performance of the protocol layers RLC/MAC/PHY for the downlink and the uplink, to produce statistics for the air interfaces on the RLC packet stream. It is noted that the RN simulator defined here is a sub-set of the RAN defined in the UMTS and it aims at capturing the RAN impacts that are essential to the VoIP performance characterisation.
  * IP/Core Simulator: This simulates the routing through a loaded IPv6 network, to capture the impairments of packet loss and delay. For the purpose of testing the conversational services, only two entry/exit pairs for the IP core network are needed---one entry/exit for RN(A) and the other entry/exit for RN(B).
  * VoIP Simulator: This simulates the VoIP specific functions between the sound cards and the RAN simulators, which comprises the speech encoder/decoder, AMR/RTP/UDP/IP/PDCP packetizing/depacketizing, robust header compression/decompression for both party A and party B of a conversation, etc. Physically, the two ends of the VoIP are located in the SRNC and belong to MAC-d entities of the two conversation parties, respectively.
  * Speech Lab: This performs the MOS tests on the AMR/AMR-WB under the network conditions simulated by VoIP, RN and IP/Core. Each side of the conversation uses **appropriate playback hardware.** The requirement for the test material and the test subject can be taken from TR26.935.
{width="5.9875in" height="3.936111111111111in"}
Figure L.5.1 Architecture of the Test System
The division of the test system into relatively independent entities serves to
clarify the concepts involved. The modular structure allows for off-line
simulation of each identified entity independently. However, the designated
conversational test requires the availability of the simulated radio carrier
in a real-time manner. The real-time simulation of the entire system is
hardware limited due to the complexity of the RN simulator. Therefore a
combination of the off-line simulation of the RN and the on-line simulation of
the VoIP is considered. This is justified by the fact that a continuous stream
of RLC PDUs can be produced by the RN simulator regardless of the payload.
### L.5.3 Radio Access Bearers
The radio bearers used for the simulation of the lower layer delay and error
performance are extracted from 25.993 in the following:
\"
7.5.3 RB for Conversational / unknown UL: [max bitrate depending on UE
category and TTI] on E-DCH DL: [max bitrate depending on UE category] on HS-
DSCH / PS RAB\ \+ RB for interactive or background / UL : [max bitrate
depending on UE category and TTI] on E-DCH DL : [max bitrate depending on UE
category] on HS-DSCH / PS RAB\ \+ RB for interactive or background / UL : [max
bitrate depending on UE category and TTI] on E-DCH DL : [max bitrate depending
on UE category] on HS-DSCH / PS RAB\ \+ UL : [max bitrate depending on UE
category and TTI] on E-DCH DL : [max bit rate depending on UE category] on HS-
DSCH SRBs for DCCH
\"
The minimum UE classes supporting this combination are : support of HS-PDSCH,
DL on HS-PDSCH: category 11 and support of E-DPDCH, UL on E-DPDCH category 1.
This is supported in Release 6.
**7.5.3.1 Uplink**
+-------------+-------------+-------------+-------------+-------------+ | | Radio | _Radio | Signalling |_ Signalling | | | Bearer\ | Bearer\ | Radio | Radio | | | on DPCH | on E-DPCH _| Bearer\ | Bearer\ | | | | | on DPCH | on E-DPCH_ | +-------------+-------------+-------------+-------------+-------------+ | Transport | | 7. | | 7. | | Channel | | 5.3.1.1.1.1 | | 5.1.1.1.1.1 | | | | for | | | | | | con | | | | | | versational | | | | | | RB, | | | | | | | | | | | | 6.10.2.4. | | | | | | 6.1.1.1.1.1 | | | | | | of [1] | | | | | | for | | | | | | Interactive | | | | | | /Background | | | | | | RBs (MAC-e | | | | | | muxed) | | | +-------------+-------------+-------------+-------------+-------------+ | TFCS | | | | | +-------------+-------------+-------------+-------------+-------------+ | Physical | 6.10.2. | | | | | Channel | 4.6.1.1.2.1 | | | | | | of [1]\ | | | | | | E-TFCI | | | | | | table index | | | | | | = 0; E-DCH | | | | | | minimum set | | | | | | E-TFCI = = | | | | | | 29 (10 ms | | | | | | TTI, TB | | | | | | size 374 | | | | | | bits) or 32 | | | | | | (2 ms TTI, | | | | | | TB size 368 | | | | | | bits) | | | | +-------------+-------------+-------------+-------------+-------------+
Note: MAC-e multiplexing of scheduled and non-scheduled MAC-d flows is
allowed.
**7.5.3.1.1** Transport channel parameters
**7.5.3.1.1.1** Transport channel parameters for E-DCH
**7.5.3.1.1.1.1** MAC-d flow#1 parameters for conversational / Unknown UL:
[max bit rate depending on UE category and TTI] on E-DCH / PS RAB
+----------------------+----------------------+----------------------+ | Higher layer | RAB/Signalling RB | RAB | +----------------------+----------------------+----------------------+ | PDCP | PDCP header size, | 0 | | | bit | | +----------------------+----------------------+----------------------+ | RLC | Logical channel type | DTCH | +----------------------+----------------------+----------------------+ | | RLC mode | UM | +----------------------+----------------------+----------------------+ | | Payload sizes, bit | 88, 104, 136, 152, | | | | 168, 184, 200, 216, | | | | 280, 288, 304, 336 | | | | (alt 328) | +----------------------+----------------------+----------------------+ | | Max data rate, bps | Depends on UE | | | | category and TTI | +----------------------+----------------------+----------------------+ | | UMD PDU header, bit | 8 | +----------------------+----------------------+----------------------+ | MAC | MAC-e multiplexing | N/A | +----------------------+----------------------+----------------------+ | | MAC-d PDU size, bit | 96, 112, 144, 160, | | | | 176, 192, 208, 224, | | | | 288, 296, 312, 344 | | | | (alt 336) | +----------------------+----------------------+----------------------+ | | Max MAC-e PDU | (non-scheduled) | | | content size, bit | (NOTE1) | +----------------------+----------------------+----------------------+ | | MAC-e/es header | 18 | | | fixed part, bit | | +----------------------+----------------------+----------------------+ | Layer 1 | TrCH type | E-DCH | +----------------------+----------------------+----------------------+ | | TTI | 10ms (alt. 2ms) | | | | (NOTE2) | +----------------------+----------------------+----------------------+ | | Coding type | TC | +----------------------+----------------------+----------------------+ | | CRC, bit | 24 | +----------------------+----------------------+----------------------+ | NOTE1: Max MAC-e PDU | | | | content sizes | | | | dependson | | | | non-scheduled grant | | | | given by SRNC | | | | | | | | NOTE2: The support | | | | of 2ms TTI depends | | | | on the UE category. | | | +----------------------+----------------------+----------------------+
**7.5.3.2 Downlink**
+-------------+-------------+-------------+-------------+-------------+ | | Radio | Radio | Signalling | Signalling | | | Bearer\ | Bearer\ | Radio | Radio | | | on DPCH | on HS-PDSCH | Bearer\ | Bearer\ | | | | | on DPCH | on HS-PDSCH | +-------------+-------------+-------------+-------------+-------------+ | Transport | | 7.4 | | 6.10.2.4. | | Channel | | .22.2.1.1.1 | | 6.3.2.1.1.2 | | | | for | | of [1] | | | | Con | | | | | | versational | | | | | | RB | | | | | | | | | | | | 6.10.2.4. | | | | | | 5.1.2.1.1.1 | | | | | | of [1] | | | | | | for | | | | | | Interactive | | | | | | /Background | | | | | | RBs | | | +-------------+-------------+-------------+-------------+-------------+ | TFCS | | | | | +-------------+-------------+-------------+-------------+-------------+ | Physical | 6.10.2. | | | | | Channel | 4.5.1.2.2.2 | | | | | | of [1]\ | | | | | | The | | | | | | physical | | | | | | channel | | | | | | co | | | | | | nfiguration | | | | | | shall use | | | | | | F-DPCH. | | | | +-------------+-------------+-------------+-------------+-------------+
**7.5.4**
\"
RB for Conversational / Unknown UL: [max bitrate depending on UE category and
TTI] on E-DCH DL: [max bitrate depending on UE category] on HS-DSCH / PS RAB\
\+ RB for interactive or background / UL : [max bitrate depending on UE
category and TTI] on E-DCH DL : [max bitrate depending on UE category] on HS-
DSCH / PS RAB\ \+ UL : [max bitrate depending on UE category and TTI] on E-DCH
DL : [max bit rate depending on UE category] on HS-DSCH SRBs for DCCH
\"
The minimum UE classes supporting this combination are: support of HS-PDSCH,
DL on HS-PDSCH: category 11 and support of E-DPDCH, UL on E-DPDCH category 1.
This is supported in Release 6.
**7.5.4.1 Uplink**
+-------------+-------------+-------------+-------------+-------------+ | | Radio | _Radio | Signalling |_ Signalling | | | Bearer\ | Bearer\ | Radio | Radio | | | on DPCH | on E-DPCH _| Bearer\ | Bearer\ | | | | | on DPCH | on E-DPCH_ | +-------------+-------------+-------------+-------------+-------------+ | Transport | | 7. | | 7. | | Channel | | 5.3.1.1.1.1 | | 5.1.1.1.1.1 | | | | for | | | | | | Con | | | | | | versational | | | | | | RB | | | | | | | | | | | | 6.10.2.4. | | | | | | 6.1.1.1.1.1 | | | | | | of [1] | | | | | | for | | | | | | Interactive | | | | | | /Background | | | +-------------+-------------+-------------+-------------+-------------+ | TFCS | | | | | +-------------+-------------+-------------+-------------+-------------+ | Physical | 6.10.2. | | | | | Channel | 4.6.1.1.2.1 | | | | | | of [1]\ | | | | | | E-TFCI | | | | | | table index | | | | | | = 0; E-DCH | | | | | | minimum set | | | | | | E-TFCI = = | | | | | | 29 (10 ms | | | | | | TTI, TB | | | | | | size 374 | | | | | | bits) or 32 | | | | | | (2 ms TTI, | | | | | | TB size 368 | | | | | | bits) | | | | +-------------+-------------+-------------+-------------+-------------+
Note: MAC-e multiplexing of scheduled and non-scheduled MAC-d flows is allowed
**7.5.4.2 Downlink**
* * *
                      Radio Bearer\                                          Radio Bearer\                                                                                      Signalling Radio Bearer\   Signalling Radio Bearer\
                      on DPCH                                                on HS-PDSCH                                                                                        on DPCH                    on HS-PDSCH
Transport Channel 7.4.22.2.1.1.1 for Conversational RB 6.10.2.4.5.1.2.1.1.1 of
[1] for Interactive/Background RB 6.10.2.4.6.3.2.1.1.2 of [1]
TFCS
Physical Channel 6.10.2.4.5.1.2.2.2 of [1]\  
The physical channel configuration shall use F-DPCH.
* * *
### L.5.4 Delay
The overall delay consists of the delay of the air interface as well as the
networks. The predominant issue that distinguishes VoIP from voice service on
circuit switched network is the variation of the delay with respect to a fixed
delay value, which is referred to as jitter. In order to capture the impact of
jitter on the performance of VoIP, a proper assumption about the overall delay
budget is necessary.
The fixed delay component is estimated using the following example of delay
budget for end-to-end VoIP calls in HSPA when the uplink uses 10 ms TTIs [19].
Table L.5.1. Example delay budget for VoIP in HSPA
* * *
**Uplink (EUL 10 ms TTI)** **Delay** **Downlink (HSDPA)** **Delay** AMR
encoder 35 ms AMR decoder 5 ms UE L1/L2 processing 5 ms UE L1/L2 processing 10
ms TTI alignment 0 -- 10 ms - - Uu interleaving 10 ms Uu interleaving 2 ms UL
re-TX 0 -- 80 ms DL Scheduling 5 -- 100 ms RNC/Iub/Node B 10 ms RNC/Iub/Noted
B 10 ms Iu + Gi 5 ms Gi + Iu 5 ms **Sum min UL** **65 ms** **Sum min DL** **37
ms** **Sum max UL** **155 ms** **Sum max DL** **132 ms**
* * *
The different delay components are described below:
  * The AMR encoder and decoder delay components includes: buffering time, due to the frame length (20 ms); look-ahead (5 ms); and processing time (10 ms and 5 ms for uplink and downlink respectively).
  * The layer 1 and 2 processing time includes the following protocol layers: Packet Data Convergence Protocol (PDCP); Radio Link Control (RLC); Medium Access Control (MAC); and the Physical (PHY) layer.
  * The TTI alignment delay component is needed in uplink since the packet may need to be buffered to align the transmission to the frame structure of the radio interface. Note that it is possible to adjust the speech encoder framing period to the air interface framing period to get 0 ms TTI alignment delay. Note also that EUL may use 2 ms TTIs, which would reduce this value to 0 -- 2 ms. For downlink, the TTI alignment delay is included in the DL Scheduling delay and is therefore not specified as a separate delay component in this delay budget.
  * The Uu interleaving consists of the actual transmission over the air interface, 10 ms and 2 ms for uplink and downlink respectively. The delay for the uplink can be reduced by using 2 ms TTIs.
  * HARQ re-transmissions add only to the jitter but not to the fixed delay component. For uplink, since 10 ms TTIs are used in this example delay budget, the re-transmission time is estimated to 40 ms and that at most 2 re-transmissions are performed before the packet is dropped. Note that the allowed number of re-transmissions, and thus the delay jitter, will be different for different implementations.
  * For downlink, the re-transmission time is included in the variable part of the DL Scheduling delay. In this case, it is assumed that the packet is dropped if it is delayed more than 100 ms in the scheduler. Note that this delay is the sum of scheduling delay and re-transmission delays. Note also that the scheduler is vendor specific and thus the delay, and especially the variable part, depends entirely on how different vendors choose to implement it.
  * The RNC/Iub/Node B delay number describes the RAN delays, i.e. Node B and RNC processing times and transmission delays in-between these nodes.
  * The Core Network delay is included in the Iu+Gi delay component.
  * Delay for the backbone network is not included in this example.
In summary, the end-to-end packet delay, divided into two parts, is estimated
as the following:
  * A fixed part, which is identical to the minimum delay, i.e. 102 ms +30 ms, where the 30 ms accounts for the backbone core network delay.
  * A variable part, which corresponds to the jitter, and is in the 0 -- 185 ms range.
### L.5.5 RN Simulator
High Speed Downlink Packet Access (HSDPA) is based on techniques such as
adaptive modulation/coding and hybrid ARQ to achieve high throughput. The new
channel HS-DSCH is terminated in the Node B and is applicable only to PS
domain RABs. MAC-d is retained in the S-RNC, while a new entity, MAC-hs
located in Node B, is introduced to host the functionalities of hybrid ARQ,
rate selection, and HS-DSCH scheduling.
EDCH for the uplink has the same features of fast rate scheduling, hybrid ARQ,
and adaptive coding in addition to DCH. It is managed by a new entity MAC-e
and terminated in Node B, while another new entity MAC-es is introduced in
S-RNC to manage the re-ordering of data from different MAC-d's. The relation
is shown in Figure L.5.2.
{width="4.7625in" height="2.827777777777778in"}
Figure L.5.2: MAC structure applicable to VoIMS via HSDPA/EDCH
The simulator will primarily simulate the functionalities of MAC-hs and MAC-e
for the downlink and uplink, respectively Scheduling for VoIP is crucial in
the downlink over the shared HS-DSCH, however, VoIP can simply operate as a
non-scheduled transmission (NST) in the uplink.
A simple implementation of RN simulator consists of the following components:
  1. Radio Access Bearer: Mechanism of the protocols involved should be implemented as assumed by the given RAB. For the physical layer radio bearer the BLER of the physical channel corresponding to the given RB deployed at the given UE location with the given mobile speed will be measured for instantaneous Ec/Nt, and recorded for use by the system level simulation. The RAB\'s are chosen from section L.5.3 Radio Access Bearers.
  2. Cellular Network: This consists of assumptions of the cell structure, channel models deployed, traffic load, antenna, locations of users, etc. Interactions between a reference user and the Node B is to be simulated here, for which the buffer configuration, the scheduler algorithm, the delay budget, number of users, etc. are needed. This simulator comprises the functions of Node_B and Iu interface, a part of the radio access network that is extensively simulated in 3GPP-RAN working groups. However, the simulation work done for the pure capacity has a different scope than here. The focus of the present work item is to test a single connection that is representative for the service provided by the network and the final test method is the listening test instead of statistical description. For this reason, the radio network simulator shall produce a sequence of coherent samples of error and delay events, which different objective of the simulator designed to evaluate the capacity or the channel quality based on statistic evaluation. The setup, the parameters and the working assumptions need to be designed specifically for this purpose. The expected main result of the simulation is a sequence of error and delay events with associated attributes necessary for the further processing. Details of the simulation assumptions can be found in Appendix A.
  3. Packets stream: Payload traffic of the reference user will be mapped to the bearer by adding. RLC/MAC headers and extracted from the radio bearer by stripping the RLC/MAC header
  4. The PDCP/IP/UDP/RTP/AMR packets at interfaces A11 and B11 are given to the transmission buffer of the RLC protocol working in UM. The RLC may segment the given bits to make RLC SDUs, and add RLC headers (sequence number and length indicators). By assumption, one IP packet is placed into an RLC PDU that is filled with padding bits.
  5. To simplify the implementation and facilitate the typical continuous speech tests, the design of the simulation should target on steady state of the connection. This implies that we can disregard network re-synchronization (although the terminal may engage in packet resynchronization) and set-up during the simulation. Depending on the assumptions, issues of the packaging, the segmentation and re-assembly can also be ignored in case the AMR/AMR-WB frame fits into the RLC-SDU. The given time limit for the determination of the packet loss during the simulation comes from the delay budget planning, which simulates the implementation of the queuing buffers.
Payload exchanged at the interfaces are:
  * A21, B21: PDCP packet with ROHC received in sequence
  * A31, B31: IP packets delivered in sequence
  * A32, B32: IP packets received in sequence
  * A22, B22: PDCP packets with ROHC delivered in sequence
### L.5.6 Core Network
The network introduces time delay for the transmission. Payload exchanged at
the interfaces are:
  * A31, B31: IP packets received in sequence
  * A32, B32: IP packets delivered out of sequence
The IP packets are uniquely identified with a RLC PDU, when each AMR/AMR-WB
speech frame is conveyed by a single RLC PDU. This assumption will simplify
the implementation.
### L.5.7 VoIP Client
The current section discusses the actions of PDCP/AMR or PDCP/AMR-WB. The PDCP
entity is assumed to map to two RLC --UM entities, each used for one of the
two directions of the conversation, as shown in Figure L.5.3. The payload
exchanged at the interfaces are:
  * A11, B11: speech frames received in order
  * A21, B21: PDCP packets (RLC SDU) delivered in order
  * A22, B22: PDCP packets (RLC SDU) received in order
  * A12, B12: speech frames delivered in order within the given time limit
  * For the conversational tests, AMR will encode the speech at the designated rate in accordance with 26.101, to make the RTP/UDP/IP/PDCH payload. Following TS 26.236, the RTP payload format should follow the bandwidth efficient mode defined in RFC-3267, and one speech frame shall be encapsulated in each RTP packet. Header compression according to RFC 3095 and TS 25.323 will be simulated as part of the PDCP protocol. For the VoIP test we are only interested in the normal operation of the PDCP, not the session set-up signalling .
Lossless RLC PDU size change. This is equal to assume that the RAB remains the
same during the call. The assumption reduces the simulation complexity for the
RN simulator.
{width="5.88125in" height="4.2659722222222225in"}
Figure L.5.3: Protocol stacks in VoIP entity
Consistently, only two PDU Formats will be considered:
  * PDCP-No-Header PDU
  * PDCP Data PDU
A decision is to be made in conjunction with other parameters in this context.
The simulation of ROHC operation aims at the implementation of the state
machine,Figure L.5.4.
{width="5.756944444444445in" height="1.8805555555555555in"}
Figure L.5.4: State machine of the compressor operation.
Clearly, the transition depends on the lower layer quality. By QoS assured
delivery, the compressor can be maintained in SO state during the call
duration with the given probability. The simulation should assume steady state
in SO. We also assume the operation mode of ROHC to be R (Reliable). That
means it involves feedback. Assuming PDCP-No-Header PDU, the simulator
delivers/receives to/from the RN simulator the RLC PDU, which consists of
header and payload as following:
RLC SDU = ROHC feedback header + ROHC base header + ROHC extension header +
UDP checksum + AMR payload
By assuming steady state of R mode operation, the header will only contain 1
byte R-0, 2 bytes ACK and a 2 byte UDP checksum. For the simulation of
reference mobiles, there are two possibilities:
  * Allow state transition between FO and SO. This would require simulation of coupled up-link and down-link.
  * Disallow state transition between FO and SO. This is equivalent to assuming that the state transition is a rare event such that it does not occur during a typical call. Then, the feedback from the de-compressor would contain ACK only. Hence, the up link and the down link can be simulated independently.
To facilitate the simulation, the second option will be taken.
### L.5.8 Interfaces
The physical composition of the test system is depicted in Fig.1. It shows
that an end-to-end connection between A and B consists of the following chain
of entities:
  * Sound card (A)
  * VoIP (A)
  * RN(A) simulator
  * IP/Core simulator
  * RN(B) simulator
  * VoIP (B)
  * Sound card (B)
The figure, however, is not informative about the logical relation between the
protocols that are spread in all entities. Figure L,5,5 visualizes the logical
relations among the components. It helps to clarify the scope of each
component simulators.
{width="5.2625in" height="1.6097222222222223in"}
Figure L.5.5: Logical Relations between simulator entities and protocols.
Color code:
{width="4.886805555555555in" height="0.6354166666666666in"}
For the convenience of verification, it is of great advantage to implement the
system component-wise. Thus, the interfaces between the component simulators
have to be specified. The physical interfaces are instances of 3 logical
interfaces, respectively:
  * **Interface 1** ={A11,A12,B11,B12}: the interface between sound card and VoIP
  * **Interface 2** = {A21, A22, B21, B22}: the interface between VoIP and RN
  * **Interface 3** ={A31, A32, B31, B32} : the interface between IP/Core and RN
The interfaces determine the information to be exchanged between the adjacent
entities in the simulator and are specified in the following.
#### L.5.8.1 Interface 1
This interface exchanges information regarding operation of the protocol
stacks AMR/RTP/UDP/IP/PDCP/RLC and the operation of rate selection. One of the
issues is the coherence of the actions when off-line simulation method is
used. Since each entity is simulated independent of others and the output
files of the simulation are used in a later time, the consistency of the
channel conditions and the selection made by AMR at a given moment cannot be
warranted unless careful measure is taken.
One of the measures to maintain the coherence is to restrict the AMR/AMR-WB to
a pre-selected single data rate for each test. This approach is justified by
the fact that the enhanced uplink and downlink have already provided
sufficient control and adaptation mechanism at the lower layers, so that the
channel condition experienced by the interface 1 is sufficiently stable and
would hardly require rate switching. The original concept of AMR is targeted
at the balance between the individual voice quality and overall capacity. But
when we fix the number of the supported users in our simulation in order to
test the probe user's voice quality, the capacity-quality trade-off would not
occur for the simulated cases. Hence, the testing of individual coder from the
AMR/AMR-WB would be sufficiently informative about the VoIP performance for
the give simulation set-up.
#### L.5.8.2 Interface 2
The output file of the RN simulator at this interface consists of 3 columns of
the following entries for a stream of RLC PDUs:
Table L.5.2: Data format of interface 2
* * *
Sequence Number (int) Loss Indicator (binary) Accumulated Es/Nt after HARQ
(dB) Time Stamp (int) 0 1 .. 0TTI 1 1 .. 1TTI 2 0 .. 2TTI ... ... .. ...
* * *
#### L.5.8.3 Interface 3
The transportation of the IP packet depends on the nodes traversed by the
datagram within the IP/Core network. What really maters here is the delay and
loss of a packet due to routing. This requires the IP/Core, based on a given
topology [tbd] and traffic load [tbd], to generate a sequence of random events
at A31 and B31, respectively, reflecting the relative delay and the loss of
the packet fed into the network at A32 and B32, respectively. Alternatively,
the delay and loss can be generated by an appropriate analytical model [tbd].
The file generated by the IP/Core at the interfaces A32 and B32 shall have the
following format:
Table L.5.3: Data format of interface 3.
* * *
Sequence Number (int) Loss Indicator (binary) Time Stamp (int) 0 1 0TTI 1 1
1TTI 2 0 2TTI ... ... ...
* * *
### L.5.9 Simulated HSPA Air-Interface
#### L.5.9.1 General Description
For the down link, the over-the-air delay of a speech frame is defined as the
latency between the time a MAC-d PDU carrying a speech frame enters the MAC-hs
priority queue in the Node-B and the time the MAC-d PDU is delivered (after
reordering by the MAC-hs) to the UE. Similarly, for the up link, the over-the-
air delay of a speech frame is defined as the latency between the time a MAC-d
PDU carrying a speech frame enters the MAC-d of the Node-B.
The delay of the network is the time consumed by a packet, while staying
within the network. Therefore, it is counted as the time difference between
the entry and exit of the network.
The delay value for each connection is measured as the sum of the over-the-air
delay for the up link and down link plus the network delay and the processing
delay at both ends, when the value is within the delay budget.
A speech frame is declared to be lost if one of the following is true:
  * The MAC-d PDU is discarded at the Node-B transmitter due to expiration of the MAC-hs discard timer
  * The MAC-d PDU is transmitted but not successfully received post-HARQ
  * The MAC-d PDU is successfully received after a specified delay bound
The MAC-hs discard timer and the MAC-hs T1 timer should be set appropriately
for the given the over-the-air delay budget.
#### L.5.9.2 Error-Delay Profiles
**In [2], we received samples coming from different simulation platforms**
  * Platform 1: Data contained in R1-061028.zip
  * Platform 2: Data contained in R1-061070.zip
Although both are generated following the network layout and configuration of
[3], there are subtle differences beyond the schedulers and the trace lengths.
The samples from the platform 1 entail 16 samples for down link and 16 samples
for up link with paired channel conditions PedB_3km, PedB30km, VehA_30km and
VehA_120km. The location of the reference user is fixed for all simulations.
The samples from the platform 2 entail 22 samples, where 20 are for the down
link and two for the up link, representing a paired channel PedB_3km. The
difference between the 20 samples lies in the network load (number of users)
and the location of the reference user (geometry).
To capture the essential in regard of our subjective tests, the samples in the
two groups have the following 4 attributes in common:
Table L.5.4: File attributes of the available data
* * *
Attribute Name Details Number Link Direction Up-Link, Down-link 2 Network Load
40,45,60,80,100 5 Channel Model PedA-3km, PedB-3km, PedB30km, VehA-30km,
VehA-120 km. 5
* * *
Table L.5.5: Number of files and length of traces, grouped according to the
network load
* * *
Network Load Number of Samples Length without Repetition 40 4 4x60s 45 10
2x(215+155+95+55) ms 60 4 4x60s 80 4 4x60s 100 14
4x60s+2x(100+155+95+215+55)ms
* * *
The definition of the conditions follow the conventions given below:
_Network Condition_
**Table L.5.6: Definition of the radio network conditions**
+-------------------------+-------------+--------------+--------+ | Radio Network Condition | Low Traffic | High Traffic | Uplink | | | | | | | | Down Link | Down Link | | +-------------------------+-------------+--------------+--------+ | Low Mobility Mobile | LM.LT | LM.HT | Lm | +-------------------------+-------------+--------------+--------+ | High Mobility Mobile | HM.LT | HM.HT | Hm | +-------------------------+-------------+--------------+--------+
In specifics:
  * [Low]{.underline} Traffic (LT): 40, or 45, or 60 mobile users per cell
  * [High]{.underline} Traffic (HT): 80, or 100 mobile users per cell
  * [Low]{.underline} Mobility (LM, Lm): ITU --Channel-Model: PedB3_km or PedA3_km
  * [High]{.underline} Mobility (HM, Hm): ITU-Channel-Model: VehA30km or Veh120km or PedB30km
The uplinks are simulated as dedicated channel, hence the traffic conditions
apply only to the downlinks. From a mobile-to-mobile connection, the order of
the uplink and downlink plays no role. Therefore, we have the following 8
possible construction of channel conditions:
Table L.5.7: Notation for the mobile-to-mobile radio network conditions
* * *
Number Notation Meaning [1] Lm.LT.LM Lm + LT.LM [2] Lm.LT.HM Lm+LT.HM [3]
Lm.HT.LM Lm+HT.LM [4] Lm.HT.HM Lm+HT.HM [5] Hm.LT.LM Hm+LT.LM [6] Hm.LT.HM
Hm+LT.HM [7] Hm.HT.LM Hm+HT.LM [8] Hm.HT.HM Hm+HT.HM
* * *
_Combined Test Conditions_
Each test condition is assigned a unique number defined as following:
* * *
x-y.z.c X Y z c e.g. 1-1.3a AMR-Mode Network Load Experiment Swap subjects
* * *
The radio network conditions are identical for all the test cases with all
three codecs under test. Hence only the table for codec AMR5.9 is shown as
example in the following.
AMR-Mode 5.9 kbps (x=1): 8 conditions (y=1), 8 conditions (y=2)
+----------+----------+----------+----------+----------+----------+ | * | _Noise |_ Radio | _Noise |_ Desc | _C | | Cond.No_ | in Room | Network _| in Room | ription_ | omments _| | | A_ | | B _| | | | | |_ Co | | | | | | | ndition* | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.1 | Hoth | A->B: | Hoth | Lm.LT.LM | sym | | | | [1] | | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.2 | Car | A->B: | Car | Hm.LT.HM | sym | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.3a | Car | A->B: | Hoth | Hm.LT.LM | asym | | | | [5] | | | | | | | | | HM.LT.Lm | | | | | B->A: | | | | | | | [2] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.3b | Hoth | A->B: | Car | Lm.LT.HM | asym | | | | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.4 | C | A->B: | C | Lm.LT.LM | sym | | | afeteria | [1] | afeteria | | | | | | | | LM.LT.Lm | | | | | B->A: | | | | | | | [1] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.5a | C | A->B: | Street | Lm.LT.HM | asym | | | afeteria | [2] | | | | | | | | | LM.LT.Hm | | | | | B->A: | | | | | | | [5] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.5b | Street | A->B: | C | Hm.LT.LM | asym | | | | [5] | afeteria | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [2] | | | | +----------+----------+----------+----------+----------+----------+ | 1-1.6 | Street | A->B: | Street | Hm.LT.HM | sym | | | | [6] | | | | | | | | | HM.LT.Hm | | | | | B->A: | | | | | | | [6] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.1 | Hoth | A->B: | Hoth | Lm.HT.LM | sym | | | | [3] | | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.2 | Car | A->B: | Car | Hm.HT.HM | sym | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.3a | Car | A->B: | Hoth | Hm.HT.LM | asym | | | | [7] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [4] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.3b | Hoth | A->B: | Car | Lm.HT.HM | asym | | | | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.4 | C | A->B: | C | Lm.HT.LM | sym | | | afeteria | [3] | afeteria | | | | | | | | LM.HT.Lm | | | | | B->A: | | | | | | | [3] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.5a | C | A->B: | Street | Lm.HT.HM | asym | | | afeteria | [4] | | | | | | | | | LM.HT.Hm | | | | | B->A: | | | | | | | [7] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.5b | Street | A->B: | C | Hm.HT.LM | asym | | | | [7] | afeteria | | | | | | | | HM.HT.Lm | | | | | B->A: | | | | | | | [4] | | | | +----------+----------+----------+----------+----------+----------+ | 1-2.6 | Street | A->B: | Street | Hm.HT.HM | sym | | | | [8] | | | | | | | | | HM.HT.Hm | | | | | B->A: | | | | | | | [8] | | | | +----------+----------+----------+----------+----------+----------+
For the designated tests comprise the following components:
  * a VoIMS sender comprising of input capture (e.g. microphone), AMR encoder, RTP packetization and IP stack, operating in real time; and
  * a VoIMS receiver comprising of IP stack, RTP de-packetization, AMR decoder with appropriate jitter handling and an output devise (e.g. headphone), operating in real tim
  * error-delay profiles (including error mask and time of delivery in milliseconds) are generated using offline system simulations by RAN1. The data files, sorted according to the radio network conditions, are grouped into sets that represent the final test conditions. The data files belong to the same set are concatenated so that a longer trace is made. Up link and down link traces are combined, with addition of a fixed delay value, to simulate delay and error trace of the mobile-to-mobile connection, and
  * use the above error-delay profiles to inject delays and packet losses in the VoIMS traffic in an error insertion devise running in real time.
Design and arrangement of the tests are detailed in the test plan.
#### L.5.A.1 Network Parameters
+----------------------------------+----------------------------------+ | **Parameter** | | +----------------------------------+----------------------------------+ | UMTS BS Nominal TX Power [dBm] | 43 | +----------------------------------+----------------------------------+ | P-CPICH Tx Power [dBm] | 33 | +----------------------------------+----------------------------------+ | UMTS BS Overhead TX Power | 34 | | [dBm] including paging, sync | | | and P/S-CCPCH | | +----------------------------------+----------------------------------+ | UMTS UE TX Power Class [dBm] | 21 | +----------------------------------+----------------------------------+ | UMTS UE Noise Figure [dB] | 10 | +----------------------------------+----------------------------------+ | BS Antenna Gain [dBi] | 17.1 | +----------------------------------+----------------------------------+ | MS Antenna Gain [dBi] | 0 | +----------------------------------+----------------------------------+ | Shadowing Standard Deviation | 8 | | [dB] | | +----------------------------------+----------------------------------+ | Path Loss Model: COST 231 | -136+35.22*log10(d), d in km | +----------------------------------+----------------------------------+ | Shadow Site to site Correlation | 50% | +----------------------------------+----------------------------------+ | Other Losses [dB] | 8 | +----------------------------------+----------------------------------+ | UMTS BS Antenna | per TR 25.896 v6.0.0 A.3.1.1 | | | | | pattern | 65 | | | | | beamwidth [degrees] | | +----------------------------------+----------------------------------+ | Propagation Channel Mixture for | 25% AWGN | | loading users | | | | 37% PedA 3 kph | | | | | | 13% PedA 30 kph | | | | | | 13% VehA 30 kph | | | | | | 12% VehA 120 kph | +----------------------------------+----------------------------------+ | Propagation Channel for the | Case 1: PedA 3 kph | | Reference UE | | | | Case 2: VehA 30 kph | | | | | | Case 3: VehA 120 kph | +----------------------------------+----------------------------------+ | Ec/Io Admission Threshold | -18 dB | +----------------------------------+----------------------------------+ | RSCP Admission Threshold | -115 dBm | +----------------------------------+----------------------------------+ | Number of Node Bs | 19 Node Bs/57 cells | +----------------------------------+----------------------------------+ | Locations of the Reference UE | Geometrical centre of each | | | sectored cell | +----------------------------------+----------------------------------+ | Cell layout | 3-Cell Clover-Leaf | +----------------------------------+----------------------------------+ | Inter-site Distance [m] | 2500 | +----------------------------------+----------------------------------+ | Frequency | 1990 MHz | +----------------------------------+----------------------------------+ | | | +----------------------------------+----------------------------------+ | | | +----------------------------------+----------------------------------+
#### L.5.A.2 Traffic Assumptions (example: AMR 7.95)
+----------------------------------+----------------------------------+ | **Parameter** | | +----------------------------------+----------------------------------+ | User-Plane Traffic Model | 100% VoIP | | | | | Vocoder Type | AMR 7.95 | | | | | Vocoder Voice Model | Markov Process with 50% activity | | | (transition probability = 0.01) | +----------------------------------+----------------------------------+ | Overhead : RTP payload (AMR | 4 bits CMR | | bandwidth efficient mode) | | | | 6 bits TOC per aggregated speech | | | frame | | | | | | 7 bits padding for octet | | | alignment | | | | | | (assuming no aggregation) | +----------------------------------+----------------------------------+ | Overhead: RTP/UDP/IPv6 | 60 bytes | | uncompressed header | | +----------------------------------+----------------------------------+ | Overhead: RLC-UM | 2 bytes | +----------------------------------+----------------------------------+ | ROHC | 1 byte R-0, | | | | | | 2 bytes UDP checksum (will be | | | zero bytes with UDP-Lite) | +----------------------------------+----------------------------------+ | ROHC | Resynchronization ignored | +----------------------------------+----------------------------------+ | RTCP | Not modeled | +----------------------------------+----------------------------------+ | SIP | Not modeled | +----------------------------------+----------------------------------+ | SID Frames | Not transmitted | +----------------------------------+----------------------------------+ | Effective Data Rate with no RTP | 10.8 kbps | | layer aggregation | | +----------------------------------+----------------------------------+ | MAC-d PDU Size[^9] | 216 bits (one speech frame per | | | MAC-d PDU) | +----------------------------------+----------------------------------+
#### L.5.A.3 Other Assumptions
+----------------------------------+----------------------------------+ | **Parameter** | | +----------------------------------+----------------------------------+ | UMTS Time Modelled [s] | 180 | +----------------------------------+----------------------------------+ | Number of Simulation Runs | 9 | +----------------------------------+----------------------------------+ | UE Category | 5 | +----------------------------------+----------------------------------+ | Receiver Type | Rake[^11] with Mobile Receive | | | Diversity from 2 Antennas | | | | | | (2 Rx correlation = 0.5, | | | mismatch 2 dB) | +----------------------------------+----------------------------------+ | Associated DPCH Data Rate | 3.4 kbps, SF 256 | +----------------------------------+----------------------------------+ | Associated DPCH Activity Factor | 5% | +----------------------------------+----------------------------------+ | HS-SCCH Channel Model | Depends on loading | | | | | Number | Yes | | | | | Errors Impact HS-DSCH Decoding | Fixed Offset | | | | | Power Allocation | | +----------------------------------+----------------------------------+ | HSDPA Scheduler Implementation | | +----------------------------------+----------------------------------+ | Mobility Model | Static location for UE | +----------------------------------+----------------------------------+ | Downlink Over-the air Delay | 90 | | Budget [ms] | | +----------------------------------+----------------------------------+ | E-DCH Scheduling | Non-scheduled transmission | +----------------------------------+----------------------------------+ | E-DCH TTI length | Both 10ms and 2ms TTI | +----------------------------------+----------------------------------+ | E-DCH max number of HARQ | 2 Tx for 10ms TTI | | transmissions | | | | 6 Tx for 2ms TTI | +----------------------------------+----------------------------------+
#### L.5.A.4 Simulation Methodology
The system simulation is dynamic and includes explicit modelling of fast
fading, power control, CQI generation, scheduling of users, etc. Channels that
connect different transmit/receive antenna pairs are generated at the UMTS
slot rate (1500Hz). The instantaneous SINR seen at each receiver is computed
at the slot rate. Virtual decoders map a sequence of slot rate SINRs to block
error events at the TTI rate for each physical channel. The virtual decoders
must generate the same statistical block error events as the true decoders
operating on a bit by bit basis in a link level simulation for the same TTI
rate for each physical channel under consideration.
Inner and outer loop power control loops are explicitly modelled for the
associated DPCH. The OVSF code and transmit power resources consumed by the
associated DPCH and HS-SCCH channels are modelled dynamically. Errors made in
HS-SCCH decoding are taken into account in determining whether the
corresponding HS-DSCH transmission is decoded correctly.
The system simulation attempts to model sufficiently the MAC-d PDU flow and
performance from the NodeB to the UE. Thus, the system simulation is
considered an "over-the-air" model and does not capture impairments beyond the
NodeB to UE subsystem
# Bibliography
[1] 3GPP TS 25.322 "RLC Protocol"
[2] 3GPP TS 34.108 "Common test environments for User Equipment (UE)
conformance testing"
[3] 3GPP TR 25.931 "UTRAN functions, examples on signaling procedures"
[4] 3GPP TS 26.236 "Performance characterization of the Enhanced aacPlus and
Extended Adaptive Multi-Rate - Wideband (AMR-WB+) audio codecs"
[5] 3GPP TS 25.323 "Packet Data Convergence Protocol"
[6] 3GPP TS 25.331 "Radio Resource Control Protocol"
[7] 3GPP TR 25.933 "IP transport in UTRAN"
[8] 3GPP TR 25.896 "Feasibility Study for the Enhanced Uplink for UTRA FDD"
[9] IETF RFC 3095
[10] IETF RFC 3267
[11] 3GPP TR 25.932 "Delay budget within the access stratum"
[12] 3GPP TS 22.105 v3.6.0 "Service and Capability"
#