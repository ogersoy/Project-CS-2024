# Foreword
This Technical Specification has been produced by the 3^rd^ Generation
Partnership Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
The present document defines a frame loss concealment procedure, also termed
frame substitution and muting procedure, which is executed by the Enhanced
Voice Services (EVS) decoder when one or more frames (speech or audio or SID
frames) are unavailable for decoding due to e.g. packet loss, corruption of a
packet or late arrival of a packet.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TS 26.441: \"Codec for Enhanced Voice Services (EVS); General
Overview\".
[3] 3GPP TS 26.442: \"Codec for Enhanced Voice Services (EVS); ANSI C code
(fixed-point)\".
[4] 3GPP TS 26.444: \"Codec for Enhanced Voice Services (EVS); Test
Sequences\".
[5] 3GPP TS 26.445: \"Codec for Enhanced Voice Services (EVS); Detailed
Algorithmic Description\".
[6] 3GPP TS 26.446: \"Codec for Enhanced Voice Services (EVS); AMR-WB Backward
Compatible Functions\".
[7] R. Martin, Noise Power Spectral Density Estimation Based on Optimal
Smoothing and Minimum Statistics, 2001
[8] 3GPP TS 26.443: \"Codec for Enhanced Voice Services (EVS); ANSI C code
(floating-point)\"
[9] 3GPP TS 26.452: \"Codec for Enhanced Voice Services (EVS); ANSI C code;
Alternative fixed-point using updated basic operators\".
# 3 Definitions, symbols and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
TR 21.905 [1] and the following apply. A term defined in the present document
takes precedence over the definition of the same term, if any, in TR 21.905
[1].
Further EVS codec specific definitions are found in clause 3.1 of [5].
## 3.2 Symbols
For the purposes of the present document, the following symbols apply:
EVS codec specific symbol definitions may be found in clause 3.2 of [5].
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in TR 21.905
[1] and the following apply. An abbreviation defined in the present document
takes precedence over the definition of the same abbreviation, if any, in TR
21.905 [1].
AMR Adaptive Multi Rate (codec)
AMR-NB Adaptive Multi Rate Narrowband (codec) = AMR
AMR-WB Adaptive Multi Rate Wideband (codec)
EFR Enhanced Full Rate (codec)
EVS Enhanced Voice Services
FB Fullband
FR (GSM) Full Rate (codec)
HR (GSM) Half Rate (codec)
JBM Jitter Buffer Management
MTSI Multimedia Telephony Service for IMS
NB Narrowband
PLC Packet Loss Concealment
PS Packet Switched
PSTN Public Switched Telephone Network
SWB Super Wideband
WB Wideband
Further EVS codec specific abbreviations may be found in clause 3.3 of [5].
# 4 General
The purpose of the frame loss concealment procedure is to conceal the effect
of any unavailable EVS frame (speech or audio or SID) for decoding. The
concealment of erased frames covers both the reconstruction of missing frames
and the techniques to ensure smooth and rapid recovery of normal synthesis
after erased segments. The frame loss concealment procedure also covers proper
strategies including muting or fading to background noise for the case of
multiple frame losses in a row. The purpose of muting the output or fading to
background noise in the case of several lost frames in a row is to indicate
the breakdown of the channel to the user and to avoid generating possible
annoying sounds as a result from the frame loss concealment procedure.
Unless stated differently, fading operations (described in subclause 5.3.4 and
subclause 5.4.6) start already with the first lost frame.
Given the architecture and features of the EVS codec (details in [EVS Codec
Detailed Algorithmic Description]) the frame loss concealment procedure
comprises concealment methods for the various major codec modules, such as
signal classification, spectral envelope (LPC), ACELP, MDCT and Bandwidth
Extension. A particular feature of the EVS codec is \'guided\' frame loss
concealment for which the encoder provides specific supplementary data guiding
the concealment during erased frames and enhancing the convergence and
recovery of the decoder after erased frames. The description in this
specification is limited on how to apply the \'guided\' frame loss concealment
data; the corresponding encoding operations are described as part of the EVS
codec algorithmic description [5].
The procedure of the present document is mandatory for implementation in all
network entities and User Equipment (UE)s supporting the EVS decoder.
The present document does not describe the ANSI C code of this procedure. For
a description of the two reference fixed-point ANSI C code implementations,
using different sets of basic operators, see [3] and [9] respectively; for a
description of the reference floating-point ANSI C code implementation see
[8].
In the case of discrepancy between the procedure described in the present
document and its ANSI-C code specifications contained in [3] the procedure
defined by [3] prevails. In the case of discrepancy between the procedure
described in the present document and its ANSI-C code specifications contained
in [8] the procedure defined by [8] prevails. In the case of discrepancy
between the procedure described in the present document and its ANSI-C code
specifications contained in [9] the procedure defined by [9] prevails.
# 5 Detailed description
## 5.1 Concealment operation related to signal classification
### 5.1.1 Overview
Many concealment methods are based on signal classification. The frame class
is either transmitted and decoded from the bit stream, or estimated in the
decoder. This estimation process is specified subsequently in subclause 5.1.2;
it is performed in the following during normal decoding, if the decoded frame
is ACELP or MDCT based TCX. In the case of mode or rate switching, the buffer
storing the signal history is resampled appropriately.
### 5.1.2 Signal class estimation
If possible, the class is directly derived from the coding mode in case of UC
or VC modes, i.e. the class is UNVOICED_CLAS in case of UC frame and
VOICED_CLAS in case of VC frame. Otherwise, it is estimated at the decoder as
follows.
The frame classification at the decoder is based on the following parameters:
zero-crossing parameter, {width="0.25in" height="0.2361111111111111in"},
pitch-synchronous normalized correlation, {width="0.20833333333333334in"
height="0.20833333333333334in"}, pitch coherence parameter, {width="0.19375in"
height="0.20833333333333334in"}, spectral tilt, {width="0.1527777777777778in"
height="0.19375in"}, and pitch synchronous relative energy at the end of the
frame, {width="0.2916666666666667in" height="0.20833333333333334in"}.
The zero-crossing parameter, {width="0.25in" height="0.2361111111111111in"},
is averaged over the whole frame. That is,
{width="1.0555555555555556in" height="0.5416666666666666in"} (1)
where {width="0.19375in" height="0.20833333333333334in"}is the number of times
the signal sign of the synthesized signal, {width="0.4722222222222222in"
height="0.2777777777777778in"}, changes from positive to negative during
subframe i. The number of subframes {width="0.2916666666666667in"
height="0.2222222222222222in"} depends of the internal sampling frequency
which could be 12.8 kHz or 16 kHz. In case of 12.8kHz the number of subframes
is 4 otherwise the number of subframes is 5. In case the internal sampling
frequency is 16 kHz, {width="0.19375in" height="0.20833333333333334in"}is
multiplied by 0.8.
The pitch synchronous normalized correlation is computed based on a pitch lag,
T0, where T0 is the integer part of the pitch lag of the last subframe, or the
average of the pitch lag of the last two subframe if it is larger than
{width="0.5416666666666666in" height="0.2222222222222222in"}, where
{width="0.3055555555555556in" height="0.2222222222222222in"} = 64 is the
subframe size. That is
{width="2.8194444444444446in" height="0.5965277777777778in"} (2)
where {width="0.24513888888888888in" height="0.27708333333333335in"} is the
fractional pitch lag at subframe i.
The pitch synchronous normalized correlation computed at the end of the frame
is given by
{width="3.486111111111111in" height="0.4861111111111111in"} (3)
where
{width="3.8333333333333335in" height="1.1388888888888888in"} (4)
where L is the frame size and {width="0.4722222222222222in"
height="0.2777777777777778in"} is the synthesized speech signal.
The pitch coherence parameter is compute only in the case that the actual
frame is not in TCX MDCT mode. The pitch coherence is given by
{width="1.6111111111111112in" height="0.3194444444444444in"} (5)
where {width="0.24513888888888888in" height="0.27708333333333335in"} is the
fractional pitch lag at subframe i. In case the internal sampling frequency is
16 kHz, {width="0.19375in" height="0.20833333333333334in"}is multiplied by
0.8.
The spectral tilt parameter, {width="0.1527777777777778in"
height="0.19375in"}, is estimated based on the last 3 subframes and given by
{width="1.6111111111111112in" height="1.0965277777777778in"} (6)
The pitch synchronous relative energy at the end of the frame is given by
{width="0.9027777777777778in" height="0.2222222222222222in"} (7)
where
{width="2.013888888888889in" height="0.5416666666666666in"} (8)
and {width="0.2222222222222222in" height="0.2222222222222222in"} is the long-
term energy. {width="0.2222222222222222in" height="0.2222222222222222in"} is
updated only when a current frame is classified as VOICED_CLAS and is of
interoperable coding mode or isn\'t of generic or transition coding mode, and
is classified as VOICED_CLAS at the same time, using the relation
{width="1.3194444444444444in" height="0.2222222222222222in"} (9)
{width="0.9305555555555556in" height="0.2222222222222222in"} (10)
The pitch lag value, T\', over which the energy, {width="0.2222222222222222in"
height="0.2222222222222222in"}, is computed is given by
{width="2.94375in" height="0.7638888888888888in"}
{width="0.9305555555555556in" height="0.2222222222222222in"} (11)
To make the classification more robust, the classification parameters are
considered together forming a function of merit, {width="0.2076388888888889in"
height="0.24583333333333332in"}. For that purpose, the classification
parameters are first scaled so that each parameter\'s typical value for
unvoiced signal translates in 0 and each parameter\'s typical value for voiced
signal translates into 1. A linear function is used between them. The scaled
version, {width="0.19236111111111112in" height="0.24583333333333332in"}, of a
certain parameter, {width="0.2076388888888889in"
height="0.20555555555555555in"}, is obtained using
{width="0.9305555555555556in" height="0.2777777777777778in"} (12)
{width="0.9305555555555556in" height="0.2222222222222222in"} (13)
and in case of pc the scaled parameter is constrained
by{width="0.6666666666666666in" height="0.25416666666666665in"}.
The function coefficients, {width="0.19236111111111112in"
height="0.23194444444444445in"}, and {width="0.22152777777777777in"
height="0.23194444444444445in"}, have been found experimentally for each of
the parameters so that the signal distortion due to the concealment and
recovery techniques used in the presence of frame erasures is minimal. The
values used are summarized in Table 1 below.
Table 1: Signal classification parameters at the decoder
* * *
Parameter Meaning Kp cp {width="0.2222222222222222in"
height="0.20833333333333334in"} Normalized correlation 0.8547 0.2479
{width="0.1527777777777778in" height="0.19375in"} Spectral tilt 0.8333 0.2917
{width="0.19375in" height="0.20833333333333334in"} Pitch coherence --0.0357
1.6071 {width="0.2916666666666667in" height="0.20833333333333334in"} Relative
frame energy 0.04 0.56 {width="0.25in" height="0.2361111111111111in"} Zero-
crossing counter --0.04 2.52
* * *
The merit function has been defined as
{width="2.138888888888889in" height="0.3611111111111111in"} (14)
where the superscript s indicates the scaled version of the parameters. In the
case of 8-kHz sampled output and a decoded bit rate of 9.6kbps, the merit
function, f, is further multiplied by 0.9.
In the case that the actual frame is not in TCX MDCT mode, the pitch coherence
is not compute therefore the merit function has been defined as
{width="1.7916666666666667in" height="0.3611111111111111in"} (15)
{width="0.9305555555555556in" height="0.2222222222222222in"} (16)
The classification is performed using the merit function,
{width="0.2222222222222222in" height="0.25in"}, and following the rules
summarized in Table 2. The default class is UNVOICED_CLAS. Note that the class
ARTIFICIAL ONSET is set at the decoder if the frame follows an erased frame
and artificial onset reconstruction is used as described in subclause
5.3.3.4.2.
Table 2: Signal classification rules at the decoder
+----------------------+----------------------+---------------------+ | Previous frame class | Rule | Current frame class | +----------------------+----------------------+---------------------+ | ONSET | {width="0 | | | ARTIFICIAL ONSET | .5965277777777778in" | | | | height="0.25in"} | | | VOICED_CLAS | | | | | | | | VOICED TRANSITION | | | +----------------------+----------------------+---------------------+ | | {width="0 | | | | .9861111111111112in" | | | | height="0.25in"} | | +----------------------+----------------------+---------------------+ | | {width="0 | | | | .6111111111111112in" | | | | height="0.25in"} | | +----------------------+----------------------+---------------------+ | UNVOICED TRANSITION | {width="0 | | | UNVOICED_CLAS | .6111111111111112in" | | | | height="0.25in"} | | | INACTIVE_CLAS | | | +----------------------+----------------------+---------------------+ | | {width="0 | | | | .9861111111111112in" | | | | height="0.25in"} | | +----------------------+----------------------+---------------------+ | | {width="0 | | | | .5965277777777778in" | | | | height="0.25in"} | | +----------------------+----------------------+---------------------+
## 5.2 Concealment operation related to spectral envelope (LPC) representation
When the LSF parameters of the first good frame are not available, the LSF
parameters of the concealed frame are extrapolated using the last LSF
parameters. The general idea is to fade the last LSF parameters towards an
adaptive LSF mean vector. First, an average LSF vector is calculated from the
last 3 known LSF vectors as
{width="1.5833333333333333in" height="0.4305555555555556in"} (17)
Then, the adaptive mean LSF vector is calculated by
{width="1.6666666666666667in" height="0.2638888888888889in"} (18)
Then the LSF vector used for concealing the lost frame is computed
{width="1.5555555555555556in" height="0.25in"} (19)
where {width="0.4027777777777778in" height="0.25in"} is the mean LSF vector
defined according to Table 3.
Table 3: Values of LSF mean vector {width="0.4027777777777778in"
height="0.25in"}
+----------------------------------+----------------------------------+ | LPC Quantization == 0 | {width="0.4027777777777778in" | | AVQ | height="0.25in"}= | +----------------------------------+----------------------------------+ | {width="4.5in" | | height="0.20833333333333334in"} | height="0.4027777777777778in"} | +----------------------------------+----------------------------------+ | {width="4.291666666666667in" | | height="0.20833333333333334in"} | height="0.4027777777777778in"} | +----------------------------------+----------------------------------+ | {width="4.125in" | | height="0.20833333333333334in"} | height="0.4027777777777778in"} | +----------------------------------+----------------------------------+ | LPC Quantization == 1 | {width="0.4166666666666667in" | | ACELP | height="0.25in"}= | +----------------------------------+----------------------------------+ | {width="4.125in" | | height="0.20833333333333334in"} | height="0.4027777777777778in"} | +----------------------------------+----------------------------------+ | {width="4.2243055555555555in" | | height="0.20833333333333334in"} | height="0.41597222222222224in"} | +----------------------------------+----------------------------------+ | {width="4.125in" | | height="0.20833333333333334in"} | height="0.4027777777777778in"} | +----------------------------------+----------------------------------+
Furthermore, {width="0.1527777777777778in" height="0.19375in"}is defined
according to Table 4.
Table 4: Values of LSF interpolation factor {width="0.1527777777777778in"
height="0.19375in"}
* * *
Bitrates: 5.9, 6.8, 8.0, 13.2, 32 and 64 kbps 9.6, 16.4, 24.4, 48, 96 and 128
kbps plcBackgroundNoiseUpdated == 1 {width="0.5277777777777778in"
height="0.19375in"} {width="0.3611111111111111in" height="0.19375in"}
plcBackgroundNoiseUpdated == 0 {width="0.5277777777777778in"
height="0.19375in"} {width="0.5277777777777778in" height="0.19375in"}
* * *
{width="0.1527777777777778in" height="0.1388888888888889in"}depends on the
previous coder type and the signal class of the last good frame for the first
3 lost frames. It is determined according to Table5.
Table 5: Values of LSF interpolation factor {width="0.1527777777777778in"
height="0.1388888888888889in"}
+---------------------+----------------------+----------------------+ | Last good received\ | Additional criteria | _α_ | | frame (coder_type) | | | +---------------------+----------------------+----------------------+ | UNVOICED | | 1 | +---------------------+----------------------+----------------------+ | INACTIVE or | Last\ | 0.8 | | | _GSC_pit_band_idx | | | AUDIO | > 0 and nbLostCmpt | | | | > 1 | | +---------------------+----------------------+----------------------+ | | else | 0.995 | +---------------------+----------------------+----------------------+ | UNVOICED_CLAS | Successively lost | {width="0 | | | | .6666666666666666in" | | | | height="0.1 | | | | 6666666666666666in"} | +---------------------+----------------------+----------------------+ | | Successively lost | 0.6 | | | frames = 2 | | +---------------------+----------------------+----------------------+ | | Successively lost | 0.4 | | | frames = 3 | | +---------------------+----------------------+----------------------+ | UNVOICED TRANSITION | | 0.8 | +---------------------+----------------------+----------------------+ | VOICED_CLAS | | 1 | +---------------------+----------------------+----------------------+ | ONSET | | 1 | +---------------------+----------------------+----------------------+ | ARTIFICIAL ONSET | | 0.6 | +---------------------+----------------------+----------------------+ | All other cases | | 0.4 | +---------------------+----------------------+----------------------+
Starting from the 4^th^ consecutive lost frame{width="0.6666666666666666in"
height="0.4027777777777778in"}.
The estimated LSF vector of the concealed frame {width="0.2777777777777778in"
height="0.25in"} is converted to LSP representation and interpolated. The
interpolation procedure corresponds to the procedure described in subclause
5.1.9.6 of [5]. The interpolation procedure calculates four or five LSP
vectors, each for a given subframe of the concealed frame. The interpolation
is done between the LSP vector of the last subframe of the last frame (the one
before the concealed frame)and the LSP vector derived from {width="0.28125in"
height="0.25in"} during concealment, as described above.
### 5.2.1 Specifics to rates 9.6, 16.4 and 24.4kbps
Additionally to estimating the LSF vector {width="0.2777777777777778in"
height="0.25in"}there is another LSF vector {width="0.3055555555555556in"
height="0.2777777777777778in"} computed
{width="1.7083333333333333in" height="0.2777777777777778in"} (20)
where
{width="0.3055555555555556in" height="0.2777777777777778in"} is an estimated
LSF vector used in ACELP concealment,
{width="0.2916666666666667in" height="0.2361111111111111in"} is the LSF
representation of the CNG noise estimation on decoder side (see clause 4.3 in
[5]).
### 5.2.2 Specifics to AMR-WB IO mode
The same procedure is performed, but instead of LSFs, ISFs are used for the
estimation. The mean LSF vector used for interpolation is
{width="5.041666666666667in" height="0.6527777777777778in"}
### 5.2.3 Check for Mid LSF stability
The interpolation of the mid-LSF can create unstable LSFs under packet erasure
conditions. Let the {width="0.1388888888888889in" height="0.19375in"}th sub-
frame LSFs are given by{width="1.0in" height="0.2361111111111111in"}. _We
denote the last sub-frame LSF of_ {width="0.1388888888888889in"
height="0.1527777777777778in"}_th frame as_ {width="0.19375in"
height="0.2638888888888889in"} _where_ {width="0.5277777777777778in"
height="0.2638888888888889in"}_. Let us denote the_
{width="9.652777777777778e-2in" height="0.18055555555555555in"}th _LSF
dimension of the_ {width="0.1388888888888889in" height="0.19375in"}th _sub-
frame of frame n as_ {width="0.25in" height="0.2777777777777778in"}
_where_{width="0.7430555555555556in" height="0.19305555555555556in"}_._
_The end-LSF quantizer quantizes_{width="0.19375in"
height="0.2638888888888889in"}_. Then mid-LSF quantizer interpolates the mid-
LSFs as follows._
{width="2.013888888888889in" height="0.2777777777777778in"} (21)
_where i-th dimension of the weighting vector_ {width="0.20833333333333334in"
height="0.20833333333333334in"} _is given by_ {width="0.2638888888888889in"
height="0.2222222222222222in"}_. The vector elements_
{width="0.2604166666666667in" height="0.21805555555555556in"} _are not
constrained. In particular if_ {width="0.625in"
height="0.20833333333333334in"} _interpolation generates a mid-LSF_
{width="0.23958333333333334in" height="0.25in"}_between_
{width="0.3333333333333333in" height="0.25in"}
_and_{width="0.23958333333333334in" height="0.25in"}_. However if_
{width="0.4888888888888889in" height="0.21805555555555556in"}_or_
{width="0.4888888888888889in" height="0.21805555555555556in"}_interpolation
might generate a mid-LSF_ {width="0.23958333333333334in" height="0.25in"}
_outside_{width="0.7083333333333334in" height="0.28125in"}_._ This could
potentially create LSF clustering that result in an unstable LSF synthesis
filter. To remedy this situation, a potential instability is detected as
described below.
In the frame that follows the packet loss, the decoder checks whether the
computed mid-LSFs are ordered correctly i.e. {width="2.2777777777777777in"
height="0.25in"}. If violation of this rule is detected the LSFs are
considered as potentially unstable. If potential LSF instability is detected,
decoder uses a fixed weighting value {width="0.3611111111111111in"
height="0.25in"} (typically 0.6) for mid LSF interpolation as follows.
{width="2.19375in" height="0.2777777777777778in"} (22)
The mid LSF interpolation based on equation (22) is continued until frame
{width="0.3194444444444444in" height="0.18055555555555555in"} such that the
frame {width="0.3194444444444444in" height="0.18055555555555555in"} is the
first frame after frame {width="0.125in" height="0.1388888888888889in"} that
uses safety net quantization for quantizing its end LSF.
### 5.2.4 Adaptive interpolation of LSFs
_The sub-frame LSFs are interpolated based on_{width="0.34652777777777777in"
height="0.2777777777777778in"}_,_ {width="0.25in"
height="0.2777777777777778in"} _and_ {width="0.25in"
height="0.2777777777777778in"} _using fixed interpolation factors given by_
> {width="2.9027777777777777in" height="0.2777777777777778in"} (23)
where {width="0.25in" height="0.2777777777777778in"} and {width="0.25in"
height="0.2777777777777778in"} correspond to the mid and end LSFs of frame n
respectively. Note that {width="0.20833333333333334in"
height="0.2361111111111111in"}and {width="0.20833333333333334in"
height="0.2361111111111111in"}such that{width="0.94375in"
height="0.2361111111111111in"}, and those are fixed values known to both
encoder and decoder. If the frame {width="0.3888888888888889in"
height="0.20833333333333334in"} is lost its end LSFs are estimated by the
decoder. However the dependence on the estimated end LSFs of the
{width="0.3888888888888889in" height="0.20833333333333334in"}th frame may
adversely affect the speech quality if the estimated end LSFs are not well
represent the actual one. This issue is addressed by selecting the
interpolation factors {width="0.20833333333333334in"
height="0.2361111111111111in"} and {width="0.20833333333333334in"
height="0.2361111111111111in"} appropriately by giving more weight to the end
LSF of frame {width="0.1388888888888889in" height="0.1527777777777778in"}
which is not lost.
_To adaptively select the LSF interpolation factors, we estimate the gain of
the synthesis filter resulting from the LSF vectors_
{width="0.3333333333333333in" height="0.25in"}_and_
{width="0.2361111111111111in" height="0.25in"}_by computing the energy of the
impulse response of the corresponding synthesis filters. Let the impulse
responses of the synthesis filters corresponding to_
{width="0.3333333333333333in" height="0.25in"}_and_
{width="0.2361111111111111in" height="0.25in"}_are given by_
{width="0.4583333333333333in" height="0.20833333333333334in"}_and_
{width="0.375in" height="0.20833333333333334in"}_. The truncated energy of the
impulse responses are given by_ {width="0.2916666666666667in"
height="0.20833333333333334in"} _and_ {width="0.20833333333333334in"
height="0.20833333333333334in"} _where_
{width="1.0138888888888888in" height="0.3194444444444444in"} (24)
Note that N is the length of the truncated response. Typically 128 samples are
used to compute the truncated impulse response. The interpolation
factors{width="0.20833333333333334in" height="0.2361111111111111in"}and
{width="0.20833333333333334in" height="0.2361111111111111in"}are picked based
on the energy ratio{width="0.8611111111111112in" height="0.25in"}, coder type,
FEC classification and the use of safety net quantization for LSF
quantization.
_These interpolation factors are picked from four different sets of
interpolation factors. For example a largest difference in_
{width="0.2222222222222222in" height="0.25in"}_should pick the interpolation
factors that give the very little or zero weight to the previous end LSF in
the interpolation_.
{width="6.695138888888889in" height="3.675in"}Figure 1: **Adaptive
interpolation of LSFs**
### 5.2.5 LPC gain compensation
At 9.6, 16.4, 24.4, 48, 96 and 128 kbps, the LPC concealment and interpolation
will lead to a change of overall gain of the signal, which is unwanted when
targeting a certain background noise level during consecutive frame loss.
Therefore the energy of the LPC is measured and stored during decoding of
regular frames. In a concealment frame the energy of the concealed LPC is
measured and compared to the LPC energy of the last correctly received frame
and any change is compensated.
To measure the LPC energy, a vector of length 64 is generated and initialized
to all zero. Then the first entry is set to one:
{width="1.9722222222222223in" height="0.2361111111111111in"} (25)
{width="0.5in" height="0.2361111111111111in"}is fed into the LPC synthesis
filter, where the filter memory is initialized with zeros. The output of the
filter (impulse response) is denoted as {width="0.46875in"
height="0.20833333333333334in"}. After filtering, the root mean square energy
is calculated by:
$\text{energ}_{\text{LPC}} = \sqrt{\sum_{i = 0}^{\text{63}}\left(
\text{imp}_{\text{LPC}}\left( i \right) \right)^{2}}$ (26)
In correctly received frames the energy is calculated and stored using the
latest LPC available.
In case of concealment the compensation differs for ACELP and TCX:
For ACELP there will be 4 or 5 sets of LPC coefficients, depending on the
number of subframes to be synthesized. For each set of coefficients the
corresponding energy is calculated and divided by the energy derived in the
last good frame. The result of the division is used as a factor to be
multiplied to each element of the excitation vector of the corresponding
subframe. See sub-clause 5.3.4.2.1.
For TCX, there will be one or two sets of coefficients (TCX10/TCX20). For each
set of coefficients the corresponding energy is calculated and divided by the
energy derived in the previous segment. The segment size equals 10 ms for
TCX10 and 20 ms for TCX20. As the fade out is performed in the time domain,
the LPC gain compensation is also done in the time domain, by linearly fading
from the last compensation factor (would be 1 for the first lost frame) to the
derived compensation factor at the end of the segment. See sub-clause
5.4.6.1.3.
## 5.3 Concealment operation related to ACELP modes
### 5.3.1 General
In case of frame erasures, the concealment strategy can be summarized as a
convergence of the signal energy and the spectral envelope to the estimated
parameters of the background noise. A frame erasure is signalled to the
decoder by setting the bad frame indicator variable for the current frame
active. The periodicity of the signal is converged to zero. The speed of the
convergence is dependent on the parameters of the last correctly received
frame and the number of consecutive erased frames, and is controlled by an
attenuation factor, α. The factor, α, is further dependent on the stability,
θ, of the LP filter for UNVOICED_CLAS frames. In general, the convergence is
slow if the last good received frame is in a stable segment and is rapid if
the frame is in a transition segment. The values of α are summarized in
subclause 5.3.4.1 for the excitation concealment of rates: 5.9, 7.2, 8.0,
13.2, 32 and 64 kbps and in subclause 5.3.4.2.3 for the rates: 9.6, 16.4 and
24.4 kbps. Similar values are also defined for LSF concealment as described in
subclause 5.2.
#### 5.3.1.1 Extrapolation of future pitch
In case of a frame loss, an estimation of the end-of-frame pitch is done to
help keeping the adaptive codebook in sync to the error free case as good as
possible. If the error free end-of-frame pitch can be predicted precisely, the
recovery after the loss will be a lot quicker. The pitch extrapolation assumes
that the encoder uses a smooth pitch contour. The information on the estimated
end-of-frame pitch is used by the glottal pulse resynchronization tool
described in subclause 5.3.1.2.
The pitch extrapolation is done only if the last good frame was classified as
UNVOICED TRANSITION, VOICED TRANSITION or VOICED_CLAS. Also the pitch
extrapolation is only performed if the frame before the loss was a good frame.
The extrapolation is done based on the pitch lags,
{width="0.19444444444444445in" height="0.2222222222222222in"}_,_ of the last 5
subframes before the erasure. Also the history of the pitch gains,
{width="0.2013888888888889in" height="0.2152777777777778in"}, of the last 6
subframes before the erasure is needed. The history update of the pitch lags
and pitch gains is done after the synthesis of every frame.
First, the difference between the pitch lags is computed:
{width="1.0277777777777777in" height="0.2916666666666667in"}
for{width="0.6805555555555556in" height="0.18055555555555555in"} (27)
where {width="0.3194444444444444in" height="0.2916666666666667in"} _denotes
the last subframe of the previous frame,_ {width="0.25in"
height="0.2222222222222222in"} _denotes the second last sub-frame of the
previous frame,_ and so on.
In case the last good frame contained information about future pitch gains and
pitch lags, {width="0.2638888888888889in" height="0.2777777777777778in"} is
instead calculated by:
{width="1.1666666666666667in" height="0.2916666666666667in"} for
{width="0.6805555555555556in" height="0.18055555555555555in"} (28)
Also in case of information about future pitch gains and pitch lags was
contained in the previous frame, the history of pitch gains is shifted by 2
subframes in a way that the {width="0.375in"
height="0.20833333333333334in"}-th pitch gain is moved to the
{width="9.652777777777778e-2in" height="0.16666666666666666in"}-th pitch gain,
for {width="0.6805555555555556in" height="0.18055555555555555in"}.
Future subframe information might be available if the last good frame was
coded with TCX MDCT and there was LTP information available, or the last good
frame was coded with ACELP and there was future pitch information transmitted
in the bitstream (see subclause 5.3.3.1).
The sum of the differences is computed as
{width="0.7916666666666666in" height="0.4722222222222222in"} (29)
The position of the maximum absolute difference, {width="1.5555555555555556in"
height="0.4583333333333333in"}, is found.
If the criterion {width="1.4027777777777777in" height="0.2222222222222222in"}
AND {width="1.2361111111111112in" height="0.3055555555555556in"} is met, pitch
prediction is performed. Else no prediction is performed and
{width="0.5277777777777778in" height="0.25in"}is used for building the
adaptive codebook during concealment.
Pitch prediction is performed by minimizing this error equation.
(30)
where:
{width="0.4166666666666667in" height="0.1527777777777778in"} is the error
function,
{width="0.2013888888888889in" height="0.2152777777777778in"} are the past
adaptive codebook gains (also denoted as {width="0.3125in"
height="0.22916666666666666in"}, {width="0.3020833333333333in"
height="0.22916666666666666in"},{width="0.2916666666666667in"
height="0.23958333333333334in"},{width="0.28125in"
height="0.22916666666666666in"}),
{width="0.1388888888888889in" height="0.1527777777777778in"} and
{width="0.1388888888888889in" height="0.19375in"} are unknown variables which
need to be determined,
{width="0.2361111111111111in" height="0.2222222222222222in"} are the adaptive
codebook lags from the past frames (also denoted as
{width="0.19444444444444445in" height="0.2222222222222222in"}),
{width="9.652777777777778e-2in" height="0.18055555555555555in"} is the
subframe index
The past adaptive codebook gains are multiplied by a vector {1.25f, 1.125f,
1.f, 0.875f, .75f};
Minimizing of this function is done by deviating the error function by a and b
separately
{width="4.69375in" height="1.2916666666666667in"} (31)
By setting the derivatives {width="0.5833333333333334in"
height="0.2361111111111111in"} and {width="0.6805555555555556in"
height="0.3611111111111111in"} to zero, this leads to:
{width="4.263888888888889in" height="1.5694444444444444in"} (32)
{width="4.19375in" height="1.5694444444444444in"} (33)
where
{width="3.3333333333333335in" height="1.0965277777777778in"} (34)
The end-of-frame pitch is determined according to this, if no information
about future subframes was available in the previous frame:
$P_{\text{pred}} = a + 4 \cdot b$ (35)
In case there was information about future pitch gains and pitch lags
available the end-of-frame pitch is predicted by:
$P_{\text{pred}} = a + 2 \cdot b$ (36)
After this processing, the predicted pitch {width="0.3611111111111111in"
height="0.2361111111111111in"} is limited between
{width="0.3055555555555556in" height="0.20833333333333334in"} and
{width="0.3194444444444444in" height="0.20833333333333334in"}.
#### 5.3.1.2 Construction of the periodic part of the excitation
For a concealment of erased frames following a correctly received
UNVOICED_CLAS frame, no periodic part of the excitation is generated. For a
concealment of erased frames following a correctly received frame other than
UNVOICED_CLAS, the periodic part of the excitation is constructed by repeating
the low-pass filtered last pitch period of the previous frame. The low-pass
filter used is a simple 3-tap linear phase FIR filter with the coefficients
equal to 0.18, 0.64 and 0.18. The pitch period, Tc, used to select the last
pitch pulse, and hence used during the concealment, is defined so that pitch
multiples or submultiples can be avoided or reduced. The following logic is
used in determining the pitch period, Tc
+-----------------------------------------------------------------+ | if ((T[--1] \ 0.6Ts)) OR (Tcnt >=5) | | | | tmp_tc = T[--1] | | | | else | | | | tmp_tc = Ts | | | | Tc = round(tmp_tc) | +-----------------------------------------------------------------+
Here, T[--1] = {width="0.4166666666666667in" height="0.2777777777777778in"} is
the pitch period of the last subframe of the last good received frame and Ts
is the pitch period of the last subframe of the last good stable voiced frame
with coherent pitch estimates. A stable voiced frame is defined here as a
VOICED_CLAS frame, preceded by a frame of voiced type (VOICED TRANSITION,
VOICED_CLAS, ONSET). The coherence of pitch is verified by examining whether
the closed-loop pitch estimates are reasonably close; i.e. whether the ratio
between the 4th subframe pitch, $d_{\text{fr}^{\left\lbrack - 1
\right\rbrack}}$ at 12.8 kHz core sampling frequency or
$d_{\text{fr}^{\left\lbrack - 2 \right\rbrack}}$ at 16 kHz core sampling
frequency, and the 2nd subframe pitch, $d_{\text{fr}^{\left\lbrack - 3
\right\rbrack}}$ at 12.8 kHz core sampling frequency or
$d_{\text{fr}^{\left\lbrack - 4 \right\rbrack}}$ at 16 kHz core sampling
frequency, is within the interval [0.7, 1.4], and whether the ratio between
the 2nd subframe pitch ($d_{\text{fr}^{\left\lbrack - 3 \right\rbrack}}$ or
$d_{\text{fr}^{\left\lbrack - 4 \right\rbrack}}$) and the last subframe pitch
of the preceding frame, $d_{\text{fr}^{\left\lbrack - y \right\rbrack}}$, is
also within that interval, where _y_ = 5 when the core sampling frequency is
12.8 kHz and _y_ = 6 otherwise. The pitch is also assumed cohererent if the
coding type is transition.
This determination of the pitch period, Tc, implies that if the pitch at the
end of the last good frame and the pitch of the last stable frame are close,
the pitch of the last good frame is used. Otherwise, this pitch is considered
unreliable and the pitch of the last stable frame is used instead to avoid the
impact of erroneous pitch estimates at voiced onsets. This logic is valid only
if the last stable segment is not too far in the past. Hence, a counter, Tcnt,
is defined that limits the effect of the last stable segment. If Tcnt is
greater than or equal to 5; i.e. if there are at least 5 frames since the last
Ts update, the last good frame pitch is used systematically. Tcnt is reset to
0 every time a stable segment is detected and Ts is updated. The period Tc is
then maintained constant during the concealment for the entire erased block.
##### 5.3.1.2.1 Particularity of rate 5.9, 7.2, 8.0 and 13.2 kbps
On top of UNVOICED_CLAS, the periodic component of the excitation is not
constructed when the last coding mode was GSC AUDIO without a temporal
contribution or the last class was INACTIVE without a temporal contribution.
#### 5.3.1.3 Glottal pulse resynchronization
The construction of the periodic part of the excitation, described in the
subclause 5.3.1.2, may result in a drift of the glottal pulse position in the
concealed frame during voiced segments, since the pitch period used to build
the excitation can be different from the encoder pitch period. This will cause
the adaptive codebook (or past CELP excitation) to be desynchronized from the
actual CELP excitation. Thus, in case a good frame is received after an erased
frame, the pitch excitation (or adaptive codebook excitation) will have an
error which may persist for several frames and affect the performance of the
correctly received frames.
To overcome this problem and improve the decoder convergence, a
resynchronization method is used which adjusts the position of the glottal
pulses in the concealed frame to be synchronized with the estimated true
glottal pulses positions where the positions of the glottal pulses are
estimated at the decoder based on the pitch extrapolation performed as in
subclause 5.3.1.1. Therefore, this resynchronization procedure is performed
based on the estimation of phase information and it aligns the maximum pulse
in each pitch period of the concealed frame to the estimated position of the
glottal pulse.
The starting point is the constructed periodic part of the excitation src_exc,
constructed as described in subclause 5.3.1.2. If {width="0.94375in"
height="0.2361111111111111in"} then samples are removed from src_exc and if
{width="0.94375in" height="0.2361111111111111in"} then samples are added to
src_exc. The samples are added or removed at the locations of the minimum
energy, between the estimated locations of the glottal pulses as well as the
locations of the minimum energy before the estimated location of the first and
after the estimated location of the last glottal pulse. The periodic part of
the excitation, modified in such way, is stored into dst_exc.
##### 5.3.1.3.1 Condition to perform resynchronisation
The glottal pulse resynchronisation is performed only if some conditions,
which describe that a reliable estimation of true pulse positions is available
and is different from the actual pulse positions, are met. First the
extrapolation of the future pitch as performed in subclause 5.3.1.1 shall have
been successful. The pitch period Tc as defined in subclause 5.3.1.2 shall be
different than the rounded predicted pitch {width="0.3611111111111111in"
height="0.2361111111111111in"} as defined in subclause 5.3.1.1. The absolute
difference between the pitch period Tc and the rounded predicted pitch
{width="0.3611111111111111in" height="0.2361111111111111in"} shall be smaller
than {width="0.5138888888888888in" height="0.20833333333333334in"}. In order
to have enough samples for the pulse resynchronization in the periodic part of
the excitation constructed by repeating the last pitch period, the relative
pitch change shall be greater than a threshold as described below:
{width="1.3611111111111112in" height="0.4583333333333333in"} (37)
where {width="0.3611111111111111in" height="0.2361111111111111in"} is the
number of subframes as defined in subclause 5.1.2.
If the conditions to perform the glottal pulse resynchronization are not met,
the samples from src_exc are simply copied to dst_exc. In some instances,
where the glottal pulse resynchronization is used, this is implemented in a
such way that src_exc points to the final location of the modified periodic
part of the excitation, and that its contents are first copied to another
temporary buffer which is then considered as src_exc inside the pulse
resynchronization and the final location which for the caller is src_exc is
considered as dst_exc inside the pulse resynchronization.
##### 5.3.1.3.2 Performing glottal pulse resynchronization
First the pitch change per sub-frame {width="0.1388888888888889in"
height="0.16666666666666666in"} is calculated as:
{width="1.19375in" height="0.4722222222222222in"} (38)
Then the number of samples to be added (to be removed if negative)
{width="0.1388888888888889in" height="0.18055555555555555in"} is calculated
as:
{width="2.0694444444444446in" height="0.4166666666666667in"} (39)
Then the location of the first maximum pulse {width="0.2916666666666667in"
height="0.19375in"}, among first {width="0.19375in"
height="0.20833333333333334in"} samples in src_exc is found using simple
search for the maximum absolute value.
The index of the last pulse that will be present in dst_exc is calculated as:
$k = \left\lceil \frac{L - d - T\lbrack 0\rbrack}{T_{C}} - 1 \right\rceil$
(40)
The delta of the samples to be added or removed between consecutive pitch
cycles {width="0.125in" height="0.1388888888888889in"} is calculated as:
{width="1.7777777777777777in" height="0.6805555555555556in"} (41)
The number of samples to be added or removed before the first pulse is
calculated as:
{width="1.9305555555555556in" height="0.4027777777777778in"} (42)
The number of samples to be added or removed before the first pulse is rounded
down and the fractional part is kept in memory:
{width="0.7777777777777778in" height="0.5416666666666666in"} (43)
For each region between 2 pulses the number of samples to be added or removed
is calculated as:
{width="1.6527777777777777in" height="0.3055555555555556in"}, {width="0.5in"
height="0.18055555555555555in"} (44)
The number of samples to be added or removed between 2 pulses, taking into
account the remaining fractional part from the previous rounding, is rounded
down:
{width="0.8055555555555556in" height="0.5416666666666666in"} (45)
If, due to the added {width="0.1527777777777778in"
height="0.1527777777777778in"}, for some i it happens that
{width="0.5833333333333334in" height="0.2777777777777778in"}, then the values
for {width="0.18055555555555555in" height="0.2777777777777778in"} and
{width="0.2916666666666667in" height="0.2777777777777778in"} are swapped.
The number of samples to be added or removed after the last pulse is
calculated as:
{width="1.5138888888888888in" height="0.5138888888888888in"} (46)
The maximum number of samples to be added or removed among the minimum energy
regions is calculated as:
{width="2.2083333333333335in" height="0.4861111111111111in"} (47)
The location of the minimum energy segment {width="0.44375in"
height="0.2777777777777778in"} between the first two pulses in src_exc, that
has {width="0.34652777777777777in" height="0.25in"} length, is then found by
simple search for minimum in the moving average of length
{width="0.34652777777777777in" height="0.25in"}. For every consecutive minimum
energy segment between two pulses, the position is calculated as:
{width="1.5694444444444444in" height="0.2777777777777778in"}, {width="0.5in"
height="0.18055555555555555in"} (48)
If {width="0.7361111111111112in" height="0.2777777777777778in"} then the
location of the minimum energy segment before the first pulse is calculated
using {width="1.2916666666666667in" height="0.2777777777777778in"}. Otherwise
the location of the minimum energy segment {width="0.4722222222222222in"
height="0.2777777777777778in"} before the first pulse in src_exc is found by
simple search for minimum in the moving average of length
{width="0.20833333333333334in" height="0.25in"}.
If {width="1.2638888888888888in" height="0.2777777777777778in"} then the
location of the minimum energy segment after the last pulse is calculated
using {width="1.5416666666666667in" height="0.2777777777777778in"}. Otherwise
the location of the minimum energy segment {width="0.6666666666666666in"
height="0.2777777777777778in"} after the last pulse in src_exc is found by
simple search for minimum in the moving average of length
{width="0.3194444444444444in" height="0.25in"}.
If there is going to be just one pulse in dst_exc, that is if {width="0.125in"
height="0.18055555555555555in"} is equal to 0, the search for
{width="0.44375in" height="0.2777777777777778in"} is limited to
{width="0.34652777777777777in" height="0.18055555555555555in"}.
{width="0.44375in" height="0.2777777777777778in"} then points to the location
of the minimum energy segment after the only pulse in dst_exc.
If {width="0.34652777777777777in" height="0.18055555555555555in"} then
{width="0.18055555555555555in" height="0.25in"} samples are added at location
{width="0.44375in" height="0.2777777777777778in"} for
{width="0.7083333333333334in" height="0.18055555555555555in"} to the signal
src_exc and stored in dst_exc, otherwise if {width="0.34652777777777777in"
height="0.18055555555555555in"} then {width="0.18055555555555555in"
height="0.25in"} samples are removed at location {width="0.44375in"
height="0.2777777777777778in"} for {width="0.7083333333333334in"
height="0.18055555555555555in"} from the signal src_exc and stored in dst_exc.
There are {width="0.3333333333333333in" height="0.18055555555555555in"}
regions where the samples are added or removed.
#### 5.3.1.4 Construction of the random part of the excitation
The innovative (non-periodic) part of the excitation is generated randomly. A
simple random generator with approximately uniform distribution is used.
Before adjusting the innovation gain, the randomly generated innovation is
scaled to some reference value, fixed here to the unitary energy per sample.
At the beginning of an erased block, the innovation gain, _g~s~_ , is
initialized by using the innovative excitation gains of each subframe of the
last good frame
for 4 subframes:
{width="2.5833333333333335in" height="0.25in"} (49)
for 5 subframes:
$g_{s} = \frac{1}{\text{15}}g_{c}^{\lbrack - 5\rbrack} +
\frac{2}{\text{15}}g_{c}^{\lbrack - 4\rbrack} +
\frac{3}{\text{15}}g_{c}^{\lbrack - 3\rbrack} +
\frac{4}{\text{15}}g_{c}^{\lbrack - 2\rbrack} +
\frac{5}{\text{15}}g_{c}^{\lbrack - 1\rbrack}$(49a)
where $g_{c}^{\lbrack - 5\rbrack}$, {width="0.3333333333333333in"
height="0.25in"}, {width="0.3333333333333333in"
height="0.2388888888888889in"}, {width="0.3333333333333333in" height="0.25in"}
and {width="0.3229166666666667in" height="0.25in"} are the algebraic codebook
gains of the four subframes of the last correctly received frame. The
attenuation strategy of the random part of the excitation is somewhat
different from the attenuation of the pitch excitation. The reason is that the
pitch excitation (and thus the excitation periodicity) is converging to 0
while the random excitation is converging to the CNG excitation energy. The
innovation gain attenuation is calculated as
{width="1.3611111111111112in" height="0.25in"} (50)
where {width="0.25in" height="0.25in"} is the innovative gain at the beginning
of the next frame, {width="0.2590277777777778in" height="0.25in"}is the
innovative gain at the beginning of the current frame, {width="0.19375in"
height="0.25in"}is the gain of the excitation used during the comfort noise
generation and α is as defined in Table 4. The comfort noise gain,
{width="0.19375in" height="0.25in"}, is given as the square root of the energy
{width="0.1840277777777778in" height="0.18888888888888888in"} as described in
subclause 5.4.3.6.4. Similarly to the periodic excitation attenuation, the
gain is thus attenuated linearly throughout the frame on a sample-by-sample
basis starting with, {width="0.27361111111111114in" height="0.25in"}, and
going to the value of {width="0.25in" height="0.25in"} that would be achieved
at the beginning of the next frame.
Finally, if the last correctly received frame is different from UNVOICED_CLAS,
the innovation excitation is filtered through a linear phase FIR high-pass
filter with coefficients --0.0125, --0.109, 0.7813,\ \--0.109, and --0.0125.
To decrease the amount of noisy components during voiced segments, these
filter coefficients are multiplied by an adaptive factor equal to
{width="0.8611111111111112in" height="0.20833333333333334in"}, with
{width="0.1527777777777778in" height="0.20833333333333334in"} denoting the
voicing factor as defined in equation (1475) in subclause 6.1.1.3.2 of [5].
The random part of the excitation is then added to the adaptive excitation to
form the total excitation signal. If the last good frame is UNVOICED_CLAS,
only the innovative excitation is used and it is further attenuated by a
factor of 0.8. In this case, the past excitation buffer is updated with the
innovation excitation, as no periodic part of the excitation is available. If
the last good frame is UNVOICED_CLAS or INACTIVE but it is not coded with UC
mode signalling non‑stationary unvoiced frame, the innovation excitation is
further attenuated by a factor of 0.8.
#### 5.3.1.5 Spectral envelope concealment, synthesis and updates
To synthesize the decoded speech, the LP filter parameters shall be obtained.
The spectral envelope is gradually moved to an estimated reference envelope,
see clause 5.2. The estimated LSF vector is converted to an LSP vector and
interpolated with the last frame\'s LSP vector for 4 or 5 subframes, depending
on the ACELP sampling rate being 12.8 kHz or 16 kHz.
The synthesized signal is obtained by filtering the sum of the adaptive and
the random excitation signal through the LP synthesis filter (see clause 6.1.3
of [5]) and post-processed similar to the steps performed in clean channel.
As the LSF quantizers uses prediction, their memories would not be up to date
after the normal operation is resumed. To reduce this effect, the quantizers\'
memories (moving average and auto-regressive) are estimated and updated at the
end of each erased frame.
##### 5.3.1.5.1 Specifics for rates 9.6, 16.4 and 24.4 kbps
The coefficients of the filter used in subclause 5.3.1.2 for low pass
filtering of the first pitch cycle are dependent on the sampling rate. The
pitch period, tmp_tc, is always equal to T[-1], where T[-1] is the pitch
period of the last sub-frame of the last good received frame, and Tc, used to
select the last pitch pulse is thus equal to round(T[-1]).
The periodic part of the excitation will be generated further by repeatedly
copying the last pitch cycle of the dst_exc for an additional half frame,
which is used for correctly updating the overlap-add buffers for MDCT
recovery.
In contrast to subclause 5.3.1.5, both excitation signals are not added up and
filtered. The synthesized signal is obtained by filtering the adaptive
excitation through the LP synthesis filter based on the LSF interpolation
according to formula (19). The random part of the excitation is filtered
through the LP filter based on formula (21). After obtaining two separate
synthesis signals, they are added up, post processed and played out like in a
correctly received frame. Note, that the memories for both of the LP synthesis
filters are initialized with the last known state of the last good frame in
the beginning of a frame loss. For consecutive loss, they are updated and
stored separately.
#### 5.3.1.6 GSC mode concealment
When the concealment is performed based on the GSC core, the construction of
the periodic part of the excitation is performed as described in subclauses
5.3.1.2 and 5.3.1.3. The reconstruction of the periodic part of the excitation
corresponds to the time domain contribution of the GSC model. Thus, the
reconstructed periodic excitation is converted into the frequency domain using
the DCT~IV~ as described in subclause 5.2.3.5.3.1 of [5] and the spectrum
above the last known cut-off frequency is smoothed-out to zero.
Then, the spectral concealment is performed by using the last good band
energies received. In case of INACTIVE content or active SWB UC mode, the last
good decoded spectrum is mixed with random noise at a rate of 4/5 random noise
and 1/5 the last decoded spectrum, making the spectrum to become noisy quite
fast. In case the last good frame was AUDIO, no noise is added, but the
spectrum dynamic is attenuated by 25 %.
The next step consists in adding the spectrum of the reconstructed periodic
excitation to the concealed spectrum of the frequency domain contribution and
to perform the inverse DCT~IV~ similarly as done in subclause 5.2.3.5.3.1 of
[5] to get the final concealed excitation in case of GSC mode.
#### 5.3.1.7 Specifics for AMR-WB IO modes
In case of AMR-WB IO the subclause 5.1.2 is complement with a few more
parameters that allow the interoperable decoder to know if the decoded frame
contains more likely speech of generic audio and if the current frame contains
an onset. The generic audio can include music, reverberant speech and can also
include background music. To determine with good confidence that the current
frame can be categorized as generic audio, two parameters are used. The total
frame energy {width="0.2222222222222222in" height="0.20833333333333334in"} as
formulated in subclause 5.1.2 and the statistical deviation of the energy
variation history{width="0.2222222222222222in"
height="0.20833333333333334in"}.
First, a mean of the past forty (40) total frame energy variations
{width="0.2777777777777778in" height="0.2361111111111111in"} is calculated
using the following relation:
{width="3.5965277777777778in" height="0.6666666666666666in"} (51)
Then, a statistical deviation of the energy variation history
{width="0.2222222222222222in" height="0.20833333333333334in"}over the last
fifteen (15) frames is determined using the following relation:
{width="2.0277777777777777in" height="0.5694444444444444in"} (52)
The resulting deviation {width="0.2222222222222222in"
height="0.20833333333333334in"} gives an indication on the energy stability of
the decoded synthesis. Typically, music has a higher energy stability (lower
statistical deviation of the energy variation history) than speech.
Additionally, the first step classification is used to evaluate the interval
between two frames classified as unvoiced {width="0.28125in"
height="0.20833333333333334in"} when the coder type is different from
INACTIVE. When a frame is classified as unvoiced and the coder type is
different from INACTIVE, meaning that the signal is unvoiced but not silence,
if the long term active content energy{width="0.21805555555555556in"
height="0.21805555555555556in"}, as formulated in subclause 5.1.2, is below 40
dB the unvoiced interval counter is set to 16, otherwise the unvoiced interval
counter {width="0.28125in" height="0.20833333333333334in"} is decreased by 8
and also limited between 0 and 300 for active signal and between 0 and 125 for
inactive signal. It is reminded that, the difference between active and
inactive signal is deduced from the voice activity detection VAD information
included in the bitstream.
A long term average is derived from this unvoiced frame counter as follow for
active signal:
{width="1.625in" height="0.2361111111111111in"} (53)
And as follows for inactive signal:
{width="1.0694444444444444in" height="0.2361111111111111in"} (54)
Furthermore, when the long term unvoiced average {width="0.3333333333333333in"
height="0.2361111111111111in"}is greater than 100 and the deviation
{width="0.2222222222222222in" height="0.20833333333333334in"} is greater than
5 and the difference between the current frame energy and the last frame
energy {width="0.2361111111111111in" height="0.25in"} is smaller than 12 dB,
the long term average is modified as follow:
{width="1.2916666666666667in" height="0.2361111111111111in"} (55)
This parameter on long term average of the number of frames between frames
classified as unvoiced is used by the classifier to determine if the frame
should be considered as generic audio or not. The more the unvoiced frames are
close in time, the more likely the frame has speech characteristics (less
probably generic audio). In the illustrative example, the threshold to decide
if a frame is considered as generic audio {width="0.2361111111111111in"
height="0.20833333333333334in"}is defined as follows:
A frame is declared {width="0.2361111111111111in"
height="0.20833333333333334in"}if
{width="1.3055555555555556in" height="0.2777777777777778in"} (56)
The parameter{width="0.2361111111111111in" height="0.25in"}, defined at the
beginning of this subclause, is added to not classify large energy variation
as generic audio, but to keep it as active content. A flag named local attack
flag {width="0.25in" height="0.2361111111111111in"}and used in subclause
6.8.1.3.5 of [6] is derived from variation of energy
parameter{width="0.2361111111111111in" height="0.25in"}. The local attack flag
{width="0.25in" height="0.2361111111111111in"}is set to 1 when the energy
variation is greater than 6 dB and the frame is classified as GENERIC AUDIO
SOUND or when the energy variation is greater than 9 dB.
The modification performed on the excitation depends on the classification of
the frame and for some type of frames there is no modification at all. The
next table 3 summarizes the case where a modification can be performed or not.
Table 6: Signal category for excitation modification
+----------------------+--------------------------+------------------+--------------+ | Frame Classification | Voice activity detected? | Category | Modification | | | | | | | | Y/N | | Y/N | +----------------------+--------------------------+------------------+--------------+ | ONSET | Y | Active voice | N | | | | | | | VOICED_CLAS | (VAD=1) | | | | | | | | | UNVOICED TRANSITION | | | | | | | | | | ARTIFICIAL ONSET | | | | +----------------------+--------------------------+------------------+--------------+ | GENERIC AUDIO SOUND | Y | Generic audio | Y | +----------------------+--------------------------+------------------+--------------+ | VOICED TRANSITION | Y | Active unvoiced | Y | | | | | | | UNVOICED_CLAS | | | | +----------------------+--------------------------+------------------+--------------+ | ONSET | N | Inactive content | Y | | | | | | | VOICED_CLAS | | | | | | | | | | UNVOICED TRANSITION | | | | | | | | | | ARTIFICIAL ONSET | | | | | | | | | | GENERIC AUDIO SOUND | | | | | | | | | | VOICED TRANSITION | | | | | | | | | | UNVOICED_CLAS | | | | +----------------------+--------------------------+------------------+--------------+
The output of the second stage classifier will be used to activate or not
different post processing based on content category.
#### 5.3.1.8 Reconstructed excitation
The total excitation from layer 1 in each subframe is constructed by
{width="2.8465277777777778in" height="0.2361111111111111in"} (57)
where {width="0.2638888888888889in" height="0.20833333333333334in"} is the
pre-filtered algebraic code vector. The excitation signal,
{width="0.3055555555555556in" height="0.20833333333333334in"}, is used to
update the contents of the adaptive codebook for the next frame. The
excitation signal, {width="0.3055555555555556in"
height="0.20833333333333334in"}, is then post‑processed as described in
subclause 6.1.1.3 of [5] to obtain the post-processed excitation signal
{width="0.2777777777777778in" height="0.20833333333333334in"}, which is
finally used as an input to the synthesis filter {width="0.4027777777777778in"
height="0.2361111111111111in"}. The final steps of synthesis, post‑processing,
de-emphasis and resampling are described in subclauses 6.1.4 of [5].
##### 5.3.1.8.1 Particularity of rate 5.9, 7.2, 8.0 and 13.2 kbps
In case of GSC based concealment, with or without a time domain contribution,
the excitation {width="0.3055555555555556in" height="0.20833333333333334in"}
corresponds directly to the output of subclause 5.3.1.6.
### 5.3.2 Concealment for bandwidth extension for ACELP modes
#### 5.3.2.1 Time domain bandwidth extension
##### 5.3.2.1.1 SWB time domain bandwidth extension
The concealment for SWB TD BWE works for 13.2 kbps, 16.4 kbps, 24.4 kbps and
32 kbps. The algorithm aims to reconstruct the high band of the current lost
frame for SWB TD BWE. The reconstruction of the lost frame depends on at least
one of the following gain adjustment information: the coder type of the
previous frame, the frame class of the last good received frame, the frame
class of the current frame, the number of the consecutive lost frame, the
energies and the tilts of the low band of both the current frame and the
previous frame.
There are gain shapes which are also the subframe gains, global frame gain and
LSF should be reconstructed when the current frame is lost. The reconstruction
of the LSF information is usually copying from the previous frame. The
reconstruction of the subframe gains of the lost frame is based on the
subframe gains and the subframe gain gradients of at least one frame before
the current frame and adjusted by some of the above gain adjustment
information. The reconstruction of the global frame gain of the lost frame is
based on the global frame gain of at least one frame before the current frame
and the global frame gain gradient of the current frame and adjusted by some
of the above gain adjustment information.
The initial high band signal of the current lost frame is synthesized
according to the decoding parameters of the frame prior to the current lost
frame, specifically it is synthesized by passing the high band excitation
through the synthesis filter, where the high band excitation is obtained from
the low band excitation and synthesis filter is obtained from the
reconstructed LSF parameters. Then the initial synthesized high band signal is
adjusted by the reconstructed global frame gain and at least two of the
reconstructed subframe gains of the current lost frame. Finally, the high band
of the current lost frame is reconstructed.
###### 5.3.2.1.1.1 The reconstruction of the global frame gain
For single frame loss: determining the frame class of the current frame, the
tilts of the current frame and the previous frame, the energies of the low
parts and high parts from the low band of both the current frame and the
previous frame.
Assuming the three following conditions:
\- Condition 1: the frame class of the current frame is not UNVOICED_CLAS and
UNVOICED_TRANSITION.
\- Condition 2: the tilt of the previous frame is less than 8.0.
\- Condition 3: the energy of low parts from the low band of the current
frame{width="0.375in" height="0.16666666666666666in"}is more than
{width="0.8465277777777778in" height="0.2361111111111111in"} and
{width="0.375in" height="0.16666666666666666in"}is less
than{width="0.8465277777777778in" height="0.2361111111111111in"}, or, the
energy of high parts from the low band of the current
frame{width="0.4305555555555556in" height="0.16666666666666666in"}is more than
{width="0.9027777777777778in" height="0.2361111111111111in"} and
{width="0.4305555555555556in" height="0.16666666666666666in"}is less
than{width="0.9166666666666666in" height="0.2361111111111111in"}. The
{width="0.5833333333333334in" height="0.2361111111111111in"}is the energy of
low parts from the low band of the current frame and the
{width="0.6388888888888888in" height="0.2361111111111111in"} is the energy of
high parts from the low band of the previous frame.
If all the above mentioned three conditions are met, the global frame gain of
the current lost frame is described as follows:
{width="3.44375in" height="0.6527777777777778in"} (58)
where the{width="0.4305555555555556in" height="0.20833333333333334in"} is
calculated by:
{width="1.2083333333333333in" height="0.2361111111111111in"} (59)
{width="2.4027777777777777in" height="0.7916666666666666in"} (60)
where {width="0.20833333333333334in" height="0.16666666666666666in"} is the
high band excitation energy of the current frame,
{width="0.4305555555555556in" height="0.2361111111111111in"} is the high band
excitation energy of the previous frame.
Then if the tilt of the low band of the current frame
{width="0.20833333333333334in" height="0.18055555555555555in"} is more than
that of the previous frame {width="0.4305555555555556in"
height="0.2361111111111111in"}, the global frame gain is updated as follows:
{width="1.9027777777777777in" height="0.4583333333333333in"} (61)
{width="1.7361111111111112in" height="0.2361111111111111in"} (62)
If the above mentioned three conditions are not met, but the following three
conditions are met:
\- Condition 4: the frame class of the current frame is not UNVOICED_CLAS or
the tilt of the previous frame is more than 8.0,
\- Condition 5: {width="0.4305555555555556in" height="0.20833333333333334in"}
is more than{width="0.4722222222222222in" height="0.19375in"},
\- Condition 6: the energy of low parts from the low band of the current
frame{width="0.375in" height="0.16666666666666666in"}is more
than{width="0.8465277777777778in" height="0.2361111111111111in"}, or the
energy of high parts from the low band of the current
frame{width="0.4305555555555556in" height="0.16666666666666666in"}is more
than{width="0.9027777777777778in" height="0.2361111111111111in"}. The
{width="0.5833333333333334in" height="0.2361111111111111in"}is the energy of
low parts from the low band of the current frame and the
{width="0.6388888888888888in" height="0.2361111111111111in"} is the energy of
high parts from the low band of the previous frame.
The global frame gain would be:
{width="1.5555555555555556in" height="0.20833333333333334in"} (63)
For multiple frame losses:
For 13.2 kbps and 32 kbps, if {width="0.4305555555555556in"
height="0.20833333333333334in"} is more than{width="0.4722222222222222in"
height="0.19375in"}, {width="0.375in" height="0.16666666666666666in"}is more
than {width="0.5833333333333334in" height="0.2361111111111111in"}and
{width="0.4305555555555556in" height="0.16666666666666666in"}is more
than{width="0.6388888888888888in" height="0.2361111111111111in"}. For 16.4
kbps and 24.4 kbps if {width="0.4305555555555556in"
height="0.20833333333333334in"} is more than{width="0.4722222222222222in"
height="0.19375in"}, the global frame gain is as follows:
{width="4.069444444444445in" height="0.4861111111111111in"} (64)
Otherwise, for 13.2 kbps and 32 kbps, if {width="0.4305555555555556in"
height="0.20833333333333334in"} is more than{width="0.19375in"
height="0.20833333333333334in"}, {width="0.375in"
height="0.16666666666666666in"}is more than {width="0.5833333333333334in"
height="0.2361111111111111in"}and {width="0.4305555555555556in"
height="0.16666666666666666in"}is more than{width="0.6388888888888888in"
height="0.2361111111111111in"}. For 16.4 kbps and 24.4 kbps if
{width="0.4305555555555556in" height="0.20833333333333334in"} is more
than{width="0.19375in" height="0.20833333333333334in"}, the global frame gain
is as follows:
{width="3.2083333333333335in" height="0.4861111111111111in"} (65)
###### 5.3.2.1.1.2 The reconstruction of the gain attenuation factor
Reconstruct the gain attenuation factor according to the following conditions:
the coder type of the previous frame, the frame class of the last good
received frame, and the energies of the low band of both the current frame and
the previous frame, the number of the consecutive lost frames. The detail
processing is as follows:
For single frame loss, judging the following three conditions:
\- Condition 1: the energy of the shaped excitation
{width="0.3611111111111111in" height="0.19375in"}of current
frame{width="0.3194444444444444in" height="0.20833333333333334in"}is more than
the energy of the shaped excitation {width="0.3611111111111111in"
height="0.19375in"}of the previous frame{width="0.6388888888888888in"
height="0.2361111111111111in"}.
\- Condition 2: The coder type of the previous frame is not UNVOICED.
\- Condition 3: The frame class of the last good received frame is not
UNVOICED_CLAS.
If condition1, 2 and 3 are met:
The gain attenuation factor {width="0.5138888888888888in"
height="0.20833333333333334in"} to the shaped excitation
{width="0.3611111111111111in" height="0.19375in"}is as follows:
{width="1.6111111111111112in" height="0.9722222222222222in"} (66)
Otherwise
\- Condition 4: the energy of the shaped excitation
{width="0.3611111111111111in" height="0.19375in"}of current
frame{width="0.3194444444444444in" height="0.20833333333333334in"}is more than
0.5 times the energy of the shaped excitation {width="0.3611111111111111in"
height="0.19375in"}of the previous frame{width="0.9027777777777778in"
height="0.2361111111111111in"}.
\- Condition 5: the energy of low parts from the low band of the current
frame{width="0.375in" height="0.16666666666666666in"}is more
than{width="0.8465277777777778in" height="0.2361111111111111in"}, or the
energy of high parts from the low band of the current
frame{width="0.4305555555555556in" height="0.16666666666666666in"}is more than
{width="0.9027777777777778in" height="0.2361111111111111in"}.
The{width="0.5833333333333334in" height="0.2361111111111111in"}is the energy
of low parts from the low band of the current frame and the
{width="0.6388888888888888in" height="0.2361111111111111in"} is the energy of
high parts from the low band of the previous frame.
\- Condition 6: The coder type of the previous frame is not UNVOICED, or the
type of the last good received is not UNVOICED_CLAS or the tilt of the
previous frame is more than 5.0.
If condition 4, 5 and 6 are met, the gain attenuation factor
{width="0.5138888888888888in" height="0.20833333333333334in"}is calculated as
follows:
{width="1.6111111111111112in" height="0.9722222222222222in"} (67)
For multiple frame losses:
If the energy of the shaped excitation {width="0.3611111111111111in"
height="0.19375in"}of current frame{width="0.3194444444444444in"
height="0.20833333333333334in"}is more than the energy of the shaped
excitation {width="0.3611111111111111in" height="0.19375in"}of the previous
frame{width="0.625in" height="0.2361111111111111in"}, the gain attenuation
factor {width="0.5138888888888888in" height="0.20833333333333334in"}is as
follows:
$\begin{matrix} \text{factor}_{\text{sε}} =
\sqrt{\frac{\text{En}_{\text{sε}}}{\text{En}_{\text{sε}_{\text{prev}}}}} \ \
\text{factor}_{\text{sε}_{\text{temp}}} = \left( \text{factor}_{\text{se}}
\right)^{0\text{.}\text{125}} \ \end{matrix}$ (68)
Otherwise if condition4, 5 and 6 are met, the gain attenuation factor
{width="0.5138888888888888in" height="0.20833333333333334in"}is as follows:
$\begin{matrix} \text{factor}_{\text{sε}} = \text{min}\left(
2\text{.}0,\sqrt{\frac{\text{En}_{\text{sε}}}{\text{En}_{\text{sε}_{\text{prev}}}}}
\right) \ \ \text{factor}_{\text{sε}_{\text{temp}}} = \left(
\text{factor}_{\text{se}} \right)^{0\text{.}\text{125}} \ \end{matrix}$ (69)
Use the {width="0.5138888888888888in" height="0.20833333333333334in"} and
{width="0.8194444444444444in" height="0.2361111111111111in"}to the subframe
gains and the shaped excitation {width="0.3611111111111111in"
height="0.19375in"}described as follows:
{width="3.5in" height="0.875in"} (70)
Use the reconstructed information including subframe gains, global frame gain
and LSFs to reconstruct the high band signal of the lost frame.
###### 5.3.2.1.1.3 Specifics for rates 13.2 and 32 kbps
Calculating the subframe gain gradients of the previous frame and the frame
immediately prior to the previous frame are described as follows:
{width="3.4027777777777777in" height="0.7916666666666666in"} (71)
where {width="1.0138888888888888in" height="0.25in"}are the subframe gains of
the previous frame, {width="1.0in" height="0.25in"}are the subframe gains of
the frame immediately prior to the previous frame.
{width="6.25in" height="1.1527777777777777in"} (72)
If the coder type of the previous frame is UNVOICED, or the frame class of the
last good received frame is UNVOICED_CLASS, and
the{width="0.7222222222222222in" height="0.2361111111111111in"}is positive.
Then the first subframe gain template {width="0.75in"
height="0.2361111111111111in"}would be:
$\text{gs}_{\text{template}}(0) = gs^{''}(3) + \text{gs}_{\text{gradfec}}(0)$
(73)
Otherwise, if {width="0.7361111111111112in" height="0.2638888888888889in"} is
positive, the subframe gain template {width="0.7638888888888888in"
height="0.2638888888888889in"}would be:
$\text{gs}_{\text{template}}(0) = gs^{''}(3) + 0\text{.}5 \ast
\text{gs}_{\text{gradfec}}(0)$ (74)
Otherwise, the subframe gain template {width="0.75in"
height="0.2361111111111111in"}would be:
$\text{gs}_{\text{template}}(0) = gs^{''}(3)$ (75)
The other gain subframe gain templates {width="1.375in"
height="0.2638888888888889in"} are determined as follows:
If {width="0.6388888888888888in" height="0.2361111111111111in"}is more than
10*{width="0.6111111111111112in" height="0.2361111111111111in"}and
the{width="0.6111111111111112in" height="0.2361111111111111in"} is positive.
Then:
{width="3.4027777777777777in" height="0.2361111111111111in"} (76)
Otherwise, if {width="0.6388888888888888in" height="0.2361111111111111in"}is
more than {width="0.8333333333333334in" height="0.2361111111111111in"}and
{width="0.6111111111111112in" height="0.2361111111111111in"} is negative.
Then:
{width="3.4027777777777777in" height="0.2361111111111111in"} (77)
Otherwise
{width="3.138888888888889in" height="0.2361111111111111in"} (78)
Reconstruct the {width="0.9583333333333334in" height="0.19375in"}use the
{width="1.3611111111111112in" height="0.2361111111111111in"}according to the
coder type of the previous frame, the frame class of the last good received
frame and the number of consecutive lost frame. The global frame gain
g[radient]{.underline}{width="0.3194444444444444in"
height="0.20833333333333334in"} is also determined by the upper three
conditions, it is initialized to 1.0:
If the coder type of the previous frame is UNVOICED or the frame class of the
last good received frame is UNVOICED_CLAS, and there is single frame loss,
then:
{width="3.013888888888889in" height="0.2361111111111111in"} (79)
{width="1.1666666666666667in" height="0.25in"} (80)
Otherwise if the coder type of the previous frame is UNVOICED or the frame
class of the last good received frame is UNVOICED_CLAS Then:
{width="2.75in" height="0.2361111111111111in"} (81)
{width="1.1111111111111112in" height="0.20833333333333334in"} (82)
Otherwise, if there are multiple frame losses, then:
{width="3.013888888888889in" height="0.2361111111111111in"} (83)
{width="1.0138888888888888in" height="0.20833333333333334in"} (84)
Otherwise then:
{width="2.75in" height="0.2361111111111111in"} (85)
{width="1.1111111111111112in" height="0.20833333333333334in"} (86)
where {width="1.875in" height="0.20833333333333334in"}are the subframe gains
of the current frame.
The global frame gain of the current frame is calculated with
{width="0.3194444444444444in" height="0.20833333333333334in"} and
{width="0.3888888888888889in" height="0.2361111111111111in"} described as
follows:
{width="1.0833333333333333in" height="0.2361111111111111in"} (87)
where the {width="0.3888888888888889in" height="0.2361111111111111in"} is the
global frame gain of the previous frame.
### 5.3.3 Guided concealment and recovery
#### 5.3.3.1 Specifics for rate 24.4 kbps
As described in subclause 5.5.4 of [5], the activation flag and differential
pitch lag are transmitted as side information to obtain better pitch lag
estimates and excitation signal for the future frame to be concealed.
The first 1 bit of the side information is read from the bit-stream yielding
the activation flag. In case the activation flag equals 0, no further decoding
is performed. If the flag equals 1, additional 4 bits are decoded yielding the
differential pitch lag. With 4bits 16 different states are signalled. 15
states are used to represent the differential pitch lag, ranging from -7 to 7.
The remaining signalling state is used to signal, that the pitch lag
difference was outside the +-7 range on encoder side.\ In case the pitch lag
difference is inside the signalled valid rage of +-7, the differential pitch
lag is added to the pitch lag of the last sub-frame. The result is used as an
initial pitch lag estimate of the future 1^st^ and 2^nd^ sub-frame. The
initial pitch lag estimates are used as an input to the pitch lag
extrapolation procedure described in subclause 5.3.1.1. If the initial pitch
lag estimates are available, the history of pitch lags used for the pitch
extrapolation is updated with the initial pitch lag estimates. In case the
criteria in clause 5.3.1.1 is not met, instead of {width="0.53125in"
height="0.25in"}, the initial pitch lag estimate is used for building the
first and second subframe of the adaptive codebook during concealment .
In case the pitch lag difference indicates that the difference is outside the
valid range of +-7 the pitch extrapolation is performed like there is no
future pitch lag information available in the bitstream.
#### 5.3.3.2 Specifics for rates 9.6, 16.4 and 24.4 kbps
As described in subclause 5.5.5 of [5], side information on the activation of
spectral envelope diffuser is transmitted to suppress too sharp peak at LP
spectrum at the decoder side, 1 bit is decoded to obtain the activation flag.
In case the value equals to 1, spectral envelope diffuser is activated,
otherwise de-activated. When spectral envelope diffuser is active, the
following procedure is performed at the recovery frame.
A modified LSF parameter {width="0.34652777777777777in"
height="0.2777777777777778in"} for the previous frame is calculated by placing
the low-order coefficients of the LSF parameter of the concealed frame
{width="0.34652777777777777in" height="0.2777777777777778in"} at equal space.
{width="1.7916666666666667in" height="0.4861111111111111in"} (88)
Then the LSF parameter for the current frame is replaced by the sum of mean
vector of the current coder type and the residual LSF vector obtained in the
decoding of the current frame, and bandwidth separation is applied.
This bandwidth separation is applied to ensure stability and suppress too
sharp peak in LP spectrum. The distances are wider than the distance used in
the normal LSF decoding process. In case the internal sampling frequency is
12.8 kHz, the distances are as follows:
{width="2.2083333333333335in" height="0.7083333333333334in"} (89)
Then, LP coefficients are calculated based on those modified LSF parameters,
and used instead of LP coefficients obtained in the ordinary decoding process.
The procedure for conversion from LSF to LPC is the same as normal decoding
process.
#### 5.3.3.3 Energy control during recovery
Precise control of the speech energy is very important in frame erasure
concealment. The importance of the energy control becomes more evident when a
normal operation is resumed after an erased block of frames. Since VC and GC
modes are heavily dependent on prediction, the actual energy cannot be
properly estimated at the decoder. In voiced speech segments, the incorrect
energy can persist for several consecutive frames, which can be very annoying,
especially when this incorrect-valued energy increases.
The goal of the energy control is to minimize energy discontinuities by
scaling the synthesized signal to render the energy of the signal at the
beginning of the recovery frame (a first non-erased frame received following
frame erasure) to be similar to the energy of the synthesized signal at the
end of the last frame erased during the frame erasure. The energy of the
synthesized signal in the received first non-erased frame is further made
converging to the energy corresponding to the received energy parameter toward
the end of that frame while limiting an increase in energy.
If the available bitrate is sufficiently high, the synthesized speech energy
information can be estimated in the encoder and transmitted as a side
information to the decoder. In EVS, the energy information is transmitted only
at 32 and 64 kb/s, using 5 bits. Further, it is transmitted only in the GC
mode. In the TC mode, the energy control is not needed as the TC mode does not
make use of the adaptive codebook, and memory-less LSF quantization is used.
At lower bitrates, the correct energy is estimated at the decoder.
The energy control for LP-based decoding is triggered in the first non-erased
frame following frame erasure for other than TC modes. At frames coded at 7.2
and 8 kb/s, in case that this first non-erased frame is using the
Autoregressive (AR) prediction for the LP filter quantization, the energy
control is continued in all subsequent frames using the AR prediction. The
energy control is then maintained in yet another frame as the synthesis filter
can still be affected by the filter coefficients interpolation.
The energy control is done in the synthesized speech signal domain. Even if
the energy is controlled in the speech domain, it is the LP excitation signal
that is scaled. The synthesis is then repeated to smooth the transitions.
The energy control in a recovery frame is done as follows. Let
{width="0.19375in" height="0.20833333333333334in"} denote the gain used to
scale the 1st sample in the current frame and {width="0.18055555555555555in"
height="0.20833333333333334in"} the gain used at the end of the frame. The
excitation signal is then scaled as follows
{width="2.3055555555555554in" height="0.20833333333333334in"} (90)
where {width="0.3611111111111111in" height="0.20833333333333334in"} is the
scaled excitation, {width="0.2916666666666667in" height="0.19375in"} is the
excitation before the scaling, {width="0.1388888888888889in"
height="0.1527777777777778in"} is the frame length and
{width="0.5555555555555556in" height="0.20833333333333334in"} is the gain
starting from {width="0.19375in" height="0.20833333333333334in"} and
converging exponentially to {width="0.18055555555555555in"
height="0.20833333333333334in"}. That is
{width="3.6805555555555554in" height="0.20833333333333334in"} (91)
with the initialization {width="0.9027777777777778in"
height="0.20833333333333334in"}. The factor {width="0.3611111111111111in"
height="0.20833333333333334in"} is the attenuation factor set to the value of
0.98. This value has been found experimentally as a compromise of having a
smooth transition from the previous (erased) frame on one side, and scaling
the last pitch period of the current frame as much as possible to the correct
(transmitted) value on the other side. The gains {width="0.19375in"
height="0.20833333333333334in"} and {width="0.18055555555555555in"
height="0.20833333333333334in"} _are defined as_
{width="0.7083333333333334in" height="0.4583333333333333in"} (92)
{width="0.6388888888888888in" height="0.4861111111111111in"} (93)
where {width="0.2638888888888889in" height="0.20833333333333334in"} is the
energy computed at the end of the previous (erased) frame, {width="0.19375in"
height="0.20833333333333334in"} is the energy at the beginning of the current
(recovered) frame, {width="0.18055555555555555in"
height="0.20833333333333334in"} is the energy at the end of the current frame,
and {width="0.20833333333333334in" height="0.2361111111111111in"} is the
target energy at the end of the current frame. At higher
bitrates,{width="0.20833333333333334in" height="0.2361111111111111in"}is
computed at the encoder, quantized and transmitted. The energy information is
quantized using a 5-bit linear quantizer in the range of 0 dB to 96 dB with a
step of 3 dB. The quantization index is given by
{width="1.4861111111111112in" height="0.4583333333333333in"} (94)
The index is limited to the range [0, 31]. At lower bitrates,
{width="0.20833333333333334in" height="0.2361111111111111in"} is estimated at
the decoder.
The energy {width="0.18055555555555555in" height="0.20833333333333334in"} of
the synthesized speech {width="0.44375in" height="0.2777777777777778in"} at
the end of the first non erased frame is first computed as follows. The energy
is the maximum of the signal energy for frames classified as VOICED_CLAS or
ONSET, or the average energy per sample for all other frames. For VOICED_CLAS
or ONSET frames, the maximum signal energy is computed pitch-synchronously at
the end of the current frame as follows:
{width="2.5555555555555554in" height="0.2777777777777778in"} (95)
where _L_ is the frame length at internal sampling rate. Signal
{width="0.44722222222222224in" height="0.28125in"} is the local synthesis
signal sampled at the internal sampling rate. The integer pitch period length
{width="0.3229166666666667in" height="0.20833333333333334in"}is the rounded
pitch period of the last subframe, i.e. $T^{\text{end}} = \left\lfloor
d_{\text{fr}}^{\left\lbrack \text{last} \right\rbrack} + 0\text{.}5
\right\rfloor$.
For all other classes, {width="0.17708333333333334in"
height="0.20833333333333334in"} is the average energy per sample of the last
half of the current frame, i.e.
$E_{1} = \frac{1}{\frac{L}{2}}\sum_{n = \frac{L}{2}}^{L -
1}{\hat{s}}_{1}^{2}\left( n \right)$. (96)
{width="0.2638888888888889in" height="0.20833333333333334in"} is computed
similarly using the synthesized speech signal of the previous (last erased)
frame. When {width="0.2638888888888889in" height="0.20833333333333334in"} is
computed pitch synchronously (i.e. if the class of the previous frame was
VOICED_CLAS or ONSET), it uses the concealment pitch period
{width="0.16666666666666666in" height="0.20833333333333334in"}.
When {width="0.19375in" height="0.20833333333333334in"} is computed pitch
synchronously (the class of the current frame is VOICED_CLAS or ONSET), it is
done similarly using the rounded pitch value {width="0.2638888888888889in"
height="0.20833333333333334in"} of the first subframe:
{width="2.0965277777777778in" height="0.2777777777777778in"} (97)
For other frame classes:
$E_{0} = \frac{1}{\frac{L}{2}}\sum_{n = 0}^{(\frac{L}{2}) -
1}{\hat{s}}_{\text{pre}}^{2}\left( n \right)$. (98)
As mentioned previously, {width="0.20833333333333334in"
height="0.2361111111111111in"}is transmitted from the encoder, but only at
high bitrates. If {width="0.20833333333333334in"
height="0.2361111111111111in"} is not available, it is initialized to
{width="0.18055555555555555in" height="0.20833333333333334in"} and further
limited as described below.
The gains {width="0.19375in" height="0.20833333333333334in"} and
{width="0.18055555555555555in" height="0.20833333333333334in"}are further
limited to a maximum allowed value to prevent too strong energy. This value
has been set to 1.2 with the exception of very low energy frames
({width="0.20833333333333334in" height="0.2361111111111111in"} \ 3 | 0.4 | +---------------------+------------------------------------+--------------+ | VOICED TRANSITION | | 0.4 | +---------------------+------------------------------------+--------------+ | UNVOICED TRANSITION | | 0.8 | +---------------------+------------------------------------+--------------+ | UNVOICED_CLAS | = 1 | 0.2 _θ_ \+ 0.8 | +---------------------+------------------------------------+--------------+ | | = 2 | 0.6 | +---------------------+------------------------------------+--------------+ | | > 2 | 0.4 | +---------------------+------------------------------------+--------------+ | AUDIO \|\| INACTVE | >1 | 0.8 | | | | | | | if GSC had temporal contribution | | +---------------------+------------------------------------+--------------+ | | \5 | 0.95 | +---------------------+------------------------------------+--------------+
#### 5.3.4.2 Specifics for rates 9.6, 16.4 and 24.4 kbps
##### 5.3.4.2.1 Fading to background level
The innovative as well as the harmonic excitation fade to individual target
levels by changing the codebook gains.
{width="2.321527777777778in" height="0.3020833333333333in"} (107)
where: {width="0.2916666666666667in" height="0.3020833333333333in"} is the
gain of the current frame;
{width="0.40625in" height="0.3020833333333333in"} is the gain of the previous
frame;
{width="0.40625in" height="0.25in"} is the target gain;
{width="0.375in" height="0.19791666666666666in"} is the fading factor, its
derivation is outlined in subclause 5.3.4.2.3.
The fading is performed as follows:
$\text{sig}_{\text{faded}}\lbrack i\rbrack = \left( g^{\lbrack m - 1\rbrack} -
\frac{i}{L_{\text{frame}}}\left( g^{\lbrack m - 1\rbrack} - g^{\lbrack
m\rbrack} \right) \right) \cdot \text{sig}\lbrack i\rbrack,i = 0\ldots
L_{\text{frame}} - 1$ (107a)
Where $\text{sig}\lbrack i\rbrack$ is the input signal, e.g. the harmonic or
the innovative excitation, and $\text{sig}_{\text{faded}}\lbrack i\rbrack$ is
the faded output signal.
The harmonic excitation is faded towards zero: {width="0.6145833333333334in"
height="0.3020833333333333in"}.
The innovative excitation is faded towards a target background noise level:
{width="0.7916666666666666in" height="0.3333333333333333in"}. It is derived
during the first lost frame based on the background noise spectrum derived by
CNG during clean channel decoding (see clause 4.3 of [5]). Its derivation is
performed as follows:
a) Derive target level in time domain based on background noise spectrum
{width="0.34375in" height="0.20833333333333334in"}:
{width="1.613888888888889in" height="0.5722222222222222in"} (108)
b) Compensate gain of LPC synthesis / de-emphasis (see also subsection 5.2.5):
$g^{\text{cng}} = g^{\text{cng}} \cdot \frac{1}{n_{\text{subfr}}} \cdot
\sum_{i =
0}^{n_{\text{subfr}}\text{-1}}\text{energ}_{\text{LPC}}^{\left\lbrack i
\right\rbrack}$ (109)
where $\text{energ}_{\text{LPC}}^{\left\lbrack i \right\rbrack}$ is derived
subframe-wise as stated in equation (26).
##### 5.3.4.2.2 Fading to background spectral shape
Separate LPCs are applied for the innovative and the harmonic excitation as
described in subclause 5.3.1. The innovative and the harmonic excitations are
faded to individual target spectral shapes by altering the LPC coefficients.
The fading from the last good LPC coefficients to the target LPC coefficients
is performed in the LSF domain as follows:
{width="2.375in" height="0.25in"} (110)
where: {width="0.3055555555555556in" height="0.3055555555555556in"} are LPC
coefficients in the LSF domain of the current frame;
{width="0.4027777777777778in" height="0.3055555555555556in"} are LPC
coefficients in the LSF domain of the previous frame;
{width="0.4166666666666667in" height="0.25in"} are the target LPC
coefficients;
> {width="0.375in" height="0.19375in"} is the fading factor as described in
> subclause 5.3.4.2.3. In case of the innovative excitation, {width="0.375in"
> height="0.19375in"} will be minimal 0.8.
The target spectral shape of the harmonic excitation is the short term mean of
the last three LPC coefficient sets. Its derivation is performed in the LSF
domain as follows:
{width="2.0965277777777778in" height="0.4305555555555556in"} (111)
The target spectral shape of the innovative excitation is derived during the
first lost frame based on the background noise spectrum derived by CNG during
clean channel decoding (see 4.3 of [5]). Its derivation is performed as
follows:
a) Compute power spectrum on the background noise spectrum.
b) Apply an inverse Fourier transform with length 640 on the power spectrum to
obtain the autocorrelation values {width="0.2916666666666667in"
height="0.20833333333333334in"}with {width="0.5833333333333334in"
height="0.18055555555555555in"}.
c) Do a normalisation of {width="0.2916666666666667in"
height="0.20833333333333334in"} to obtain {width="0.2916666666666667in"
height="0.20833333333333334in"}, if {width="0.625in"
height="0.20833333333333334in"}set {width="0.2916666666666667in"
height="0.20833333333333334in"}to 100 and multiply
{width="0.2916666666666667in" height="0.20833333333333334in"} by 1.0005.
d) Execute the Levinson-Durbin algorithm with the order 16 to obtain the LP
parameters from {width="0.2916666666666667in" height="0.20833333333333334in"}.
e) Finally, transform the LPC coefficients to the LSF domain to obtain
{width="0.4583333333333333in" height="0.25in"}
##### 5.3.4.2.3 Fading speed
The damping factor {width="0.375in" height="0.20833333333333334in"} controls
the fading speed of the innovative and the harmonic excitation and depends on
a bunch of parameters. These are: the number of consecutive lost frames, the
LSF stability factor {width="0.125in" height="0.16666666666666666in"}, the
coder type, the class of the last good frame, the pitch gain
{width="0.2222222222222222in" height="0.2361111111111111in"} and the current
coding mode. With this set of parameters the damping factor is determined as
follows:
\- Firstly, if current coding mode is ACELP_CORE, then
\- in case the coder type is UNVOICED and the number of consecutive lost
frames is maximally three, then {width="0.375in"
height="0.20833333333333334in"}is set to 1
\- else if the last good frame was UNVOICED_CLAS and
\- if it is the first lost frame, then {width="1.1527777777777777in"
height="0.20833333333333334in"}
\- else if exactly two frames are lost, then{width="0.69375in"
height="0.20833333333333334in"}
\- otherwise, if three or more frames are lost, then{width="0.69375in"
height="0.20833333333333334in"}
\- else if the last good frame was UNVOICED_TRANSITION, then{width="0.69375in"
height="0.20833333333333334in"}
\- else if the last good frame was ONSET and number of lost frames are
maximally three and the coder type is GENERIC, then{width="0.69375in"
height="0.20833333333333334in"}
\- else if the last good frame was either VOICED_CLAS or the last good frame
was ONSET and the number of lost frames is maximally three,
then{width="0.5694444444444444in" height="0.20833333333333334in"}
\- otherwise, {width="0.69375in" height="0.20833333333333334in"}
\- besides that, if the last good frame was not one out of the set of {
UNVOICED_CLAS, UNVOICED_TRANSITION, VOICED_TRANSITION }, then
\- in case it is the first erased frame, then {width="1.2222222222222223in"
height="0.2916666666666667in"}, whereas {width="0.34652777777777777in"
height="0.2916666666666667in"}is limited from 0.85 to 0.98
\- else if the number of lost frames are exactly two, then
{width="1.5694444444444444in" height="0.2361111111111111in"}
\- otherwise, if more than two frames are consecutive lost, then the pitch of
gain is changed to the new gain {width="1.375in"
height="0.2361111111111111in"} and following the damping factor is calculated
as{width="1.0965277777777778in" height="0.2361111111111111in"}
\- Otherwise, if current coding mode is not ACELP_CORE and
\- if it is the first lost frame, then {width="1.1527777777777777in"
height="0.20833333333333334in"}
\- else if exactly two frames are lost, then{width="1.2222222222222223in"
height="0.20833333333333334in"}
\- otherwise, if three or more frames are lost,
then{width="1.2222222222222223in" height="0.20833333333333334in"}
## 5.4 Concealment operation related to MDCT modes
### 5.4.1 PLC method selection
There is a multitude of PLC methods for MDCT coding modes available. Best
possible codec performance in error-prone situations with frame losses is
obtained through selecting the most suitable method for a given bit rate,
coded audio bandwidth, used MDCT mode and signal class.
The main selector is the MDCT mode of the previous frame, i.e. TCX MDCT or HQ
MDCT. Second level criteria are described in the following subclauses.
### 5.4.2 TCX MDCT
#### 5.4.2.1 PLC method selection
In case the last good frame prior to a loss was coded with the MDCT based TCX,
a range of different specifically optimized PLC methods are available that are
selected based on second level criteria described in this subclause. The PLC
methods are:
\- TCX time domain concealment
\- MDCT frame repetition with sign scrambling
\- tonal MDCT concealment using phase prediction
\- non-tonal concealment with waveform adjustment
The criteria evaluated in this second level PLC method selection are
\- Last MDCT mode: The MDCT mode of the last good frame {width="0.53125in"
height="0.17708333333333334in"} is obtained by decoding the bitstream in every
good frame.
\- Number of consecutively lost frames: The number of consecutively lost
frames is increased in case of a frame loss and is reset in a good received
frame.
\- Last unmodified LTP gain: If LTP information is updated in the last good
frame, the variable {width="0.9888888888888889in"
height="0.20833333333333334in"} contains the LTP gain, and otherwise it is
zero.
\- Tonal MDCT peak detection flag: The flag {width="0.9680555555555556in"
height="0.17708333333333334in"} describes whether tonal MDCT concealment using
phase prediction should be done. It is set to zero by default and remains zero
if one of the following conditions is true:
\- the last core or the second last core is not mode TCX20
\- the last unmodified LTP gain is bigger than 0.4 and the last pitch is
bigger than {width="0.29097222222222224in" height="0.17708333333333334in"}
\- the last pitch differs from the second last pitch
\- TNS was active in the last or second last frame
Otherwise, {width="0.9680555555555556in" height="0.17708333333333334in"} is
set to one if the output of the peak detection of tonal components (see
subclause 5.4.2.4.2) matches one of the following criteria:
\- the number of found peaks is higher than 10; or
\- the number of found peaks is higher than 5 and the difference between the
3^rd^ and 2^nd^ last pitch is smaller than 0.5 or
\- at least one peak is found and the last good frame was either
UNVOICED_TRANSITION or UNVOICED_CLAS and the difference between the 3^rd^ and
2^nd^ last pitch is smaller than 0.5 and the last unmodified LTP gain is
{width="0.40625in" height="0.16666666666666666in"}.
\- Flag enabling non-tonal concealment with waveform adjustment: The flag
{width="1.2597222222222222in" height="0.20833333333333334in"} is set to one if
the bit rate is one out of the set of {48 kbps, 96 kbps, 128 kbps}.
\- Intelligent gap filling:\ The intelligent gap filling flag
{width="0.23958333333333334in" height="0.20833333333333334in"}describes
whether intelligent gap filling is active (1) or not (0) (see subclause
5.4.2.6).
\- TCX_Tonality flag array:\ array of tonality flags of the last ten received
frames (see subclause 5.4.5.3a).
The decision logic of the different PLC methods is done with the criteria
shown above. The selection of the PLC is performed only in the first lost
frame after a good frame and pertained in subsequently lost frames.
**TCX time domain concealment** is selected if:
\- {width="0.9722222222222222in" height="0.18055555555555555in"}flag is zero;
and
> \- {width="0.5277777777777778in" height="0.18055555555555555in"} is TCX_CORE
> and {width="1.3055555555555556in" height="0.20833333333333334in"}and the
> last good frame was neither UNVOICED_TRANSITION nor UNVOICED_CLAS.
In all other cases, the three MDCT-based concealment methods are selected as
described below.
**MDCT frame repetition with sign scrambling** is selected if:
\- {width="0.9680555555555556in" height="0.17708333333333334in"} is one (in
conjunction with tonal MDCT concealment using phase prediction); or
\- {width="0.9722222222222222in" height="0.18055555555555555in"} is zero and
non-tonal concealment with waveform adjustment is not active.
**Tonal MDCT Concealment using phase prediction** is selected if:
\- {width="0.9722222222222222in" height="0.18055555555555555in"} is one
**Non-tonal concealment with waveform adjustment** is selected if:
\- {width="1.2638888888888888in" height="0.20833333333333334in"} is one,
{width="0.9722222222222222in" height="0.18055555555555555in"}is zero and there
is no transition having a larger frame size than a normal TCX20 frame; and
\- the lost frame is considered to be a non-tonal frame, which requires that
the TCX_Tonality flag array contains five or less ones or one out of the last
three frames is not TCX20.
If a MDCT-based PLC mode is selected and {width="0.2361111111111111in"
height="0.20833333333333334in"}is one, some missing information are added with
the intelligent gap filling concealment.
#### 5.4.2.2 TCX time domain concealment
The time domain PLC for TCX is called if the core of the last good frame was
TCX and if in the PLC method selection as describe in subclause 5.4.2.1 the
TCX time domain concealment was chosen. This concealment method has some
similarity to the ACELP like concealment described in subclause 5.3.1. Due to
the fact, that this method is operating in the excitation domain to shape the
noise towards the vocal tract and preventing discontinuities, a local LPC
analysis is applied to the synthesized time domain signal
{width="0.4722222222222222in" height="0.20833333333333334in"} of the last
frame. To improve the LPC analysis, first the {width="0.4722222222222222in"
height="0.20833333333333334in"} signal is filtered with the pre-emphasis
filter described in subclause 5.1.3 of [5] to obtain
{width="0.6527777777777778in" height="0.2361111111111111in"}. After that, an
LPC analysis is applied on {width="0.6527777777777778in"
height="0.2361111111111111in"} same as in subclause 5.1.5 of [5], but with the
frame length{width="0.1388888888888889in" height="0.1527777777777778in"}and
the analysis window, which first three-quarter part is a hamming window and
last quarter part is a cosine window. The residual signal
{width="0.3611111111111111in" height="0.20833333333333334in"} is obtained by
filtering {width="0.6527777777777778in" height="0.2361111111111111in"} through
the inverse filter same as in subclause 5.2.2.4.1.1 of [5]. The local LPC
parameters and the excitation signal {width="0.3611111111111111in"
height="0.20833333333333334in"} are stored for multiple frame loss.
##### 5.4.2.2.1 Construction of the periodic part of the excitation
If the last good frame was neither UNVOICED_CLAS nor UNVOICED_TRANSITION in
combination with coder type being GENERIC, a harmonic part and a random part
of excitation have to be generated for a concealment of erased frames.
Otherwise, only a random part has to be generated. The harmonic part of the
excitation is constructed by repeating the last pitch period of the previous
frame. If this is the case of the first erased frame after a good frame and
the ISF stability factor is lower than one, the first pitch cycle is first
low-pass filtered. The filter used is core sampling rate dependant and
consists of an 11-tap linear phase FIR filter. The filter coefficients for
core sampling rates lower or equal then 16 000 Hz are:
{width="5.083333333333333in" height="0.20833333333333334in"}, (112)
for core sampling rate equal to 25600 Hz
{width="5.125in" height="0.20833333333333334in"} (113)
and for higher core sampling rates
{width="5.346527777777778in" height="0.20833333333333334in"}. (114)
The periodic part of the excitation is constructed as described in subclause
5.3.1 including the pitch extrapolation as described in subclause 5.3.1.1 and
the glottal pulse resynchronization as described in subclause 5.3.1.3. The
pitches used to get the pitch extrapolation are based on the LTP lag and gains
coming from the last TCX frames.
These LTP lag and gain are sent in the bitstream as side information. The
specific handling as described in subclause 5.3.1.5 is used for TCX time
domain concealment at all bitrates, additionally with the specific low-pass
filtering of the first pitch cycle as described above.
The gain of pitch,{width="0.2222222222222222in"
height="0.2361111111111111in"}, is calculated on {width="0.6527777777777778in"
height="0.2361111111111111in"} as follows:
{width="3.4583333333333335in" height="1.0965277777777778in"} (115)
where {width="0.6666666666666666in" height="0.2361111111111111in"} are samples
of pre-emphased prior time data,{width="0.375in"
height="0.2361111111111111in"} is the length of a subframe in samples and
{width="0.16666666666666666in" height="0.20833333333333334in"} is the rounded
pitch period equal to the LTP lag of the last good frame. The gain of pitch is
limited between zero and one to prevent unexpected increase of energy. The
formed adaptive excitation is attenuated sample-by-sample throughout the frame
starting with one and ending with the damping factor calculated same as in
subclause 5.3.4.2.3. To get a proper overlap add in the case the next good
frame is a valid TCX frame, half a frame is additional created the same as
describe above.
The attenuation strategy of the periodic part of the excitation is the same as
done in subclause 5.3.4.2.1.
##### 5.4.2.2.2 Construction of the random part of the excitation
The innovative (non-periodic) part of the excitation is generated by a simple
random generator with approximately uniform distribution. If the last good
frame was VOICED_CLAS or ONSET, a pre-emphased filtering of the noise is done
same as [19] subclause 5.1.3, but with the pre-emphasis factor of 0.2 for core
sampling rates lower or equal then 16 kHz and 0.6 for all other rates. The
filtering is applied to decrease the amount of noisy components in the lower
frequencies speech region. Furthermore, to shift the noise more to higher
frequencies, the noise gets filtered by a 10-order high pass FIR filter in
case of the first erased frame after a good frame and if the last good frame
was neither UNVOICED_CLAS nor UNVOICED_TRANSITION. The filter coefficients are
{width="5.513888888888889in" height="0.20833333333333334in"} (116)
for core sampling rates lower or equal than 16000 Hz,
{width="5.638888888888889in" height="0.20833333333333334in"} (117)
for the core sampling rate of 25600 Hz and
{width="5.638888888888889in" height="0.20833333333333334in"} (118)
for all other rates. For the second and further lost frames, the noise is
composed via a linear interpolation between the fullband and a highpass-
filtered version of it as
{width="4.75in" height="0.2361111111111111in"} (119)
where {width="0.4861111111111111in" height="0.20833333333333334in"}are noise
samples generated as described in beginning of this subclause,
{width="0.6111111111111112in" height="0.2361111111111111in"} are
{width="0.4861111111111111in" height="0.20833333333333334in"} filtered with
the highpass filter above and {width="1.375in"
height="0.20833333333333334in"}is a frame wise cumulative factor of the
damping factors. This ensures that the noise fades to fullband noise with the
fading speed dependently on the damping factor.
The innovation gain,{width="0.19375in" height="0.20833333333333334in"}, which
is used for adjusting the noise level, is calculated as
{width="3.3465277777777778in" height="0.8333333333333334in"} (120)
where {width="0.2222222222222222in" height="0.2361111111111111in"}is
calculated as in equation (115). However, if the last good frame was neither
UNVOICED_CLAS nor UNVOICED_TRANSITION in combination with coder type being
GENERIC, {width="0.2222222222222222in" height="0.2361111111111111in"}is set to
zero for calculating{width="0.19375in" height="0.20833333333333334in"} and the
pitch buffer get reset.
The attenuation strategy of the random part of the excitation is somewhat
different from the attenuation of the periodic excitation. The reason is that
the pitch excitation is converging to zero while the random excitation is
fading towards the background level {width="0.3194444444444444in"
height="0.25in"} described in 5.3.4.2.1. The background level is limited
to{width="0.3333333333333333in" height="0.20833333333333334in"}. The random
part of the excitation is attenuated linearly throughout the frame on a
sample-by-sample basis starting with {width="0.19375in"
height="0.20833333333333334in"} and going to the end of the frame gain which
is
{width="2.0833333333333335in" height="0.25in"} (121)
where {width="0.3194444444444444in" height="0.25in"} is the gain in the last
sample of the noise signal and {width="0.375in"
height="0.20833333333333334in"} is the damping factor as calculated in
subclause 5.3.4.2.3. Due to the fact that {width="0.19375in"
height="0.20833333333333334in"} is a relative component, the noise gets
normalized. If the last good frame was UNVOICED_CLAS and the coder type is not
UNVOICED, the innovative excitation is further attenuated by a factor of 0.8.
Otherwise, if the last good frame was not UNVOICED_CLAS and not
UNVOICED_TRANSITION, the excitation is further attenuated by
{width="0.7361111111111112in" height="0.2361111111111111in"}.
To get a proper overlap add in the case the next good frame is a valid TCX
frame, half a frame is additional created the same as describe above.
##### 5.4.2.2.3 Construction of the total excitation, synthesis and updates
Finally, the random part of the excitation is added to the adaptive excitation
to form the total excitation signal. If the last good frame is UNVOICED_CLAS
or last good frame is UNVOICED_TRANSITION and coder type is GENERIC, only the
innovative excitation is used as mentioned above. The synthesized signal is
obtained by filtering the total excitation signal through the LP synthesis
filter (see [5] subclause 6.1.3) with the local calculated LPC parameters and
post-processed with the de-emphases filter, which is the inverse of [5]
subclause 5.1.3.
If LTP information is available in the last good frame and {width="0.19375in"
height="0.20833333333333334in"}is equal to zero then the
{width="0.9861111111111112in" height="0.20833333333333334in"}is reset to zero.
In the end the overlap and add buffers get updated same as in subclause 5.4.5.
#### 5.4.2.3 MDCT frame repetition with sign scrambling
The excitation of the concealed frame (input to FDNS) {width="0.5in"
height="0.25in"}is derived by sign scrambling of the last received excitation
spectrum {width="0.9861111111111112in" height="0.2361111111111111in"}:
{width="4.208333333333333in" height="0.4305555555555556in"} (122)
{width="0.7222222222222222in" height="0.20833333333333334in"} is the IGF cross
over frequency. The {width="0.8611111111111112in"
height="0.18055555555555555in"} is derived as
$\text{randomVector}(k) = \text{randomVector}(k - 1) \cdot \text{31821} +
\text{13849},\text{\ \ for\ }k = \lbrack
1,\text{.}\text{.}\text{.},\text{igfStartLine}\rbrack$ (123)
For any lost frame following a received frame, the initial value is reset:
$\text{randomVector}(0) = \text{1977}$ (123a)
If the last 2 spectra are coded using TCX5, then the one with smaller energy
is chosen.
The spectrum {width="0.5in" height="0.25in"} is faded towards noise as
described in subclause 5.4.6.1.3.2.1.
#### 5.4.2.4 Tonal MDCT concealment using phase prediction
##### 5.4.2.4.1 Overview
The phase prediction described in subclause 5.4.2.4.3 is performed on the
spectral coefficients belonging to tonal components found using the peak
detection described in subclause 5.4.2. For the spectral coefficients not
belonging to the tonal components, the sign scrambling is applied as described
in subclause 5.4.2.3.
##### 5.4.2.4.2 Peak detection of tonal components
Peak detection is performed if the current frame is lost but the previous
frame has been received.
The peaks are first searched in the power spectrum of frame
{width="0.3229166666666667in" height="0.16666666666666666in"}, using
predefined thresholds. Based on the location of the peaks in frame
{width="0.3229166666666667in" height="0.16666666666666666in"}, the thresholds
for the search in the power spectrum of frame$m - 1\text{.}5$ are adapted,
whereas frame $m - 1\text{.}5$ represents the second 10ms of frame $m - 2$ and
the first 10ms of frame $m - 1$. Thus, peaks existing in both spectra
({width="0.3229166666666667in" height="0.16666666666666666in"} and $m -
1\text{.}5$) are found. Their exact location is based on the power spectrum of
frame $m - 1\text{.}5$.
The power spectra ${\overset{\sim}{P}}^{\lbrack m - 1\text{.}5\rbrack}\left( k
\right)$ and ${\overset{\sim}{P}}^{\lbrack m - 1\rbrack}\left( k \right)$ are
obtained as follows:
${\overset{\sim}{P}}^{\lbrack y\rbrack}\left( k \right) = \left| S^{\lbrack
y\rbrack}\left( k \right) \right|^{2} + \ \left| C^{\lbrack y\rbrack}\left( k
\right) \right|^{2},y \in \left{ m - 1\text{.}5,m - 1 \right},k =
0\ldots\text{nSamples} - 1$ (124)
where $S^{\lbrack y\rbrack}\left( k \right)$ represents the MDST coefficients
and $C^{\lbrack y\rbrack}\left( k \right)$represents the MDCT coefficients and
{width="0.5833333333333334in" height="0.20833333333333334in"} being the number
of spectral coefficients. A minimum significant value of a spectral line in
the power spectrum is assured by this operation:
{width="2.0833333333333335in" height="0.4888888888888889in"} (125)
$C^{\lbrack m - 1\text{.}5\rbrack}\left( k \right)$ and $S^{\lbrack m -
1\text{.}5\rbrack}\left( k \right)$ are derived from the time domain signal
via MDCT/MDST. $C^{\left\lbrack m - 1 \right\rbrack}\left( k \right)$is given
and $S^{\left\lbrack m - 1 \right\rbrack}\left( k \right)$ is estimated:
$\left| S^{\lbrack m - 1\rbrack}(k) \right| = \left| C^{\lbrack m -
1\rbrack}(k + 1) - C^{\lbrack m - 1\rbrack}(k - 1) \right|$ (126)
If the change of the pitch lag between the last and the second last frame is
larger or equal than 0.25 or the pitch lag is smaller than 10ms (corresponding
to $F_{0} = 22 23 else {width="0.6666666666666666in"
height="0.4305555555555556in"}
* * *
The smoothed power spectra are calculated as follows:
$P_{\text{smoothed}}^{\left\lbrack y \right\rbrack}(k) = 0\text{.}\text{75}
\cdot P^{\lbrack y\rbrack}(k - 1) + P^{\lbrack y\rbrack}(k) +
0\text{.}\text{75} \cdot P^{\lbrack y\rbrack}(k + 1),y \in \left{ m -
1\text{.}5,m - 1 \right}$ (131)
##### 5.4.2.4.2.1 Detection of the peak candidates {#detection-of-the-peak-
candidates .H6}
If the smoothed spectrum $P_{\text{smoothed}}^{\left\lbrack m - 1
\right\rbrack}$ is above the envelope {width="0.84375in" height="0.25in"} at
bin {width="0.125in" height="0.17708333333333334in"}and the smoothed spectrum
at bin {width="0.125in" height="0.17708333333333334in"} is bigger than at bins
{width="0.2916666666666667in" height="0.16666666666666666in"} and
{width="0.3020833333333333in" height="0.17708333333333334in"}, $k$ is treated
as peak candidate {width="0.2916666666666667in"
height="0.20833333333333334in"} and the right and left foot of this peak
candidate are searched for.
The right foot is defined as the spectral bin with index
{width="0.13541666666666666in" height="0.20833333333333334in"}, for which
{width="1.5416666666666667in" height="0.25in"} (132)
and
{width="2.8222222222222224in" height="0.25in"} (133)
It is also allowed for an {width="1.0930555555555554in" height="0.25in"} that
{width="1.5520833333333333in" height="0.25in"} is true, but only if
{width="1.6972222222222222in" height="0.25in"}and if there is a $k  \
\text{Envelope}^{\lbrack m - 1\rbrack}(k) \ 1\text{.}5\ \text{otherwise}\ \
\end{matrix} \right.\ $ (136)
If the change of the pitch between the last and the second last frame is
smaller then 0.5, then for each
\- {width="0.6666666666666666in" height="0.20833333333333334in"}, for each
{width="0.5409722222222222in" height="0.19791666666666666in"}, $N$being the
number of the harmonics of $F_{0}$, {width="0.9583333333333334in"
height="0.20833333333333334in"}
\- $k = \left\lfloor m \cdot F_{0}^{\text{orig}} \right\rfloor$, for each $m
\in \left\lbrack 1,\left\lfloor F_{0}F_{0}^{\text{orig}} + 0\text{.}5
\right\rfloor \right\rbrack$,$\text{frac} = m \cdot F_{0}^{\text{orig}} - k$
thresholds are updated as follows:
$\begin{matrix} \text{Threshold}(k) = \text{thresh}_{\text{base}} \
\text{Threshold}(k - 1) = \text{thresh}_{\text{base}} + 2 \cdot \text{frac} \
\text{Threshold}(k + 1) = \text{thresh}_{\text{base}} + 2 \cdot (1 -
\text{frac}) \ \end{matrix}$ (137)
with
$\text{thresh}_{\text{base}} = \left{ \begin{matrix} 0\text{.}\text{70}\
\text{when}\ F_{0}^{\text{orig}} > 0\ \text{and}\ F_{0} = 0 \
0\text{.}\text{35}\ \text{when}\ F_{0}^{\text{orig}} > 0\ \text{and}\ F_{0} >
0 \ \end{matrix} \right.\ $ (138)
For all bins not belonging to peaks or harmonics the threshold is set as:
$\text{Threshold}(k) = \text{16}$. (140)
Note: The base threshold 7.59, as given in equation 129, corresponds to
$8\text{.}8\text{dB}$. All other thresholds, represented by
$\text{Threshold}(k)$, are given relative to this base threshold. Thus,
\- 0.35 corresponds to $4\text{.}\text{24}\text{dB}$
\- 0.7 corresponds to $7\text{.}\text{25}\text{dB}$
\- 1.1 corresponds to $9\text{.}\text{21}\text{dB}$
\- 1.5 correspnds to $\text{10}\text{.}\text{56}\text{dB}$
\- 16 corresponds to $\text{20}\text{.}\text{84}\text{dB}$
##### 5.4.2.4.2.2 Final detection of the tonal components {#final-detection-
of-the-tonal-components .H6}
After setting the thresholds {width="0.7916666666666666in"
height="0.20833333333333334in"} as described in subclause 5.4.2.4.2.1, peaks
detected in frame $m - 1$ are now searched for in the power spectrum of frame
$m - 1\text{.}5$.
If the following is fulfilled:
$\begin{matrix} P_{\text{smoothed}}^{\left\lbrack m - 1\text{.}5
\right\rbrack}(k) > \text{Envelope}^{\lbrack m - 1\text{.}5\rbrack}(k) \cdot
\text{Threshold}(k) \ P_{\text{smoothed}}^{\left\lbrack \text{m-1}\text{.}5
\right\rbrack}(k) \geq \text{max}\left( P_{\text{smoothed}}^{\left\lbrack
\text{m-1}\text{.}5 \right\rbrack}(k - 1),P_{\text{smoothed}}^{\left\lbrack
\text{m-1}\text{.}5 \right\rbrack}(k + 1) \right) \ \end{matrix}$ (141)
the right and left foot of the peak is searched for in $P^{\lbrack m -
1\text{.}5\rbrack}$ around {width="0.125in" height="0.17708333333333334in"}.
The algorithm for the foot search is the same as the one in subclause
5.4.2.4.2.1.
**The local maximum** {width="0.2916666666666667in"
height="0.20833333333333334in"} **is then found between the left and the right
foot.**
**A tonal component is defined as the set of spectral bins**
{width="1.6354166666666667in" height="0.20833333333333334in"}. If two
neighboring tonal components would overlap, their surroundings are
symmetrically reduced such that each spectral bin belongs only to one tonal
component. All tonal components then build the set {width="0.375in"
height="0.20833333333333334in"}.
##### 5.4.2.4.3 Phase prediction
For all found tonal components {width="0.375in"
height="0.20833333333333334in"}, that include spectrum peaks and their
surroundings, as described in subclause 5.4.2.4.2.2, the MDCT phase prediction
is used. For all other spectrum coefficients sign scrambling described in
subclause 5.4.2.3 is used.
The phases are derived for each bin of a tonal component as:
$\phi^{\lbrack m - 1\text{.}5\rbrack}\left( k \right) = \text{arctan}\left(
\frac{S^{\lbrack m - 1\text{.}5\rbrack}(k)}{C^{\lbrack m -
1\text{.}5\rbrack}(k)} \right)$, {width="1.375in"
height="0.20833333333333334in"} (142)
The fractional part {width="0.17708333333333334in"
height="0.16666666666666666in"} is given by:
{width="1.0541666666666667in" height="0.4013888888888889in"} (143)
with _a_ given in Table 2, depending on the neighboring bins around a spectral
peak {width="0.4722222222222222in" height="0.20833333333333334in"}.
Table 9: Variable a from equation (143)
* * *
if a {width="1.8590277777777777in" height="0.25in"}
{width="0.6243055555555556in" height="0.4013888888888889in"}
{width="1.8729166666666666in" height="0.25in"} {width="0.6243055555555556in"
height="0.4013888888888889in"} else {width="2.261111111111111in"
height="1.0402777777777779in"}
* * *
Where the bandwidth _b_ is 7, the maximum ratio {width="0.2222222222222222in"
height="0.1388888888888889in"}is 44.8 and the constant _G_ is
{width="0.45694444444444443in" height="0.3597222222222222in"}.
The phase shift, being the same for every spectrum bin in
{width="0.3333333333333333in" height="0.20833333333333334in"}, is derived as
follows
$\text{Δϕ} = \pi \cdot l\text{\%}4 + \text{Δl}$, (144)
where {width="0.46875in" height="0.20833333333333334in"} is the index of the
bin closest to the peak and {width="0.17708333333333334in"
height="0.16666666666666666in"}is the fractional part (i.e. distance of the
peak from {width="0.2916666666666667in" height="0.20833333333333334in"} given
as the fractional number of bins).
The current phase {width="0.46875in" height="0.25in"} is estimated for each
{width="0.5416666666666666in" height="0.20833333333333334in"} using:
$\phi^{\lbrack m\rbrack}\left( k \right) = \phi^{\lbrack m -
1\text{.}5\rbrack}\left( k \right) + n_{\text{frmdist}} \cdot \text{Δϕ}$ (145)
where $n_{\text{frmdist}} = 1\text{.}5$ for the first concealed frame and
$n_{\text{frmdist}}$ is increased for 1 for every consecutive frame loss. The
correspondingt MDCT bins are estimated as:
$C^{\lbrack m\rbrack}\left( k \right) = \sqrt{P^{\lbrack m -
1\text{.}5\rbrack}\left( k \right)} \cdot \text{cos}\left( \phi^{\lbrack
m\rbrack}\left( k \right) \right)$. (146)
#### 5.4.2.5 Non-tonal concealment with waveform adjustment
##### 5.4.2.5.1 Preliminary concealment in frequency domain
The MDCT coefficients of the current lost frame are computed by using the MDCT
coefficients of the frame prior to the current lost frame as follows:
The MDCT coefficients at all frequency points of the frame prior to the
current lost frame are multiplied by random signs to obtain the MDCT
coefficients of all frequency points of the current lost frame. In other
words, when the current lost frame is the {width="0.25in" height="0.25in"}
frame,
{width="2.4305555555555554in" height="0.25in"} (147)
wherein {width="0.44375in" height="0.25in"}is the MDCT coefficient at the
frequency point {width="0.18055555555555555in" height="0.1527777777777778in"}
of the {width="0.25in" height="0.25in"} frame, {width="0.2222222222222222in"
height="0.18055555555555555in"} is the total number of the frequency points,
and {width="0.5277777777777778in" height="0.2222222222222222in"} is the random
sign at the frequency point {width="0.18055555555555555in"
height="0.1527777777777778in"}.
The obtained MDCT coefficients of the current lost frame are transformed by an
IMDCT to produce the initially compensated signal of the current lost frame.
##### 5.4.2.5.2 Waveform adjustment in time domain
Waveform adjustment is performed on the initially compensated signal of the
current lost frame to obtain the compensated signal of the current lost frame.
The detailed procedure of the waveform adjustment is described as follows:
When the first lost frame occurs, the pitch period of the current lost frame
is estimated as follows:
The pitch search is performed over the time-domain signal of the frame prior
to the current lost frame by using the autocorrelation method to obtain the
value of the pitch period of the frame prior to the current lost frame. The
obtained pitch period value is used as the pitch period value of the current
lost frame and to compute the maximum of normalized autocorrelation of the
current lost frame. Detailedly, {width="2.1666666666666665in" height="0.25in"}
is searched so that
{width="1.2638888888888888in" height="0.7083333333333334in"} (148)
achieves the maximum value, then the resulting {width="9.652777777777778e-2in"
height="0.16666666666666666in"} is the value of the pitch period, denoted by
{width="0.1527777777777778in" height="0.18055555555555555in"}, wherein
{width="0.3055555555555556in" height="0.25in"} and
{width="0.2916666666666667in" height="0.2361111111111111in"} are the upper and
lower limits for the pitch searching, respectively, and
{width="0.1527777777777778in" height="0.18055555555555555in"} is the frame
length, {width="0.2916666666666667in" height="0.2222222222222222in"} with
{width="0.8055555555555556in" height="0.19375in"} is the time-domain signal
(the signal before TCX long-time prediction and post-processing) over which
the pitch search is performed. {width="0.3055555555555556in" height="0.25in"}
and {width="0.2916666666666667in" height="0.2361111111111111in"}are obtained
as follows:
{width="1.2222222222222223in" height="0.20833333333333334in"} (149)
{width="1.3888888888888888in" height="0.20833333333333334in"} (150)
wherein {width="0.5555555555555556in" height="0.2222222222222222in"} denotes
the rounding operation. Define
{width="1.8333333333333333in" height="1.0138888888888888in"} (151)
then {width="0.3888888888888889in" height="0.2222222222222222in"} is the
maximum of normalized autocorrelation. When the frame length
{width="0.1527777777777778in" height="0.18055555555555555in"} is not greater
than 320, define:
{width="0.6805555555555556in" height="0.20833333333333334in"} (152)
wherein {width="0.19375in" height="0.19375in"} indicates taking the greatest
integer value less than or equal to {width="0.1388888888888889in"
height="0.1527777777777778in"}_. Comparing_ {width="0.3333333333333333in"
height="0.19375in"} with {width="0.4305555555555556in"
height="0.20833333333333334in"}_, the pitch period is reset as_
{width="0.4583333333333333in" height="0.20833333333333334in"} _in case_
{width="0.8611111111111112in" height="0.20833333333333334in"}_._
When the frame length {width="0.1527777777777778in"
height="0.18055555555555555in"} is greater than 320, in the procedure of
estimating pitch period the following processing is carried out before pitch
searching over the time-domain signal of the frame prior to the current lost
frame: the time-domain signal of the frame prior to the current lost frame is
down-sampled towards a half sampling rate, and the down-sampled time-domain
signal is used to replace the original time-domain signal of the frame prior
to the current lost frame for the pitch estimate. Accordingly, the searching
limits {width="0.3055555555555556in" height="0.25in"} and
{width="0.2916666666666667in" height="0.2361111111111111in"}herein are
obtained specifically as follows:
{width="1.375in" height="0.20833333333333334in"} (153)
{width="1.3888888888888888in" height="0.20833333333333334in"} (154)
The following procedure is used to determine whether the pitch period value of
the current lost frame estimated by the above method is usable regarding
subsequent waveform adjustment:
i. Verify the following conditions to find if any one of them is met. If so,
the obtained pitch period value is unusable.
(1) The cross-zero rate of the initially compensated signal of the first lost
frame, denoted by {width="0.7222222222222222in"
height="0.18055555555555555in"}, is greater than a threshold
{width="0.16666666666666666in" height="0.1527777777777778in"}, wherein
{width="0.44375in" height="0.16666666666666666in"} for $L \leq \text{256}$,
and {width="0.5in" height="0.16666666666666666in"} in other cases.
(2) In the frame prior to the current lost frame, the ratio of lower-frequency
energy to whole-frame energy, denoted by {width="0.9722222222222222in"
height="0.20833333333333334in"}, is smaller than a threshold of 0.02. This
ratio is defined as
{width="2.125in" height="1.0138888888888888in"} (155)
wherein {width="0.5138888888888888in" height="0.18055555555555555in"} when the
current lost frame is TCX20, {width="0.5138888888888888in"
height="0.16666666666666666in"} when the current lost frame is TCX10,
{width="0.19375in" height="0.1527777777777778in"} is the total number of the
frequency points.
(3) In the frame prior to the current lost frame, the spectral tilt, denoted
by{width="0.20833333333333334in" height="0.16666666666666666in"}, is smaller
than a threshold {width="0.34652777777777777in"
height="0.1527777777777778in"}, wherein {width="0.6666666666666666in"
height="0.16666666666666666in"} for {width="0.4861111111111111in"
height="0.16666666666666666in"} and {width="0.6666666666666666in"
height="0.16666666666666666in"} otherwise. This spectral tilt is defined as
{width="1.5416666666666667in" height="1.0138888888888888in"} (156)
wherein {width="1.1805555555555556in" height="0.20833333333333334in"} is a
low-pass filtered signal of the time-domain signal of the prior frame. The
low-pass filter is given by:
{width="1.8333333333333333in" height="0.4027777777777778in"} (157)
(4) In the frame prior to the current lost frame, the cross-zero rate of the
second half frame {width="0.2638888888888889in" height="0.19375in"} is greater
than that of the first half frame {width="0.2361111111111111in"
height="0.19375in"} by four times.
ii. If none of the above-mentioned conditions (i.e. the conditions (1)-(4)) is
met, verify whether the obtained pitch period value is usable according to the
following criteria:
(a) When the current lost frame is within a silence segment, the obtained
pitch period value is considered to be unusable. The silence segment is
identified if the logarithm energy of the frame prior to the current lost
frame is smaller than a threshold of 50 or the following two conditions are
met simultaneously:
(1) The maximum of normalized autocorrelation mentioned above in the pitch
estimate procedure is smaller than 0.9.
(2) The result of the current long-time logarithm energy minus the logarithm
energy of the frame prior to the current lost frame is greater than 8.0.
The logarithm energy is defined as:
{width="1.5965277777777778in" height="0.5138888888888888in"} (158)
where {width="1.0555555555555556in" height="0.20833333333333334in"} is the
time-domain signal used as the final decoder output.
The long-time logarithm energy is defined as follows:
Set an initial value {width="0.3888888888888889in"
height="0.16666666666666666in"}. For each frame, if its logarithm energy is
greater than 50 and its cross-zero rate is smaller than 100, the long-time
logarithm energy is updated as below:
{width="2.2222222222222223in" height="0.20833333333333334in"} (159)
where {width="0.7083333333333334in" height="0.16666666666666666in"} and
{width="0.5138888888888888in" height="0.16666666666666666in"}.
(b) When the current lost frame is not within a silence segment and the
maximum of normalized autocorrelation mentioned above is greater than 0.8, the
obtained pitch period value is considered to be usable.
(c) When the criteria (a) and (b) are not met and the cross-zero rate of the
frame prior to the current lost frame is greater than 100, the obtained pitch
period value is considered to be unusable,
(d) When the criteria (a), (b), and (c) are not met and the result of the
current long-time logarithm energy minus the logarithm energy of the frame
prior to the current lost frame is greater than 6.0, the obtained pitch period
value is considered to be unusable,
(e) When the criteria (a), (b), (c), and (d) are not met, and the result of
the logarithm energy of the frame prior to the current lost frame minus the
current long-time logarithm energy is greater than 1.0 and the maximum of
normalized autocorrelation mentioned above is greater than 0.6, the obtained
pitch period value is considered to be usable,
(f) When the criteria (a), (b), (c), (d), (e), and (f) are not met, the
harmonic characteristic of the frame prior to the current lost frame is
verified. When a value {width="0.4027777777777778in" height="0.19375in"}
representing the harmonic characteristic is smaller than a threshold
{width="0.19375in" height="0.18055555555555555in"}, the obtained pitch period
value is considered to be unusable, When the value
{width="0.34652777777777777in" height="0.18055555555555555in"} is greater than
or equal to the threshold {width="0.19375in" height="0.18055555555555555in"},
the obtained pitch period value is considered to be usable, In this case,
{width="0.4861111111111111in" height="0.16666666666666666in"}.
{width="0.34652777777777777in" height="0.18055555555555555in"} can be computed
as follows:
{width="1.0833333333333333in" height="1.0138888888888888in"} (160)
wherein {width="0.16666666666666666in" height="0.2361111111111111in"} is the
fundamental frequency point, {width="0.7222222222222222in"
height="0.20833333333333334in"} is the {width="0.19375in"
height="0.2222222222222222in"} harmonic frequency point of
{width="0.1527777777777778in" height="0.20833333333333334in"}~,~
{width="0.3333333333333333in" height="0.20833333333333334in"} is the MDCT
coefficient at the frequency point {width="0.16666666666666666in"
height="0.25in"}. Due to the quantitative relation between the pitch period
and the pitch frequency, the value of {width="0.7083333333333334in"
height="0.20833333333333334in"} can be computed with the pitch period value
mentioned above. When {width="0.1527777777777778in"
height="0.20833333333333334in"} is not an integer,
{width="0.32013888888888886in" height="0.16527777777777777in"} is computed
with its adjacent one or several frequency points by using rounding.
When the current lost frame is not the first lost frame, the pitch period of
the first lost frame is taken as the estimated pitch period of the current
lost frame,
If the pitch period of the current lost frame is not usable, the initially
compensated signal of the current lost frame is taken as the compensated
signal of the current lost frame; if the pitch period is usable, waveform
adjustment is performed on the initially compensated signal with the time-
domain signal of the frame prior to the current lost frame, that is, the pitch
period is adjusted under certain conditions at first, and then the following
are conducted:
It is supposed that the current lost frame is the $x^{\text{th}}$ lost frame,
wherein $x > 0$, and when $x$ is larger than 4, the initially compensated
signal of the current lost frame is taken as the compensated signal of the
current lost frame, otherwise the following steps are performed;
(a) A buffer is established with a length of $L$;
(b) When $x$ equals 1, the first $\frac{T}{4}$ samples of the buffer are
configured as a first $\frac{T}{4}$-length signal of the initially compensated
signal of the current lost frame, wherein $T$ is the pitch period of the
current lost frame;
(c) When $x$ equals 1, the last pitch period of time-domain signal of the
frame prior to the current lost frame and the first $\frac{T}{4}$-length
signal in the buffer are concatenated, and repeatedly copied into the buffer,
until the buffer is filled up to obtain a time-domain signal with a length of
$L$, and during each copy, if the length of the existing signal in the buffer
is $l$, the signal is copied to locations from $l - \frac{T}{4}$ to $l + T -
1$ of the buffer, wherein $l > 0$, and for the resultant overlapped area with
a length of $\frac{T}{4}$, the signal of the overlapped area is obtained by
adding signals of two overlapping parts after windowing respectively; when $x$
is larger than 1, the last pitch period of compensated signal of the frame
prior to the current lost frame is repeatedly copied into the buffer without
overlapping, until the buffer is filled up to obtain a time-domain signal with
a length of $L$;
(d) When $x$ is less than 4, the signal in the buffer is taken as the
compensated signal of the current lost frame; when $x$ equals 4, overlap-add
is performed on the signal in the buffer and the initially compensated signal
of the current lost frame, and the obtained signal is taken as the compensated
signal of the current lost frame.
For each lost frame without overlap-add processing, an additional signal as a
noise is added to the compensated signal of the frame after the compensated
signal is obtained. The detailed method of adding additional signal is as
follows: firstly, a past signal, namely, the time-domain signal of the frame
prior to the first lost frame (in the case of the first lost frame) or the
initially compensated signal of the prior lost frame (in the case of the
second, third, or fourth lost frame) is passed through a high-pass filter
given as follows to obtain an additional signal:
$H_{\text{HP}}(z) = 1 - 0\text{.}\text{68}z^{- 1}$ (160a)
secondly, additional-signal gain values of the lost frame are estimated as
follows:
$\text{NoiseGain} = 0\text{.}\text{99}\text{NoiseGain} +
0\text{.}\text{01}\text{GainBob}$ (160b)
wherein $\text{NoiseGain}$ is updated sample by sample during a series of
consecutively lost frames with an initial value of zero at the beginning of
the first lost frame and
$\text{GainBob} = 1 - \frac{1}{2}f(T)$ (160c)
where $f(T)$ is the maximum of normalized autocorrelation as described by
equation (151); then, the additional signal is multiplied with the estimated
additional-signal gain values sample by sample, and the additional signal
resulting from multiplication is added to the compensated signal, to obtain a
new compensated signal. For each lost frame with overlap-add processing,
overlap-add is performed after the additional signal is added to the signal in
the buffer.
For the first correctly received frame after the frame loss, if the number of
consecutively lost frames is less than 4, a buffer is established with a
length of $L$, the last pitch period of compensated signal of the frame prior
to the first correctly received frame is repeatedly copied into the buffer
without overlapping until the buffer is filled up, overlap-add is performed on
the signal in the buffer and the time-domain signal obtained by decoding the
first correctly received frame, and the obtained signal is taken as a time-
domain signal of the first correctly received frame. The additional signal
described above is added to the signal in the buffer before overlap-add.
#### 5.4.2.6 Intelligent gap filling
The intelligent gap filling tool is applied on the constructed signal,
generated from one of the three MDCT-based TCX PLC methods, as described in
[5], subclause 6.2.2.3.8. However, with increasing number of lost frames, the
tiled IGF signal gets further attenuated by changing the IGF gain factor for
each scale factor band.
In case of a lost frame, the IGF gain factors calculated in [5] subclause
6.2.2.3.8.3.8 firstly get limited to the maximum value of 12. After that, the
gain factors get changes as follows:
{width="3.2916666666666665in" height="0.4305555555555556in"} (161)
where {width="0.3055555555555556in" height="0.20833333333333334in"} is the IGF
gain factor at scale factor band {width="0.125in"
height="0.18055555555555555in"}and {width="0.75in"
height="0.20833333333333334in"}are the number of consecutively lost frames.
### 5.4.3 HQ MDCT
#### 5.4.3.1 Preliminary signal analysis of past synthesis
The buffer containing the past decoded signal is analysed in a preliminary
step to prepare the PLC selection method described in clause 5.4.3.2 and the
MDCT concealment described in clause 5.4.3.6.
##### 5.4.3.1.1 Resampling to 8 kHz
The last 2 frames of the previous synthesis signal are resampled to 8 kHz
using zero-delay low-pass FIR filter with a cutoff frequency at 4 kHz. The FIR
filter order is 20, 40, 60 for a sampling frequency of 16, 32, 48 kHz,
respectively. The FIR filter coefficients are denoted
{width="0.5138888888888888in" height="0.2361111111111111in"} at 16 kHz,
{width="0.5416666666666666in" height="0.2361111111111111in"} at 32 kHz and
{width="0.5416666666666666in" height="0.2361111111111111in"} at 48 kHz.
Low-pass filtering and downsampling steps are jointly performed with a
polyphase approach; the resampled signal at 8kHz,
{width="1.3194444444444444in" height="0.25in"}, can be computed using the
relationship based on the past synthesis {width="0.4305555555555556in"
height="0.2222222222222222in"}, {width="0.4305555555555556in"
height="0.2222222222222222in"}, {width="0.4305555555555556in"
height="0.2222222222222222in"} at respectively 16, 32 and 48 kHz:
{width="3.5in" height="1.3611111111111112in"} (162)
Note that in the above summations, the past synthesis outside the last 2
frames is by convention considered to be zero. For instance, at 16 kHz, it is
considered that {width="0.6388888888888888in"
height="0.2222222222222222in"}when {width="0.3611111111111111in"
height="0.18055555555555555in"} or {width="0.5138888888888888in"
height="0.18055555555555555in"}.
##### 5.4.3.1.2 Pitch search by cross-correlation
The past synthesis signal resampled to 8 kHz and of length 40 ms,
{width="1.3194444444444444in" height="0.25in"}, is used to perform an open-
loop pitch search as follows:
\- The target signal is defined as the last 6 ms segment from the 40 ms buffer
at 8 kHz: {width="2.013888888888889in" height="0.25in"}
\- A search vector of the same length (6 ms), {width="1.4722222222222223in"
height="0.25in"}, with sliding starting point {width="0.875in"
height="0.2222222222222222in"} is used. The search range
{width="0.4027777777777778in" height="0.2222222222222222in"} covers 33 ms when
the voicing parameter indicates a voiced segment (i.e.
{width="0.12361111111111112in" height="0.1486111111111111in"}=1) and 28 ms
otherwise; therefore the pitch search range is adapted depending on the
voicing indicator {width="0.12361111111111112in"
height="0.1486111111111111in"}, to use a longer search range in case of voiced
signals. The cross-correlation is computed for each index {width="0.125in"
height="0.19375in"} as:
{width="2.388888888888889in" height="0.9722222222222222in"} (163)
> To minimize computational complexity the term {width="0.5694444444444444in"
> height="0.4722222222222222in"} is pre-computed and the term
> {width="1.0138888888888888in" height="0.4722222222222222in"} is updated
> incrementally by removing the first term and adding a new term in each
> iteration.
>
> For each index {width="0.125in" height="0.19375in"}, the maximum correlation
> {width="0.12361111111111112in" height="0.1486111111111111in"} and maximum
> location {width="0.3055555555555556in" height="0.2222222222222222in"} are
> updated as follows: If {width="0.7777777777777778in"
> height="0.20833333333333334in"},{width="0.7729166666666667in"
> height="0.20347222222222222in"} and {width="0.5694444444444444in"
> height="0.2222222222222222in"}, with the initial conditions
> {width="0.35833333333333334in" height="0.1763888888888889in"} and
> {width="0.5694444444444444in" height="0.2222222222222222in"}; this loop is
> stopped whenever {width="0.12361111111111112in"
> height="0.1486111111111111in"}=0 and {width="0.9583333333333334in"
> height="0.20833333333333334in"}.
The pitch is then defined as {width="0.9861111111111112in"
height="0.2222222222222222in"}, which corresponds to the time offset with
respect to the beginning of the target signal (i.e. 34 ms after the beginning
of the past synthesis {width="0.5277777777777778in" height="0.25in"}).
#### 5.4.3.2 PLC method selection
In case the last good frame prior to a loss was coded with HQ MDCT a range of
different specifically optimized PLC methods is available that are selected
based on second level criteria described in this subclause.
The criteria evaluated in this second level PLC method selection are:
\- Output sampling rate\ The output sampling rate
{width="0.3597222222222222in" height="0.21666666666666667in"} in which
response the second level PLC method is selected is one out of the set of
{8000Hz, 16000Hz, 32000Hz, 48000Hz}.
\- Bit rate\ The bit rate {width="0.11041666666666666in"
height="0.12222222222222222in"}in which response the second level PLC method
is selected is one out of the set of the supported bit rates of the EVS
default operation mode [5].
\- Voicing\ The voicing parameter {width="0.12361111111111112in"
height="0.1486111111111111in"}in which response the second level PLC method is
selected is a binary parameter.
\- Correlation\ The correlation parameter {width="0.12361111111111112in"
height="0.1486111111111111in"}computed as in clause 5.4.3.1.2, in which
response the second level PLC method is selected is a correlation coefficient
defined in the number range from [0...1].
\- Transient condition\ The transient condition{width="0.5541666666666667in"
height="0.20347222222222222in"} in which response the second level PLC method
is selected is a vector of dimension 2 of binary parameters
{width="0.2916666666666667in" height="0.20833333333333334in"}indicating a
transient condition {width="0.1527777777777778in"
height="0.20833333333333334in"}in the last good frame or in the frame before
{width="0.125in" height="0.20833333333333334in"}. The determination of the
transient condition for a given HQ MDCT frame is specified in [5], subclause
5.3.2.4.1.1.
\- Spectral envelope stability based speech/music classification\ The Spectral
envelope stability based speech/music classification
{width="0.29097222222222224in" height="0.2298611111111111in"} in which
response the second level PLC method is selected is a binary parameter. This
parameter is a post-processed instance of the envelope stability parameter
{width="0.1388888888888889in" height="0.16597222222222222in"}that is specified
in [5], subclause 6.2.3.2.1.3.2.3 (Noise level adjustment). The spectral
envelope stability based speech/music classification is calculated during the
decoding of the preceding good HQ MDCT frame and stored for use in the context
of the PLC method selection during a bad frame.
The post-processing of this parameter is a Markov smoother with:
\- {speech, music} as hidden states,
\- the normalized envelope stability parameter,
{width="2.2083333333333335in" height="0.3194444444444444in"} (164)
> and its reverse {width="0.31666666666666665in"
> height="0.18888888888888888in"}\ as direct state observation likelihoods for
> music and, respectively, speech,
\- and the transition probabilities\ {width="1.0215277777777778in"
height="0.20347222222222222in"}for going from speech or, respectively, music
state to speech state, and\ {width="1.0486111111111112in"
height="0.20347222222222222in"}for going from speech or, respectively, music
state to music state.
For each good HQ MDCT frame the following sequence of operations is executed:
1) Calculation of the normalized envelope stability parameter
{width="0.1527777777777778in" height="0.20833333333333334in"}and its reverse
{width="0.31666666666666665in" height="0.18888888888888888in"}.
2) Calculation of a priori likelihoods {width="0.19375in"
height="0.20833333333333334in"}for speech and music states based on the state
likelihoods for the instant {width="0.1527777777777778in"
height="0.20833333333333334in"}of the previous (good) frame and the transition
probabilities:
{width="1.3611111111111112in" height="0.4583333333333333in"} (165)
3) Element-wise multiplication of the vector of a priori likelihoods
{width="0.19375in" height="0.20833333333333334in"}with the vector of direct
state observation likelihoods for music and, respectively, speech:
{width="1.1388888888888888in" height="0.5277777777777778in"} (166)
Subsequent normalization yield the vector of state likelihoods
{width="0.125in" height="0.16666666666666666in"}of the current frame:
$p = \frac{p}{\left| p \right|}$ (167)
4) Finally, the index of the largest element of the state likelihood vector
{width="0.125in" height="0.16666666666666666in"}is identified and taken as
speech/music classification result {width="0.29097222222222224in"
height="0.2298611111111111in"} for the present frame.
{width="1.0in" height="0.2777777777777778in"} (168)
5) The state likelihood vector {width="0.125in"
height="0.16666666666666666in"}of the current frame is stored for subsequent
use in the next good HQ MDCT frame.
With the above-specified parameters the second level PLC method selection is
performed as follows:
\- Firstly, if output sampling rate {width="0.3597222222222222in"
height="0.21666666666666667in"}equals 8000 Hz, the PLC method specified in
clauses 5.4.3.3, 5.4.3.4 is applied.
\- Otherwise (if output sampling rate {width="0.3597222222222222in"
height="0.21666666666666667in"}is equal or exceeds 16000 Hz), then:
\- in case the bit rate {width="0.11041666666666666in"
height="0.12222222222222222in"}is less or equal to 48 kbps and
\- if the voicing parameter {width="0.11041666666666666in"
height="0.13541666666666666in"}is set or the correlation parameter
{width="0.11041666666666666in" height="0.13541666666666666in"}exceeds 0.85,
then
> \- the frame loss concealment method specified in subclause 5.4.3.6 is
> applied;
>
> \- otherwise,
>
> \- the frame loss concealment method specified in subclause 5.4.3.5 is
> applied.
>
> \- otherwise (in case the bit rate {width="0.11041666666666666in"
> height="0.12222222222222222in"}is larger than 48 kbps), then:
>
> \- the frame loss concealment method specified in subclause 5.4.3.6 is
> applied under the same condition as above (for bit rates less or equal to 48
> kbps) except for the case that the spectral envelope stability based
> speech/music classification {width="0.29097222222222224in"
> height="0.2298611111111111in"} indicates music, in which case this frame
> loss concealment method is only applied if the correlation parameter
> {width="0.11041666666666666in" height="0.13541666666666666in"}is below 0.6
> or if the voicing parameter {width="0.11041666666666666in"
> height="0.13541666666666666in"}is set;
>
> \- otherwise, if the above condition is not satisfied the frame loss
> concealment method specified in subclause 5.4.3.5 is applied.
\- However, in addition to the conditions specified above, the frame loss
concealment method specified in subclause 5.4.3.6 is only applied under the
provision that the current frame is the first bad frame following a good frame
and that the transient condition vector does not indicate a transient in the
previous or it indicates a transient in the frame before the previous frame.
If this provision is not satisfied, the frame loss concealment method
specified in subclause 5.4.3.5 is applied.
The decoding of HQ MDCT for NB includes the following modules:
\- a frequency domain packet loss concealment (PLC) block,
\- a spectrum decoding block,
\- a memory update block,
\- an IMDCT block,
\- and a time-domain PLC block.
If it is determined that there is an erased frame, the erased frame is
concealed using a PLC method. The bad frame indicator (BFI) set to 1 indicates
that a current frame is erased, or that no useful information exists for that
frame. Similarly, the Prev_BFI flag set to 1 indicates that a previous frame
has been erased.
Figure 2 shows the block diagram for packet loss concealment of NB signals for
the MDCT mode. A frequency-domain approach operates on the frequency domain
signal such as the input to the IMDCT block in the figure. A time-domain
approach operates on the time domain signal after the IMDCT block. When a
frame erasure occurs, the spectral coefficients of the current frame are
estimated. To accomplish this using the frequency-domain approach, the
synthesized spectral coefficients of the last good frame are repeated for the
current frame with signal modification such as a gain scaling and a random
sign changing. In the time-domain approach, an additional PLC operation is
added to enhance the performance of the frequency-domain approach depending on
the input signal characteristics. For this additional operation, the
appropriate packet loss concealment tool, either the phase matching tool or
the repetition and smoothing tool is selected.
{width="3.0659722222222223in" height="5.583333333333333in"}
Figure 2: **Block diagram for NB PLC for MDCT mode**
#### 5.4.3.3 MDCT frame repetition with random sign and gain scaling
When a first frame erasure occurs, packet loss concealment is performed as
follows. In order to conceal the erasure, the signal characteristics of a
decoded signal are used, which results in a classification of the
characteristics of the decoded signal into a stationary and normal frame. A
current frame is determined to be transient using the frame type
(is_transient) which is transmitted from the encoder. The energy difference
(energy_diff) is used to determine if the current frame is stationary, and is
represented by the following equation. The energy difference indicates the
absolute value of a normalized energy difference between energy _E~curr~_ of
the current frame and a moving average _E~MA~_ of per-frame energy. _E~MA~_
will be updated to _E~MA_old~_ in the next frame.
{width="1.2361111111111112in" height="0.4583333333333333in"} (169)
Where,
{width="1.9722222222222223in" height="0.2361111111111111in"} (170)
{width="1.3333333333333333in" height="0.7083333333333334in"} (171)
Depending on the frame type and characteristics, scaling and a random sign are
used when the spectral coefficients are repeated for the current erased frame.
if ( is_transient == 0 ) {
if(energy_diff \old_is_transient[1] == 1 ) {
Repeating the spectral coefficients of the last good frame with 3dB scale-
down;
}
else {
Repeating the spectral coefficients of the last good frame with 3dB scale-
down;
Use random sign from the 2^nd^ band (8^th^ spectral coefficient)
}
}
When multiple erasures have occurred, an adaptive fade-out by regression
method is used. In this adaptive fade-out by regression, a grouped average
norm value of an erased frame is predicted using K grouped average norm values
of the previous good frame through regression analysis.
Figure 3 illustrates the structure of grouped sub-bands when the regression
analysis is applied to a narrowband (supported up to 4.0 KHz) signal. Grouped
average norm values obtained from grouped sub-bands form a vector, which is
referred to as an average vector of grouped norms. K grouped average norm
values of each grouped sub-band (GSb) are used for the regression analysis.
{width="5.551388888888889in" height="2.415277777777778in"}
Figure 3: **Structure of grouped sub-bands**
Figure 4 illustrates the concept of a linear regression analysis and a non-
linear regression analysis. Between the two methods the linear regression
analysis is applied to the adaptive fade-out, wherein the \'average of norms\'
indicates an average norm value obtained by grouping several bands and is the
target the regression analysis is applied to. A linear regression analysis is
performed when the quantized value of the norm is used for an average norm
value of a previous frame. \'Number of PGF\', which is used for a regression
analysis, indicates the number of the previous good frames and is used for a
regression analysis is a variable. The linear regression analysis is
represented by equations (172) and (173).
{width="0.5965277777777778in" height="0.19375in"} (172)
{width="2.0in" height="0.5694444444444444in"} (173)
As in equation (172), when a linear equation is used, the upcoming
transition(_y_) is predicted by obtaining {width="0.125in"
height="0.1388888888888889in"} and {width="0.125in"
height="0.16666666666666666in"}. In this equation, {width="0.125in"
height="0.1388888888888889in"} can be a frame index. In equation (173),
{width="0.125in" height="0.1388888888888889in"} and {width="0.125in"
height="0.16666666666666666in"} are obtained by an inverse matrix. Gauss-
Jordan Elimination is a simple method of obtaining an inverse matrix.
{width="4.040972222222222in" height="1.8930555555555555in"}
Figure 4: **The concept of a linear regression analysis and a non-linear
regression analysis**
Figure 5 is a block diagram of a packet loss concealment block with adaptive
fade-out. Referring to Figure 5, the signal characteristic determiner
determines the characteristics of a signal by using a decoded signal and
classifies the characteristics of the decoded signal into transient and normal
frames. A method of determining a transient frame is now described. The
current frame classification of transient is determined by two parameters: the
frame type (is_transient) which is transmitted from the encoder, and the
energy difference (energy_diff), which is represented by Equation (169).
if(energy_diff \ 0 ){
a = 0;
norm_p[i] = norm_values[0];
}
else {
norm_p[i] = (b+a*(nbLostCmpt-1+num_pgf);
}
With this modified value of {width="0.125in" height="0.1388888888888889in"},
the average norm value of each group is predicted. When the predicted norm is
larger than zero and the norm of the previous frame is non-zero, the gain
calculator block calculates a gain between the average norm value of each
group that is predicted for the erased frame and an average norm value of each
group in the previous good frame. Otherwise, the gain is scaled down by 3 dB
from the initial value of 1.0.
The calculated gain is also adjusted to a predetermined range. In EVS, the
maximum value of the gain is 1.0.
The scaler block applies gain scaling to the previous good frame to predict
spectral coefficients of the erased frame. The scaler block also applies
adaptive muting to the erased frame and a random sign to predicted spectral
coefficients according to characteristics of an input signal, which is also
controlled by the results of the signal characteristic determiner block.
The number indicated by mute_start indicates that muting forcibly starts when
bfi_cnt is equal to or greater than mute_start and when continuous frame
erasures occur. In addition, random_start, related to the random sign, is
analysed in the same way.
According to a method of applying adaptive muting, spectral coefficients are
forcibly down-scaled by 3dB. In addition, the sign of each of the spectral
coefficients is randomly modified to reduce modulation noise generated due to
repetition of spectral coefficients in each frame.
In addition, the random sign is applied to frequency bands equal to or higher
than the second frequency band, as it should be better to use the sign of a
spectral coefficient that is identical to that of the previous frame in a very
low frequency band (0\~200Hz for the first band). Accordingly, a sharp change
in the signal can be smoothed, and an erased frame accurately restored to be
adaptive to the characteristics of the signal, in particular, a transient
characteristic.
{width="3.8069444444444445in" height="4.322222222222222in"}
Figure 5: **Block diagram of a** packet loss **concealment block with adaptive
fade-out**
#### 5.4.3.4 MDCT frame repetition with sign prediction
An analysis of the sign change of the MDCT coefficients in the received frames
is continuously performed. The analysis of {width="0.5277777777777778in"
height="0.2638888888888889in"}and {width="0.6388888888888888in"
height="0.2638888888888889in"}is performed on 4-dimensional bands up to 1.6
kHz ({width="0.4027777777777778in" height="0.16666666666666666in"} MDCT
coefficients divided into {width="0.4027777777777778in"
height="0.16666666666666666in"} bands).
Two 16-dimensional state variables, used to determine the sign of the
reconstructed MDCT vector, {width="0.4722222222222222in" height="0.25in"}and
{width="0.5694444444444444in" height="0.25in"}hold the number of sign switches
between consecutive frames. The analysis takes also into account signal
dynamics (measured by a transient detector), to decide on the reliability of
past data. Updates for both state variables are done only
for{width="0.9722222222222222in" height="0.16666666666666666in"}, if
{width="0.94375in" height="0.16666666666666666in"}the values are set to zero.
Within a sub- band{width="0.8055555555555556in"
height="0.18055555555555555in"}, first state variable is incremented whenever
the sign of the corresponding MDCT coefficients switches:
{width="2.1666666666666665in" height="0.7888888888888889in"} (174)
The second state variable accumulates number of sign switches over consecutive
frames:
{width="2.25in" height="0.24861111111111112in"} (175)
When frame {width="0.15625in" height="0.13541666666666666in"}is lost, the
missing MDCT vector is reconstructed by copying the last available
coefficients. The sign of the reconstructed vector can be preserved or changed
on a sub-band basis (every 4 coefficients). Inside a band {width="0.125in"
height="0.16666666666666666in"}the decision whether to change the sign or not
is based on comparing the second state variable to a pre-determined threshold
as follows (wherein a sign flip or reversal is indicated by -1 and
preservation of the sign is indicated by +1):
> {width="3.5069444444444446in" height="0.5555555555555556in"} (176)
The threshold {width="0.13541666666666666in" height="0.15625in"}is adjusted to
the past decision of the transient detector. The sequential decision logic is
illustrated in Table 10.
Table 10: Sign extrapolation decision logic
+----------------------------------+----------------------------------+ | 1. If any of frames | Apply random sign to the copied | | > {width="0.3229166666666667in" | | | > | | | height="0.16666666666666666in"} | | | > or | | | > {width="0.34375in" | | | > | | | height="0.16666666666666666in"} | | | > contains transient | | +----------------------------------+----------------------------------+ | 2. If frames | Apply sign extrapolation with | | > {width="0.3333333333333333in" | | > | height="0.16666666666666666in"} | | height="0.16666666666666666in"} | | | > or | | | > {width="0.34375in" | | | > | | | height="0.16666666666666666in"} | | | > are good, but frame | | | > {width="0.3333333333333333in" | | | > | | | height="0.16666666666666666in"} | | | > contains transient | | +----------------------------------+----------------------------------+ | 3. If frames | Apply sign extrapolation with | | > {width="0.34375in" | | > height="0 | height="0.16666666666666666in"} | | .16666666666666666in"},{width="0.34375in" | | | > | | | height="0.16666666666666666in"}, | | | > and | | | > {width="0.3333333333333333in" | | | > | | | height="0.16666666666666666in"} | | | > are good | | +----------------------------------+----------------------------------+
#### 5.4.3.5 Phase ECU
Phase ECU is a frame loss concealment method especially suitable for general
audio and music signals. It provides a smooth and faithful time evolution of
the reconstructed signal for a lost frame, wherein the audible impact of a
frame loss is minimized.
Phase ECU is a frame loss concealment technique that operates with a
sinusoidal model under the assumption that the audio signal is composed of a
limited number of individual sinusoidal components. The general principle of
Phase ECU comprises sinusoidal analysis of a previously received good HQ MDCT
coded frame of the audio signal (analysis frame), wherein the sinusoidal
analysis involves identifying frequencies of sinusoidal components of the
audio signal. Further, a sinusoidal model is applied on this previously
synthesized frame, wherein it is used as a prototype frame in order to create
a substitution frame for a lost audio frame. The creation of the substitution
frame is done by time-evolving the identified sinusoidal components of the
prototype frame, up to the time instance of the lost audio frame, in response
to the corresponding identified sinusoidal frequencies.
In more detail Phase ECU operation comprises the steps of sinusoidal analysis,
described in subclause 5.4.3.5.2, and application of the sinusoidal model
based on a prototype frame of the earlier synthesized signal in order to
generate a substitution frame for the lost audio frame, described in subclause
5.4.3.5.3. In addition and prior to this basic Phase ECU operation a transient
analysis step is carried out, described in subclause 5.4.3.5.1 with the
purpose to detect audio signal and burst frame loss conditions under which the
basic Phase ECU operation is adapted in order to ensure maximum reconstruction
signal quality.
##### 5.4.3.5.1 Transient analysis
The purpose of the calculations in transient analysis is the detection of
properties of the previously reconstructed good signal frame or the frame loss
statistics that could lead to suboptimal signal reconstruction quality with
the Phase ECU. Upon such detected conditions phase and magnitude of the
substitution frame are selectively adjusted in order to mitigate potential
quality degradations. Conditions under which such adjustments are carried out
are detected transients or burst losses with several consecutive frame losses.
The result of the transient analysis is phase and magnitude modification
factors corresponding to such adjustments.
Transient analysis is performed on each lost frame, and the following steps
are performed for the first lost frame or for the second lost frame in case
the first lost frame was handled with the method according to subclause
5.4.3.6. For subsequent lost frames transient analysis relies on previously
calculated and stored parameters (that were calculated based on the synthesis
of the last good HQ MDCT frame). For these losses transient analysis adjusts
magnitude spectrum attenuation factors and phase dithering degrees in response
to detected transient or burst loss condition.
The transient analysis is performed in the frequency domain. Two FFTs are
performed on a left and a right part of the analysis frame buffer which
contains the previous synthesis
{width="2.4583333333333335in" height="0.5118055555555555in"} (177)
where {width="0.3194444444444444in" height="0.2076388888888889in"} is the
length of the transient analysis, set to 64, 128, or 192 for WB, SWB, and FB,
and {width="0.3888888888888889in" height="0.2076388888888889in"}is a hamming
window of corresponding length. The resulting FFT spectrum is split into bands
according to Table 11 that are approximately following the size of the human
auditory critical bands, and the energy in each band is calculated.
Table 11: Band start of Phase ECU
* * *
{width="0.125in" height="0.16597222222222222in"} 0 1 2 3 4 5 6 7 8
{width="0.5138888888888888in" height="0.2076388888888889in"} 1 3 6 10 16 32 64
128 192
* * *
{width="1.4722222222222223in" height="1.0930555555555554in"} (178)
Next the ratio of these energies is calculated as
{width="1.0138888888888888in" height="0.4152777777777778in"} (179)
This means that the transient detection is made frequency selectively for each
frequency band{width="0.125in" height="0.16597222222222222in"}. The gain
{width="0.5138888888888888in" height="0.2076388888888889in"} is then compared
with an upper and a lower threshold for onset or respectively offset
detection. If {width="0.7916666666666666in" height="0.2076388888888889in"}or
{width="0.8194444444444444in" height="0.2076388888888889in"}is fulfilled, then
band {width="0.125in" height="0.17916666666666667in"}contains a transient and
{width="0.4861111111111111in" height="0.2076388888888889in"}is set to 1. The
gains {width="0.5277777777777778in" height="0.23472222222222222in"}are set to
1. If a band has a transient, then gain {width="0.5277777777777778in"
height="0.23472222222222222in"}is updated to:
{width="1.625in" height="0.27708333333333335in"} (180)
The gains {width="0.5277777777777778in" height="0.23472222222222222in"} for
the first lost frame are saved into{width="0.5277777777777778in"
height="0.23472222222222222in"}.
The derivation of magnitude and phase modification factors in response to a
detected burst loss condition is described in the following. The variable
{width="0.3055555555555556in" height="0.2076388888888889in"}is set to 1,
{width="0.3194444444444444in" height="0.2076388888888889in"}is set to 0,
and{width="0.69375in" height="0.2076388888888889in"}. An average energy of
each band is calculated:
{width="1.9861111111111112in" height="0.45694444444444443in"} (181)
{width="0.5138888888888888in" height="0.2361111111111111in"}corresponds to a
low-resolution spectrum of the last good frame. This spectrum is used as part
of the burst loss handling feature of Phase ECU. It is used for a spectrally
shaped additive noise signal to which the substitution signal is pulled in
case of burst frame losses.
For subsequent lost frames, the gain {width="0.5277777777777778in"
height="0.23472222222222222in"}is updated according to:
{width="1.7916666666666667in" height="0.27708333333333335in"} (182)
where
$\left{ \begin{matrix} G_{\text{att}} = 0, \ G_{\text{att}} =
K_{\text{att}}\left( N_{\text{lost}} - T_{\text{att}} \right), \
G_{\text{att}} = \text{15}K_{\text{att}} + \left( N_{\text{lost}} -
T_{\text{att}} - \text{15} \right) \cdot 6\text{.}\text{0206}, \
K_{\text{att}} = 4 - \text{round}(S) \ T_{\text{att}} = 2 + \text{round}(S) \
\end{matrix} \right.\ \begin{matrix} N_{\text{lost}}  \text{15} + T_{\text{att}} \ \ \ \end{matrix}$ (183)
Here {width="0.3333333333333333in" height="0.2076388888888889in"}is the number
of consecutive lost frames and$S \in \left\lbrack 0,1 \right\rbrack$is
envelope stability feature described in [5] subclause 6.2.3.2.1.3.3, where the
range endpoints 0 and 1 represent speech and music respectively. If
{width="0.6111111111111112in" height="0.2076388888888889in"}then
{width="1.0833333333333333in" height="0.20833333333333334in"}.
The attenuation factors {width="0.3055555555555556in"
height="0.2076388888888889in"} and {width="0.3194444444444444in"
height="0.2076388888888889in"}are updated as:
{width="1.4722222222222223in" height="0.4840277777777778in"} (184)
Through variable {width="0.3055555555555556in" height="0.2076388888888889in"}
the concealment method is modified by selectively adjusting the magnitude of
the substitution frame spectrum, based on the frequency domain transient
detector status{width="0.5138888888888888in" height="0.2076388888888889in"},
see equation (189).
The scaling factor {width="0.3194444444444444in"
height="0.20833333333333334in"}is used to scale the spectrally shaped additive
noise signal such that, except for the incorporated gradual muting behaviour
through factor {width="0.3611111111111111in" height="0.20833333333333334in"},
it compensates for the energy loss caused by the attenuation with factor
{width="0.3055555555555556in" height="0.20833333333333334in"}. This is an
aspect of the long-term muting behaviour which is outlined in subclause
5.4.6.2.2.
For {width="0.3194444444444444in" height="0.16597222222222222in"},
{width="0.3194444444444444in" height="0.19236111111111112in"} is further
adjusted as{width="0.9583333333333334in" height="0.19236111111111112in"} and
for {width="0.3194444444444444in"
height="0.16597222222222222in"}{width="0.9583333333333334in"
height="0.2076388888888889in"}. This superimposes a low-pass characteristic on
the additive noise signal, which avoids unpleasant high-frequency noise in the
substitution signal.
The variable{width="0.8465277777777778in" height="0.2076388888888889in"} is
initialized to 0, and for {width="1.1805555555555556in"
height="0.2076388888888889in"}the phase dither is calculated:
{width="2.9305555555555554in" height="0.42916666666666664in"} (185)
##### 5.4.3.5.2 Spectrum analysis
The spectrum analysis is carried out in the frequency domain. It is only done
once for the first lost frame after a good HQ MDCT frame. The buffer with the
previous synthesis of the last good HQ MDCT frame (analysis frame) is windowed
and passed through a FFT.
{width="2.263888888888889in" height="0.23472222222222222in"} (186)
where {width="0.44375in" height="0.2076388888888889in"}is a hamming-
rectangular window, and {width="0.34652777777777777in"
height="0.23472222222222222in"}is the length of the FFT set to 512, 1024, or
1536 for WB, SWB, and FB signals,
{width="3.4583333333333335in" height="1.0659722222222223in"} (187)
and {width="0.19375in" height="0.2076388888888889in"}is the length of the
hamming part, and is 96, 192, or 288 for WB, SWB, and FB.
The spectrum {width="0.44375in" height="0.2076388888888889in"}is saved and
used for all consecutive frame losses. Then the magnitude spectrum
{width="0.4861111111111111in" height="0.23472222222222222in"} is calculated.
Then the peaks of this magnitude spectrum are located by a peak picking
method. The number of found peaks is{width="0.4305555555555556in"
height="0.23472222222222222in"}, and the peaks locations
are{width="1.4722222222222223in" height="0.23472222222222222in"}. The
frequency resolution of these peak locations is however still insufficient for
good Phase ECU performance, since the true frequencies of the sinusoidal model
components are rather found in the vicinity of them. Thus, after the peaks in
the magnitude FFT spectrum are found, their positions are further refined to
make them available in highest possible resolution. The refinement is carried
out by using parabolic interpolation, which yields the fractional peak
locations{width="1.4722222222222223in" height="0.23472222222222222in"}.
This sinusoidal model is also used in reconstruction of the lost audio frame.
##### 5.4.3.5.3 Frame reconstruction
The substitution frame for the lost frame is calculated by applying the
sinusoidal model on a frame of the previously synthesized good frame signal,
where this frame serves as a prototype frame. The previously calculated
sinusoidal components of this prototype frame are time evolved to the time
instant of the lost frame. For numerical simplicity, this prototype frame and
its spectrum are chosen to be identical to the windowed analysis frame and,
respectively, its already calculated and saved spectrum (see subclause
5.4.3.5.2). While the exact time evolution of the sinusoids of the windowed
prototype frame would require a complex superposition of frequency-shifted,
phase-evolved and sampled instances of the spectrum of the used window
function, Phase ECU operates with an approximation of the window function
spectrum such that it comprises only a region around its main lobe. With this
approximation the substitution frame spectrum is composed of strictly non-
overlapping portions of the approximated window function spectrum and hence
the time-evolution of the sinusoids of the windowed prototype frame reduces to
phase-shifting the sinusoidal components of the prototype spectrum in
{width="0.1388888888888889in" height="0.16597222222222222in"}-regions around
the corresponding spectral peaks {width="0.125in"
height="0.19236111111111112in"}by an amount{width="0.3055555555555556in"
height="0.2076388888888889in"}. Note that this
amount{width="0.3055555555555556in" height="0.2076388888888889in"}merely
depends on the respective sinusoidal frequency (peak location)
{width="1.4861111111111112in" height="0.23472222222222222in"} and the time
shift between the lost frame and the prototype frame. This is expressed in the
following equation. The phase shift is calculated as:
{width="3.1805555555555554in" height="0.45694444444444443in"} (188)
where {width="0.2916666666666667in" height="0.23472222222222222in"}is the
offset in number of samples since the last good frame.
{width="0.2916666666666667in" height="0.23472222222222222in"} is a variable
incremented by {width="0.1388888888888889in"
height="0.15138888888888888in"}for each lost frame,
and{width="0.16666666666666666in" height="0.15138888888888888in"}equals 40,
80, or 120 for WB, SWB, or FB signals.
Note, that if either of the last two frames have the
{width="0.6805555555555556in" height="0.16666666666666666in"}flag set, then
the number of peaks is set to 0.
Next the spectrum around the spectral peaks is updated and random noise
component related to burst loss handling is added
{width="3.19375in" height="0.24861111111111112in"} (189)
where{width="1.0965277777777778in" height="0.2076388888888889in"},
{width="0.125in" height="0.16597222222222222in"}is set according to Table 11,
{width="0.3055555555555556in" height="0.17916666666666667in"}is a random
number between -1 and 1, and
{width="1.9305555555555556in" height="0.8722222222222222in"} (190)
If {width="0.8465277777777778in" height="0.2076388888888889in"}is non-zero,
the amplitude is adjusted, and a small random component is added to the phase
{width="1.9166666666666667in" height="0.19236111111111112in"} (191)
{width="2.6805555555555554in" height="0.2076388888888889in"} (192)
The spectral coefficients which have not been updated are also updated in a
similar manner but with a randomized phase.
For clarity it is to be noted that the first additive term in equation (189)
relates to phase shifting the sinusoidal components of the prototype spectrum.
In addition, if {width="0.8465277777777778in" height="0.2076388888888889in"}is
non-zero, the phase is modified with a random component. This avoids quality
degrading tonal sounds due to too strong periodicity and is useful both in
case of transients and burst frame loss. In addition, for the same reason the
magnitude of the prototype frame spectral coefficients is attenuated with the
scaling factor{width="0.3055555555555556in" height="0.20833333333333334in"}.
The second additive term in equation (189) modifies the substitution frame
spectral coefficients by an additive noise component, where the magnitude of
the additive noise component corresponds to the scaled coefficient of the low-
resolution magnitude spectrum of the previous good frame,
{width="0.3333333333333333in" height="0.2361111111111111in"}, which derivation
is described in subclause 5.4.3.5.1. The scaling factor
{width="0.3194444444444444in" height="0.20833333333333334in"}is chosen such
that, except for the incorporated gradual muting behaviour, it compensates for
the energy loss caused by the attenuation with factor
{width="0.3055555555555556in" height="0.20833333333333334in"}. This is an
aspect of the long-term muting behaviour which is outlined in subclause
5.4.6.2.2.
The reconstructed substitution frame spectrum is passed through the IFFT to
create a time domain substitution frame.
{width="1.3333333333333333in" height="0.23472222222222222in"} (193)
Where {width="0.8055555555555556in" height="0.23472222222222222in"}.The signal
{width="0.4583333333333333in" height="0.23472222222222222in"}is zero extended
outside of this range. This signal {width="1.44375in"
height="0.23472222222222222in"} is then windowed and time-domain aliased as
described in [5], clause 5.3.2.2 ({width="0.3194444444444444in"
height="0.2076388888888889in"}is the number of zero samples in the ALDO
window). The resulting windowed and time-domain aliased signal is then
overlap-added with the previous frame as described in [5], clause 6.2.4.1.
#### 5.4.3.6 MDCT concealment based on sinusoidal synthesis and adaptive noise
filling
The MDCT concealment based on sinusoidal synthesis and adaptive noise
injection is illustrated in Figure 6. Note that the resampling to 8 kHz and
pitch search are already described in clause 5.4.3.1.
{width="6.685416666666667in" height="0.8555555555555555in"}
Figure 6: **Block diagram of MDCT concealment** based on sinusoidal synthesis\
and adaptive noise filling
##### 5.4.3.6.1 FFT
The pitch cycle of length {width="0.16666666666666666in"
height="0.2222222222222222in"} is extracted from the resampled past synthesis
{width="0.5277777777777778in" height="0.25in"} of length 320 as:
{width="3.0833333333333335in" height="0.2777777777777778in"}. This pitch cycle
is analyzed in frequency domain using the following steps:
\- The signal {width="1.5in" height="0.25in"} is linearly interpolated to a
length corresponding to a power of 2 to obtain the segment {width="0.625in"
height="0.25in"} of length {width="0.2222222222222222in"
height="0.2222222222222222in"} such that {width="0.875in" height="0.25in"}
where {width="0.18055555555555555in" height="0.2222222222222222in"} is the
rounding upward to the nearest integer. A linear interpolation is applied as
follows:
{width="5.180555555555555in" height="0.7472222222222222in"} (194)
> where {width="0.20833333333333334in" height="0.2222222222222222in"} is the
> rounding downward to the nearest integer and {width="1.1805555555555556in"
> height="0.2222222222222222in"}.
\- The segment {width="0.625in" height="0.25in"} is decomposed in frequency
domain by FFT of length {width="0.7083333333333334in"
height="0.2222222222222222in"} to obtain the spectrum
{width="0.3333333333333333in" height="0.20833333333333334in"},
{width="1.1527777777777777in" height="0.2222222222222222in"}
\- The amplitude spectrum {width="0.375in" height="0.25in"}is computed for
{width="1.3194444444444444in" height="0.2222222222222222in"} and the overall
amplitude is also computed as:
{width="1.19375in" height="0.4701388888888889in"} (195)
##### 5.4.3.6.2 Selection of sinusoidal components
Sinusoidal components are selected by first detecting the number
{width="0.375in" height="0.25in"} of spectral peaks following condition:
{width="1.0555555555555556in" height="0.25in"} and
{width="1.0694444444444444in" height="0.25in"} . When the binary voicing
indication has the value {width="0.12361111111111112in"
height="0.1486111111111111in"}=1, the peak selection is extended to select not
only the peak at index {width="0.1388888888888889in"
height="0.18055555555555555in"} meeting the preceding condition but also
neighboring peaks at index {width="0.3194444444444444in"
height="0.18055555555555555in"} and {width="0.3194444444444444in"
height="0.18055555555555555in"}; this allows capturing a larger portion of the
overall spectral energy and lowering the noise to be re-injected for voiced
signals.
The final number of peaks to be kept is {width="1.6805555555555556in"
height="0.25in"}to reduce the computational load of the subsequent sinusoidal
synthesis. This final selection of peaks is performed by iteratively selecting
the peak maximizing {width="0.375in" height="0.25in"} among peaks that are not
yet selected as long as the conditions {width="0.12361111111111112in"
height="0.1486111111111111in"}=1 or {width="1.7083333333333333in"
height="0.3194444444444444in"} is still met, where the latter condition
ensures that 70% of the amplitude spectrum is covered.
For each _i_ -th peak that gets selected, the amplitude
{width="0.7222222222222222in" height="0.25in"}, phase
{width="0.8055555555555556in" height="0.2222222222222222in"} and normalized
frequency {width="0.9305555555555556in" height="0.2222222222222222in"} are
computed.
##### 5.4.3.6.3 Sinusoidal synthesis
A segment of length {width="0.2638888888888889in"
height="0.2222222222222222in"} corresponding to 2 frames of 20 ms (40 ms) and
8 kHz to resampling delay is generated from the {width="0.6111111111111112in"
height="0.25in"} selected frequency bins as:
{width="2.0555555555555554in" height="0.4840277777777778in"}, {width="0.125in"
height="0.22152777777777777in"}{width="1.0277777777777777in"
height="0.2222222222222222in"} (196)
This sinusoidal synthesis is implemented using an autoregressive of order 2.
The extra segment length (after the current frame) is used for crossfading
with the next decoded frame and to compensate for resampling delay.
##### 5.4.3.6.4 Adaptive noise filling
Frequency components that do not correspond to selected sinusoids below 4 kHz
or that are above 4 kHz are re-injected by adaptive noise filling, in
particular to compensate for energy loss.
The pitch computed according to clause 5.4.3.1.2 is mapped to the output
sampling rate {width="0.3333333333333333in" height="0.2361111111111111in"}
as{width="0.25in" height="0.2222222222222222in"}, where
{width="0.1388888888888889in" height="0.18055555555555555in"} is the
decimation factor used in sub-clause 5.4.3.1.1 with
{width="0.1388888888888889in" height="0.18055555555555555in"}=2, 4, 6 for
{width="0.3333333333333333in" height="0.2361111111111111in"}=16, 32 or 48 kHz
respectively. For a 20 ms frame length {width="0.3888888888888889in"
height="0.25in"} at {width="0.3333333333333333in"
height="0.2361111111111111in"}, a residual signal is computed as:
{width="1.6805555555555556in" height="0.27708333333333335in"},
{width="0.125in" height="0.22152777777777777in"}{width="1.1111111111111112in"
height="0.2222222222222222in"} (197)
where the residual length is {width="0.4861111111111111in"
height="0.2222222222222222in"} {width="0.25in" height="0.2222222222222222in"}
if {width="0.25in"
height="0.2222222222222222in"}\ Note that the upper limit {width="1.1805555555555556in" height="0.25in"} of
> the time interval is actually saturated to {width="1.94375in"
> height="0.2777777777777778in"}.
\- The start index is updated: {width="1.8055555555555556in"
height="0.3194444444444444in"}
The iterations stop as soon as {width="0.9583333333333334in" height="0.25in"}.
##### 5.4.3.6.5 Synthesis
The signal is synthesized as:
{width="1.4722222222222223in" height="0.2222222222222222in"}, {width="0.125in"
height="0.22152777777777777in"}{width="1.0277777777777777in"
height="0.2222222222222222in"} (200)
Note that when the binary voicing indicator has the value
{width="0.12361111111111112in" height="0.1486111111111111in"}=1, the noise
vector {width="0.5277777777777778in" height="0.2222222222222222in"} has been
scaled down by a factor of 0.25, to avoid artefacts for voiced signals.
This signal is overlap-added with the previously decoded synthesis to ensure
signal continuity between frames.
#### 5.4.3.7 Time-domain PLC and OLA
##### 5.4.3.7.1 PLC mode selection
The frequency domain PLC block includes a frequency domain erasure concealment
algorithm and operates when the BFI flag is set to 1 and the decoding mode of
the previous frame is the frequency domain mode. The frequency domain PLC
block generates spectral coefficients of the erased frame by repeating the
synthesized spectral coefficients of the previous good frame stored in memory.
With these coefficients the IMDCT block generates the time domain signal by
performing a time-frequency inverse transform. The conventional OLA block
performs a general OLA processing by using the time domain signal of the
previous frame, and generates a final time domain signal of the current frame
as a result of the general OLA processing.
To achieve an additional quality enhancement taking into account the input
signal characteristics, the time-domain PLC introduces two concealment tools,
consisting of a phase matching tool and a repetition and smoothing tool. With
these tools, an appropriate concealment method is selected by checking the
stationarity of the input signal.
Figure 7 shows the two concealment tools and the conventional OLA for the
time-domain PLC.
The phase matching block in the figure will be introduced in subclause
5.4.3.7.2 and the repetition and smoothing block in the figure will be
introduced in subclause 5.4.3.7.3.
{width="5.488888888888889in" height="4.242361111111111in"}
Figure 7: **Block diagram of a Time-domain PLC module**
Table 12 summarizes the PLC modes that are used for time-domain PLC. There are
two tools for the time-domain PLC. Each of these tools has several modes
representing the erased frame types. The erased frame types are classified as
single erasure frame, burst erasure frame, next good frame after erasure
frame, and next good frame after burst erasure.
Table 12: Used PLC modes for Time-domain PLC
* * *
Name of tools Single erasure frame Burst erasure frame Next good frame Next
good frame after burst erasures **Phase matching** Phase matching for erased
frame Phase matching for burst erasures Phase matching for next good frame
Phase matching for next good frame **Repetition & Smoothing** Repetition
&smoothing for erased frame Repetition &smoothing for erased frame Repetition
&smoothing for next good frame Next good frame after burst erasures
* * *
Table 13 summarizes the PLC mode selection method for the PLC mode selection
block in Figure.7.
Table 13: PLC mode selection
+-------+-------+-------+-------+-------+-------+-------+-------+ | **Pa |** S | **Def | | | | | | | ramet | tatus | initi | | | | | | | ers** | of | ons**| | | | | | | | Pa | | | | | | | | | ramet | | | | | | | | | ers** | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | BFI | 1 | 0 | 1 | 1 | 0 | 0 | Bad | | | | | | | | | frame | | | | | | | | | indi | | | | | | | | | cator | | | | | | | | | for | | | | | | | | | the | | | | | | | | | cu | | | | | | | | | rrent | | | | | | | | | frame | +-------+-------+-------+-------+-------+-------+-------+-------+ | Prev | - | 1 | 1 | - | 1 | 1 | BFI | | _BFI | | | | | | | for | | | | | | | | | the | | | | | | | | | pre | | | | | | | | | vious | | | | | | | | | frame | +-------+-------+-------+-------+-------+-------+-------+-------+ | nbLos | 1 | - | - | - | - | >1 | The | | tCmpt | | | | | | | n | | | | | | | | | umber | | | | | | | | | of | | | | | | | | | conti | | | | | | | | | guous | | | | | | | | | e | | | | | | | | | rased | | | | | | | | | f | | | | | | | | | rames | +-------+-------+-------+-------+-------+-------+-------+-------+ | P | 1 | - | - | 0 | 0 | 0 | The | | hase\ | | | | | | | flag | | _mat\ | | | | | | | for | | _flag | | | | | | | the | | | | | | | | | Phase | | | | | | | | | mat | | | | | | | | | ching | | | | | | | | | pr | | | | | | | | | ocess | | | | | | | | | | | | | | | | | | (1: | | | | | | | | | used, | | | | | | | | | 0: | | | | | | | | | not | | | | | | | | | used) | +-------+-------+-------+-------+-------+-------+-------+-------+ | P | 0 | 1 | 1 | 0 | 0 | 0 | The | | hase\ | | | | | | | flag | | _mat\ | | | | | | | for | | _next | | | | | | | the | | | | | | | | | Phase | | | | | | | | | mat | | | | | | | | | ching | | | | | | | | | pr | | | | | | | | | ocess | | | | | | | | | for | | | | | | | | | burst | | | | | | | | | era | | | | | | | | | sures | | | | | | | | | or | | | | | | | | | next | | | | | | | | | good | | | | | | | | | frame | | | | | | | | | | | | | | | | | | (1: | | | | | | | | | used, | | | | | | | | | 0: | | | | | | | | | not | | | | | | | | | used) | +-------+-------+-------+-------+-------+-------+-------+-------+ | stat\ | - | - | - | (1 | (1) | 0 | The | | _mode | | | | )^*^ | ^*^ | | flag | | _out | | | | | | | for | | | | | | | | | Repet | | | | | | | | | ition | | | | | | | | | &smoo | | | | | | | | | thing | | | | | | | | | pr | | | | | | | | | ocess | | | | | | | | | | | | | | | | | | (1: | | | | | | | | | used, | | | | | | | | | 0: | | | | | | | | | not | | | | | | | | | used) | +-------+-------+-------+-------+-------+-------+-------+-------+ | di | - | - | - | (\ | (\ | | 9063) | /imag | diffe | | | | | | ^*^ | ^*^ | e906. | rence | | | | | | | | wmf){ | | | | | | | | | width | | | | | | | | | ="0.1 | | | | | | | | | 25in" | | | | | | | | | hei | | | | | | | | | ght=" | | | | | | | | | 0.152 | | | | | | | | | 77777 | | | | | | | | | 77777 | | | | | | | | | 778in | | | | | | | | | "}0.1 | | | | | | | | | 59063 | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Sel | Phase | Phase | Phase | Repet | Repet | Next | | | ected | mat | mat | mat | ition | ition | good | | | PLC | ching | ching | ching | &smoo | &smoo | frame | | | mode | for | for | for | thing | thing | after | | | | e | next | burst | for | for | burst | | | | rased | good | era | e | next | era | | | | frame | frame | sures | rased | good | sures | | | | | | | frame | frame | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Name | Phase | Repet | | | | | | | of | mat | ition | | | | | | | tools | ching | and | | | | | | | | | Smoo | | | | | | | | | thing | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | NOTE: | | | | | | | | | ^\ | | | | | | | | | *^The | | | | | | | | | () | | | | | | | | | means | | | | | | | | | \ | | | | | | | | | "OR\" | | | | | | | | | co | | | | | | | | | nnect | | | | | | | | | ions. | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+
The pseudo code to select a PLC mode for the phase matching tool is as
follows.
if( (nbLostCmpt==1)&&(phase_mat_flag==1)&&(phase_mat_next==0) ) {
Phase matching for erased frame ();
}
else if((prev_bfi == 1)&&(bfi == 0) &&(phase_mat_next == 1)) {
Phase matching for next good frame ();
}
else if((prev_bfi == 1)&&(bfi == 1) &&(phase_mat_next == 1)) {
Phase matching for burst erasures ();
}
Using this selection method, the phase matching flag (phase_mat_flag)
determines at the point of the memory update block in the previous good frame
whether phase matching erasure concealment processing is used for every good
frame when an erasure occurs in a next frame. To this end, energy and spectral
coefficients of each sub-band are used. The energy is obtained from the norm
value. More specifically, when a sub-band having the maximum energy in a
current frame belongs to a predetermined low frequency band, and the inter-
frame energy change is not large, the phase matching flag is set to 1.
The detailed method is as follows. When a sub-band having the maximum energy
in the current frame is within the range of 75 Hz to 1000 Hz, a difference
between the index of the current frame and the index of a previous frame with
respect to a corresponding sub-band is 1 or less, and the current frame is a
stationary frame of which an energy change is less than the threshold
(ED_THRES_90P), and three past frames stored in the buffer are not transient
frames, then phase matching erasure concealment processing will be applied to
a next frame to which an erasure has occurred.
> if ((Min_ind\ (diff_energy\ (!is_transient) && (!old_is_transient[1])) {
if((Min_ind==0) && (Max_ind\prev_ BFI == 1) {
if((stat_mode_out==1) \|\| (diff_energy\ 1) {
Next good frame after burst erasures ();
}
else {
Conventional OLA ();
}
}
else { /* if(BFI == 1) */
if( (stat_mode_out==1) \|\| (diff_energy\2.0)\|\|(mean_en_high\ b) The excitation is shaped by FDNS towards a previously measured background
> shape.
c) The LTP is faded out.
##### 5.4.6.1.3.2.1 Fading the excitation to noise {#fading-the-excitation-to-
noise .H6}
For 9.6, 16.4 and 24.4kbps, the sign scrambled excitation (input to FDNS, see
subclause 5.4.2.3) is faded towards a white noise, on which a tilt is applied
prior to the fading procedure. The method is based on the following
parameters: the last received excitation spectrum
{width="0.9861111111111112in" height="0.2361111111111111in"}, a noise tilt
compensation factor {width="0.94375in" height="0.20833333333333334in"}
(derived similar to the clean channel operation) and a damping factor
{width="0.7638888888888888in" height="0.20833333333333334in"}.
The tilt factor is given by
{width="2.9027777777777777in" height="0.4166666666666667in"} (208)
Subsequently a tilt vector is derived as
$\begin{matrix} \text{tilt}(0) = 1 \ \text{tilt}(k) = \text{tilt}(k - 1) \cdot
\text{tiltFactor},k = \lbrack 1,\text{.}\text{.}\text{.},\text{igfStartLine} -
1\rbrack \ \end{matrix}$ (209)
The{width="0.8958333333333334in" height="0.19791666666666666in"}given by
equation (123) then gets multiplied with the tilt to achieve a target noise
vector with the desired tilt:
$C_{\text{noise}_{\text{tilt}}}(k) = \text{tilt}(k) \cdot
\text{randomVector}(k)\text{,\ \ \ \ \ \
k=}\lbrack\text{0,}\ldots\text{,igfStartLine-1}\rbrack$ (210)
The energy of this target noise vector is derived
$E_{\text{noise}} = \sum_{k = 0}^{\text{igfStartLine} - 1}\left(
C_{\text{noise}_{\text{tilt}}}(k) \right)^{2}$ (211)
and the energy of the last excitation is derived
$E_{C} = \sum_{k = 0}^{\text{igfStartLine} - 1}\left(
C_{\text{exc}_{\text{lastGood}}}(k) \right)^{2}$. (212)
The excitation is then derived as follows:
$C_{\text{exc}}^{\lbrack m\rbrack}(k) = \text{gain} \cdot
C_{\text{noise}_{\text{tilt}}}(k) + \text{dampingFac} \cdot
C_{\text{exc}}^{\lbrack m\rbrack}(k),\text{for\ k\ =\
}\lbrack\text{0,}\ldots\text{,igfStartLine-1}\rbrack$ (213)
with {width="2.0in" height="0.4583333333333333in"} and
{width="0.3229166666666667in" height="0.25in"}is given by equation (122). The
fading speed controlled by {width="0.7597222222222222in"
height="0.19791666666666666in"} as described in subclause 5.4.6.1.4.
##### 5.4.6.1.3.2.2 Shaping the excitation towards the background shape
{#shaping-the-excitation-towards-the-background-shape .H6}
The excitation is shaped towards a target spectral shape by altering the LPC
coefficients. The fading from the last good LPC coefficients to the target LPC
coefficients is performed in the LSF domain as follows:
$f^{\lbrack m\rbrack} = \text{alpha} \cdot f^{\lbrack m - 1\rbrack} + (1 -
\text{alpha}) \cdot f^{\text{target}}$ (214)
where: {width="0.3020833333333333in" height="0.3020833333333333in"} are LPC
coefficients in the LSF domain of the current frame;
{width="0.40625in" height="0.3020833333333333in"} are LPC coefficients in the
LSF domain of the previous frame;
$f^{\text{target}}$ are the target LPC coefficients, derived according to
formula 111
{width="0.375in" height="0.19791666666666666in"} is the fading factor as
described in subclause 5.3.4.2.3, but limited to the minimum value of 0.8.
void (215)
For 9.6, 16.4 and 24.4kbps, the target spectral shape of the excitation is
derived during the first lost frame based on the background noise spectrum
derived by CNG during clean channel decoding (see section 4.3 of [5]). Its
derivation is performed as described in subclause 5.3.4.2.2 for the harmonic
excitation.
For 48, 96 and 128kbps, the target spectral shape of the excitation is the
short term mean of the last three LPC coefficient sets. Its derivation is
performed as described in subclause 5.3.4.2.2 for the innovative excitation.
The achieved LPC is converted into FDNS parameters as follows:
{width="2.3333333333333335in" height="0.40625in"} (216)
{width="2.4166666666666665in" height="0.40625in"} (217)
where {width="0.19791666666666666in" height="0.20833333333333334in"} are the
LPC coefficients. The two signals {width="0.16666666666666666in"
height="0.13541666666666666in"} and {width="0.19791666666666666in"
height="0.16666666666666666in"} get zero filled to the length of 128 before a
complex Fourier transform of length 128 will be applied on them to receive the
real part {width="0.20833333333333334in" height="0.16666666666666666in"} and
the imaginary part {width="0.20833333333333334in" height="0.15625in"}(see [5],
subsection 5.1.4). The FDNS parameters will finally be obtained as:
{width="2.625in" height="0.3020833333333333in"} (218)
##### 5.4.6.1.3.2.3 LTP fade-out {#ltp-fade-out .H6}
The LTP continues to run during concealment. The LTP lag is kept constant. The
LTP gain is faded towards zero as follows:
{width="1.5965277777777778in" height="0.2916666666666667in"} (219)
where: {width="0.2916666666666667in" height="0.2916666666666667in"} is the LTP
gain of the current frame;
{width="0.4027777777777778in" height="0.2916666666666667in"} is the LTP gain
of the previous frame;
{width="0.7638888888888888in" height="0.19375in"} is the damping factor, its
derivation is outlined in subclause 5.4.6.1.4.
##### 5.4.6.1.4 Fading speed
Several algorithms use a time-varying damping factor for fade-out, cross-fade
etc. Depending on the application, either the damping factor or the cumulative
damping factor is needed.
The damping factor, here described as{width="0.7638888888888888in"
height="0.20833333333333334in"}, depends on the number of lost frames and the
ISF stability factor. The ISF stability factor is already computed in the
clean channel. With the lost frame having the index 0, it is derived as
follows
{width="2.0833333333333335in" height="0.25in"} (220)
{width="2.111111111111111in" height="0.25in"} (221)
{width="2.272222222222222in" height="0.2534722222222222in"} (222)
The cumulative damping factor, here described as{width="1.15625in"
height="0.20833333333333334in"}, is initialized with 1 during clean-channel
decoding and derived as follows during concealment:
{width="3.821527777777778in" height="0.2534722222222222in"} (223)
##### 5.4.6.1.5 Waveform adjustment
The fade out is performed as described in section 5.4.6.1.3, just that no lpc
gain compensation (see section 5.2.5) takes place.
#### 5.4.6.2 HQ MDCT
##### 5.4.6.2.1 Burst loss handling for 8 kHz audio output sampling rate
The burst loss handling for 8 kHz audio sampling rate is described as part of
the HQ MDCT PLC method description for 8 kHz signals, see clauses 5.4.3.3 and
5.4.3.4.
##### 5.4.6.2.2 Burst loss handling audio output sampling rates larger or
equal to 16 kHz
In case the audio output signal frequency exceeds 8 kHz and the current frame
loss is the first loss after a good HQ MDCT frame the PLC method is selected
according to the method described in subclause 5.4.3.2. If however the current
frame loss is at least the second consecutive loss after a preceding good HQ
MDCT frame, then the procedure described in this clause applies.
In case the current frame loss is the second loss in a row and the PLC method
according to subclause 5.4.3.6 was applied for the first bad frame, Phase ECU
according to subclause 5.4.3.5 is applied with the following adaptations:
Transient analysis and spectrum analysis are carried out with the previous
synthesis signal of the last good HQ MDCT frame. The offset
{width="0.2916666666666667in" height="0.23472222222222222in"}in number of
samples since the last good frame is accordingly incremented
by{width="0.1388888888888889in" height="0.15138888888888888in"}.
Otherwise, in case the current frame loss is the second loss in a row and if
Phase ECU was applied for the first frame loss, Phase ECU according to
subclause 5.4.3.5 is applied with the adaptation that no spectral analysis is
carried out and that transient analysis relies on previously calculated and
stored parameters. Details are described in subclause 5.4.3.5.1.
In case the current frame loss is the third or more in a row Phase ECU is
applied according to subclause 5.4.3.5 with the adaptation that no spectral
analysis is carried out and that transient analysis relies on previously
calculated and stored parameters (that were calculated based on the synthesis
of the last good HQ MDCT frame). The operation of the Phase ECU is modified in
response to the frame loss burst condition. Specifically, magnitude and phase
of the substitution frame spectrum are adjusted in order to mitigate potential
quality losses that might otherwise arise from too periodic or tonal sounds.
With increasing loss burst length, the magnitude spectrum is adjusted by
gradually increasing attenuation. At the same time the phase spectrum is
dithered with an increasing degree. Further details are described in subclause
5.4.3.5.1.
A special feature is the long-term muting behaviour in case of long loss
bursts with many consecutive lost frames. In that case, the quality of the
audio signal that is reconstructed by Phase ECU might still suffer from tonal
artefacts, despite the performed phase randomization. Too strong magnitude
attenuation could at the same time lead to quality impairments, as this could
be perceived as signal drop-outs. The feature avoids such impairments to a
large degree by gradually superposing the substitution signal of the Phase ECU
with a noise signal, where the frequency characteristic of the noise signal is
a low-resolution spectral representation of a previously received good frame.
With increasing number of frame losses in a row, the substitution signal of
the Phase ECU is gradually attenuated. At the same time, the frame energy loss
is compensated for through the addition of a noise signal with similar
spectral characteristics like the last received good frame but with a certain
degree of low-pass behaviour. For very long frame loss bursts
({width="0.6111111111111112in" height="0.2076388888888889in"}) the additional
noise contribution faded out in order to enforce a muting characteristic of
the decoder. Further details of the long-term muting feature are described in
subclauses 5.4.3.5.1 and 5.4.3.5.3.
## 5.5 SID frame concealment operation
In the case of the loss of an SID frame, the comfort noise will be generated
based on the last received SID frame.
#