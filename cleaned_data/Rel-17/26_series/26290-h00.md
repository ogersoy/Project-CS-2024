# Foreword
This Technical Specification has been produced by the 3^rd^ Generation
Partnership Project (3GPP). This document describes the Extended Adaptive
Multi-Rate Wideband (AMR-WB+) coder within the 3GPP system.
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
This Telecommunication Standard (TS) describes the detailed mapping from input
blocks of monophonic or stereophonic audio samples in 16 bit uniform PCM
format to encoded blocks and from encoded blocks to output blocks of
reconstructed monophonic or stereophonic audio samples. The coding scheme is
an extension of the AMR-WB coding scheme [3] and is referred to as extended
AMR-WB or AMR-WB+ codec. It comprises all AMR-WB speech codec modes including
VAD/DTX/CNG [2][8][10] as well as extended functionality for encoding general
audio signals such as music, speech, mixed, and other signals.
In the case of discrepancy between the requirements described in the present
document and the ANSI-C code computational description of these requirements
contained in [4], [5], the description in [4], [5], respectively, will
prevail. The ANSI-C code is not described in the present document, see [4],
[5] for a description of the floating-point or, respectively, fixed-point
ANSI-C code.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] GSM 43.050: \" Digital cellular telecommunications system (Phase 2);
Transmission planning aspects of the speech service in the GSM Public Land
Mobile Network (PLMN) system\"
[2] 3GPP TS 26.194: \"AMR wideband speech codec; Voice Activity Detection
(VAD)\".
[3] 3GPP TS 26.190: \" AMR Wideband speech codec; Transcoding functions \".
[4] 3GPP TS 26.304: \"ANSI-C code for the floating point Extended AMR Wideband
codec\".
[5] 3GPP TS 26.273: \"ANSI-C code for the fixed point Extended AMR Wideband
codec\".
[6] M. Xie and J.-P. Adoul, \"Embedded algebraic vector quantization (EAVQ)
with application to wideband audio coding,\" IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP), Atlanta, GA, U.S.A, vol. 1,
pp. 240-243, 1996.
[7] J.H. Conway and N.J.A. Sloane, \"A fast encoding method for lattice codes
and quantizers,\" _IEEE Trans. Inform. Theory_ , vol. IT-29, no. 6, pp.
820-824, Nov. 1983
[8] 3GPP TS 26.193: \"AMR Wideband speech codec; Source controlled rate
operation\".
[9] 3GPP TS 26.244: \"Transparent end-to-end packet switched streaming service
(PSS); 3GPP file format (3GP)\"
[10] 3GPP TS 26.192: \"AMR Wideband speech codec; Comfort noise aspects\"
# 3 Definitions and abbreviations
## 3.1 Definitions
For the purposes of the present document, the following terms and apply.
**adaptive codebook:** The adaptive codebook contains excitation vectors that
are adapted for every subframe. The adaptive codebook is derived from the
long-term filter state. The lag value can be viewed as an index into the
adaptive codebook.
**algebraic codebook:** A fixed codebook where algebraic code is used to
populate the excitation vectors (innovation vectors). The excitation contains
a small number of nonzero pulses with predefined interlaced sets of potential
positions. The amplitudes and positions of the pulses of the k^th^ excitation
codevector can be derived from its index k through a rule requiring no or
minimal physical storage, in contrast with stochastic codebooks whereby the
path from the index to the associated codevector involves look-up tables.
**anti-sparseness processing:** An adaptive post-processing procedure applied
to the fixed codebook vector in order to reduce perceptual artifacts from a
sparse fixed codebook vector.
**closed‑loop pitch analysis:** This is the adaptive codebook search, i.e., a
process of estimating the pitch (lag) value from the weighted input speech and
the long term filter state. In the closed‑loop search, the lag is searched
using error minimization loop (analysis‑by‑synthesis). In the adaptive multi-
rate wideband codec, closed‑loop pitch search is performed for every subframe.
**direct form coefficients:** One of the formats for storing the short term
filter parameters. In the adaptive multi-rate wideband codec, all filters
which are used to modify speech samples use direct form coefficients.
**fixed codebook:** The fixed codebook contains excitation vectors for speech
synthesis filters. The contents of the codebook are non‑adaptive (i.e.,
fixed). In the adaptive multi-rate wideband codec, the fixed codebook is
implemented using an algebraic codebook.
**fractional lags:** A set of lag values having sub‑sample resolution. In the
adaptive multi-rate wideband codec a sub‑sample resolution of ¼^th^ or ½^nd^
of a sample is used.
**super frame:** A time interval equal to 1024 samples (80ms at a 12.8 kHz
sampling rate).
**frame:** A time interval equal to 256 samples (20ms at a 12.8 kHz sampling
rate).
**Immittance Spectral Frequencies:** (see Immittance Spectral Pair)
**Immittance Spectral Pair:** Transformation of LPC parameters. Immittance
Spectral Pairs are obtained by decomposing the inverse filter transfer
function A(z) to a set of two transfer functions, one having even symmetry and
the other having odd symmetry. The Immittance Spectral Pairs (also called as
Immittance Spectral Frequencies) are the roots of these polynomials on the
z-unit circle.
**integer lags:** A set of lag values having whole sample resolution.
**interpolating filter:** An FIR filter used to produce an estimate of sub-
sample resolution samples, given an input sampled with integer sample
resolution. In this implementation, the interpolating filter has low pass
filter characteristics. Thus the adaptive codebook consists of the low-pass
filtered interpolated past excitation.
**inverse filter:** This filter removes the short term correlation from the
speech signal. The filter models an inverse frequency response of the vocal
tract.
**lag:** The long term filter delay. This is typically the true pitch period,
or its multiple or sub‑multiple.
**LP analysis window:** For each frame, the short term filter coefficients are
computed using the high pass filtered speech samples within the analysis
window. In the adaptive multi-rate wideband codec, the length of the analysis
window is always 384 samples. For all the modes, a single asymmetric window is
used to generate a single set of LP coefficients. The 5 ms look-ahead is used
in the analysis.
**LP coefficients:** Linear Prediction (LP) coefficients (also referred as
Linear Predictive Coding (LPC) coefficients) is a generic descriptive term for
the short term filter coefficients.
**open‑loop pitch search:** A process of estimating the near optimal lag
directly from the weighted speech input. This is done to simplify the pitch
analysis and confine the closed‑loop pitch search to a small number of lags
around the open‑loop estimated lags. In the adaptive multi-rate wideband
codec, an open‑loop pitch search is performed in every other subframe.
**residual:** The output signal resulting from an inverse filtering operation.
**short term synthesis filter:** This filter introduces, into the excitation
signal, short term correlation which models the impulse response of the vocal
tract.
**perceptual weighting filter:** This filter is employed in the
analysis‑by‑synthesis search of the codebooks. The filter exploits the noise
masking properties of the formants (vocal tract resonances) by weighting the
error less in regions near the formant frequencies and more in regions away
from them.
**subframe:** A time interval equal to 64 samples (5ms at 12.8 kHz sampling
rate).
**vector quantization:** A method of grouping several parameters into a vector
and quantizing them simultaneously.
**zero input response:** The output of a filter due to past inputs, i.e. due
to the present state of the filter, given that an input of zeros is applied.
**zero state response:** The output of a filter due to the present input,
given that no past inputs have been applied, i.e., given that the state
information in the filter is all zeroes.
## 3.2 Abbreviations
For the purposes of the present document, the following abbreviations apply:
TCX Transform coded excitation
ACELP Algebraic Code Excited Linear Prediction
AGC Adaptive Gain Control
AMR Adaptive Multi-Rate
AMR-WB Adaptive Multi-Rate Wideband
AMR-WB+ Extended Adaptive Multi-Rate Wideband
CELP Code Excited Linear Prediction
FIR Finite Impulse Response
ISF Immittance Spectral Frequency
ISP Immittance Spectral Pair
ISPP Interleaved Single‑Pulse Permutation
LP Linear Prediction
LPC Linear Predictive Coding
LTP Long Term Predictor (or Long Term Prediction)
MA Moving Average
MRWB-ACELP Wideband Multi-Rate ACELP
S-MSVQ Split-MultiStage Vector Quantization
WB Wideband
# 4 Outline description
This TS is structured as follows:
Section 4.1 contains a functional description of the audio parts including the
A/D and D/A functions. Section 4.2 describes input format for the AMR-WB+
encoder and the output format for the AMR-WB+ decoder. Section 4.3 presents a
simplified description of the principles of the AMR-WB codec. In subclause
4.4, the sequence and subjective importance of encoded parameters are given.
Section 5 presents the functional description of the encoding functions of the
AMR-WB+ extension modes, whereas clause 6 describes the decoding procedures
for the extension modes. In section 7, the detailed bit allocation of the AMR-
WB+ codec extension modes is tabulated. The AMR-WB speech modes are
functionally unchanged as well as their bit allocation. Detailed information
on them is found in [1].
## 4.1 Functional description of audio parts
The analogue‑to‑digital and digital‑to‑analogue conversion will in principle
comprise the elements given below. In case of stereo codec operation, the
given principles will be applied to the 2 available audio channels.
1) Analogue to uniform digital PCM
\- microphone;
\- input level adjustment device;
‑ input anti‑aliasing filter;
‑ sample‑hold device sampling at 16/24/32/48 kHz;
‑ analogue‑to‑uniform digital conversion to 16‑bit representation.
The uniform format shall be represented in two\'s complement.
2) Uniform digital PCM to analogue
‑ conversion from 16‑bit uniform PCM sampled at 16/24/32/48 kHz to analogue;
‑ a hold device;
‑ reconstruction filter including x/sin( x ) correction;
‑ output level adjustment device;
‑ earphone or loudspeaker.
In the terminal equipment, the A/D function may be achieved
‑ by direct conversion to 14‑bit uniform PCM format;
For the D/A operation, the inverse operations take place.
## 4.2 Preparation of input samples
The encoder is fed with data from one/two input channels comprising of samples
with a resolution of 16 bits in a 16‑bit word. The decoder outputs data in the
same format and number of output channels. Though, mono output of decoded
stereo signals is supported.
## 4.3 Principles of the extended adaptive multi-rate wideband codec
The AMR-WB+ audio codec contains all the AMR-WB speech codec modes 1-9 and
AMR-WB VAD and DTX. AMR-WB+ extends the AMR-WB codec by adding TCX, bandwidth
extension, and stereo.
The AMR-WB+ audio codec processes input frames equal to 2048 samples at an
internal sampling frequency _F~s~_ . The internal sampling frequency is
limited to the range 12800-38400 Hz, see section 8 for more details. The
2048-sample frames are split into two critically sampled equal frequency
bands. This results in two superframes of a 1024 samples corresponding to the
low frequency (LF) and high frequency (HF) band. Each superframe is divided
into four 256-samples frames.
Sampling at the internal sampling rate is obtained by using a variable
sampling conversion scheme, which re-samples the input signal.
The LF and HF signals are then encoded using two different approaches: the LF
is encoded and decoded using the \"core\" encoder/decoder, based on switched
ACELP and transform coded excitation (TCX). In ACELP mode, the standard AMR-WB
codec is used. The HF signal is encoded with relatively few bits (16
bits/frame) using a bandwidth extension (BWE) method.
The basic set of rates are built based on AMR-WB rates in addition to
bandwidth extension. The basic set of mono rates are shown in Table 1.
Table 1: Basic set of mono rates
+----------------------+---------------------------+ | Mono rate(incl. BWE) | Corresponding AMR-WB mode | | | | | _(bits/frame)_ | | +----------------------+---------------------------+ | 208 | NA | +----------------------+---------------------------+ | 240 | NA | +----------------------+---------------------------+ | 272 | 12.65 | +----------------------+---------------------------+ | 304 | 14.25 | +----------------------+---------------------------+ | 336 | 15.85 | +----------------------+---------------------------+ | 384 | 18.25 | +----------------------+---------------------------+ | 416 | 19.85 | +----------------------+---------------------------+ | 480 | 23.05 | +----------------------+---------------------------+
Note that in ACELP mode of operation, compared to AMR-WB, the VAD bit is
removed, two bits per frame are added for gain prediction, and 2 bits are
added for signaling frame encoding type. This adds 3 bits per frame. Note also
that 16 bits/frame is always used for bandwidth extension (to encode the HF
band). The first two basic mono rates are similar to other rates except that
they use a fixed codebook with 20 bits or 28 bits, respectively.
For stereo coding, the set of stereo extension rates given in Table 2 are
used.
Table 2: Basic set of stereo rates
+------------------------------------+-----+ | Stereo extension rates (incl. BWE) | | | | | | (Bits/frame) | | +------------------------------------+-----+ | 40 | 104 | +------------------------------------+-----+ | 48 | 112 | +------------------------------------+-----+ | 56 | 120 | +------------------------------------+-----+ | 64 | 128 | +------------------------------------+-----+ | 72 | 136 | +------------------------------------+-----+ | 80 | 144 | +------------------------------------+-----+ | 88 | 152 | +------------------------------------+-----+ | 96 | 160 | +------------------------------------+-----+
Note that the bandwidth extension is applied to both channels which requires
additional 16 bits/frame for the stereo extension.
A certain mode of operation is obtained by choosing a rate from Table 1, in
case of mono operation, or by combining a rate from Table 1 with a stereo
extension rate from Table 2, in case of stereo operation. The resulting coding
bitrate is (mono rate + stereo rate) Fs / 512.
**Examples** :
\- For an internal sampling frequency of 32 kHz by choosing mono rate equal to
384 bits/frame and without stereo, we can obtain a bit-rate equal to 24 kbps
and the frame length would be of a 16 ms duration.
\- For an internal sampling frequency of 25.6 kHz by choosing mono rate equal
to 272 bits/frame and stereo rate equal to 88 bits/frame, we can obtain a bit-
rate equal to 18 kbps and the frame length would be of a 20 ms duration.
**Note**. The documentation of the AMR-WB+ floating-point C-code in [4]
contains further information on how to use the executables compiled from this
source code to exercise the various possible uses, in the codec, of mono bit
rate, stereo bit rate and internal sampling frequency, and the resulting total
bit rates.
### 4.3.1 Encoding and decoding structure
Figure 1 presents the AMR-WB+ encoder structure. The input signal is separated
in two bands. The first band is the low-frequency (LF) signal, which is
critically sampled at Fs/2 . The second band is the high-frequency (HF)
signal, which is also downsampled to obtain a critically sampled signal. The
LF and HF signals are then encoded using two different approaches: the LF
signal is encoded and decoded using the \"core\" encoder/decoder, based on
switched ACELP and transform coded excitation (TCX). In ACELP mode, the
standard AMR-WB codec is used. The HF signal is encoded with relatively few
bits using a bandwidth extension (BWE) method.
The parameters transmitted from encoder to decoder are the mode selection
bits, the LF parameters and the HF parameters. The parameters for each
1024-sample super-frame are decomposed into four packets of identical size.
When the input signal is stereo, the Left and right channels are combined into
mono signal for ACELP/TCX encoding, whereas the stereo encoding receives both
input channels.
Figure 2 presents the AMR-WB+ decoder structure. The LF and HF bands are
decoded separately after which they are combined in a synthesis filterbank. If
the output is restricted to mono only, the stereo parameters are omitted and
the decoder operates in mono mode.
{width="6.689583333333333in" height="3.770138888888889in"}
Figure 1: High-level structure of AMR-WB+ encoder
{width="6.692361111111111in" height="3.3340277777777776in"}
Figure 2: High-level structure of AMR-WB+ decoder
### 4.3.2 LP analysis and synthesis in low-frequency band
The AMR-WB+ codec applies LP analysis for both the ACELP and TCX modes when
encoding the LF signal. The LP coefficients are interpolated linearly at every
64-sample sub-frame. The LP analysis window is a half-cosine of length 384
samples.
### 4.3.3 ACELP and TCX coding
To encode the core mono signal (0-Fs/4 kHz band), the AMR-WB+ codec utilises
either ACELP or TCX coding for each frame. The coding mode is selected based
on closed-loop analysis-by-synthesis method. Only 256-sample frames are
considered for ACELP frames (as in AMR-WB), whereas frames of 256, 512 or 1024
samples are possible in TCX mode.
ACELP encoding and decoding are similar to standard AMR-WB speech codec. The
ACELP coding consists of LTP analysis and synthesis and algebraic codebook
excitation. The ACELP coding mode is used in AMR-WB operation within AMR-WB+
codec.
In TCX mode the perceptually weighted signal is processed in the transform
domain. The Fourier transformed weighted signal is quantised using split
multi-rate lattice quantisation (algebraic VQ). Transform is calculated in
1024, 512 or 256 samples windows. The excitation signal is recovered by
inverse filtering the quantised weighted signal through the inverse weighting
filter (same weighting filter as in AMR-WB).
### 4.3.4 Coding of high-frequency band
Whereas the LF signal (0-Fs/4 kHz band) is encoded using the previously
described switched ACELP/TCX encoding approach, the HF signal is encoded using
a low-rate parametric bandwidth extension (BWE) approach. Only gains and
spectral envelope information are transmitted in the BWE approach used to
encode the HF signal.
The bandwidth extension is done separately for left and right channel in
stereo operation.
### 4.3.5 Stereo coding
In the case of stereo coding, a similar band decomposition as in the mono case
is used. The two channels L and R are decomposed into LF and HF signals. The
LF signals of the two channels are down-mixed to form an LF mono signal,
(0-Fs/4 kHz band). This mono signal is encoded separately by the core codec.
The LF part of the two channels is further decomposed into two bands
(0-5Fs/128 kHz band) and (5Fs/128 kHz- Fs/4 kHz band). The very low frequency
(VLF) band is critically down-sampled, and the side signal is computed. The
resulting signal is semi-parametrically encoded in the frequency domain using
the algebraic VQ. The frequency domain encoding is performed in closed loop by
choosing among 40-, 80- and 160-sample frame lengths.
The high frequency part of the LF signals (Midband) are parametrically
encoded. In the decoder, the parametric model is applied on the mono signal
excitation in order to restore the high frequency part of the original LF part
of the two channels.
The HF part of the two channels are encoded by using parametric BWE described
below.
### 4.3.6 Low complexity operation
In the low complexity operation (use case B) the decision on the usage of
ACELP and TCX mode is done in an open-loop manner. This approach introduces
computational savings in the encoder.
### 4.3.7 Frame erasure concealment
When missing packets occur at the receiver, the decoder applies concealment.
The concealment algorithm depends on the mode of the correctly received
packets preceding and following the missing packet. Concealment uses either
time-domain coefficient extrapolation, as in AMR-WB, or frequency-domain
interpolation for some of the TCX modes.
### 4.3.8 Bit allocation
The bit allocation for the different parameters in the low-frequency band
coding (Core) (0-Fs/4 kHz band) is shown in Tables 3, 4, 5, and 6. Note that
there are two mode bits sent in each 256-sample packet. These mode bits are
not shown in the bit allocation tables. The bit allocations for the stereo
part is shown in Tables 7, 8, and 9. Note that there are also two additional
mode bits for the VLF stereo encoder, which are not shown in the bit
allocation. The bit allocation for the stereo HF part is by definition that of
the bandwidth extension, as presented in Tables 7,8 and 9.
Tables 2 and 3 show the total bits per 256-sample packet, including mode bits.
Table 3: Bit allocations for ACELP core rates including BWE (per frame)
* * *
Parameter Number of bits  
Mode bits 2  
ISF Parameters 46  
Mean Energy 2  
Pitch Lag 30  
Pitch Filter 4 × 1  
Fixed-codebook Indices 4 × 20 4 × 28 4 × 36 4 × 44 4 × 52 4 × 64 4 × 72 4 × 88
Codebook Gains 4 × 7  
HF ISF Parameters 9  
HF gain 7  
Total in bits 208 240 272 304 336 384 416 480
* * *
Table 4: Bit allocations for 256-sample TCX window (Core)
* * *
Parameter Number of bits  
Mode bits 2  
ISF Parameters 46  
Noise factor 3  
Global Gain 7  
Algebraic VQ 134 166 198 230 262 310 342 406 HF ISF Parameters 9  
HF gain 7  
Total in bits 208 240 272 304 336 384 416 480
* * *
Table 5: Bit allocations for 512-sample TCX window (Core)
* * *
Parameter Number of bits  
Mode bits 2+2  
ISF Parameters 46  
Noise factor 3  
Global Gain 7  
Gain redundancy 6  
Algebraic VQ 318 382 446 510 574 670 734 862 HF ISF Parameters 9  
HF gain 7  
HF Gain correction 8 × 2  
Total in bits 416 480 544 608 672 768 832 960
* * *
Table 6: Bit allocations for 1024-sample TCX window (Core)
* * *
Parameter Number of bits  
Mode bits 2+2+2+2  
ISF Parameters 46  
Noise factor 3  
Global Gain 7  
Gain redundancy 3+3+3  
Algebraic VQ 695 823 951 1079 1207 1399 1527 1783 HF ISF Parameters 9  
HF gain 7  
HF Gain correction 16 × 3  
Total in bits 832 960 1088 1216 1344 1536 1664 1920
* * *
Table 7 Bit allocations for stereo encoder for 256-sample window
* * *
Parameter Number of bits  
Mode bits 2  
Global Gain 7  
Gain 7  
Unused bits 1  
Midband 6 12  
Algebraic VQ 1 9 17 25 33 41 49 51 59 67 75 83 91 99 107 115 HF ISF Parameters
9  
HF gain 7  
Total in bits 40 48 56 64 72 80 88 96 104 112 120 128 136 144 152 160
* * *
Table 8 Bit allocations for stereo encoder for 512-sample window
* * *
Parameter Number of bits  
Mode bits 2+2  
Global Gain 7  
Gain 7  
Unused bits 1+1  
Midband 6×2 12×2  
Algebraic VQ 16 32 48 64 80 96 112 116 132 148 164 180 196 212 228 244 HF ISF
Parameters 9  
HF gain 7  
HF Gain correction 8 × 2  
Total in bits 80 96 112 128 144 160 176 192 208 224 240 256 272 288 304 320
* * *
Table 9 Bit allocations for stereo encoder for 1024-sample window
* * *
Parameter Number of bits  
Mode bits 2+2+2+2  
Global Gain 7  
Gain 7  
Unused bits 1+1+1+1  
Midband 6×4 12×4  
Algebraic VQ 46 78 110 142 174 206 238 246 278 310 342 374 406 438 470 502 HF
ISF Parameters 9  
HF gain 7  
HF Gain correction 16 × 3  
Total in bits 160 192 224 256 288 320 352 384 416 448 480 512 544 576 608 640
* * *
# 5 Functional description of the encoder
In this clause, the different functions of the encoder extension modes
represented in Figure 1 are described. Input signals are understood as
internal, i.e. sampled at the internal sampling frequency _Fs_.
## 5.1 Input signal pre-processing
Input signals are pre-processed in order to bring them to the internal
sampling frequency of the encoder _Fs kHz_. The signal is upsampled by a
factor _K_ (related to the desired internal sampling frequency), filtered by a
a low pass filter and then downsampled by a factor 180. This operation is
efficiently implemented by a polyphase filter implementation.
The resulting signals are further decomposed into two equal critically sampled
bands as shown in the following figure:
{width="5.346527777777778in" height="1.4319444444444445in"}
At an internal sampling rate of _Fs kHz_ , the lower band signals are obtained
by first low-pass filtering to _Fs_ /4 kHz critically downsampling the low-
pass filtered signal to Fs/2 kHz. The higher band signals are obtained by
band-pass filtering the input signals to frequencies above Fs/4 kHz, and
critically downsampling the high-pass filtered signal to Fs/2kHz sampling
frequency.
### 5.1.1 High Pass Filtering
The lower band signals are high pass filtered. The high-pass filter serves as
a precaution against undesired low frequency components. A high pass filter is
used, and it is given by
{width="1.875in" height="0.5in"}
where the filter parameters are dependent on the internal sampling rate.
### 5.1.2 Stereo Signal Downmixing/Bandsplitting
When the input audio signal is stereo, the lower band mono signal is obtained
by downmixing the left and right channels according to the following
{width="1.9583333333333333in" height="0.2361111111111111in"}
where {width="0.4722222222222222in" height="0.2361111111111111in"}, resp.
{width="0.4722222222222222in" height="0.2361111111111111in"}, is the lower
band signal from the left, resp. right, channels. The lower band mono signal
is supplied to the core low band encoder for TCX/ACELP encoding.
For stereo encoding, the obtained downmixed mono signal
{width="0.4861111111111111in" height="0.2361111111111111in"} and the right
channel signal {width="0.4722222222222222in" height="0.2361111111111111in"}
are further split into two bands: a critically sampled low frequency band and
a residual high frequency band according to the following diagram
{width="5.378472222222222in" height="1.4229166666666666in"}
The critically sampled low band output signals, {width="0.5416666666666666in"
height="0.25in"} and {width="0.5138888888888888in" height="0.25in"} are fed to
the stereo low band encoder, while the signals {width="0.5965277777777778in"
height="0.25in"} and {width="0.5833333333333334in" height="0.25in"} to the
stereo mid band encoder.
## 5.2 Principle of the hybrid ACELP/TCX core encoding
The encoding algorithm at the core of the AMR-WB+ codec is based on a hybrid
ACELP/TCX model. For every block of input signal, the encoder decides (either
in open-loop or closed-loop) which encoding model (ACELP or TCX) is best. The
ACELP model is a time-domain, predictive encoder, best suited for speech and
transient signals. The AMR-WB encoder is used in ACELP modes. Alternatively,
the TCX model is a transform-based encoder, and is more appropriate for
typical music samples. Frame lengths of variable sizes are possible in TCX
mode, as will be explained in Section 5.2.1.
In Sections 5.2.1 to 5.2.4, the general principles of the hybrid ACELP/TCX
core encoder will be presented. Then Section 5.3 and its subsections will give
the details of the ACELP and TCX encoding modes.
### 5.2.1 Timing chart of the ACELP and TCX modes
The ACELP/TCX core encoder takes a mono signal as input, at a sampling
frequency of Fs/2 kHz. This signal is processed in super-frames of 1024
samples in duration. Within each 1024-sample super-frame, several encoding
modes are possible, depending on the signal structure. These modes are:
256-sample ACELP, 256-sample TCX, 512-sample TCX and 1024-sample TCX. These
encoding modes will be described further, but first we look at the different
possible mode combinations, described by a timing chart.
Figure 4 shows the timing chart of all possible modes within an 1024-sample
superframe. As the figure shows, each 256-sample frame within a super-frame
can be into one of four possible modes, which we call ACELP, TCX256, TCX512
and TCX1024. When in ACELP mode, the corresponding 256-sample frame is encoded
with AMR-WB. In TCX256 mode, the frame is encoded using TCX with a 256-sample
support, plus 32 samples of look-ahead used for overlap-and add since TCX is a
transform coding approach. The TCX512 mode means that two consecutive
256-sample frames are grouped to be encoded as a single 512-sample block,
using TCX with a 512-sample support plus 64 samples look-ahead. Note that the
TCX512 mode is only allowed by grouping either the first two 256-sample frames
of the super-frame, or the last two 256-sample frames. Finally, the TCX1024
mode indicates that all 256-sample frames within the super-frame are grouped
together to be encoded in a single block using TCX with an 1024-sample support
plus 128 samples look-ahead.
{width="6.156944444444444in" height="5.219444444444444in"}
Figure 4: Timing chart of the frame types
### 5.2.2 ACELP/TCX mode combinations and mode encoding
From Figure 4, there are exactly 26 different ACELP/TCX mode combinations
within an 1024-sample superframe. These are shown in Table10.
Table 10: Possible mode combinations in an 1024-sample super-frame
* * *
(0, 0, 0, 0) (0, 0, 0, 1) (2, 2, 0, 0)  
(1, 0, 0, 0) (1, 0, 0, 1) (2, 2, 1, 0)  
(0, 1, 0, 0) (0, 1, 0, 1) (2, 2, 0, 1)  
(1, 1, 0, 0) (1, 1, 0, 1) (2, 2, 1, 1)  
(0, 0, 1, 0) (0, 0, 1, 1) (0, 0, 2, 2)  
(1, 0, 1, 0) (1, 0, 1, 1) (1, 0, 2, 2)  
(0, 1, 1, 0) (0, 1, 1, 1) (0, 1, 2, 2) (2, 2, 2, 2) (1, 1, 1, 0) (1, 1, 1, 1)
(1, 1, 2, 2) (3, 3, 3, 3)
* * *
We interpret each quadruplet of numbers (_m_ ~0~, _m_ ~1~, _m_ ~2~, _m_ ~3~)
in Table 10 as follows: _m_ ~k~ is the mode indication for the _k^th^_
256-sample frame in the 1024-sample super-frame, where _m_ ~k~ can take the
following values:
_\- m_ ~k~ = 0 means the mode for frame _k_ is 256-sample ACELP
_\- m_ ~k~ = 1 means the mode for frame _k_ is 256-sample TCX
_\- m_ ~k~ = 2 means the mode for frame _k_ is 512-sample TCX
_\- m_ ~k~ = 3 means the mode for frame _k_ is 1024-sample TCX
Obviously, when the first 256-sample frame is in mode \"2\" (512-sample TCX),
the second 256-sample frame must also be in mode 2. Similarly, when the third
256-sample frame is in mode \"2\" (512-sample TCX), the fourth 256-sample
frame must also be in mode 2. And there is only one possible mode
configuration including the value \"3\" (1024-sample TCX), namely all four
256-sample frames are in the same mode (_m_ ~k~ = 3 for _k_ = 0, 1, 2 and 3).
This rigid frame structure can be exploited to aid in frame erasure
concealment.
As discussed above, the parameters for each 1024-sample super-frame are
actually decomposed into four frames of identical size. To increase
robustness, the mode bits are actually sent as two bits (the values of _m_
~k~) in each transmitted frame. For example, if the superframe is encoded in a
full 1024-sample TCX frame, which is then decomposed into four packets of
equal size, then each of these four packets will contain the binary value
\"11\" (mode _m_ ~k~ = 3) as mode indicator.
### 5.2.3 ACELP/TCX closed-loop mode selection
The best mode combination out of the 26 possible combinations of Table 10 is
determined in closed-loop. This means that the signal in each 256-sample frame
within an 1024-sample super-frame has to be encoded in several modes before
selecting the best combination. This closed-loop approach is explained in
Figure 5.
The left portion of Figure 5 (Trials) shows what encoding mode is applied to
each 256-sample frame in 11 successive trials. Fr0 to Fr3 refer to Frame 0 to
Frame 3 in the super-frame. The trial number (1 to 11) indicates a step in the
closed-loop mode-selection process. Note that each 256-sample frame is
involved in only four of the 11 encoding trials. When more than 1 frame is
involved in a trial (lines 5, 10 and 11 of Figure 5), then TCX of the
corresponding length is applied (TCX512 or TCX1024). The right portion of
Figure 5 gives an example of mode selection, where the final decision (after
Trial 11) is 1024-sample TCX. This would result in sending a value of 3 for
the mode in all four packets for this super-frame. Bold numbers in the example
at the right of Figure 5 show at what point a mode decision is taken in the
intermediate steps of the mode selection process. The final mode decision is
only known after Trial 11.
The mode selection process shown in Figure 5 proceeds as follows. First, in
trials 1 and 2, ACELP (AMR-WB) then 256-sample TCX encoding are tried in the
first 256-sample frame (Fr0). Then, a mode selection is made for Fr0 between
these two modes. The selection criterion is the average segmental SNR between
the weighted speech _x~w~_(_n_) and the synthesized weighted speech
{width="0.4166666666666667in" height="0.25in"}. The segmental SNR in subframe
_i_ is defined as
{width="2.8055555555555554in" height="0.94375in"}
where _N_ is the length of the subframe (equivalent to a 64-sample sub-frame
in the encoder). Then, the average segmental SNR is defined as
{width="1.9027777777777777in" height="0.5in"}
where _N~SF~_ is the number of subframes in the frame. Since a frame can be
either 256, 512 or 1024 samples in length, _N~SF~_ can be either 4, 8 or 16.
In the example of Figure 5, we assume that, according to the
{width="0.5833333333333334in" height="0.2638888888888889in"}decision
criterion, mode ACELP was retained over TCX. Then, in trials 3 and 4, the same
mode comparison is made for Fr1 between ACELP and 256-sample TCX. Here, we
assume that 256-sample TCX was better than ACELP, based again on the segmental
SNR measure described above. This choice is indicated in bold on line 4 of the
example at the right of Figure 5. Then, in trial 5, Fr0 and Fr1 are grouped
together to form a 512-sample frame which is encoded using 512-sample TCX. The
algorithm now has to choose between 512-sample TCX for the first 2 frames,
compared to ACELP in the first frame and TCX256 in the second frame. In this
example, on line 5 in bold, the sequence ACELP-TCX256 was selected over
TCX-512, according to the segmental SNR criterion.
| TRIALS (11) |  | Example of selection (in bold = comparison is made) |  |  |  |  |  |   
---|---|---|---|---|---|---|---|---|---  
| Fr 0 | Fr 1 | Fr 2 | Fr 3 |  | Fr 0 | Fr 1 | Fr 2 | Fr 3  
1 | ACELP |  |  |  |  | ACELP |  |  |   
2 | TCX256 |  |  |  |  | **ACELP** |  |  |   
3 |  | ACELP |  |  |  | ACELP | ACELP |  |   
4 |  | TCX256 |  |  |  | ACELP | **TCX256** |  |   
5 | TCX512 | TCX512 |  |  |  | **ACELP** | **TCX256** |  |   
6 |  |  | ACELP |  |  | ACELP | TCX256 | ACELP |   
7 |  |  | TCX256 |  |  | ACELP | TCX256 | **TCX256** |   
8 |  |  |  | ACELP |  | ACELP | TCX256 | TCX256 | ACELP  
9 |  |  |  | TCX256 |  | ACELP | TCX256 | TCX256 | **TCX256**  
10 |  |  | TCX512 | TCX512 |  | ACELP | TCX256 | **TCX512** | **TCX512**  
11 | TCX1024 | TCX1024 | TCX1024 | TCX1024 |  | **TCX1024** | **TCX1024x** | **TCX1024** | **TCX1024**  
Figure 5: Closed-loop selection of ACELP/TCX mode combination
The same procedure as trials 1 to 5 is then applied to the third and fourth
frames (Fr2 and Fr3), in trials 6 to 10. After trial 10, in the example of
Figure 5, the four 256-sample frames are classified as: ACELP for F0, then
TCX256 for F1, then TCX512 for F2 and F3 grouped together. A last trial (line
11) is then performed where all four 256-sample frames (the whole super-frame)
are encoded with 1024-sample TCX. Using the segmental SNR criterion, again
with 64-sample segments, this is compared with the signal encoded using the
mode selection in trial 10. In this example, the final mode decision is
1024-sample TCX for the whole frame. The mode bits for each 256-sample frame
would then be (3, 3, 3, 3) as discussed in Table10.
### 5.2.4 ACELP/TCX open-loop mode selection
**The alternative method for ACELP/TCX mode selection is the low complexity
open-loop method. The open-loop mode selection is divided into three selection
stages: Excitation classification (EC), excitation classification refinement
(ECR) and TCX selection (TCXS). The mode selection is done purely open-loop
manner in EC and ECR. The usage of TCXS algorithm depends on EC and ECR and it
is closed loop TCX mode selection.**
**1\. stage**
The first stage excitation classification **is done before LP analysis. The EC
algorithm** is based on the frequency content of the input signal using the
VAD algorithm filter bank.
AMR-WB VAD produces signal energy **_E(n)_** in the 12 non-uniform bands over
the frequency range from 0 to Fs/4 kHz for every 256-sample frame. Then energy
levels of each band are normalised by dividing the energy level **_E(n)_**
from each band by the width of that band in Hz producing normalised
**_E~N~(n)_** energy levels of each band where n is the band number from 0 to
11. Index 0 refers to the lowest sub band.
For each of the 12 bands, the standard deviation of the energy levels is
calculated using two windows: a short window **_std~short~(n)_** and a long
window **_std~long~(n)_**. The length of the short and long window is 4 and 16
frames, respectively. In these calculations, the 12 energy levels from the
current frame together with past 3 or 15 frames are used to derive two
**_stda~short~_** and **_stda~long~_** standard deviation values. The standard
deviation calculation is performed only when VAD indicates active signal.
The relation between lower frequency bands and higher frequency bands are
calculated in each frame. The energy of lower frequency bands **_LevL_** from
1 to 7 are normalised by dividing it by the length of these bands in Hz. The
higher frequency bands 8 to 11 are normalised respectively to create
**_LevH_**. Note that the lowest band 0 is not used in these calculations
because it usually contains so much energy that it will distort the
calculations and make the contributions from other bands too small. From these
measurements the relation **_LPH = LevL / LevH_** is defined. In addition, for
each frame a moving average **_LPHa_** is calculated using the current and 3
past **_LPH_** values. The final measurement of the low and high frequency
relation **_LPHaF_** for the current frame is calculated by using weighted sum
of the current and 7 past **_LPHa_** values by setting slightly more weighting
for the latest values.
The average level (**_AVL_**) in the current frame is calculated by
subtracting the estimated level of background noise from each filter bank
level after which the filter bank levels are normalised to balance the high
frequency bands containing relatively less energy than the lower bands. In
addition, total energy of the current frame, **_TotE~0,~_** is derived from
all the filter banks subtracted by background noise estimate of the each
filter bank. Total energy of previous frame is therefore _**TotE~-1~**._
After calculating these measurements, a choice between ACELP and TCX
excitation is made by using the following pseudo-code:
> if (**_stda~long~_** \ else if (LPHaF > 280)
SET TCX_MODE
> else if (**_stda~long~_** >= 0.4)
>
> if ((5+(1/( **_stda~long~_** -0.4))) > LPHaF)
SET TCX_MODE
> else if ((-90* **_stda~long~_** +120) \ else
SET UNCERTAIN_MODE
> if (ACELP_MODE or UNCERTAIN_MODE) and (**_AVL_** > 2000)
SET TCX_MODE
> if (UNCERTAIN_MODE)
>
> if (**_stda~short~_** \ else if (**_stda~short~_** >= 0.2)
>
> if ((2.5+(1/( **_stda~short~_** -0.2))) > LPHaF)
SET TCX_MODE
> else if ((-90* **_stda~short~_** +140) \ else
SET UNCERTAIN_MODE
> if (UNCERTAIN_MODE)
>
> if ((**_TotE~0~_** / **_TotE~-1\ ~_**)>25)
SET ACELP_MODE
> if (TCX_MODE \|\| UNCERTAIN_MODE))
>
> if (**_AVL_** > 2000 and **_TotE~0\ ~_** \ if (**_SD~n~_** > 0.2)
>
> Mode = ACELP_MODE;
>
> else
>
> if (**_LagDif~buf~_** \
> if (**_Lag~n\ ~_** == HIGH LIMIT or **_Lag~n~_** == LOW LIMIT){
>
> if (**_Gain~n~_** -**_NormCorr~n~_** \0.9)
>
> Mode = ACELP_MODE
>
> else
>
> Mode = TCX_MODE
>
> else if (**_Gain~n~_** \- **_NormCorr~n~_** \
> 0.88)
>
> Mode = ACELP_MODE
>
> else if (**_Gain~n~_** \-- **_NormCorr~n~_** > 0.2)
>
> Mode = TCX_MODE
>
> else
>
> **_NoMtcx_** = **_NoMtcx_** +1
>
> if (**_MaxEnergy~buf~_** \
> if (**_SD~n~_** > 0.15)
>
> Mode = ACELP_MODE;
>
> else
>
> **_NoMtcx_** = **_NoMtcx_** +1.
Where spectral distance, **_SD~n~_** , of the frame _n_ is calculated from ISP
parameters as follows:
{width="2.0694444444444446in" height="0.4722222222222222in"},
where ISP~n~ is the ISP coefficients vector of the frame _n_ and ISP~n~(i) is
_i_ th element of it.
**_LagDif~buf\ ~_** is the buffer containing open loop lag values of previous
ten frames (256 samples).
**_Lag~n~_** contains two open loop lag values of the current frame _n_.
**_Gain~n~_** contains two LTP gain values of the current frame _n_.
**_NormCorr~n~_** contains two normalised correlation values of the current
frame _n_.
**_MaxEnergy~buf~_** is the maximum value of the buffer containing energy
values. The energy buffer contains last six values of current and previous
frames (256 samples).
**_lph~n\ ~_** indicates the spectral tilt.
If VAD flag is set and mode has been classified in EC algorithm as ACELP mode,
the mode decision is verified according to following algorithm where mode can
be switched to TCX mode.
> if (**_LagDif~buf~_** \
> if (**_NormCorr~n~_** \
> Mode = TCX_MODE;
>
> if (**_lph~n~_** > 200 and **_SD~n~_** \
> Mode = TCX_MODE
If VAD flag is set in current frame and VAD flag has set to zero at least one
of frames in previous super-frame and the mode has been selected as TCX mode,
the usage of TCX1024 is disabled (the flag **_NoMtcx_** is set).
> if (**_vadFlag~old~_** == 0 and **_vadFlag_** == 1 and Mode == TCX_MODE))
>
> **_NoMtcx_** = **_NoMtcx_** +1
If VAD flag is set and mode has been classified as uncertain mode
(TCX_OR_ACELP) or TCX mode, the mode decision is verified according to
following algorithm.
> if (**_Gain~n~_** \- **_NormCorr~n~_** \ 0.92
> and **_Lag~n~_** > 21)
>
> **_DFTSum_** = 0;
>
> for (i=1; i\
> **_DFTSum_** = **_DFTSum_** \+ **_mag_**[i];
>
> if (**_DFTSum_** > 95 and **_mag_**[0] \
> Mode = TCX_MODE;
>
> else
>
> Mode = ACELP_MODE;
>
> **_NoMtcx_** = **_NoMtcx_** +1
**_vadFlag~old\ ~_** is the VAD flag of the previous frame and **_vadFlag_**
is the VAD flag of the current frame.
**_NoMtcx_** is the flag indicating to avoid TCX transformation with long
frame length (1024 samples), if TCX coding model is selected.
**_Mag_** is a discete Fourier transformed (DFT) spectral envelope created
from LP filter coefficients, **_Ap,_** of the current frame. **_DFTSum_** is
the sum of first 40 elements of the vector **_mag_** , excluding the first
element (**_mag(0)_**) of the vector **_mag_**.
If VAD flag is set and the mode, **_Mode(Index)_** , of the **_Index_** th
frame of current superframe has still been classified as uncertain mode
(TCX_OR_ACELP), the mode is decided based on selected modes in the previous
and current superframes. The counter, **_TCXCount_** , gives the number of
selected long TCX frames (TCX512 and TCX1024) in previous superframe (1024
samples). The counter, **_ACELPCount_** , gives the number of ACELP frames
(256 samples) in previous and current superframes.
> if ((**_prevMode(i)_** == TCX1024 or **_prevMode(i)_** == TCX512) and
> **_vadFlag~old~(i)_** == 1 and **_TotE~i~_** > 60)
>
> **_TCXCount_** = **_TCXCount_** \+ 1
>
> if (**_prevMode(i)_** == ACELP_MODE)
>
> **_ACELPCount_** = **_ACELPCount_** \+ 1
>
> if (**_Index_** != **_i_**)
>
> if (**_Mode(i)_** == ACELP_MODE)
>
> **_ACELPCount_** = **_ACELPCount_** \+ 1
Where **_prevMode(i)_** is the **_i_ _th_ frame (256 samples) in the previous
superframe, **_Mode(i)_**is the** _i_ _th_ frame in the current superframe.
**_i_** is the frame (256 samples) number in superframe (1, 2, 3, 4), The
mode, **_Mode(Index)_** , is selected based on the counters **_TCXCount_** and
**_ACELPCount_** as follows
> if (**_TCXCount_** > 3)
>
> **_Mode(Index)_** = TCX_MODE;
>
> else if (**_ACELPCount_** > 1)
>
> **_Mode(Index)_** = ACELP_MODE
>
> else
>
> **_Mode(Index)_** = TCX_MODE
**3\. stage: TCXS is done only if** the number of ACELP modes selected in EC
and ECR is less than three (ACELP\ Same as 3GPP TS 26.190.
#### **5.3.4.6 Quantization of the adaptive and fixed codebook gains**
The adaptive codebook gain (pitch gain) and the fixed (algebraic) codebook
gain are vector quantized using the same 7-bit codebook used in AMR-WB for
modes 2 to 8. However, instead of using MA prediction to obtain the predicted
gain _g_ \'_~c~_ , it is found by directly quantizing the average innovation
energy in the whole frame.
Let _E~s~_(_n_) be the innovation energy (in dB) at subframe _n_ , and given
by
{width="3.3194444444444446in" height="0.5in"}
where _N_ =64 is the subframe size, _c_(_i_) is the fixed codebook excitation,
and _E~i~_ is the un-scaled innovation energy given by
{width="1.1111111111111112in" height="0.4722222222222222in"}
An estimated innovation energy {width="0.20833333333333334in"
height="0.2638888888888889in"} is computed and quantized, and used to find the
estimated gain _g_ \'_~c~_ . That is,
{width="1.0965277777777778in" height="0.2777777777777778in"}
which is derived from the relation {width="1.4583333333333333in"
height="0.2638888888888889in"}.
A correction factor between the gain _g~c~_ and the estimated one _g_ \'_~c~_
is given by
{width="0.8055555555555556in" height="0.2638888888888889in"}
The pitch gain, _g~p~_ , and correction factor γ are jointly vector quantized
using the same 7-bit codebook used in AMR-WB, and using the same error
minimization procedure. That is, the gain codebook search is performed by
minimizing the mean-square of the weighted error between original and
reconstructed signal.
The estimated innovation energy is computed and quantized as follows. First,
the LP residual energy is computed in each subframe _n_ by
{width="2.111111111111111in" height="0.5in"}
then the average residual energy per subframe is found by
> {width="1.2777777777777777in" height="0.4722222222222222in"}
The innovation energy is estimated from the residual energy by removing an
estimate of the adaptive codebook contribution. This is done by removing an
energy related to the average normalized correlation obtained from the two
open-loop pitch analyses performed in the frame. That is
> {width="1.0965277777777778in" height="0.2638888888888889in"}
where {width="0.18055555555555555in" height="0.20833333333333334in"} is the
average of the normalized pitch correlations obtain for each half-frame from
the open-loop pitch analysis.
The estimated innovation energy is quantized once per frame using 2 bits, with
the quantization levels: 18, 30, 42, and 54. Further, the quantized estimated
innovation energy {width="0.20833333333333334in"
height="0.2638888888888889in"} is constrained to be larger than _E~max~_ -37,
where _E~max~_ is the maximum value of _E~res~_(_n_) from the 4 subframes.
This is done by incrementing {width="0.20833333333333334in"
height="0.2638888888888889in"} by 12 (and the quantization index by 1) until
{width="1.0416666666666667in" height="0.2638888888888889in"} or
{width="0.5694444444444444in" height="0.2638888888888889in"}.
The quantized estimated innovation energy is then used to compute the
estimated gain in each subframe is explained above.
### 5.3.5 TCX Excitation encoder
This section presents the details of the TCX encoder, which is one of the
possible modes to encode the mono, low-frequency signal in the 0-Fs/4 kHz
band. Section 5.3.5.1 first presents the block diagram of the TCX encoder.
Then, the details of each module are given in sections 5.3.5.2 to 5.3.5.13.
#### **5.3.5.1 TCX encoder block diagram**
Figure 6 shows a block diagram of the TCX encoding mode. The TCX encoding
principle is similar for TCX frames of 256, 512 and 1024 samples, with a few
differences mostly involving the windowing and filter interpolation. The input
audio signal is first filtered through a time-varying weighting filter (same
perceptual filter as in AMR-WB) to obtain a weighted signal **_x_**. The
weighting filter coefficients are interpolated in the ISP domain as in Section
5.3.2.6. The interpolation is linear, and the beginning and end of the
interpolation depend on the refresh rate of the LPC filter. The LPC filter is
transmitted only once per TCX frame. For longer frames (TCX512 and TCX1024)
the interpolated LPC filters will be farther apart that in the case of TCX256
or ACELP frames.
Continuing in Figure 6, if the past frame was an ACELP frame, the zero-input
response (ZIR) of the weighting filter is removed from the weighted signal,
using the filter state at the end of the previous (ACELP) frame. The signal is
then windowed (the window shape will be described in section 5.3.5.4) and a
transform is applied to the windowed signal. In the transform domain, the
signal is first pre-shaped, to minimize coding noise artefact in the low-
frequencies, and then quantized using a specific lattice quantizer.
Specifically, an 8-dimensional multi-rate lattice quantizer is used, based on
an extension of the Gosset lattice.
After quantization, the inverse pre-shaping function is applied to the
spectrum which is then inverse transformed to provide a quantized time-domain
signal. The gain for that frame is then rescaled to optimize the correlation
with the original weighted signal. After gain rescaling, a window is again
applied to the quantized signal to minimize the block effects due to
quantizing in the transform domain. Overlap-and-add is used with the previous
frame if it was also in TCX mode. Finally, the excitation signal is found
through inverse filtering with proper filter memory updating. This TCX
excitation is in the same \"domain\" as the ACELP (AMR-WB) excitation.
{width="6.299305555555556in" height="8.959027777777777in"}
Figure 6: Principle of TCX encoding
Each module of Figure 6 will now be detailed in the following subsections.
#### 5.3.5.2 Computation of the target signal for transform coding
To obtain the weighted signal, the input frame of audio samples is filtered
with a perceptual filter having the following transfer function:
{width="1.3055555555555556in" height="0.4583333333333333in"}
Here, {width="0.3611111111111111in" height="0.2638888888888889in"}is the
quantized LP filter, interpolated at every 64-sample sub-frame in the ISP
domain as in Section 5.3.2.6, and {width="0.75in"
height="0.2638888888888889in"}is the weighted version of that filter. The
denominator of _W_(_z_) is a constant polynomial of order 1, which is equal to
the numerator of the pre-emphasis filter in Section 5.3.1.
#### 5.3.5.3 Zero-input response subtraction
If the previous encoded frame was ACELP, then the zero-input response (ZIR) of
the combination of the weighting filter and synthesis filter is removed from
the weighted signal. The ZIR is truncated to 128 samples and windowed in such
a way that its amplitude monotonically decreases to zero at after 128 samples.
The truncated ZIR is computed through the following steps:
Using the filter states at the end of the previous frame, compute the ZIR of
the following transfer function over 2 consecutive subframes (128 samples
duration):
{width="1.6666666666666667in" height="0.5in"}
where {width="0.3611111111111111in" height="0.2638888888888889in"}and
{width="0.75in" height="0.2638888888888889in"} are as defined in Section
5.3.5.2.
Then, calling _z_(_n_) the truncated ZIR of _H_(_z_) (truncated to the first 2
_N_ samples, where N=64 is the subframe length), compute _z~w~_(_n_), the
windowed ZIR such that it is always forced to zero at the last sample:
_z~w~_(_n_) = _z_(_n_)*_w_(_n_) for _n_ = 0 to 2 _*N_ -1
where
_w_(_n_) = 1 for _n_ = 0 to _N_ -1
and _w_(_n_) = (2*_N_ -_n_) / _N_ for _n_ = _N_ to 2 _*N_ -1
The shape of _w_(_n_) is shown in Figure 7 below, for a value of _N_ = 64.
{width="4.789583333333334in" height="2.8875in"}
Figure 7: Shape of window to truncate the ZIR
After computing _z~w~_(_n_), it is removed from the first 2*_N_ samples of the
weighted signal _x(n)_. This removal of the ZIR from the past frame is
performed only when the past frame was in ACELP mode.
#### 5.3.5.4 Windowing of target signal
In TCX mode, windowing in applied prior to the transform, and after the
inverse transform, in order to apply overlap-and-add to minimize the framing
effects due to quantization.
To smooth the transition between ACELP and TCX modes, proper care has to be
given to windowing and overlap of successive frames. Figure 8 shows the window
shapes depending on the TCX frame length and the type of the previous frame
(ACELP of TCX).
{width="6.104861111111111in" height="7.063194444444444in"}
Figure 8: Target signal windowing in TCX coding
The window is defined as the concatenation of the following three sub-windows:
_w_ ~1~(_n_) = sin(_2_ π _n_ / (4 _L_ ~1~) ) for _n_ = 0, ..., _L_ ~1~-1
_w_ ~2~(_n_) = 1 for _n_ = 0, ..., _L_ \- _L_ ~1~-1
_w_ ~3~(_n_) = sin(_2_ π _n_ / (4 _L_ 2) ) for _n_ = _L_ ~2~, ..., 2 _L_ ~2~-1
The constants _L_ ~1~, _L_ ~2~ and _L_ are defined as follows.
_L_ ~1~ = 0 when the previous frame is a 256-sample ACELP frame
_L_ ~1~ = 32 when the previous frame is a 256-sample TCX frame
_L_ ~1~ = 64 when the previous frame is a 512-sample TCX frame
_L_ ~1~ = 128 when the previous frame is an 1024-sample TCX frame
Additionally:
**For 256** -sample **TCX** : _L_ = 256 and _L_ ~2~ = 32
**For 512** -sample **TCX** : _L_ = 512, and _L_ ~2~ = 64
**For 1024** -sample **TCX** : _L_ = 1024, and _L_ ~2~ = 128 and
We note again that all these window types are applied to the weighted signal,
only when the present frame is a TCX frame. Frames of type ACELP are encoded
as in AMR-WB encoding (i.e. through analysis-by-synthesis encoding of the
excitation signal, so as to minimize the error in the target signal -- the
target signal is essentially the weighted signal from which the zero-input
response of the weighting filter is removed).
#### **5.3.5.5 Transform**
After windowing, the signal is mapped to the frequency domain through a
Discrete Fourier Transform (DFT), defined as:
{width="2.138888888888889in" height="0.5416666666666666in"}
where _L~TOT~_ is the number of samples in the DFT. _L~TOT~_ depends on the
frame length (256, 512 or 1024 samples, plus the lookahead which is a function
of the frame length).
An FFT is used to accelerate the computation of the Fourier coefficients. A
radix-9 FFT is used to adapt to the frame length which is not a power of 2.
Including the overlap in the windowing described in Section 5.3.5.4, the
number of samples at the input of the FFT is, respectively, _L~TOT~_ = 288 for
256-sample TCX frames (256 samples in the frame plus 32 samples in the look-
ahead), _L~TOT~_ =576 for 512-sample TCX (512 samples in the frame plus 64
samples in the lookahead), and _L~TOT~_ =1152 samples for 1024-sample TCX
(1024 samples in the frame plus 128 samples in the lookahead).
#### 5.3.5.6 Spectrum pre-shaping
Once the Fourier spectrum (FFT) is computed, an adaptive low-frequency
emphasis module is applied to the spectrum, to minimize the perceived
distortion in the lower frequencies. The inverse low-frequency emphasis will
be applied at the decoder, as well as in the encoder to allow obtaining the
excitation signal necessary to encode the next frames. The adaptive low-
frequency emphasis is applied only on the first quarter of the spectrum, as
follows.
First, we call _X_ the transformed signal at the output of the transform (FFT)
in Figure 6. The Fourier coefficient at Nyquist frequency is systematically
set to 0. Then, if _L~TOT~_ is the number of samples in the FFT (_L~TOT~_ is
thus the window length), the _K_ = _L~TOT~_ /2 complex-valued Fourier
coefficients are grouped in blocks of four consecutive coefficients, forming
8-dimensional real-valued blocks. This block size of 8 is chosen to coincide
with the 8-dimensional lattice quantizer used for spectral quantization. The
energy of each block is computed, up to the first quarter of the spectrum. The
energy _E~max~_ and position index _I_ of the block with maximum energy are
stored. Then, we calculate a factor for each 8-dimensional block with position
index _m_ smaller than _I_ , as follows:
\- calculate the energy _E~m~_ of the 8-dimensional block at position index
_m_
\- compute the ratio _R~m~_ = _E~max~_ / _E~m~_
\- compute the value (_R~m~_) ^¼^
\- if _R~m~_ > 10, then set _R~m~_ = 10 (maximum gain of 20 dB)
\- also, if _R~m~_ > _R~m-1~_ then _R~m~_ = _R ~m-1~_
This last condition ensures that the ratio function _R~m~_ decreases
monotonically. Further, limiting the ratio _R~m~_ to be smaller or equal to 10
means that no spectral components in the low-frequency emphasis function will
be modified by more than 20 dB.
After computing the ratio _R~m~_ = (_E~max~_ / _E~m~_) ^¼^ for all blocks with
position index smaller that _I_ (and with the limiting conditions described
above), we then apply these ratios as a gain for each corresponding block.
This has the effect of increasing the energy of blocks with relatively low
energy compared to the block with maximum energy _E~max~_. Applying this
procedure prior to quantization has the effect of shaping the coding noise in
the lower band, such that low energy components before the first spectral peak
will be better encoded.
#### 5.3.5.7 Split multi-rate lattice VQ
To quantize the pre-shaped spectrum _X_ of the weighted signal in TCX mode, a
method based on lattice quantizers is used. Specifically, the spectrum is
quantized in 8-dimensional blocks using vector codebooks composed of subsets
of the Gosset lattice, referred to as the _RE~8~_ lattice (see [6]). All
points of a given lattice can be generated from the so-called _generator
matrix G_ of the lattice, as _c_ = _k_ _G_ , where _k_ is a line vector with
integer values and _c_ is the generated lattice point. To form a vector
codebook at a given rate, only lattice points inside a sphere (in 8
dimensions) of a given radius are taken. Multi-rate codebooks can thus be
formed by taking subsets of different radii.
In lattice quantization, the operation of finding the nearest neighbour of an
input vector _x_ among all codebook points is reduced to a few simple
operations, involving rounding the components of a vector and verifying a few
constraints. Hence, no exhaustive search is carried out as in stochastic
quantization, which uses stored tables. Once the best lattice codebook point
is determined, further calculations are also necessary to compute the binary
index that will be sent to the decoder. The larger the components of the input
vector _x_ , the more bits will be required to encode the index of its nearest
neighbour in the lattice codebook. Hence, to remain within a pre-defined bit
budget, a gain-shape approach has to be used, where the input vector is first
scaled down, i.e. divided by a gain which has to be estimated, then quantized
in the lattice, then scaled up again to produce the quantization result. To
reduce computation complexity, the binary indices will actually only be
calculated if a given TCX mode is retained as the best mode for a frame.
For simplicity, we let _N_ be the length of the DFT. Since the transform used
to obtain _X_ is a Discrete Fourier Transform, there are _N_ /2+1 Fourier
coefficients including _X_(_N_ /2) at Nyquist frequency. In the quantization
process, coefficient _X_(_N_ /2) is always set to 0, so there are exactly _N_
/2 Fourier coefficients to quantize. Then, all coefficients of _X_ are
complex, except _X_(0) which is real.
To be quantized using the _RE~8~_ lattice codebooks, the pre-shaped spectrum
_X_ is split into consecutive blocks of 8 real values (4 consecutive complex
coefficients). There are _K_ =_N_ /8 such blocks in the whole spectrum. We
call _B~k~_ the _k^th^_ block, with _k_ = 0, 1, ..., _K_ -1. To remain within
the total bit budget, the spectrum _X_ will have to be divided by a global
gain _g_ prior to quantization, and multiplied by the quantized global gain
after each block _B~k~_ is encoded using the _RE~8~_ lattice. We call _X_
\'=_X_ /_g_ the scaled spectrum and _B\'~k~_ = _B~k~_ / _g_ the _k^th^_ scaled
block. Thus, the parameters sent to the decoder to encode the TCX spectrum _X_
are the global gain _g_ and the index of the nearest neighbour of each block
_B~k~_ within the lattice codebook.
The index of the nearest neighbour in the lattice is actually composed of
three parts: 1) a codebook index, which essentially represents the bit
allocation for each 8-dimensional vector; 2) a vector index, which uniquely
identifies a lattice vector in a so-called _base codebook C_ ; and 3) an
extention index _k_ , which is used to extend the base codebook when the
selected point in the lattice is not in the base codebook _C_. The extension
used, called the _Voronoi_ extension, will be described in Step 5 below.
These parameters are encoded using the 5 Steps described below.
**Step 1** Find the energy _E~k~_ of each block _B~k~_ :
{width="1.9861111111111112in" height="0.4722222222222222in"}
and obtain from _E~k~_ a first estimate of the bit budget using the starting
assumption that the global gain _g_ equals 1 (i.e. that the spectrum _X_ is
quantized without scaling first):
{width="1.125in" height="0.3611111111111111in"}
The formula for _R~k~_(1) is based on the properties of the underlying _RE~8~_
lattice, and the method used for encoding the index of a lattice point
selected by the quantizer. These properties and encoding method will be
described in Steps 3 and 5.
Unless the energy of the frame is very small, the block energies _E~k~_ will
be too large to ensure that the total bit consumption (sum of all _R~k~_(1))
remains within the total bit budget for the frame. Hence, it is necessary to
estimate a gain _g_ so that the quantization of _X_ \'=_X_ /_g_ in the _RE~8~_
lattice will produce a set of indices that stay within the bit budget. This
gain estimation is performed in Step 2.
**Step 2** The estimation of the global gain _g_ for the TCX frame is
performed in an iteration, as follows.
**Initialisation:** Set _fac_ = 128, _offset_ = 0 and _nbits_max_ =
0.95*(NB_BITS_ - _K_)
**Iteration:** Do the following block of operations _NITER_ times (here,
_NITER_ = 10).
1- offset = offset + fac
2- {width="1.9722222222222223in" height="0.44375in"}
3- if nbits \ 0, then _y_ 1~k~(_I_) = _y_ 1~k~(_I_) + 2
_6\. z_ ~k~ = 0.5 * (_B\'~k~_ \- **1.0**) where **1.0** denotes a vector with
all 1\'s
7\. Round each component of _z_ ~k~ to the nearest integer, to generate
{width="0.18055555555555555in" height="0.20833333333333334in"}
_8\. y_ 2~k~ = 2{width="0.18055555555555555in" height="0.20833333333333334in"}
9\. calculate _S_ as the sum of the components of _y_ 2~k~
10\. If _S_ is not an integer multiple of 4 (negative values are possible),
then modify one of its components as follows:
\- find the position _I_ where abs(_z_ ~k~(_i_)- _y_ 2~k~(_i_)) is the highest
\- if _z_ ~k~(_I_)- _y_ 2~k~(_I_) \ 0, then _y_ 2~k~(_I_) = _y_ 2~k~(_I_) + 2
_11\. y_ 2~k~ = _y_ 2~k~ + **1.0**
12\. Compute _e_ 1~k~ = (_B\'~k~_ \- _y_ 1~k~)^2^ and _e_ 2~k~ = (_B\'~k~_ \-
_y_ 2~k~)^2^
13\. If _e_ 1~k~ > _e_ 2~k~, then the best lattice point (nearest neighbour in
the lattice) is _y_ 1~k~
otherwise the best lattice point is _y_ 2~k~ .
This is noted as {width="0.4722222222222222in"
height="0.2361111111111111in"}where _c~k~_ is the best lattice point as
selected above.
Through this quantization procedure, the scaling gain _g_ , estimated in Step
2, is left unquantized. The gain will be quantized only after being recomputed
as in Section 5.3.5.10, to obtain {width="0.1527777777777778in"
height="0.2222222222222222in"}. The quantized spectrum will then be obtained
as {width="0.625in" height="0.25in"}.
We note that after this lattice quantization step, the indices of the selected
lattice points are not known. The indices will only be computed if a
particular TCX mode is selected instead of an ACELP mode. (See Step 5 for the
lattice index computation)
**Step 4** A last step in the quantization procedure is the determination and
quantization of a comfort noise factor. Comfort noise enhances the perceived
quality in transform-based coders, which is the case for the TCX modes.
Comfort noise will be added only to unquantized spectral components in the
upper-half of the spectrum (Fs/8 kHz and above). Taking again _K_ as the total
number of 8-dimensional blocks in the spectrum, the comfort noise factor is
calculated as follows:
**Initialisation:** Set _nbits_ = 0, _n_ = 1 and take the _offset_ value at
the end of the iteration in Step 2 above.
**Iteration** : For _k_ = _K_ / 2 to _K_ -1, do
_1 tmp_ = _R~k~_(1) - _offset_ ( with _R~k~_(1) as calculated in Step 1)
2\. if (_tmp_ \ 10, then set _R~m~_ = 10 (maximum gain of 20 dB)
\- also, if _R~m~_ > _R~m-1~_ then _R~m~_ = _R ~m-1~_
After computing the ratio _R~m~_ = (_E~max~_ / _E ~m~_) ^½^ for all blocks
with position index smaller that _I_ (and with the limiting conditions
described above), we then divide each block by the corresponding ratio. Note
that if we neglect the effects of quantization, this de-shaping is the inverse
of the pre-shaping function as applied in Section 5.3.5.6.
#### 5.3.5.9 Inverse transform
The quantized spectrum {width="0.4027777777777778in" height="0.25in"}is
inverse transformed to obtain the time-domain quantized signal
{width="0.34652777777777777in" height="0.2222222222222222in"}. The Inverse DFT
is applied, as defined by:
{width="1.6805555555555556in" height="0.5277777777777778in"}
where _L~TOT~_ is the number of samples in the TCX frame, as defined in
Section 5.3.5.5. An Inverse FFT is used to optimize the computation time of
the inverse DFT.
#### 5.3.5.10 Gain optimization and quantization
The global gain estimated in Section 5.3.5.7 to scale the spectrum prior to
the multi-rate lattice quantization is not guaranteed to maximize the
correlation between the original weighted signal _x_ and the quantized
weighted signal {width="0.1388888888888889in" height="0.19375in"}. Thus, after
the inverse transform of the quantized spectrum (Section 5.3.5.9), the optimal
gain between _x_ and {width="0.1388888888888889in" height="0.19375in"} is
computed as follows:
{width="1.2777777777777777in" height="0.94375in"}
with _L~TOT~_ as defined previously. Then, the gain _g*_ is quantized on a
logarithmic scale to a 7-bit index, using the following procedure. The
procedure is purely algebraic and does not require storing a gain codebook.
1\. Calculate the energy of the quantized weighted signal:{width="0.125in"
height="0.2361111111111111in"}{width="0.9861111111111112in"
height="0.4861111111111111in"}
2\. Compute the RMS value: {width="1.0277777777777777in"
height="0.5277777777777778in"} (known also at the decoder)
3\. Set _G_ = _g*_ x _rms_ (normalization step)
4\. Calculate the index as {width="1.8333333333333333in" height="0.25in"}
where {width="0.2638888888888889in" height="0.25in"} denotes removing the
fractional part of _x_ (rounding towards 0).
5\. If _index_ \127, then set
_index_ = 127.
The quantized gain {width="0.25in" height="0.2222222222222222in"}can be
calculated as follows, both as the encoder and decoder since the decoder can
calculate locally the value of _rms_ :
{width="0.875in" height="0.375in"}
#### 5.3.5.11 Windowing for overlap-and-add
After gain scaling, the quantized weighted signal is windowed again, according
to the TCX frame length and the mode of the previous frame. The window shapes
are as shown in Figure 8 and defined in Section 5.3.5.4.
To reconstruct the complete quantized weighted signal, overlap-and-add is
applied between the memory of the past frame and the beginning of the present
frame corresponding to the non-flat portion of the window. Recall that if the
past frame was in ACELP mode, the memory of the past frame corresponds to the
windowed, truncated ZIR of the perceptual filter, as calculated in Section
5.3.5.3.
#### **5.3.5.12 Memory update**
The samples in the lookahead (windowed portion to the right of the TCX frames
in Figure 8) are kept in memory for the overlap-and-app procedure in the next
TCX frame.
#### **5.3.5.13 Excitation signal computation**
The excitation signal is finally computed by filtering the quantized weighted
signal through the inverse weighting filter with zero-memory. The excitation
is needed at the encoder in particular to update the long-term predictor
memory.
## 5.4 Mono Signal High-Band encoding (BWE)
The encoding of the HF signal is detailed in Figure 9. The HF signal is
composed of the frequency components above Fs/4 kHz in the input signal. The
bandwidth of this HF signal depends on the input signal sampling rate. To
encode the HF signal at a low rate, a bandwidth extension (BWE) approach is
employed. In BWE, energy information is sent to the decoder in the form of
spectral envelope and frame energy, but the fine structure of the signal is
extrapolated at the decoder from the received (decoded) excitation signal in
the LF signal.
The down-sampled HF signal is called _s~HF~_(_n_) in Figure 9. The spectrum of
this signal can be seen as a folded version of the high-frequency band prior
to down-sampling. An LP analysis is performed on _s~HF~_(_n_) to obtain a set
of coefficients which model the spectral envelope of this signal. Typically,
fewer parameters are necessary than in the LF signal. Here, a filter of order
8 is used. The LP coefficients are then transformed into ISP representation
and quantized for transmission. The number of LP analysis in an 1024-sample
super-frame depends on the frame lengths in the super-frame.
{width="6.690972222222222in" height="2.932638888888889in"}
Figure 9: High frequency encoding
The LP filter for the HF signal is denoted by _A~HF~_(_z_), and its quantized
version is denoted by {width="0.16666666666666666in"
height="0.2222222222222222in"}_~HF~_ (_z_). From the LF signal (_s_(_n_) in
Figure 9), a residual signal is first obtained by filtering _s_(_n_) through
the inverse filter {width="0.16666666666666666in"
height="0.2222222222222222in"}(_z_). Then, this residual is filtered through
the quantized HF synthesis filter, 1/{width="0.16666666666666666in"
height="0.2222222222222222in"}_~HF~_ (_z_). Up to a gain factor, this produces
a good approximation of the HF signal, but in a spectrally folded version. The
actual HF synthesis signal will be recovered when up-sampling is applied to
this signal
Since the excitation is taken from the LF signal, an important step is to
compute the proper gain for the HF signal. This is done by comparing the
energy of the reference HF signal (_s~HF~_(_n_)) with the energy of the
synthesized HF signal. The energy is computed once per 64-sample subframe,
with energy match ensured at the Fs/4 kHz subband boundary. Specifically, the
synthesized HF signal and the reference HF signal are filtered through a
perceptual filter derived from _A~HF~_(_z_). The ratio of the energy of these
two filtered signals is computed every 64 samples, and expressed in dB. There
are 4 such gains in a 256-sample frame (one for every 64-sample subframe).
This 4-gain vector represents the gain that should be applied to the HF signal
to properly match the HF signal energy. Instead of transmitting this gain
directly, an estimated gain ratio is first computed by comparing the gains of
filters {width="0.16666666666666666in" height="0.2222222222222222in"}(_z_)
from the lower band and {width="0.16666666666666666in"
height="0.2222222222222222in"}_~HF~_ (_z_) from the higher band. This gain
ratio estimation is detailed in Figure 10 and will be explained below. The
gain ratio estimation is interpolated every 64 samples, expressed in dB and
subtracted from the measured gain ratio. The resulting gain differences or
gain corrections, noted {width="0.19375in" height="0.25in"} to
{width="0.34652777777777777in" height="0.25in"} in Figure 9, are quantized as
4-dimensional vectors, i.e. 4 values per 256-sample frame.
The gain estimation computed from filters {width="0.16666666666666666in"
height="0.2222222222222222in"}(_z_) and {width="0.16666666666666666in"
height="0.2222222222222222in"}_~HF~_ (_z_) is detailed in Figure 12. These two
filters are available at the decoder side. The first 64 samples of a decaying
sinusoid at Nyquist frequency _π_ radians per sample is first computed by
filtering a unit impulse through a one-pole filter. The Nyquist frequency is
used since the goal is to match the filter gains at around Fs/4 kHz, i.e. at
the junction frequency between the LF and HF signals. Note the 64-sample
length of this reference signal is the sub-frame length (64 samples). The
decaying sinusoid is then filtered first through
{width="0.16666666666666666in" height="0.2222222222222222in"}(_z_), to obtain
a low-frequency residual, then through 1/{width="0.16666666666666666in"
height="0.2222222222222222in"}_~HF~_ (_z_) to obtain a synthesis signal from
the HF synthesis filter. We note that if filters
{width="0.16666666666666666in" height="0.2222222222222222in"}(_z_) and
{width="0.16666666666666666in" height="0.2222222222222222in"}_~HF~_ (_z_) have
identical gains at the normalized frequency of _π_ radians per sample, the
energy of the output of 1/{width="0.16666666666666666in"
height="0.2222222222222222in"}_~HF~_ (_z_) would be equivalent to the energy
of the input of {width="0.16666666666666666in"
height="0.2222222222222222in"}(_z_) (the decaying sinusoid). If the gains
differ, then this gain difference is taken into account in the energy of the
signal at the output, noted _x_(_n_). The correction gain should actually
increased as the energy of _x_(_n_) decreases. Hence, the gain correction is
computed as the multiplicative inverse of the energy of signal _x_(_n_), in
the logarithmic domain (i.e. in dB). To get a true energy ratio, the energy of
the decaying sinusoid, in dB, should be removed from the output. However,
since this energy offset is a constant, it will simply be taken into account
in the gain correction encoder.
At the decoder, the gain of the HF signal can be recovered by adding
{width="0.20833333333333334in" height="0.25in"} to
{width="0.34652777777777777in" height="0.25in"} (known at the decoder) to the
decoded gain corrections.
. {width="6.689583333333333in" height="3.7125in"}
Figure 10: Gain matching between low and high frequency envelope
## 5.5 Stereo signal encoding
### 5.5.1 Stereo Signal Low-Band Encoding
{width="4.679166666666666in" height="8.771527777777777in"}
#### 5.5.1.1 Principle
The stereo Low band encoder receives the signals {width="0.5416666666666666in"
height="0.25in"} and {width="0.5138888888888888in" height="0.25in"} for
encoding. The Low band encoder is based on fidelity optimized encoding of the
low band side signal. The Lo side signal is obtained by computing the
difference
{width="1.7916666666666667in" height="0.25in"},
The encoding of the side signal is performed following a similar approach to
that of the core encoder, except that the ACELP mode is not used. For each
input signal block, the encoder decides in closed loop which encoding models
to use. A signal to noise ratio fidelity criterion is used.
All 4 encoding models are based on encoding in the frequency domain a
redundancy reduced side signal. In order to account for transients, there is
an encoding model that uses pre-echo reduction. Encoding in the frequency
domain uses the same split multi-rate lattice VQ.
Within each super-frame, the different encoding modes are:
* * *
mode Duration (length + overlap) Encoding 0 40 + 8 RR + Pre-echo + AVEQ 1 40 +
8 RR + AVEQ 2 80 + 16 RR + AVEQ 3 160 + 32 RR + AVEQ
* * *
The timing chart as well as the possible mode combinations is similar to that
of the core encoder and is described in the following figure:
{width="5.293055555555555in" height="3.890972222222222in"}
Selection of the encoding mode is done by closed loop search identical to the
one used for the core encoder.
#### 5.5.1.2 Signal Windowing
The two signals {width="0.5in" height="0.25in"} and
{width="0.5416666666666666in" height="0.25in"} are windowed prior to
redundancy removal and frequency transformation. This is necessary in order to
apply overlap-add to minimize the framing effects due to quantization. The
window shape is adaptive depending on the previous coding mode and is similar
to that described in section 5.3.5.4. The windowed signals are denoted by
{width="0.5138888888888888in" height="0.25in"} and
{width="0.5416666666666666in" height="0.25in"}.
#### 5.5.1.3 Pre-echo mode
In order to encode transients more efficiently, a pre-echo mode is used. It is
often the case in transients that the energy envelope of the mono signal is
highly correlated with that of the side signal. The energy envelope of the
mono signal is derived and normalized, it is then used to compensate for the
energy envelope of the side signal.
#### 5.5.1.4 Redundancy reduction
For all encoding modes, a balance factor is used in order to remove the
portion of the side signal that is correlated with the mono signal. The
balance factor is given by
{width="2.486111111111111in" height="0.7222222222222222in"}
the balance factor is quantized by a uniform scalar quantizer with 7 bits.
### 5.5.2 Stereo Signal Mid-Band Processing
#### 5.5.2.1 Principle
The encoder takes the mid band mono and right channel signals,
{width="0.5965277777777778in" height="0.25in"} and
{width="0.5833333333333334in" height="0.25in"}, and inverse filters it with
the core codec LPC filters derived from the mono signal. In the residual
domain a shape constrained FIR filter is computed for approximating the side
signal. The filter is computed by means of the covariance method using a novel
spectral shape constraint. A new filter is computed for each _Ldiv_ =256
sample frame with an analysis frame of 320 samples. The energy of the filter
is smoothed to avoid sudden energy changes.The smoothed filter is quantized
with a multistage predictive vector quantizer (MSPVQ).
The mono residual signal {width="0.5965277777777778in" height="0.25in"}is
filtered with the quantized filter and gain factors are computed for the left
and right channels respectively.
{width="6.688194444444444in" height="2.2784722222222222in"}
#### 5.5.2.2 Residual computation
The residual signal is computed according to
{width="3.513888888888889in" height="0.4722222222222222in"}
{width="3.388888888888889in" height="0.4722222222222222in"}
The quantized and interpolated LPC coefficients from the core codec are used
in the inverse filter operation, in addition an extra subframe is computed for
the overlapped analysis section. The residual side signal is computed as
{width="3.3055555555555554in" height="0.2638888888888889in"}
#### 5.5.2.3 Filter computation, smoothing and quantization
The filter is computed that minimizes the expression
{width="2.486111111111111in" height="0.5277777777777778in"}under the
constraint of a spectral null at 0Hz. The filter coefficients for the filter
are computed with the well know covariance method using a modified cholesky
algorithm taking into account the shape constraint.
To avoid to fast changes in the filter energy, the filter energy is smoothed
over time. The filter energy is first computed as
{width="0.8055555555555556in" height="0.4722222222222222in"}
the new filter energy is computed such that the filter energy is saturated to
16 and that transitions between frames are limited within a +/- 1.5 dB
interval.
After the smoothing operation the filter coefficients are quantized using a
predictive multistage vector quantizer.
#### 5.5.2.4 Channel energy matching
The quantized filter coefficients {width="0.9166666666666666in"
height="0.2638888888888889in"} are used to filter the mono signal excitation
in order to get an initial estimate of the left and the right channel
excitation signals. These estimates are computed as
{width="4.083333333333333in" height="0.4722222222222222in"}
{width="4.055555555555555in" height="0.4722222222222222in"}
The energy matching for the left and right channels is computed as
{width="1.8465277777777778in" height="0.9722222222222222in"}
{width="1.8611111111111112in" height="0.9722222222222222in"}
The computed gains are adjusted in case of anti-correlation by computing a
correlation gain
{width="2.7916666666666665in" height="0.9722222222222222in"}
if {width="0.4027777777777778in" height="0.25in"} \ _nb, n~k~_ =0 else _nb_ = _nb_ \- _R~k~_
If _n~k\ ~_ ≥ 2, _last_ = _k_
Write downward _n^E^~k~_ (except the stop bit) in table **t** _~p~_ starting
from _pos~n~_ ,_~p~_ , and decrement _pos~n~_ ,_~p~_ by _n~k~_ -1
If _nb_ ≥ 0, write the stop bit of the unary code and decrement _pos~n~_
,_~p~_ by 1
It can be checked that for _P_ ≤4 with a near-equal distribution of _R_ in
_r~p~_ , no overflow (i.e. bit in excess) in tables t _~l~_ can happen at this
step (for _p_ =0,..,_P_ -1). In general this property must be verified to
apply the algorithm.
_3) Split and write all indices:_
This is the tricky part of the multiplexing algorithm due to the possibility
of overflow.
Find the positions _pos^ovf^~p~_ in each binary table t _~p~_ (with _p_ =
1..._P_) from which the bits in overflow can be written. These positions are
computed assuming the indices are written by 4-bit block.
For _p_ = 0.._P_ -1
_pos = 0_
_nb = pos~n,p~ + 1_
**For _k _=_ p _to_ last _with a step of_ P_**
If _n~k~_ > 0,
If _4n~k~ ≤ nb, nb~1~_ = _n~k~_
else _nb~1\ ~_ = _nb_ >> 2 (where >> is a bit shift operator)
_nb_ = _nb_ \-- 4* _nb~1~_
_pos_ = _pos_ \+ _nb~1~_
pos^ovf^~p~ = pos*4
The indices can then be written as follows:
**For _p_ = 0.._P_ -1**
**_pos_ = 0**
**For _l _=_ p _to_ N _-1 with a step of_ P_**
**_nb_ = _pos~n,p~_ \-- *pos***
_Write the 4n~k~ bits of i~k~:_
Compute the number, _nb~1~_ , of 4-bit blocks which can fit in table **t**
_~p~_ and the number, _nb~2~_ , of 4-bit blocks in excess (to be written
temporarily in table **t** _~ex~_):
If 4n~k~ ≤ nb, nb~1~ = n~k~, nb~2~ = 0
else nb~1~ = nb >> 2 (where >> is a bit shift operator), nb~2~ = n~k~ -- nb~1~
Write upward the _4nb~1~_ bits of _i~k~_ from _pos~i,p~_ to _pos~i,p~_ +4
_nb~1~_ -1 in table **t** _~p~_ , and increment _pos~i,p~_ by _4nb~1~_
If _nb~2\ ~_ ≥ 0,
Initialize _pos~ovf~_ to 0
Write upward the remaining _4nb~2~_ bits of _i~k~_ from _pos~ovf~_ to
_pos~ovf~_ +4 _nb~2~_ -1 in table **t** _~ex~_ , and increment _pos~ovf~_ by
_4nb~ovf~_
**Distribute the 4 _nb_ ~2~** **bits in table** t _~p~_ **(with _q_ ≠ _p_)
based on the pointers _pos^ovf^~q~_ and _pos~n,q~_ and the pointers
_pos^ovf^~q~_ are updated.**
### 5.6.2 Packetization procedure for all parameters
The coding parameters computed in a 1024-sample super-frame at the encoder are
multiplexed into 4 binary packets of equal size. The packetization consists of
a multiplexing loop over 4 iterations. The size of each packet is set to
_R~total~ / 4_ where _R~total~_ is the number of bits allocated to the super-
frame.
Recall that the mode selected in the 1024-sample super-frame has the form
_(m~1~, m~2~, m~3~, m~4~)_ , where _m~k~_ =0, 1, 2 or 3, with the mapping: 0 →
256-sample ACELP, 1 → 256-sample TCX, 2 → 512-sample TCX, 3 → 1024-sample TCX
{width="6.694444444444445in" height="6.7in"}
Figure 12: Structure of transmission packets for all four frame types
The multiplexing in the _k_ -th packet is performed according to the value of
_m~k~_. The corresponding packet format is shown in Figure 12. There are 3
cases:
If _m~k~_ =0 or 1, the _k_ -th packet simply contains all parameters related
to a 256-sample frame, where the parameters are the 2-bit mode information
(\'00\' or \'01\' in binary format), the parameters of ACELP or those of
256-sample TCX, and the parameters of 256-sample HF coding.
If _m~k~_ =2, the _p_ -th packet contains half of the bits of the 512-sample
TCX mode, half of the bits of 512-sample HF coding, plus the 2-bit mode
information (\'10\' in binary format).
If _m~k~_ =3, the _k_ -th packet contains one fourth of the bits describing
the 512-sample TCX mode, one fourth of the bits of 1024-sample HF coding, plus
the 2-bit mode information (\'11\' in binary format).
The packetization is therefore straightforward if the _k_ -th packet
corresponds to ACELP or 256-sample TCX. The packetization is slightly more
involved if 512- or 1024-sample TCX mode is used, because the bits of the 512-
or 1024-sample modes have to be shared into even parts.
### 5.6.3 TCX gain multiplexing
It was found that the TCX gain is important to maintain audible quality in
case of packet loss. Thus, in 512-sample and 1024-sample TCX frames, the TCX
gain value is encoded redundantly in multiple packets to protect against
packet loss. The TCX gain is encoded at a resolution of 7 bits, and these bits
are labelled \"Bit 0\" to \"Bit 6\", where \"Bit 0\" is the Least Significant
Bit (LSB) and \"Bit 6\" is the Most Significant Bit (MSB). We consider two
cases, TCX512 and TCX1024, where the encoded bits are split into two or four
packets, respectively.
**_At the Encoder side_**
**TCX512** : The first packet contains the full gain information (7 bits). The
second packet repeats the most significant 6 bits (\"Bit 1\" to \"Bit 7\").
**TCX1024** : The first packet contains the full gain information (7 bits).
The third packet contains a copy of the three bits \"Bit 4\", \"Bit 5\" and
\"Bit 6\". The fourth packet contains a copy of the three bits \"Bit 1\",
\"Bit 2\" and \"Bit 3\".
Additionally, a 3-bit \"parity\" is formed as thus: combining by logical XOR
\"Bit 1\" and \"Bit 4\" to generate \"Parity Bit 0\", combining by logical XOR
\"Bit 2\" and \"Bit 5\" to generate \"Parity Bit 1\", and combining by logical
XOR \"Bit 3\" and \"Bit 6\" to generate \"Parity Bit 2\". These three parity
bits are sent in the second packet.
**_At the Decoder side_**
_The logic applied at the decoder to recover the TCX gain when missing packets
occur for 512-sample TCX and 1024-sample TCX. We assume that there is at least
one packet missing before entering the flowchart._
**TCX512** : If the fist packet is flagged as being lost, the TCX global gain
is taken from the second packet, with the LSB (\"Bit 0\") being set to zero.
If only the second packet is lost, then the full TCX gain is obtained from the
first packet.
**TCX1024** : The gain recovery algorithm is only used if 1 or 2 packets
forming an 1024-sample TCX frame are lost; as described in Section 6.5.1.1. If
3 or more packets are lost in a TCX1024 frame, the MODE is changed to
(1,1,1,1) and BFI=(1,1,1,1). When only 1 or 2 packets are lost in a TCX1024
frame, the recovery algorithm is as follows:
As described above, the second, third and fourth packets of a TCX1024 frame
contain the parity bits, \"Bit 6\" to \"Bit 4\", and \"Bit 3\" to \"Bit 1\" of
the TCX gain. These bits (three each) are stored in \"parity\", \"index0\" and
\"index1\" respectively.
If the third packet is lost, \"index0\" is replaced by the logical XOR
combination of \"parity\" and \"index1\". That is, \"Bit 6\" is generated from
the logical XOR of \"Parity Bit 2\" and \"Bit 3\", \"Bit 5\" is generated from
the logical XOR of \"Parity Bit 1\" and \"Bit 2\", and \"Bit 4\" is generated
from the logical XOR of \"Parity Bit 0\" and \"Bit 1\".
If the fourth packet is lost, \"index1\" is replaced by the logical XOR
combination of \"parity\" and \"index0. That is, \"Bit 3\" is generated from
the logical XOR of \"Parity Bit 2\" and \"Bit 6\", \"Bit 2\" is generated from
the logical XOR of \"Parity Bit 1\" and \"Bit 5\", and \"Bit 1\" is generated
from the logical XOR of \"Parity Bit 0\" and \"Bit 4\".
Finally, the 7-bit TCX gain value is taken from the recovered bits (\"Bit 1\"
to \"Bit 6\") and \"Bit 0\" is set to zero.
### 5.6.4 Stereo Packetization
{width="6.6930555555555555in" height="4.5152777777777775in"}
Stereo parameters computed in a 1024-sample super-frame at the encoder are
multiplexed into 4 binary packets of equal size. The packetization consists of
a similar multiplexing loop as for the core encoder. The stereo packets are
appended at the end of the mono packets.
# 6 Functional description of the decoder
The function of the decoder consists of decoding the transmitted parameters
(LP parameters, ACELP/TCX mode, adaptive codebook vector, adaptive codebook
gain, fixed codebook vector, fixed codebook gain, TCX parameters, high-band
parameters, stereo information) and performing synthesis to obtain the
reconstructed low-frequency and high-frequency signals. For stereo signal
synthesis, the stereo low- and mid-band signals are reconstructed using the
low-frequency mono signal and the transmitted and decoded stereo parameters
(...).
Section 6.1 describes the reconstruction, by the decoder, of the mono low-band
signal in the 0-Fs/4 kHz bandwidth (core ACELP/TCX decoder). The
reconstruction of the higher frequency band using bandwidth extension and the
mixing of the low and high frequencies of the mono signal will be described
respectively in Sections 6.2 and 6.3. The generation of the stereo signals
will be described in Section 6.4. Finally, Section 6.5 describes the
concealment algorithm in the case of missing frames.
## 6.1 Mono Signal Low-Band synthesis
The 0-Fs/4 kHz band of the mono signal is reconstructed by the core ACELP/TCX
decoder. In ACELP mode, the decoder is the same as AMR-WB. The TCX mode of the
decoder will be described in more details below. Selection between ACELP and
TCX decoding in each 256-sample frame is controlled by the mode indicators
described in Section 5.2.2 of the encoder. These mode indicators are
transmitted as 2 bits in each 256-sample packet.
### 6.1.1 ACELP mode decoding and signal synthesis
Same as 3GPP TS 26.190.
### 6.1.2 TCX mode decoding and signal synthesis
The TCX decoder is shown in Figure 13.
{width="6.690972222222222in" height="5.56875in"}
Figure 13: Block diagram of the TCX decoder
Figure 13 shows a block diagram of the TCX decoder including the following two
cases:
**Case 1** : Packet-erasure concealment in TCX-256 when the TCX frame length
is 256 samples and the related packet is lost i.e. **BFI_TCX** = (1), as shown
in Figure 13-a.
**Case 2** : Normal TCX decoding, possibly with partial packet losses, as
shown in Figure 13-b..
In Case 1, no information is available to decode the 256-sample TCX frame. The
TCX synthesis is found by processing the past excitation delayed by _T_ ,
where _T=pitch_tcx_ is a pitch lag estimated in the previously decoded TCX
frame, by a non-linear filter roughly equivalent to
{width="0.5138888888888888in" height="0.2638888888888889in"}. A non-linear
filter is used instead of {width="0.5138888888888888in"
height="0.2638888888888889in"} to avoid clicks in the synthesis. This filter
is decomposed in 3 steps:
**Step 1** : filtering by
{width="1.2222222222222223in" height="0.5277777777777778in"}
to map the excitation delayed by _T_ into the TCX target domain;
**Step 2** : applying a limiter (the magnitude is limited to ± _rms_ ~wsyn~)
**Step 3** : filtering by
{width="0.5833333333333334in" height="0.5138888888888888in"}
to find the synthesis. Note that the buffer **OVLP_TCX** is set to zero in
this case.
**Decoding of the algebraic VQ parameters**
In Case 2, TCX decoding involves decoding the algebraic VQ parameters
describing each quantized block {width="0.2361111111111111in"
height="0.2604166666666667in"} of the scaled spectrum _X\'_ , where _X\'_ is
as described in Step 2 of Section 5.3.5.7. Recall that **_X\'_** has dimension
_N_ , where _N_ = 288, 576 and 1152 for TCX-256, 512 and 1024 respectively,
and that each block _B\'~k~_ has dimension 8. The number _K_ of blocks
_B\'~k~_ is thus 36, 72 and 144 for TCX-256, 512 and 1024 respectively. The
algebraic VQ parameters for each block _B\'~k~_ are described in Step 5 of
Section 5.3.5.7. For each block _B\'~k~_ , three sets of binary indices are
sent by the encoder:
a) the [codebook index]{.underline} _n~k~_ , transmitted in unary code as
described in Step 5 of Section 5.3.5.7;
b) the [rank]{.underline} _I~k~_ of a selected lattice point _c_ in a so-
called _base codebook_ , which indicates what permutation has to be applied to
a specific _leader_ (see Step 5 of Section 5.3.5.7) to obtain a lattice point
**_c_** ;
c) and, if the quantized block{width="0.2361111111111111in"
height="0.2604166666666667in"} (a lattice point) was not in the base codebook,
the 8 indices of the [Voronoi extension index]{.underline} vector **_k_**
calculated in sub-step V1 of Step 5 in Section; from the Voronoi extension
indices, an extension vector **_z_** can be computed as in reference [7]. The
number of bits in each component of index vector **_k_** is given by the
extension order _r_ , which can be obtained from the unary code value of index
_n~k~_ . The scaling factor _M_ of the Voronoi extension is given by _M_ = 2
_^r^_.
Then, from the scaling factor _M_ , the Voronoi extension vector **_z_** (a
lattice point in _RE~8~_) and the lattice point **_c_** in the base codebook
(also a lattice point in _RE~8~_), each quantized scaled block
{width="0.2361111111111111in" height="0.2604166666666667in"} can be computed
as
{width="0.2361111111111111in" height="0.2604166666666667in"} = _M_ **c +_z_**
When there is no Voronoi extension (i.e. _n~k~_ \ 256 samples,
_pitch_tcx_ is set to 256 ; otherwise, if _T_ ~est~ ≤ 256, multiple pitch
period in 256 samples are avoided by setting _pitch_tcx_ to
_pitch_tcx_ = max {  _n_ _T_ ~est~  \| _n_ integer > 0 and _n_ _T_ ~est~ ≤
256}
where  _._  denotes the rounding to the nearest integer towards -∞.
Inverse transform
To obtain the quantized perceptual signal, an inverse transform is applied to
the de-shaped spectrum _X\'._ The transform used at the encoder and decoder is
a the discrete Fourier transform, and is implemented as an FFT and IFFT,
respectively. Recall that due to the ordering used at the TCX encoder, the
transform coefficients **X\'** =(_X\'~0~_ ,...,_X\'~N-1~_) are such that:
_X\'~0\ ~_ corresponds to the DC coefficient,
_X\'~1\ ~_ corresponds to the Nyquist frequency, and
the coefficients X\'_~2k~_ and X\'_~2k+1~_ , for _k_ =1..N/2-1, are the real
and imaginary parts of the Fourier component of frequency of _k(_ /_N_ /2) *
Fs/4 kHz.
_X\'~1~_ is always forced to 0. After this zeroing, the time-domain TCX target
signal **_x\'_** ~w~ is found by applying an inverse FFT to the quantized
scaled spectrum _X_. Rescaling will be applied in the following section, to
obtain the total quantized weighted signal prior to windowing and overlapping.
Decoding of the glocal TCX gain and scaling
The (global) TCX gain _g_ ~TCX~ is decoded by inverting the 7-bit logarithmic
quantization calculated in the TCX encoder as in Section 5.2.5.10 . First, the
r.m.s. value of the TCX target signal **_x\'_** ~w~ is computed as:
_rms_ = sqrt(1/_N_ (_x_ \'~w0~^2^ + _x_ \'~w1~^2^ +...+ _x_ \'~w _L-1_ ~^2^))
From the received 7-bit index 0 ≤ _idx_ ~2~ ≤ 127, the TCX gain is given by:
{width="1.4583333333333333in" height="0.2638888888888889in"}
The (logarithmic) quantization step is around 0.71 dB.
This gain is used to scale **_x\'_** ~w~ into **_x_** ~w~. Note that from the
mode extrapolation and the gain repetition strategy, the index _idx_ ~2~ is
available in case of frame loss. However, in case of partial packet losses (1
loss for TCX-512 and up to 2 losses for TCX-1024) the least significant bit of
_idx_ ~2~ may be set by default to 0 in the demultiplexer.
Windowing and overlap
Since the TCX encoder employs windowing with overlap and weighted ZIR removal
prior to transform coding of the target signal, the reconstructed TCX target
signal **_x_** = (_x_ ~0~, _x_ ~1~, ..., _x~N~_ ~-1~) is actually found by
overlap-add. The overlap-add depends on the type of the previous decoded frame
(ACELP or TCX). The TCX target signal is first multiplied by a window **w** =
[_w_ ~0~ w~1~ ... w _~N-1~_], whose shape is described in Section 5.3.5.4.
Then, the overlap from the past decoded frame (**OVLP_TCX**) is added to the
present windowed signal **x**. The overlap length OVLP_TCX depends on the past
TCX framelength and on the mode of the past frame (ACELP or TCX).
Computation of the synthesis signal
The reconstructed TCX target is then filtered through the zero-state inverse
perceptual filter {width="1.8194444444444444in" height="0.2638888888888889in"}
to find the synthesis signal which will be applied to the synthesis filter.
The excitation is also calculated to update the ACELP adaptive codebook and
allow to switch from TCX to ACELP in a subsequent frame. Note that the length
of the TCX synthesis is given by the TCX frame length (without the overlap):
256, 512 or 1024 samples.
### 6.1.3 Post-processing of Mono Low-Band signal
In the low-frequency pitch enhancement, two-band decomposition is used and
adaptive filtering is applied only to the lower band. This results in a total
post-processing that is mostly targeted at frequencies near the first
harmonics of the synthesized speech signal.
{width="6.233333333333333in" height="3.4659722222222222in"}
Figure 14: Block diagram of the low frequency pitch enhancer
Figure 14 shows the block diagram of the two-band pitch enhancer. In the
higher branch the decoded signal is filtered by a high-pass filter to produce
the higher band signal (_s_ ~H~). In the lower branch, the decoded signal is
first processed through an adaptive pitch enhancer, and then filtered through
a low-pass filter to obtain the lower band post-processed signal (_s_ ~LEF~).
The post-processed decoded signal is obtained by adding the lower band post-
processed signal and the higher band signal. The object of the pitch enhancer
is to reduce the inter-harmonic noise in the decoded signal, which is achieved
here by a time-varying linear filter with a transfer function
{width="2.0833333333333335in" height="0.4305555555555556in"}
and described by the following equation:
{width="3.0555555555555554in" height="0.4305555555555556in"} (1)
where _α_ is a coefficient that controls the inter-harmonic attenuation, _T_
is the pitch period of the input signal {width="0.3333333333333333in"
height="0.2222222222222222in"}, and{width="0.4583333333333333in"
height="0.2361111111111111in"} is the output signal of the pitch enhancer.
Parameters _T_ and _α_ vary with time and are given by the pitch tracking
module. With a value of _α_ = 1, the gain of the filter described by Equation
(1) is exactly 0 at frequencies 1/(2 _T_),3/(2 _T_), 5/(2 _T_), etc.; i.e. at
the mid-point between the harmonic frequencies 1/_T,_ 3 _/T,_ 5 _/T,_ etc.
When _α_ approaches 0, the attenuation between the harmonics produced by the
filter of Equation (1) decreases.
To confine the post-processing to the low frequency region, the enhanced
signal _s~LE~_ is low pass filtered to produce the signal _s~LEF~_ which is
added to the high-pass filtered signal _s~H~_ to obtain the post-processed
synthesis signal _s~E~_.
Another configuration equivalent to the one in Figure 14 is used here which
eliminates the need to high-pass filtering. This is explained as follows.
Let _h~LP~_(_n_) be the impulse response of the low-pass filter and
_h~HP~_(_n_) is the impulse response of the complementary high-pass filter.
The post-processed signal _s~E~_(_n_) is given by
{width="5.388888888888889in" height="1.9722222222222223in"}
Thus, the post-processing is equivalent to subtracting the scaled low-pass
filtered long-term error signal from the synthesis signal
{width="0.3333333333333333in" height="0.2222222222222222in"}. The transfer
function of the long-term prediction filter is given by
{width="1.8333333333333333in" height="0.25in"}
The alternative post-processing configuration is depicted in Figure 15.
{width="6.233333333333333in" height="3.2319444444444443in"}
Figure 15: Implemented post-processing configuration
The value _T_ is given by the received closed-loop pitch lag in each subframe
(the fractional pitch lag rounded to the nearest integer). A simple tracking
for checking pitch doubling is performed. If the normalized pitch correlation
at delay T/2 is larger than 0.95 then the value T/2 is used as the new pitch
lag for post-processing.
The factor {width="0.16666666666666666in" height="0.1527777777777778in"} is by
{width="0.7777777777777778in" height="0.2638888888888889in"} constrained to
{width="0.7916666666666666in" height="0.19375in"}
where {width="0.2222222222222222in" height="0.2638888888888889in"} is the
decoded pitch gain. Note that in TCX mode the value of
{width="0.16666666666666666in" height="0.1527777777777778in"} is set to zero.
A linear phase FIR low-pass filter with 25 coefficients is used, with a cut-
off frequency at 5Fs/256 kHz (the filter delay is 12 samples).
## 6.2 Mono Signal High-Band synthesis
The synthesis of the HF signal implements a kind of bandwidth extension (BWE)
mechanism and uses some data from the LF decoder. It is an evolution of the
BWE mechanism used in the AMR-WB speech decoder. The HF decoder is detailed in
Figure 16. The HF signal is synthesized in 2 steps: calculation of the HF
excitation signal and computation of the HF signal from the HF excitation. The
HF excitation is obtained by shaping in time-domain the LF excitation signal
with scalar factors (or gains) per 64-sample subframes. This HF excitation is
post-processed to reduce the \"buzziness\" of the output, and then filtered by
a HF linear-predictive synthesis filter 1/_A_ ~HF~(_z_). Recall that the LP
order used to encode and then decode the HF signal is 8. The result is also
post-processed to smooth energy variations.
{width="6.680555555555555in" height="4.428472222222222in"}
Figure 16: Block diagram of high frequency decoder
The HF decoder synthesizes an 1024-sample HF superframe. This superframe is
segmented according to **MODE** = (_m_ ~0~, _m_ ~1~, _m_ ~2~, _m_ ~3~). To be
more specific, the decoded frames used in the HF decoder are synchronous with
the frames used in the LF decoder. Hence, _m_ ~k~ ≤ 1, _m_ ~k~ = 2 and _m_ ~k~
= 3 indicate respectively a 256, 512 and 1024-sample frame. These frames are
referred to as HF-256, HF-512 and HF-1024, respectively.
From the synthesis chain described above, it is clear that the only parameters
needed for HF decoding are ISF and gain parameters. The ISF parameters
represent the filter 1/_A_ ~HF~(_z_), while the gain parameters are used to
shape the LF excitation signal. These parameters are demultiplexed based on
**MODE** and knowing the format of the bitstream.
Control data which are internal to the HF decoder are generated from the bad
frame indicator vector **BFI** = (_bfi_ ~0~, _bfi_ ~1~, _bfi_ ~2~, _bfi_ ~3~).
These data are _bfi_isf_hf_ , **BFI_GAIN** , and the number of subframes for
ISF interpolation. The nature of these data is defined in more details below:
_bfi_isf_hf_ is a binary flag indicating loss of the ISF parameters. Its
definition is given below from **BFI**.
For HF-256 in packet _k,_ _bfi_isf_hf_ = _bfi_ ~k~ ,
For HF-512 in packets _k_ and _k+1, bfi_isf_hf_ = _bfi_ ~k~ ,
For HF-1024 (in packets k=_0 to 3), bfi_isf_hf_ = _bfi_ ~0~
This definition can be readily understood from the bitstream format. Recall
that the ISF parameters for the HF signal are always in the first packet
describing HF-256, -512 or --1024 frames.
**BFI_GAIN** is a binary vector used to signal packet losses to the HF gain
decoder: **BFI_GAIN** = ( _bfi_ ~k~ ) for HF-256 in packet _k_ , ( _bfi_ ~k~
_bfi_ ~k+1~ ) for HF-512 in packets _k_ and _k+1_ , **BFI_GAIN** = **BFI** for
HF-1024.
The number of subframes for ISF interpolation refers to the number of
64-sample subframes in the decoded frame. This number is 4 for HF-256, 8 for
HF-512 and 16 for HF-1024.
The ISF vector **isf_hf_q** is decoded using AR(1) predictive VQ. If
_bfi_isf_hf_ = 0, the 2-bit index _i_ ~1~ of the 1^st^ stage and the 7-bit
index _i_ ~2~ of the 2^nd^ stage are available and **isf_hf_q** is given by
**isf_hf_q** = **cb1**(_i_ ~1~) + **cb2**(_i_ ~2~) + **mean_isf_hf** \+
μ~isf_hf~ * **mem_isf_hf**
where **cb1**(_i_ ~1~) is the _i_ ~1~--th codevector of the 1^st^ stage,
**cb2**(_i_ ~2~) is the _i_ ~2~--th codevector of the 2^st^ stage,
**mean_isf_hf** is the mean ISF vector, μ~isf_hf~ = 0.5 is the AR(1)
prediction coefficient and **mem_isf_hf** is the memory of the ISF predictive
decoder.
If _bfi_isf_hf_ = 1, the decoded ISF vector corresponds to the previous ISF
vector shifted towards the mean ISF vector:
**isf_hf_q** = α ~isf_hf~ * **mem_isf_hf** \+ **mean_isf_hf**
with α ~isf_hf~ = 0.9. After calculating **isf_hf_q** , the ISF reordering
defined in AMR-WB speech coding is applied to **isf_hf_q** with an ISF gap of
9 Fs/1280 Hz. Finally the memory **mem_isf_hf** is updated for the next HF
frame as:
**mem_isf_hf** = **isf_hf_q** \- **mean_isf_hf**
Note that the initial value of **mem_isf_hf** (at the reset of the decoder) is
zero.
A simple linear interpolation between the ISP parameters of the previous
decoded HF frame (HF-256, HF-512 or HF-1024) and the new decoded ISP
parameters is performed. The interpolation is conducted in the ISP domain and
results in ISP parameters for each 64-sample subframe, according to the
formula:
**isp** ~subframe-_i_ ~ = _i_ /_nb_ * **isp** ~new~ + (1-_i_ /_nb)_ * **isp**
~old~,
where _nb_ is the number of subframes in the current decoded frame (_nb_ =4
for HF-256, 8 for HF-512, 16 for HF-1024), _i_ =0,...,_nb_ -1 is the subframe
index, **isp** ~old~ is the set of ISP parameters obtained from the ISF
parameters of the previously decoded HF frame and **isp** ~new~ is the set of
ISP decoded. The interpolated ISP parameters are then converted into linear-
predictive coefficients for each subframe.
The computation of the gain _g_ ~match~ in dB is detailed in the next
paragraphs. This gain is interpolated for each 64-sample subframe based on its
previous value _old_ __g_ ~match~ as:
{width="0.19375in" height="0.25in"} = _i_ /_nb_ * _g_ ~match~ + (1-_i_ /_nb)_
* _old_ __g_ ~match~,
where _nb_ is the number of subframes in the current decoded frame (_nb_ =4
for HF-256, 8 for HF-512, 16 for HF-1024), _i_ =0,...,_nb_ -1 is the subframe
index. This results in a vector ({width="0.20833333333333334in"
height="0.25in"}_,_ ... {width="0.34652777777777777in" height="0.25in"} ).
**_[Gain estimation computation to match magnitude at Fs/4 kHz]{.underline}_**
**_Same as section 5.6 (Figure 9)_**
_[Decoding of correction gains and gain computation]{.underline}_
Recall that after gain interpolation the HF decoder gets the estimated gains
(_g_ ^est^~0~, _g_ ^est^~1~, ..., _g_ ^est^~nb-1~) in dB for each of the _nb_
subframes of the current decoded frame. Furthermore, _nb_ = 4, 8 and 16 in
HF-256, -512 and --1024, respectively. The correction gains in dB are then
decoded which will be added to the estimated gains per subframe to form the
decode gains {width="0.20833333333333334in"
height="0.25in"},{width="0.19375in" height="0.2361111111111111in"}, ...,
{width="0.34652777777777777in" height="0.25in"} :
({width="0.20833333333333334in" height="0.25in"}_(dB)_ ,{width="0.19375in"
height="0.2361111111111111in"} _(dB)_ , ..., {width="0.34652777777777777in"
height="0.25in"}_(dB)_) = ({width="0.20833333333333334in"
height="0.25in"},{width="0.19375in" height="0.2361111111111111in"}, ...,
{width="0.34652777777777777in" height="0.25in"}) \+
({width="0.20833333333333334in" height="0.25in"},{width="0.19375in"
height="0.2361111111111111in"}, ..., {width="0.34652777777777777in"
height="0.25in"})
where
({width="0.20833333333333334in" height="0.25in"},{width="0.19375in"
height="0.2361111111111111in"}, ..., {width="0.34652777777777777in"
height="0.25in"}) = (_g^c1^_ ~1~, _g^c1^_ ~1~, ..., _g^c1^_ ~nb-1~) + (_g^c2^_
~0~, _g^c2^_ ~1~, ..., _g^c2^_ ~nb-1~).
Therefore, the gain decoding corresponds to the decoding of predictive two-
stage VQ-scalar quantization, where the prediction is given by the
interpolated Fs/4 kHz junction matching gain. The quantization dimension is
variable and is equal to _nb_.
_Decoding of the 1^st^ stage:_
The 7-bit index 0 ≤ _idx_ ≤ 127 of the 1^st^ stage 4-dimensional HF gain
codebook is decoded into 4 gains (_G_ ~0~, _G_ ~1~, _G_ ~2~, _G_ ~3~). A bad
frame indicator _bfi = BFI_GAIN~0~_ in HF-256, -512 and --1024 allows to
handle packet losses. If _bfi_ = 0, these gains are decoded as
(_G_ ~0~, _G_ ~1~, _G_ ~2~, _G_ ~3~) = **cb_gain_hf**(idx) + _mean_gain_hf_
where **cb_gain_hf**(_idx_) is the _idx_ -th codevector of the codebook
**cb_gain_hf**. If _bfi_ =1, a memory _past_gain_hf_q_ is shifted towards --20
dB:
_past_gain_hf_q_ := α~gain_hf~ * (_past_gain_hf_q + 20) -- 20._
where α~gain_hf~ = 0.9 and the 4 gains (_G_ ~0~, _G_ ~1~, _G_ ~2~, _G_ ~3~)
are set to the same value:
_G_ ~k~ = _past_gain_hf_q_ \+ _mean_gain_hf_ , for _k_ = 0,1,2 and 3
Then the memory _past_gain_hf_q_ is updated as:
_past_gain_hf_q_ := (G~0~ + G~1~ + G~2~ + G~3~)/4 - _mean_gain_hf_.
The computation of the 1^st^ stage reconstruction is then given as:
HF-256: (_g^c1^_ ~0~, _g^c1^_ ~1~, _g^c1^_ ~2~ , _g^c1^_ ~3~) = (_G_ ~0~, _G_
~1~, _G_ ~2~, _G_ ~3~).
HF-512: (_g^c1^_ ~0~, _g^c1^_ ~1~, _...,_ _g^c1^_ ~7~) = (_G_ ~0~, _G_ ~0~,
_G_ ~1~, _G_ ~1~, _G_ ~2~, _G_ ~2~, _G_ ~3~, _G_ ~3~).
HF-1024: (_g^c1^_ ~0~, _g^c1^_ ~1~, _...,_ _g^c1^_ ~15~) = (_G_ ~0~, _G_ ~0~,
_G_ ~0~, _G_ ~0~, _G_ ~1~, _G_ ~1~, _G_ ~1~, _G_ ~1~, _G_ ~2~, _G_ ~2~, _G_
~2~, _G_ ~2~, _G_ ~3~, _G_ ~3~, _G_ ~3~, _G_ ~3~).
_Decoding of 2^nd^ stage:_
In TCX-256, (_g^c2^_ ~0~, _g^c2^_ ~1~, _g^c2^_ ~2~_,_ _g^c2^_ ~3~) is simply
set to (0,0,0,0) and there is no real 2^nd^ stage decoding. In HF-512, the
2-bit index 0 ≤ _idx_ ~i~ ≤ 3 of the _i_ -th subframe, where _i_ =0, ..., 7,
is decoded as:
If _bfi_ = 0, _g^c2^_ ~i~ = 3 * _idx_ ~i~ -- 4.5 else _g^c2^_ ~i~ = 0.
In TCX-1024, 16 subframes 3-bit index the 0 ≤ _idx_ ~i~ ≤ 7 of the _i_ -th
subframe, where _i_ =0, ..., 15, is decoded as:
If _bfi_ = 0, _g^c2^_ ~i~ = 3 * idx -- 10.5 else _g^c2^_ ~i~ = 0.
In TCX-512 the magnitude of the second scalar refinement is up to ± 4.5 dB and
in TCX-1024 up to ± 10.5 dB. In both cases, the quantization step is 3 dB.
_HF gain reconstruction:_
The gain for each subframe is then computed as:{width="0.4722222222222222in"
height="0.2222222222222222in"}
**[_Buzziness reduction_ _and energy smoothing_]{.underline}**
The role of energy smoothing is to attenuate pulses in the time-domain HF
excitation signal _r_ ~HF~(_n_), which often cause the audio output to sound
\"buzzy\". Pulses are detected by checking if the absolute value \| r~HF~(n)
\| > 2 * _thres_(_n_), where _thres_(_n_) is an adaptive threshold
corresponding to the time-domain envelope of _r_ ~HF~(_n_). The samples _r_
~HF~(_n_) which are detected as pulses are limited to ± 2 * _thres_(_n_),
where ± is the sign of _r_ ~HF~(_n_).
Each sample _r_ ~HF~(_n_) of the HF excitation is filtered by a 1^st^ order
low-pass filter 0.02/(1 - 0.98 _z_ ^-1^) to update _thres_(_n_). Note that the
initial value of _thres_(_n_) (at the reset of the decoder) is 0. The
amplitude of the pulse attenuation is given by:
∆ = max( \|_r_ ~HF~(_n_)\|-2*_thres_(_n_) , 0.0).
Thus, ∆ is set to 0 if the current sample is not detected as a pulse, which
will let _r_ ~HF~(_n_) unchanged. Then, the current value _thres_(_n_) of the
adaptive threshold is changed as:
_thres_(_n_):= _thres_(_n_) + 0.5 * ∆.
Finally each sample _r_ ~HF~(_n_) is modified to: _r\'_ ~HF~(_n_) = _r_
~HF~(_n_) --∆ if _r_ ~HF~(_n_) ≥ 0, and _r\'_ ~HF~(_n_) = _r_ ~HF~(_n_) +∆
otherwise.
The short-term energy variations of the HF synthesis _s_ ~HF~(_n_) are then
smoothed. The energy is measured by subframe. The energy of each subframe is
modified by up to ± 1.5 dB based on an adaptive threshold.
For a given subframe _s_ ~HF~(_n_), _n_ =0,...,63, the subframe energy is
calculated as
{width="1.5416666666666667in" height="0.4722222222222222in"}
The value _t_ of the threshold is updated as:
_t_ := min( ε* 1.414, _t_ ), if ε \0, the value _m_
~k~ = 1 will be selected.
\- If 3 packets are lost and if the only available mode indicator is _m_ ~k~ =
3 with _k_ =0,1,2 or 3, a mode (3,3,3,3) corresponding to TCX-1024 should
normally be extrapolated. Yet, with the bitstream format described in Section
5.6, losing 3 packets out of 4 in TCX-1024 means
1) losing roughly 3 quarters of the TCX target spectrum and
2) having no information about the TCX global gain since the gain repetition
in TCX-1024 is designed to perform well for up to 2 packet losses.
As a consequence, the mode (3,3,3,3) is rather replaced by the mode (1,1,1,1)
in the extrapolation when more than 2 packets are lost. Note that this causes
the concealment of TCX-256 to be used (the synthesis will actually be
progressively faded out).
#### 6.5.1.2 TCX bad frame concealment
Concealment of TCX256 erased frames was described in Section 6.2.1.
In the case of a TCX1024 partial frame loss and given that the previous
decoded frame was also a TCX1024 frame a spectral fill-in strategy is used in
order to conceal the lost packets. The fill-in strategy assumes that since we
have a case of two consecutive 1024-sample TCX frames, the signal is quasi
stationary so that lost subvectors can be interpolated from the previous
frame.
##### 6.5.1.2.1 Spectrum de-shaping
Spectrum de-shaping is applied to the quantized spectrum as described in
Section 5.3.5.8. In case of frame erasure, the de-shaping uses a prediction of
the new maximum using the previously saved quantized spectrum. De-shaping is
done according to the following steps:
\- Compute the maximum energy _OldE~max~_ of the 8-dimensional block at
position index _m_ of the previous 1024-sample TCX frame
\- Compute the maximum energy _E~max~_ of the 8-dimensional block at position
index _m_ of the current 1024-sample TCX frame
\- If _E~max~_ \ 10, then set _R~m~_ = 10 (maximum gain of 20 dB)
\- also, if _R~m~_ > _R ~m-1~_ then _R~m~_ = _R~m-1~_
This allows in case of the loss of the 8-dimensional block corresponding to
the maximum to use the previous maximum.
##### 6.5.1.2.2 Spectrum Extrapolation
Spectrum extrapolation is applied to the quantized spectrum prior to applying
the inverse FFT. Spectrum extrapolation consists of amplitude and phase
extrapolation applied to the lost spectral coefficients. The extrapolated
amplitude and phase are combined to form the extrapolated spectral
coefficient. Combining the extrapolated and the received spectral coefficients
is done in order to form quantized spectrum {width="0.3888888888888889in"
height="0.25in"}.
##### 6.5.1.2.3 Amplitude Extrapolation
Spectral amplitude extrapolation consists of is performed according to the
following steps;
\- Compute the previous frame amplitude spectrum,
{width="1.3055555555555556in" height="0.3055555555555556in"}
\- Compute the current frame spectrum, {width="0.9027777777777778in"
height="0.3055555555555556in"}
\- Compute the gain difference of energy of non-lost spectral coefficients
between the previous and the current frame\ {width="1.5694444444444444in"
height="0.8194444444444444in"}
\- Extrapolate the amplitude of the missing spectral coefficients using\ if
(_lost[k]_) {width="1.4305555555555556in" height="0.2222222222222222in"}
##### 6.5.1.2.4 Phase Extrapolation
{width="5.888194444444444in" height="3.4138888888888888in"}
Phase extrapolation uses the principle of group delay conservation for quasi-
stationary signals. First the group delay is estimated on the previous frame
and then used in the current frame in order to extrapolate the phase on the
missing spectral coefficients. The estimation of the group delay is done by
computing
{width="2.313888888888889in" height="0.22777777777777777in"}
The phase of the missing spectral coefficients {width="0.3611111111111111in"
height="0.2361111111111111in"} is computed by using the following recursive
algorithm
{width="3.9305555555555554in" height="0.25in"}
where
{width="4.055555555555555in" height="0.25in"}
{width="0.94375in" height="0.2361111111111111in"} is used to start the
recursion., and {width="0.69375in" height="0.2222222222222222in"} are received
(non lost) bins.
### 6.5.2 Stereo
The stereo error concealment is controlled by the bad frame indicators _bfi_
~k~ , k = 0...3. In response to the bad frame indicators of the present super
frame together with some bad frame indicator history proper actions are taken
mitigating the perceptual impact of bad frames. Particular error mitigation
actions are taken on the stereo low-band, the mid-band, and the high-band.
#### 6.5.2.1 Low-band
_Balance factor_
The balance factor to be used for the derivation of the side signal is not
available depending on _bfi_ ~k~ and on the stereo TCX frame length, i.e. if
_bfi_ ~k~ = 1, k = 0...3 in case of 256-sample stereo TCX frames,
_bfi_ ~k~ = 1, k = 0, 2 in case of 512-sample stereo TCX frames, or
_bfi_ ~k~ = 1, k = 0 in case of 1024-sample stereo TCX frames,
In this case, the balance factor is derived from the balance factor of the
previous stereo TCX frame, however, attenuated by 0.9.
For the case of a future frame loss, the balance factor of the present stereo
TCX frame is stored in a history buffer.
_Side signal error signal_
The side signal error signal is derived using the TCX decoder and the
associated bad frame concealment described above (6.6.1.3). Input to the TCX
bad frame concealment is a flag, signalling if any of the frames associated
with the present stereo TCX frame is bad.
_Side signal_
Stereo TCX frames of size 512 samples and 1024 samples are reconstructed as in
the case without bad frames, however using the balance factor and side signal
error signal derived as specified above.
Bad stereo TCX frames of size 256 samples are, however, reconstructed
differently. A parametric model with transfer function
{width="1.3194444444444444in" height="0.4722222222222222in"}, _P_ =8
is applied to the windowed mono signal for reconstructing a substitution
signal for the side signal. The filter coefficients are taken from a state
memory and are always derived during preceding stereo TCX frames if the
associated _bfi_ ~k~ flags are equal to zero. The coefficients are calculated
by solving the following equation system:
{width="0.875in" height="0.2777777777777778in"},
where {width="0.3194444444444444in" height="0.2777777777777778in"} is a
Toeplitz matrix of autocorrelations _r~mm~_ of the windowed mono signal:
{width="2.263888888888889in" height="0.2777777777777778in"},
and where {width="0.25in" height="0.2361111111111111in"}is a vector of cross-
correlations _r~ms~_ of the windowed mono signal and the side signal _:_
{width="1.8055555555555556in" height="0.25in"}.
_Left/right signal reconstruction_
The side signal used for left/right signal reconstruction is attenuated in
case of severe frame loss conditions of an estimated frame loss rate of
greater than 1%. Using an estimate {width="0.16666666666666666in"
height="0.25in"} of the present average frame loss rate, an attenuation factor
α is derived according to the following formula:
{width="2.19375in" height="0.25in"},
where, in addition, α is limited to be within the range of 0...1.
Before reconstructing left and right signals, the side signal is multiplied
with factor α.
The average frame loss rate is estimated according to the following algorithm.
A first estimate _f_ is calculated according to
{width="2.0555555555555554in" height="0.4861111111111111in"}, _N_ =500,
where _w~j~_ is a weighting factor defined as
{width="1.3888888888888888in" height="0.4305555555555556in"},
and _bfi_buf_ is a buffer comprising the _N_ most recent flags _bfi_ ~k~.
The final frame loss rate estimate is then obtained by AR-1 filtering:
{width="1.3611111111111112in" height="0.25in"},
where {width="0.20833333333333334in" height="0.25in"} is the frame loss
estimate calculated during processing of the preceding frame.
#### 6.5.2.2 Mid-band
The mid-band synthesis is performed on every frame. When a frame is lost the
parameters of the mid-band decoder are extrapolated by using the predictive
decoders fed with a zero error signal. This implies that the error will
propagate to few frames which does not impact the overall quality. The
extrapolated parameters are the filter coefficients and the channel gains and
are computed as:
{width="2.736111111111111in" height="0.75in"}
## 6.6 Output signal generation
The decoder output signal(s) are generated by combining the low and high band
signal to produce full band signals. This operation is the inverse of the
encoder band-splitting operation described in section 5.1. The following
figure shows how the operation is performed.
{width="4.749305555555556in" height="1.2125in"}
The exact same filters used in the encoder are re-used in the decoder.
Furthermore, if the desired output sampling rate is different from the
internal sampling rate, then a resampling operation is preformed which is the
reverse operation of that performed in the encoder.
# 7 Detailed bit allocation of the Extended AMR-WB codec
The detailed allocation of the bits in the AMR-WB+ audio encoder is shown for
each frame type in tables 14-17 for mono and tables 18-20 for stereo. These
tables show the order of the bits produced by the audio encoder. Note that the
most significant bit (MSB) of each codec parameter is always sent first. For
TCX512 frames, the frame is split in two equal packets. For TCX1024 frames,
the frame is split in four equal packets. The splitting of TCX512 and TCX1024
frames in several packets is explained in Section 5.6.1.
Table 14: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of ACELP coding type
* * *
                         Bits (MSB‑LSB)
Description 480 bits/frame 416 bits/frame 384 bits/frame 336 bits/frame 304
bits/frame 272 bits/frame 240 bits/frame 208 bits/frame Mode bits b0-b1 b0-b1
b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 1^st^ ISP subvec b2 -- b9 b2 -- b9 b2 --
b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 2^nd^ ISP subvec b10 -- b17
b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17
3^rd^ ISP subvec b18 ‑ b23 b18 ‑ b23 b18 ‑ b23 b18 ‑ b23 b18 ‑ b23 b18 ‑ b23
b18 ‑ b23 b18 ‑ b23 4^th^ ISP subvecr b24 -- b30 b24 -- b30 b24 -- b30 b24 --
b30 b24 -- b30 b24 -- b30 b24 -- b30 b24 -- b30 5^th^ ISP subvec b31 -- b37
b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37
6^th^ ISP subvec b38 -- b42 b38 -- b42 b38 -- b42 b38 -- b42 b38 -- b42 b38 --
b42 b38 -- b42 b38 -- b42 7^th^ ISP subvec b43 -- b47 b43 -- b47 b43 -- b47
b43 -- b47 b43 -- b47 b43 -- b47 b43 -- b47 b43 -- b47 index of mean energy
b48 -- b49 b48 -- b49 b48 -- b49 b48 -- b49 b48 -- b49 b48 -- b49 b48 -- b49
b48 -- b49 subframe 1  
Adaptive CB index b50 -- b58 b50 -- b58 b50 -- b58 b50 -- b58 b50 -- b58 b50
-- b58 b50 -- b58 b50 -- b58 LTP-filtering-flag b59 b59 b59 b59 b59 b59 b59
b59 Algebraic CB indices b60 -- b147 b60 -- b131 b60 -- b123 b60 -- b111 b60
-- b103 b60 -- b95 b60 -- b87 b60 -- b79 codebook gains b148 -- b154 b132 --
b138 b124 -- b130 b112 -- b118 b104 -- b110 b96 -- b102 b88 -- b94 b80 -- b86
subframe 2  
Adaptive CB index b155 -- b160 b139 -- b144 b131 -- b136 b119 -- b124 b111 --
b116 b103 -- b108 b95 -- b100 b87 -- b92 LTP-filtering-flag b161 b145 b137
b125 b117 b109 b101 b93 Algebraic CB indices b162 -- b249 b146 -- b217 b138 --
b201 b126 -- b177 b118 -- b161 b110 -- b145 b102 -- b129 b94 -- b113 codebook
gains b250 -- b256 b218 -- b224 b202 -- b208 b178 -- b184 b162 -- b168 b146 --
b152 b130 -- b136 b114 -- b120 subframe 3  
Adaptive CB index b257 -- b265 b225-- b233 b209 -- b217 b185 -- b193 b169 --
b177 b153 -- b161 b137 -- b145 b121 -- b129 LTP-filtering-flag b266 b234 b218
b194 b178 b162 b146 b130 Algebraic CB indices b267 -- b354 b235 -- b306 b219
-- b282 b195 -- b246 b179 -- b222 b163 -- b198 b147 -- b174 b131 -- b150
codebook gains b355 -- b361 b307 -- b313 b283 -- b289 b247 -- b253 b223 --
b229 b199 -- b205 b175 -- b181 b151 -- b157 subframe 4  
Adaptive CB index b362 -- b367 b314 -- b319 b290 -- b295 b254 -- b259 b230 --
b235 b206 -- b211 b182 -- b187 b158 -- b163 LTP-filtering-flag b368 b320 b296
b260 b236 b212 b188 b164 Algebraic CB indices b369 -- b456 b321 -- b392 b297
-- b360 b261 -- b312 b237 -- b280 b213 -- b248 b189 -- b216 b165 -- b184
codebook gains b457 -- b463 b493 -- b399 b361 -- b367 b313 -- b319 b281 --
b287 b249 -- b255 b217 -- b223 b185 -- b191 Bandwidth extension  
Index of HF ISP b464 -- b472 b400 -- b408 b368 -- b376 b320 -- b328 b288 --
b296 b256 -- b264 b224 -- b232 b192 -- b200 Index of HF gain b473 -- b479 b409
-- b415 b377 -- b383 b329-- b335 b297 -- b303 b265 -- b271 b233 -- b239 b201
-- b207
* * *
Table 15: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX256 frame type
* * *
                        Bits (MSB‑LSB)
Description 480 bits/frame 416 bits/frame 384 bits/frame 336 bits/frame 304
bits/frame 272 bits/frame 240 bits/frame 208 bits/frame mode bits b0-b1 b0-b1
b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 1^st^ ISP subvec b2 -- b9 b2 -- b9 b2 --
b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 2^nd^ ISP subvec b10 -- b17
b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17
3^rd^ ISP subvec b18 ‑ b23 b18 ‑ b23 b18 ‑ b23 b18 ‑ b23 b18 ‑ b23 b18 ‑ b23
b18 ‑ b23 b18 ‑ b23 4^th^ ISP subvecr b24 -- b30 b24 -- b30 b24 -- b30 b24 --
b30 b24 -- b30 b24 -- b30 b24 -- b30 b24 -- b30 5^th^ ISP subvec b31 -- b37
b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37 b31 -- b37
6^th^ ISP subvec b38 -- b42 b38 -- b42 b38 -- b42 b38 -- b42 b38 -- b42 b38 --
b42 b38 -- b42 b38 -- b42 7^th^ ISP subvec b43 -- b47 b43 -- b47 b43 -- b47
b43 -- b47 b43 -- b47 b43 -- b47 b43 -- b47 b43 -- b47 Noise factor b48-b50
b48-b50 b48-b50 b48-b50 b48-b50 b48-b50 b48-b50 b48-b50 Global gain b51 -- b57
b51 -- b57 b51 -- b57 b51 -- b57 b51 -- b57 b51 -- b57 b51 -- b57 b51 -- b57
Algebraic VQ b58 -- b463 b58 -- b399 b58 -- b367 b58 -- b319 b58 -- b287 b58
-- b255 b58 -- b223 b58 -- b191 Bandwidth extension  
Index of HF ISP b464 -- b472 b400 -- b408 b368 -- b376 b320 -- b328 b288 --
b296 b256 -- b264 b224 -- b232 b192 -- b200 Index of HF gain b473 -- b479 b409
-- b415 b377 -- b383 b329-- b335 b297 -- b303 b265 -- b271 b233 -- b239 b201
-- b207
* * *
Table 16a: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX512 frame type -- First Packet
* * *
                        Bits (MSB‑LSB)
Description 480 bits/frame 416 bits/frame 384 bits/frame 336 bits/frame 304
bits/frame 272 bits/frame 240 bits/frame 208 bits/frame mode bits b0-b1 b0-b1
b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 1^st^ ISP subvec b2 -- b9 b2 -- b9 b2 --
b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 2^nd^ ISP subvec b10 -- b17
b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17
Noise factor b18-b20 b18-b20 b18-b20 b18-b20 b18-b20 b18-b20 b18-b20 b18-b20
Global gain b21 -- b27 b21 -- b27 b21 -- b27 b21 -- b27 b21 -- b27 b21 -- b27
b21 -- b27 b21 -- b27 Split Algebraic VQ b28 -- b463 b28 -- b399 b28 -- b367
b28 -- b319 b28 -- b287 b28 -- b255 b28 -- b223 b28 -- b191 Bandwidth
extension  
Index of HF ISP b464 -- b472 b400 -- b408 b368 -- b376 b320 -- b328 b288 --
b296 b256 -- b264 b224 -- b232 b192 -- b200 Index of HF gain b473-- b479 b409
-- b415 b377 -- b383 b329-- b335 b297 -- b303 b265 -- b271 b233 -- b239 b201
-- b207
* * *
Table 16b: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX512 frame type -- Second Packet
+-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | Bits | | | | | | | | | | (MSB | | | | | | | | | | ‑LSB) | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | D | 480 | 416 | 384 | 336 | 304 | 272 | 240 | 208 | | escri | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | | ption | frame | frame | frame | frame | frame | frame | frame | frame | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | mode | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | | bits | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 3^rd^ | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | | ISP | b7 | b7 | b7 | b7 | b7 | b7 | b7 | b7 | | s | | | | | | | | | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 4^th^ | b8 -- | b8 -- | b8 -- | b8 -- | b8 -- | b8 -- | b8 -- | b8 -- | | ISP | b14 | b14 | b14 | b14 | b14 | b14 | b14 | b14 | | su | | | | | | | | | | bvecr | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 5^th^ | b15 | b15 | b15 | b15 | b15 | b15 | b15 | b15 | | ISP | -- | -- | -- | -- | -- | -- | -- | -- | | s | b21 | b21 | b21 | b21 | b21 | b21 | b21 | b21 | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 6^th^ | b22 | b22 | b22 | b22 | b22 | b22 | b22 | b22 | | ISP | -- | -- | -- | -- | -- | -- | -- | -- | | s | b26 | b26 | b26 | b26 | b26 | b26 | b26 | b26 | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 7^th^ | b27 | b27 | b27 | b27 | b27 | b27 | b27 | b27 | | ISP | -- | -- | -- | -- | -- | -- | -- | -- | | s | b31 | b31 | b31 | b31 | b31 | b31 | b31 | b31 | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Gain | b3 | b3 | b3 | b3 | b3 | b3 | b3 | b3 | | redun | 2-b37 | 2-b37 | 2-b37 | 2-b37 | 2-b37 | 2-b37 | 2-b37 | 2-b37 | | dancy | | | | | | | | | | (6 | | | | | | | | | | MSBs) | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Split | b38 | b38 | b38 | b38 | b38 | b38 | b38 | b38 | | Alge | -- | -- | -- | -- | -- | -- | -- | -- | | braic | b463 | b399 | b367 | b319 | b287 | b255 | b223 | b191 | | VQ | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Band | | | | | | | | | | width | | | | | | | | | | exte | | | | | | | | | | nsion | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Gain | b464 | b400 | b368 | b320 | b288 | b256 | b224 | b192 | | corre | -b479 | -b415 | -b383 | -b335 | -b303 | -b271 | -b239 | -b207 | | ction | | | | | | | | | | | | | | | | | | | | 8x2 | | | | | | | | | | bits | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+
Table 17a: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX1024 frame type -- First Packet
* * *
                        Bits (MSB‑LSB)
Description 480 bits/frame 416 bits/frame 384 bits/frame 336 bits/frame 304
bits/frame 272 bits/frame 240 bits/frame 208 bits/frame mode bits b0-b1 b0-b1
b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 b0-b1 1^st^ ISP subvec b2 -- b9 b2 -- b9 b2 --
b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 b2 -- b9 2^nd^ ISP subvec b10 -- b17
b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17 b10 -- b17
Global gain b18 -- b24 b18 -- b24 b18 -- b24 b18 -- b24 b18 -- b24 b18 -- b24
b18 -- b24 b18 -- b24 Split Algebraic VQ b25 -- b463 b25 -- b399 b25 -- b367
b25 -- b319 b25 -- b287 b25 -- b255 b25 -- b223 b25 -- b191 Bandwidth
extension  
Index of HF ISP b464 -- b472 b400 -- b408 b368 -- b376 b320 -- b328 b288 --
b296 b256 -- b264 b224 -- b232 b192 -- b200 Index of HF gain b473 -- b479 b409
-- b415 b377 -- b383 b329-- b335 b297 -- b303 b265 -- b271 b233 -- b239 b201
-- b207
* * *
Table 17b: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX1024 frame type -- Second packet
+-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | Bits | | | | | | | | | | (MSB | | | | | | | | | | ‑LSB) | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | D | 480 | 416 | 384 | 336 | 304 | 272 | 240 | 208 | | escri | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | | ption | frame | frame | frame | frame | frame | frame | frame | frame | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | mode | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | | bits | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 3^rd^ | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | | ISP | b7 | b7 | b7 | b7 | b7 | b7 | b7 | b7 | | s | | | | | | | | | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Noise | b | b | b | b | b | b | b | b | | f | 8-b10 | 8-b10 | 8-b10 | 8-b10 | 8-b10 | 8-b10 | 8-b10 | 8-b10 | | actor | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | G | b11 | b11 | b11 | b11 | b11 | b11 | b11 | b11 | | lobal | -- | -- | -- | -- | -- | -- | -- | -- | | gain | b13 | b13 | b13 | b13 | b13 | b13 | b13 | b13 | | p | | | | | | | | | | arity | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Split | b14-- | b14 | b14 | b14 | b14 | b14 | b14 | b14 | | Alge | b463 | -- | -- | -- | -- | -- | -- | -- | | braic | | b399 | b367 | b319 | b287 | b255 | b223 | b191 | | VQ | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Band | | | | | | | | | | width | | | | | | | | | | exte | | | | | | | | | | nsion | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Gain | b464 | b400 | b368 | b320 | b288 | b256 | b224 | b192 | | corre | -b479 | -b415 | -b383 | -b335 | -b303 | -b271 | -b239 | -b207 | | ction | | | | | | | | | | | | | | | | | | | | 8x2 | | | | | | | | | | bits | | | | | | | | | | | | | | | | | | | | (MSBs | | | | | | | | | | 1^st^ | | | | | | | | | | 8 | | | | | | | | | | subfr | | | | | | | | | | ames) | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+
Table 17c: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX1024 frame type -- Third packet
+-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | Bits | | | | | | | | | | (MSB | | | | | | | | | | ‑LSB) | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | D | 480 | 416 | 384 | 336 | 304 | 272 | 240 | 208 | | escri | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | | ption | frame | frame | frame | frame | frame | frame | frame | frame | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | mode | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | | bits | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 4^th^ | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | | ISP | b8 | b8 | b8 | b8 | b8 | b8 | b8 | b8 | | su | | | | | | | | | | bvecr | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 6^th^ | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | | ISP | b13 | b13 | b13 | b13 | b13 | b13 | b13 | b13 | | s | | | | | | | | | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | G | b14 | b14 | b14 | b14 | b14 | b14 | b14 | b14 | | lobal | -- | -- | -- | -- | -- | -- | -- | -- | | gain | b16 | b16 | b16 | b16 | b16 | b16 | b16 | b16 | | redun | | | | | | | | | | dancy | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Split | b17-- | b17-- | b17 | b17 | b17 | b17 | b17 | b17 | | Alge | b463 | b399 | -- | -- | -- | -- | -- | -- | | braic | | | b367 | b319 | b287 | b255 | b223 | b191 | | VQ | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Band | | | | | | | | | | width | | | | | | | | | | exte | | | | | | | | | | nsion | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Gain | b464 | b400 | b368 | b320 | b288 | b256 | b224 | b192 | | corre | -b479 | -b415 | -b383 | -b335 | -b303 | -b271 | -b239 | -b207 | | ction | | | | | | | | | | | | | | | | | | | | 8x2 | | | | | | | | | | bits | | | | | | | | | | | | | | | | | | | | (MSBs | | | | | | | | | | 2^nd^ | | | | | | | | | | 8 | | | | | | | | | | subfr | | | | | | | | | | ames) | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+
Table 17d: Source encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX1024 frame type -- Fourth packet
+-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | Bits | | | | | | | | | | (MSB | | | | | | | | | | ‑LSB) | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | D | 480 | 416 | 384 | 336 | 304 | 272 | 240 | 208 | | escri | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | bits/ | | ption | frame | frame | frame | frame | frame | frame | frame | frame | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | mode | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | b0-b1 | | bits | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 5^th^ | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | b2 -- | | ISP | b8 | b8 | b8 | b8 | b8 | b8 | b8 | b8 | | s | | | | | | | | | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | 7^th^ | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | b9 -- | | ISP | b13 | b13 | b13 | b13 | b13 | b13 | b13 | b13 | | s | | | | | | | | | | ubvec | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | G | b14 | b14 | b14 | b14 | b14 | b14 | b14 | b14 | | lobal | -- | -- | -- | -- | -- | -- | -- | -- | | gain | b16 | b16 | b16 | b16 | b16 | b16 | b16 | b16 | | redun | | | | | | | | | | dancy | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Split | b17-- | b17-- | b17 | b17 | b17 | b17 | b17 | b17 | | Alge | b463 | b399 | -- | -- | -- | -- | -- | -- | | braic | | | b367 | b319 | b287 | b255 | b223 | b191 | | VQ | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Band | | | | | | | | | | width | | | | | | | | | | exte | | | | | | | | | | nsion | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Gain | b464 | b400 | b368 | b320 | b288 | b256 | b224 | b192 | | corre | -b479 | -b415 | -b383 | -b335 | -b303 | -b271 | -b239 | -b207 | | ction | | | | | | | | | | | | | | | | | | | | 16x1 | | | | | | | | | | bits | | | | | | | | | | | | | | | | | | | | (LSB | | | | | | | | | | 16 | | | | | | | | | | subfr | | | | | | | | | | ames) | | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+
N~1~ is the number of bits per frame allocated for the low and midband and is
calculated according to
N~1~ = N-1, 1 bit unused
Table 18: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX48 frame type, mode 0 and 1
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Balance factor B9-b15 b15-b21 Global
gain b16 -- b22 b22-b28 Algebraic VQ b23 -- bN~1~ b29- bN~1~
* * *
Table 19a: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX96 frame type, mode 2 - First packet
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Balance factor B9-b15 b15-b21
Algebraic VQ b16 -- bN~1~ b22- bN~1~
* * *
Table 19b: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX96 frame type, mode 2 - Second packet
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Global gain b9-b15 b15-b21 Algebraic
VQ b16-- bN~1~ b22- bN~1~
* * *
Table 20a: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX96 frame type, mode 3 - First packet
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Balance factor b9-b15 b15-b21
Algebraic VQ b16-- bN~1~ b22- bN~1~
* * *
Table 20b: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX96 frame type, mode 3 - Second packet
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Algebraic VQ b9 -- bN~1~ b15- bN~1~
* * *
Table 20c: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX96 frame type, mode 3 - Third packet
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Global gain B9-b15 b15-b21 Algebraic
VQ b16 -- bN~1~ b22- bN~1~
* * *
Table 20d: Stereo encoder output parameters in order of occurrence and bit
allocation within the audio frame of TCX96 frame type, mode 3 - Fourth packet
* * *
                   Bits (MSB‑LSB)
Description N bits/frame \ 76 Midband stereo  
Midband filter b0-b3 b0-b6 Midband gain b4-b5 b7-b11 Lowband stereo  
Mode bits b6-b7 b12-b13 reserved b8 b14 Algebraic VQ b9 -- bN~1~ b15- bN~1~
* * *
# 8 Storage and Transport Interface formats
The AMR-WB+ codec storage and transport interface formats are described in
this section.
## 8.1 Available Modes and Bitrates
The AMR-WB+ format contains the AMR-WB modes and a set of AMR-WB+ extension
modes.
The AMR-WB+ codec includes the AMR-WB modes, as shown in Table 21 below.
Table 21: AMR-WB+ modes.
* * *
Index _Mode_ _Sampling rate (kHz)_ _Mono/Stereo_ _Number of data octets per
frame (AMR-WB modes zero-padded)_ 0 AMR-WB 6.60 kbit/s 16 Mono 17 1 AMR-WB
8.85 kbit/s 16 Mono 23 2 AMR-WB 12.65 kbit/s 16 Mono 32 3 AMR-WB 14.25 kbit/s
16 Mono 36 4 AMR-WB 15.85 kbit/s 16 Mono 40 5 AMR-WB 18.25 kbit/s 16 Mono 46 6
AMR-WB 19.85 kbit/s 16 Mono 50 7 AMR-WB 23.05 kbit/s 16 Mono 58 8 AMR-WB 23.85
kbit/s 16 Mono 60 9 AMR-WB SID 16 Mono 5 10 AMR-WB+ 13.6 kbit/s 16/24 Mono 34
11 AMR-WB+ 18 kbit/s 16/24 Stereo 45 12 AMR-WB+ 24 kbit/s 16/24 Mono 60 13
AMR-WB+ 24 kbit/s 16/24 Stereo 60 14 FRAME_ERASURE - - 0 15 NO_DATA - - 0
* * *
There are four special extension modes (Index 10-13 in table 21) that have a
fixed internal sampling frequency (25600 Hz) and audio input frequencies (16
or 24 kHz). These modes share the property with the AMR-WB modes that each
frame is only capable of representing 20 ms.
Besides the AMR-WB+ operation according to the modes specified in table 21,
AMR-WB+ operation is specified by three parameters: mono bit-rate as given in
Table 22, stereo bit-rate as given in Table 23, and internal sampling
frequency (ISF) as given in Table 24.
Table 22: Mono rate indices.
* * *
Mono Index Mono rate Bit rate at 25.6 kHz ISF Octets per frame 0 AMR-WB+ 208
bit/frame 10.4 kbit/s 26 1 AMR-WB+ 240 bit/frame 12 kbit/s 30 2 AMR-WB+ 272
bit/frame 13.6 kbit/s 34 3 AMR-WB+ 304 bit/frame 15.2 kbit/s 38 4 AMR-WB+ 336
bit/frame 16.8 kbit/s 42 5 AMR-WB+ 384 bit/frame 19.2 kbit/s 48 6 AMR-WB+ 416
bit/frame 20.8 kbit/s 52 7 AMR-WB+ 480 bit/frame 24 kbit/s 60
* * *
Table 23: Stereo rate indices.
* * *
Stereo index _Stereo extension rate(bits/frame)_ _Stereo rate for ISF of 25.6
kHz_ _Number of data octets per frame_ 0 40 bits/frame 2.0 kbit/s 5 1 48
bits/frame 2.4 kbit/s 6 2 56 bits/frame 2.8 kbit/s 7 3 64 bits/frame 3.2
kbit/s 8 4 72 bits/frame 3.6 kbit/s 9 5 80 bits/frame 4.0 kbit/s 10 6 88
bits/frame 4.4 kbit/s 11 7 96 bits/frame 4.8 kbit/s 12 8 104 bits/frame 5.2
kbit/s 13 9 112 bits/frame 5.6 kbit/s 14 10 120 bits/frame 6.0 kbit/s 15 11
128 bits/frame 6.4 kbit/s 16 12 136 bits/frame 6.8 kbit/s 17 13 144 bits/frame
7.2 kbit/s 18 14 152 bits/frame 7.6 kbit/s 19 15 160 bits/frame 8.0 kbit/s 20
* * *
It is to be noted that the number of samples each frame corresponds to is
always the same but the duration of each frame varies depending on the
internal sampling frequency. There is no preferred sampling frequency for the
codec to operate at, but in order to limit the possible settings for an
effective transmission, the format supports the sampling frequencies given in
Table 24. . Herein, index 0 is used for AMR-WB and the 4 extension modes of
Table 21.
Table 24: Internal sampling frequencies and corresponding frame lengths in
time
* * *
ISF Index _Internal Sampling Rate (Hz)_ _Frame duration (ms)_ _Bit Rate
factor_ 0 N/A 20 N/A 1 12800 40 ½ 2 14400 35.55 9/16 3 16000 32 5/8 4 17067 30
2/3 5 19200 26.67 ¾ 6 21333 24 5/6 7 24000 21.33 15/16 8 25600 20 1 9 28800
17.78 9/8 10 32000 16 5/4 11 34133 15 4/3 12 36000 14.22 45/32 13 38400 13.33
3/2
* * *
The bit-rate will be dependent on the internal sampling frequency. The last
column of Table 24 indicates which multiplication factor, any bit-rate value
for 25600 Hz internal sampling factor should be converted with. The ISF index
is carried in the bitstream format to indicate which internal sampling
frequency is used for each AMR-WB+ encoded frame.
The frame type is used to identify the content of an AMR-WB+ encoded frame.
This type indicates if it is; an AMR-WB mode, Comfort noise, NO_DATA, AMR-WB+
core mode in mono usage, or a combination of a core mode and a stereo mode.
The frame types are presented in Table 25 below. The core mode and stereo mode
index values are according to Table 22 and 23 respectively. The bit-rate value
assumes an internal sampling frequency of 25600 Hz.
Table 25: Normative frame type table. Bit-rates assumes 25600 Hz internal
sampling frequency.
* * *
Frame type Core mode Stereo mode Bit rate Octets per frame 0-15 As specified
in Table 21  
16 0 None 10.4 26 17 1 None 12.0 30 18 2 None 13.6 34 19 3 None 15.2 38 20 4
None 16.8 42 21 5 None 19.2 48 22 6 None 20.8 52 23 7 None 24.0 60 24 0 0 12.4
31 25 0 1 12.8 32 26 0 4 14 35 27 1 1 14.4 36 28 1 3 15.2 38 29 1 5 16 40 30 2
2 16.4 41 31 2 4 17.2 43 32 2 6 18 45 33 3 3 18.4 46 34 3 5 19.2 48 35 3 7 20
50 36 4 4 20.4 51 37 4 6 21.2 53 38 4 9 22.4 56 39 5 5 23.2 58 40 5 7 24 60 41
5 11 25.6 64 42 6 8 26 65 43 6 10 26.8 67 44 6 15 28.8 72 45 7 9 29.6 74 46 7
10 30 75 47 7 15 32 80 48-127 Reserved
* * *
## 8.2 AMR-WB+ Transport Interface Format
The transport interface format serves as an intermediate interface to the
transport format. The transport interface frame contains a two-octet header
followed by data octets.
The header in each frame contains the following two octets.
* * *
              MSB                       LSB
**Octet** bit 8 bit 7 bit 6 bit 5 bit 4 bit 3 bit 2 bit 1 **1** 0 Frame type
(FT)  
**2** TFI 0 ISF mode (5 bits)
* * *
**Frame type** (FT) (7 bits): Indicates the frame type setting of the codec
used for the corresponding frame (the combination of AMR-WB+ core and stereo
mode, the AMR-WB mode, or comfort noise, as specified by Table 25 above).
**Transport Frame Index (TFI)** (2 bits): An index from 0 (first) to 3 (last)
indicating this transport frame\'s position in the superframe.
**ISF index** (5 bits): Indicates the internal sampling frequency employed for
the corresponding frame. The index values correspond to internal sampling
frequency as specified in Table 24 above. This field SHALL be set to 0 for
operation according to the AMR-WB+ modes defined in table 21 (Frame types
0-13).
FT=14 (AUDIO_LOST) is used to indicate frames that are lost. NO_DATA (FT=15)
frame could mean either that there is no data produced by the audio encoder
for that frame or that no data for that frame is transmitted in the current
packet (i.e., valid data for that frame could be sent in either an earlier or
later packet). The duration for these non-included frames is dependent on the
internal sampling frequency indicated by the ISF mode field.
For operation according to FT 0-13 the ISF field shall be set 0 and has no
meaning. The frame length for that operation is fixed to 20 ms in time.
If receiving a frame with an FT value not defined the whole frame SHOULD be
discarded and assumed erased.
The AMR-WB+ SCR/DTX is identical with AMR-WB SCR/DTX described in [8] and
SHALL only be used in combination with the AMR-WB modes (0-8).
The audio data follows the header octets. The number of data octets per frame
corresponding to a certain frame type is given in Table 25.
**_Example_**
The following diagram (Table 26) shows a frame of AMR-WB+ using 14 kbit/s
frame type (FT=26) with a frame length of 35 octets (280 bits). The internal
sampling frequency in this example is 25.6 kHz (ISF mode = 8). FT 26
corresponds to mono mode 0 (208 bits/frame) and stereo mode 4 (72 bits/frame).
The frame is the first frame in the superframe (TFI=0).
The data octets are placed according to the detailed bit allocation given in
tables 14 to 20. The first bit of the AMR-WB+ data b0 is placed in bit 8 of
octet 3.
Table 26: AMR-WB+ transport interface format for 14 kbit/s operation with ISF
mode 8 (bit rate factor=1).
* * *
               MSB                                       LSB
**Octet** bit 8 bit 7 bit 6 bit 5 Bit 4 bit 3 bit 2 bit 1 **1** FT = 26  
0 0 0 1 1 0 1 0 **2** TFI=0 ISF = 8  
0 0 0 0 1 0 0 0 **3** AMR-WB+ data (octet 1)  
b0 b1 b2 b3 b4 b5 b6 b7 **4..27** AMR-WB+ data (octets 2 to 25)  
b8 ... ... ... ... ... ... ... **28** AMR-WB+ data (octet 26)  
b200 b201 b202 b203 B204 b205 b206 b207 **29** AMR-WB+ data (octet 27)  
s0 s1 s2 s3 s4 s5 s6 s7 **30..36** AMR-WB+ data (octet 28 to 34)  
s8 ... ... ... ... ... ... ... **37** AMR-WB+ data (octet 35)  
S64 S65 S66 S67 S68 S69 S70 S71
* * *
## 8.3 AMR-WB+ File Storage Format
This format is relevant only for file storage and defines a storage unit
contained in an AMR-WB+ sample of a 3GP file [9]. It is quite similar to
transport interface format with the exception that the two-octet header is
used once per superframe for AMR-WB+ extension modes and once per frame for
AMR-WB modes. Note that in AMR-WB+, the operation code and internal sampling
frequency can be switched only on a superframe basis boundaries so the header
octets are needed only once per superframe.
All media streams in a 3GP file are stored in timed units called samples. This
format defines the syntax of the basic component of a sample, which is here
called a storage unit..
A storage unit consists of a two-octet header followed by data octets
corresponding to either:
1) A whole superframe (4 transport frames) when FT = 10..13 or OC = 16...47 .
2) A frame otherwise
For the first case, the number of data octets per superframe is given by 4
times the number of octets per frame (the right-most column in Table 25).
The length of an AMR-WB+ storage unit in ms (corresponding to one superframe)
depends on the internal sample frequency and given by 80×ISF/25600 where ISF
is the internal sampling frequency in Hz (ISF modes are shown in Table 24).
The header in each storage unit contains the following two octets.
* * *
              MSB                           LSB
**Octet** bit 8 bit 7 bit 6 bit 5 bit 4 bit 3 bit 2 bit 1 **1** 0 Frame type
(7 bits)  
**2** 0 0 0 ISF mode (5 bits)
* * *
**Frame type** (FT) (7 bits): Indicates the frame type setting of the codec
used for the corresponding frame (the combination of AMR-WB+ core and stereo
mode, the AMR-WB mode, or comfort noise, as specified by Table 25 above).
**ISF index** (5 bits): Indicates the internal sampling frequency employed for
the corresponding frame. The index values correspond to internal sampling
frequency as specified in Table 24 above. This field SHALL be set to 0 for
operation according to the AMR-WB+ modes defined in table 21 (frame types
0-13).
For frame types according to FT 0-13 the ISF field shall be set 0 and has no
meaning. The frame length for that operation is fixed to 20 ms in time.
The audio data follows the header octets. The number of data octets per
storage unit corresponding to frame types 10..13 and 16...47 are given as 4
times the number of octets per frame (right-most column in Table 25), for the
other frame types, the number of octets are those corresponding to 1 frame
only.
It should be noticed that when FT \<10, i.e. AMR-WB frames, the original AMR-
WB storage format should be preferred in order to ensure backward decoding
compatibility.
**_Example_**
The following diagram (Table 27) shows a storage sample of AMR-WB+ using 14
kbit/s frame types (FT=26) with a superframe length of 4×35=140 octets. The
internal sampling frequency in this example is 25.6 kHz (ISF mode = 8). FT 26
corresponds to mono mode 0 (208 bits/frame) and stereo mode 4 (72 bits/frame).
The data octets are packetized according to the detailed bit allocation given
in tables 14 to 20. The first bit of the AMR-WB+ data b0 is placed in bit 8 of
octet 3.
Table 27: AMR-WB+ storage sample (superframe) for 14 kbit/s operation with ISF
mode 8 (bit rate factor=1).
* * *
                 MSB                                             LSB
**Octet** bit 8 bit 7 bit 6 bit 5 bit 4 bit 3 bit 2 bit 1 **1** FT = 26  
0 0 0 1 1 0 1 0 **2** ISF = 8  
0 0 0 0 1 0 0 0 **3** Frame 1 AMR-WB+ data (octet 1)  
b0 b1 b2 b3 b4 b5 b6 b7 **4..27** Frame 1 AMR-WB+ data (octets 2 to 25)  
b8 ... ... ... ... ... ... ... **28** Frame 1 AMR-WB+ data (octet 26)  
b200 b201 b202 b203 B204 b205 b206 b207 **29** Frame 1 AMR-WB+ data (octet 27)  
s0 s1 s2 s3 s4 s5 s6 s7 **30..36** Frame 1 AMR-WB+ data (octet 28 to 34)  
s8 ... ... ... ... ... ... ... **37** Frame 1 AMR-WB+ data (octet 35)  
S64 S65 S66 S67 S68 S69 S70 S71 **38** Frame 2 AMR-WB+ data (octet 1)  
b0 b1 b2 b3 b4 b5 b6 b7 **39..62** Frame 2 AMR-WB+ data (octets 2 to 25)  
b8 ... ... ... ... ... ... ... **63** Frame 2 AMR-WB+ data (octet 26)  
b200 b201 b202 b203 B204 b205 b206 b207 **64** Frame 2 AMR-WB+ data (octet 27)  
s0 s1 s2 s3 s4 s5 s6 s7 **65..71** Frame 2 AMR-WB+ data (octet 28 to 34)  
s8 ... ... ... ... ... ... ... **72** Frame 2 AMR-WB+ data (octet 35)  
S64 S65 S66 S67 S68 S69 S70 S71 **73** Frame 3 AMR-WB+ data (octet 1)  
b0 b1 b2 b3 b4 b5 b6 b7 **74..97** Frame 3 AMR-WB+ data (octets 2 to 25)  
b8 ... ... ... ... ... ... ... **98** Frame 3 AMR-WB+ data (octet 26)  
b200 b201 b202 b203 B204 b205 b206 b207 **99** Frame 3 AMR-WB+ data (octet 27)  
s0 s1 s2 s3 s4 s5 s6 s7 **100..106** Frame 3 AMR-WB+ data (octet 28 to 34)  
s8 ... ... ... ... ... ... ... **107** Frame 3 AMR-WB+ data (octet 35)  
S64 S65 S66 S67 S68 S69 S70 S71 **108** Frame 4 AMR-WB+ data (octet 1)  
b0 b1 b2 b3 b4 b5 b6 b7 **109..132** Frame 4 AMR-WB+ data (octets 2 to 25)  
b8 ... ... ... ... ... ... ... **133** Frame 4 AMR-WB+ data (octet 26)  
b200 b201 b202 b203 B204 b205 b206 b207 **134** Frame 4 AMR-WB+ data (octet
27)  
s0 s1 s2 s3 s4 s5 s6 s7 **135..141** Frame 4 AMR-WB+ data (octet 28 to 34)  
s8 ... ... ... ... ... ... ... **142** Frame 4 AMR-WB+ data (octet 35)  
S64 S65 S66 S67 S68 S69 S70 S71
* * *
#