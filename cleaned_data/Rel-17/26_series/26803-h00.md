# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
In the present document, modal verbs have the following meanings:
**shall** indicates a mandatory requirement to do something
**shall not** indicates an interdiction (prohibition) to do something
The constructions \"shall\" and \"shall not\" are confined to the context of
normative provisions, and do not appear in Technical Reports.
The constructions \"must\" and \"must not\" are not used as substitutes for
\"shall\" and \"shall not\". Their use is avoided insofar as possible, and
they are not used in a normative context except in a direct citation from an
external, referenced, non-3GPP document, or so as to maintain continuity of
style when extending or modifying the provisions of such a referenced
document.
**should** indicates a recommendation to do something
**should not** indicates a recommendation not to do something
**may** indicates permission to do something
**need not** indicates permission not to do something
The construction \"may not\" is ambiguous and is not used in normative
elements. The unambiguous constructions \"might not\" or \"shall not\" are
used instead, depending upon the meaning intended.
**can** indicates that something is possible
**cannot** indicates that something is impossible
The constructions \"can\" and \"cannot\" are not substitutes for \"may\" and
\"need not\".
**will** indicates that something is certain or expected to happen as a result
of action taken by an agency the behaviour of which is outside the scope of
the present document
**will not** indicates that something is certain or expected not to happen as
a result of action taken by an agency the behaviour of which is outside the
scope of the present document
**might** indicates a likelihood that something will happen as a result of
action taken by some agency the behaviour of which is outside the scope of the
present document
**might not** indicates a likelihood that something will not happen as a
result of action taken by some agency the behaviour of which is outside the
scope of the present document
In addition:
**is** (or any other verb in the indicative mood) indicates a statement of
fact
**is not** (or any other negative verb in the indicative mood) indicates a
statement of fact
The constructions \"is\" and \"is not\" do not indicate requirements.
# Introduction
In this Technical Report, we study the architectural enablers and extensions
to the 5G Media Streaming Architecture for edge media processing. It covers
aspects such as discovery, configuration, execution, and management of media
processing in 5G to address the needs identified for example by the XR5G and
FLUS items.
# 1 Scope
The present document is a study of use cases for multimedia processing in the
edge and the potential 5G media streaming architecture extensions to enable
them.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TS 23.501: \"System architecture for the 5G System (5GS)\".
[3] 3GPP TS 23.558: \"Architecture for enabling Edge Applications (EA)\".
[4] 3GPP TR 23.748: \"Study on enhancement of support for Edge Computing in 5G
Core network (5GC)\".
[5] 3GPP TS 23.503: \"Policy and charging control framework for the 5G System
(5GS); Stage 2\".
[6] 3GPP TR 26.928: \"Extended Reality (XR) in 5G\".
[7] 3GPP TS 26.512: \"5G Media Streaming (5GMS); Protocols\".
[8] 3GPP TR 26.998: \"Support of 5G glass-type Augmented Reality / Mixed
Reality (AR/MR) devices\", Release 17.
[9] 3GPP TR 26.804: \"Study on 5G media streaming extensions\", Release 17.
[10] 3GPP TS 23.502: \"Procedures for the 5G System (5GS)\".
# 3 Definitions of terms, symbols and abbreviations
## 3.1 Terms
For the purposes of the present document, the terms given in 3GPP TR 21.905
[1] and the following apply. A term defined in the present document takes
precedence over the definition of the same term, if any, in 3GPP TR 21.905
[1].
**example:** text used to clarify abstract rules by applying them literally.
## 3.2 Symbols
> Void
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
AC Application Client
ACR Application Context Relocation
AF Application Function
ASP Application Service Provider
DNAI Data Network Access Identifier
DNS Domain Name Service
EASDF Edge Application Server Discovery Function
ECS Edge Configuration Server
EEC Edge Enabler Client
EES Edge Enabler Server
PCF Policy Control Function
PDU Protocol Data Unit
PSA PDU Session Anchor
QoS Quality of Service
LADN Local Area Data Network
LBO Local Break Out
NEF Network Exposure Function
SSC Session and Service Continuity
SMF Session Management Function
UPF User Plane Function
URSP UE Route Selection Policy
# 4 Overview of Relevant Architectures
## 4.1 General
In this clause, we provide an overview of ongoing SA activities on edge
computing architectures.
## 4.2 SA6 Edge Architecture
### 4.2.1 Edge computing architecture
SA6 has taken significant steps towards the definition of normative edge
computing architecture for 5GC in TS 23.558 [3]. Starting from common
scenarios, described in the Annex, a set of requirements is defined, and the
following architecture is proposed:
{width="6.156367016622922in" height="2.9479166666666665in"}
Figure 1: SA6 Edge data network architecture
The architecture defines the key nodes and functions as well as the interfaces
between them.
The identified functions with a brief description are given here:
  * Edge Enabler Server (EES): provides supporting functions needed for Edge Application Servers and Edge Enabler Client.
  * Edge Enabler Client (EEC): provides supporting functions needed for Application Client(s).
  * Edge Configuration Server (ECS): provides supporting functions needed for the Edge Enabler Client to connect with an Edge Enabler Server.
  * Edge Application Server (EAS): the application server resident in the Edge Data Network, performing the server functions. The Application Client connects to the Edge Application Server in order to avail the services of the application with the benefits of Edge Computing.
  * Application Client (AC): application resident in the UE performing the client function. Details of the Application Client are out of scope of this specification.
A typical sequence of steps to use edge computing services is as follows:
1\. **Service Provisioning**
\- The EEC is provisioned with a list of EES instances, e.g. from the ECS.
2\. **Registration**
\- EES instances register with the ECS to publish their edge configuration
capabilities.
\- The EEC registers with a selected EES for further EAS discovery and Edge
Computing Service usage.
\- EAS instances register with EES instances to publish their edge
capabilities.
3\. **EAS discovery**
\- The EEC queries the EES to discover specific EASs. Different types of
filtering information contained in the EAS discovery filters can be used
during this discovery phase in the EAS discovery request.
\- The EES identifies the appropriate EAS instance(s) according to the UE-
specific service information and the UE location.
\- Via the EAS discovery response, the EEC receives the discovered EAS
instance(s) with the corresponding EAS profile which may include additional
information regarding matched capabilities, e.g. service permission levels,
service area, KPIs.
\- The detailed information for key messages and elements of the EAS discovery
procedures is shown as below in Tables 1, 2, 3, 4 and 5.
Table 1: EAS discovery request
Information element Status Description
* * *
Requestor identifier M The ID of the requestor (e.g. EECID) UE Identifier O
The identifier of the UE (i.e. GPSI or identity token) Security credentials M
Security credentials resulting from a successful authorization for the edge
computing service. EAS discovery filters O Set of characteristics to determine
required EASs, as detailed in Table Y.
Table 2: EAS discovery filters
+-----------------------------+--------+-----------------------------+ | Information element | Status | Description | +=============================+========+=============================+ | List of AC characteristics | O | Describes the ACs for which | | (NOTE 1) | | a matching EAS is needed. | +-----------------------------+--------+-----------------------------+ | > AC profile (NOTE 2) | M | AC profile containing | | | | parameters used to | | | | determine matching EAS. AC | | | | profiles are further | | | | described in Table 8.2.2-1 | | | | of TS 23.558 [3]. | +-----------------------------+--------+-----------------------------+ | List of EAS characteristics | O | Describes the | | (NOTE 1, NOTE 3) | | characteristic of required | | | | EASs. | +-----------------------------+--------+-----------------------------+ | > EASID | O | Identifier of the required | | | | EAS. | +-----------------------------+--------+-----------------------------+ | > EAS provider identifier | O | Identifier of the required | | | | EAS provider | +-----------------------------+--------+-----------------------------+ | > EAS type | O | The category or type of | | | | required EAS (e.g. V2X) | +-----------------------------+--------+-----------------------------+ | > EAS schedule | O | Required availability | | | | schedule of the EAS (e.g. | | | | time windows) | +-----------------------------+--------+-----------------------------+ | > EAS Geographical Service | O | Location(s) (e.g. | | Area | | geographical area, route) | | | | where the EAS service | | | | should be available. | +-----------------------------+--------+-----------------------------+ | > EAS Topological Service | O | Topological area (e.g. cell | | Area | | ID, TAI) for which the EAS | | | | service should be | | | | available. See possible | | | | formats in Table 8.2.7-1 of | | | | TS 23.558 [3]. | +-----------------------------+--------+-----------------------------+ | > Service continuity | O | Indicates if the service | | support | | continuity support is | | | | required or not. | +-----------------------------+--------+-----------------------------+ | > EAS status | O | Required status of the EAS | | | | (e.g. enabled, disabled, | | | | etc.) | +-----------------------------+--------+-----------------------------+ | > Service permission level | O | Required level of service | | | | permissions e.g. trial, | | | | gold-class | +-----------------------------+--------+-----------------------------+ | > Service feature(s) | O | Required service features | | | | e.g. single vs. | | | | multi-player gaming service | +-----------------------------+--------+-----------------------------+ | NOTE 1: Only one of the | | | | information elements shall | | | | be present. | | | | | | | | NOTE 2: \"Preferred ECSP | | | | list\" IE shall not be | | | | present. | | | | | | | | NOTE 3: The \"List of EAS | | | | characteristics\" IE must | | | | include at least one | | | | optional IE, if used as an | | | | EAS discovery filter. | | | +-----------------------------+--------+-----------------------------+
Table 3: EAS discovery response
Information element Status Description
* * *
Successful response O Indicates that the EAS discovery request was successful.
> Discovered EAS list O List of discovered EAS(s). Each element includes the
information described below. >> EAS profile M Profile of the EAS. Each element
is described in Table XX. >> Lifetime O Time interval or duration during which
the information elements in the EAS profile is valid and supposed to be cached
in the EEC (e.g. time-to-live value for an EAS Endpoint) Failure response O
Indicates that the EAS discovery request failed. > Cause O Indicates the cause
of EAS discovery request failure.
Table 4: EAS Profile
+-----------------------------+--------+-----------------------------+ | Information element | Status | Description | +=============================+========+=============================+ | EASID | M | The identifier of the EAS | +-----------------------------+--------+-----------------------------+ | EAS Endpoint | M | Endpoint information (e.g. | | | | URI, FQDN, IP address) used | | | | to communicate with the | | | | EAS. This information maybe | | | | discovered by EEC and | | | | exposed to ACs so that ACs | | | | can establish contact with | | | | the EAS. | +-----------------------------+--------+-----------------------------+ | ACID(s) | O | Identifies the AC(s) that | | | | can be served by the EAS | +-----------------------------+--------+-----------------------------+ | EAS Provider Identifier | O | The identifier of the EAS | | | | Provider | +-----------------------------+--------+-----------------------------+ | EAS Type | O | The category or type of EAS | | | | (e.g. V2X) | +-----------------------------+--------+-----------------------------+ | EAS description | O | Human-readable description | | | | of the EAS | +-----------------------------+--------+-----------------------------+ | EAS Schedule | O | The availability schedule | | | | of the EAS (e.g. time | | | | windows) | +-----------------------------+--------+-----------------------------+ | EAS Geographical Service | O | The geographical service | | Area | | area that the EAS serves. | | | | ACs in UEs that are located | | | | outside that area shall not | | | | be served. | +-----------------------------+--------+-----------------------------+ | EAS Topological Service | O | The topological service | | Area | | area that the EAS serves. | | | | ACs in UEs that are located | | | | outside that area shall not | | | | be served. See possible | | | | formats in Table 8.2.7-1 of | | | | TS 23.558 [3]. | +-----------------------------+--------+-----------------------------+ | EAS Service KPIs | O | Service characteristics | | | | provided by EAS, detailed | | | | in Table YY | +-----------------------------+--------+-----------------------------+ | EAS service permission | O | Level of service | | level | | permissions e.g. trial, | | | | gold-class supported by the | | | | EAS | +-----------------------------+--------+-----------------------------+ | EAS Feature(s) | O | Service features e.g. | | | | single vs. multi-player | | | | gaming service supported by | | | | the EAS | +-----------------------------+--------+-----------------------------+ | Service continuity support | O | Indicates if the EAS | | | | supports service continuity | | | | or not. This IE may also | | | | indicate whether the EAS | | | | supports ACT. | +-----------------------------+--------+-----------------------------+ | List of EAS DNAI(s) | O | DNAI(s) associated with the | | | | EAS. This IE is used as | | | | Potential Locations of | | | | Applications in | | | | clause 5.6.7 of | | | | 3GPP TS 23.501 [2]. | | | | | | | | It is a subset of the | | | | DNAI(s) associated with the | | | | EDN where the EAS resides. | +-----------------------------+--------+-----------------------------+ | List of N6 Traffic Routing | O | The N6 traffic routing | | requirements | | information and/or routing | | | | profile ID corresponding to | | | | each EAS DNAI. | +-----------------------------+--------+-----------------------------+ | EAS Availability Reporting | O | The availability reporting | | Period | | period (i.e. heartbeat | | | | period) that indicates to | | | | the EES how often it needs | | | | to check the EAS\'s | | | | availability after a | | | | successful registration. | +-----------------------------+--------+-----------------------------+ | EAS Required Service APIs | O | A list of the Service APIs | | | | that are required by the | | | | EAS | +-----------------------------+--------+-----------------------------+ | EAS Status | O | The status of the EAS (e.g. | | | | enabled, disabled, etc.) | +-----------------------------+--------+-----------------------------+
> Table 5: Edge Application Server Service KPIs
Information element Status Description
* * *
Maximum Request rate O Maximum request rate from the Application Client
supported by the server. Maximum Response time O The maximum response time
advertised for the Application Client\'s service requests. Availability O
Advertised percentage of time the server is available for the Application
Client\'s use. Available Compute O The maximum compute resource available for
the Application Client. Available Graphical Compute O The maximum graphical
compute resource available for the Application Client. Available Memory O The
maximum memory resource available for the Application Client. Available
Storage O The maximum storage resource available for the Application Client.
Connection Bandwidth O The connection bandwidth in Kbit/s advertised for the
Application Client\'s use.
4\. EAS relocation:
Under certain circumstances, it is necessary to relocate an EAS instance to a
different edge location. In such cases, it may also be necessary to relocate
the application context currently associated with the EAS instance in order to
support service continuity.
The EAS relocation procedure may be triggered for any of the following
reasons:
\- UE mobility, including predictive or expected UE mobility.
\- Overload situations in the EAS instance or in the Edge DN.
\- Maintenance aspects, such as graceful shutdown of an EAS instance.
\- Temporal edge resource requirements, for example the application needs an
EAS instance with a new capability not available in the current one.
Three roles are defined in the context of EAS relocation:
\- The _detection entity_ role can be potentially performed by the Application
Client (AC), the Edge Enabler Client (EEC), an Edge Enabler Server (EES)
and/or an Edge Application Server (EAS).
\- A _decision-making entity_ determines that application context relocation
is required and instructs the execution entity to perform application context
transfer.
\- An _execution entity_ performs application context relocation as and when
instructed by the decision-making entity.
\- After successful application context relocation, the EES is informed of the
completion by the EAS and the EEC is informed of the completion by the EES.
#### 4.2.2 High-level call flows for EAS relocation scenarios
A complete set of call flows for the EAS relocation scenarios described in TS
23.558 [3] is depicted in figure 2 below.
Figure 2: Call flows in EAS relocation scenarios defined in SA6
## 4.3 SA2 Edge Support
### 4.3.1 Overview
Edge Computing has been identified as a key feature of 5G early on and has
been specified as part of the 5G System architecture in clause 5.13 of [2]. It
describes the selection of a close UPF for non-roaming or LBO-connected UEs.
The specification lists different options to enable access to edge computing:
  * User plane (re)selection: the 5G Core Network (re)selects UPF to route the user traffic to the local Data Network.
  * Local Routing and Traffic Steering: the 5G Core Network selects the traffic to be routed to the applications in the local Data Network.
  * Session and service continuity to enable UE and application mobility.
  * An Application Function may influence UPF (re)selection and traffic routing via PCF or NEF.
  * Network capability exposure: 5G Core Network and Application Function to provide information to each other via NEF or directly.
  * QoS and Charging: PCF provides rules for QoS Control and Charging for the traffic routed to the local Data Network.
  * Support of Local Area Data Network: 5G Core Network provides support to connect to the LADN in a certain area where the applications are deployed.
In addition, SA2 has started a new release 17 study item on enhancement of
support for edge computing in 5GC [4] to address identified gaps to enable
edge computing. The findings will be documented in TR 23.748 [4].
So far, the identified key issues are:
1\. **Discovery of Edge Application Server:** The UE needs to find the optimal
Edge Application Server (EAS) so that traffic is locally routed to the
respective EAS. Furthermore, replacing the old EAS with new EAS when the old
EAS is no more optimal is also an important aspect to address. This key issue
deals with such EAS discovery.
2\. **Edge relocation:** As the UE moves across the 5G system, the UE location
may change and require the network and the EAS to deal with the change.
Furthermore, Edge Application Server (EAS) may become congested or may even
become unavailable due to outage, which also need to be dealt by changing the
EAS. This key issue deals with addressing such EAS relocations.
3\. **Network Information Provisioning to Locate Applications with Low
Latency:** There might be a need to deliver certain timely QoS information to
the Edge Application Server (EAS) that is deployed locally. The usual way to
do this is via the NEF, however it will not be possible to do this with low
latency because the NEF is usually located in the central location to avoid
frequent switching between NEFs. This key issue deals with being able to
provision such QoS information to the local applications that run in the EAS
with low latency.
4\. **(Consecutive traffic steering in different N6-LAN)** Traffic steering
might be needed consecutively first to Local Application Server and then to
Central Application Server for further processing. Also for downlink, there
might be a traffic first that moves to Central Application Server and then
brought to the Local Application Server (to get it closer to the UE) and then
finally to the UE.
5\. **Activating the traffic routing towards local data network per AF
request:** In order to activate the traffic routing towards Local (access to)
Data Network, the SMF should be configured with the required DNAI. For ETSUN
case, either SMF or I-SMF should be configured with the requested DNAI. For
some of edge computing use case scenarios, the SMF or I-SMF of the PDU session
may not be configured with the requested DNAI. This key issue deals with the
mechanism to activate the traffic routing towards the Local Data Network in
such cases.
Clause 6 of TR 23.748 [4] documents a set of solutions for the previously
identified key issues.
The following architecture figures show 5GS and Edge Application Servers
hosted in Edge Hosting Environment.
NOTE: These figures show the relationship between the EAS and 5GC defined in
TS 23.501 [2]. The application layer architecture for enabling edge computing
is out of the scope of the SA2 study.
Figure 3: SA2 Architecture for Accessing Edge Application Server with UL CL/BP
Figure 4: SA2 Architecture for Accessing Edge Application Server without UL
CL/BP
5GC supports at least the following three connectivity models to enable Edge
Computing:
**\- Distributed Anchor Point:** the PDU Session anchor is moved far out in
the network, to the local sites. It is the same for all the user PDU session
traffic. Re-anchoring (SSC#2 and SSC#3) is used to optimize traffic routing
for all applications when moving long distances.
**\- Session Breakout:** The PDU session has a PDU Session anchor in a central
site and a PDU Session anchor in the local site. Only one of them provides the
IP anchor point. The Edge Computing application traffic is selectively
diverted to the local PDU Session anchor using UL Classifier or multihoming BP
technology. Re-anchoring of the local PDU Session anchor is used to optimize
traffic routing for locally diverted traffic as the user moves.
**\- Multiple PDU sessions:** Edge Computing applications use a specific PDU
session with the PDU Session anchor in the local site. The rest of
applications use a PDU Session with a central PDU Session anchor. The mapping
between applications and PDU sessions is steered by the URSP rules. Re-
anchoring (SSC#2 and SSC#3) is used to optimize traffic routing for Edge
Computing applications as the user moves.
These three connectivity models are illustrated in the figure below:
Figure 5: SA2 5GC Connectivity Models for Edge Computing
### 4.3.2 Process of Discovering EAS
#### 4.3.2.1 General
DNS based solutions have been concluded as the final solution for discovering
the Edge Application Server for the above three connectivity models.
#### 4.3.2.2 DNS-based solutions for Multiple PDU Sessions
This solution proposes to enhance the NEF service(s) to allow the AF to
influence PCF decisions for URSP rules so that Domain Descriptors are used to
steer the DNS and the Application traffic into specific PDU sessions with the
PDU Session Anchor UPF that is servicing the EAS.
The following clarifications are therefore required in normative
specification(s) on how the Domain Descriptors in URSP are used by the UE in
clause 7.1.4 of TS 23.503 [5]:
\- When a UE attempts to resolve an FQDN, the PDU Session through which to
send the DNS query message is controlled by URSP rules.
\- The UE should be able to use URSP procedures to set up the PDU session
prior to sending a DNS query.- The IP address of the DNS server for the PDU
Session is configured on the UE by the SMF using one of the methods already
specified.
The solution is not guaranteed to work when:
a) The UE doesn\'t support URSP rules provisioned from the PCF.
b) The DNS Server configuration at the UE has been overridden by the user.
c) The Application Client deliberately circumvents the Operating System's
default DNS libraries, for example by using DNS-over-TCP (DoT), DNS-over-HTTPS
(DoH) or any other over-the-top mechanism.
NOTE: This can correspond to devices doing tethering, or to devices deployed
for specific corporate purposes. Whether URSP rules work in the OS level is up
to implementations. How the cooperation between the OS level and the modem
works depends on the further studies.
These limitations and informative guidelines will be captured in a technical
specification to cover scenarios where the Operating System, user or
applications may override the operator-provided URSP or DNS settings. The
guidelines should assume no restriction on the Operating System, user or
application.
#### 4.3.2.3 DNS-based solutions for Distributed Anchors
The decision for anchoring the UE in the distributed anchor point scenario for
Edge Computing will be described in a technical specification as:
a) Using subscription policy information to set proper UE policy (e.g. URSP
via usage of dedicated DNN); and/or
b) Applying proper policies at session (SMF) level to apply PCC rules based on
the Nnef_TrafficInfluence service and based on the user subscription.
#### 4.3.2.4 DNS-based solutions for Session Breakout
For Session Breakout connectivity mode, the EASDF (EAS Discovery Function), a
new stand-alone 5GC network function is proposed. It allows coordination of
EAS Discovery using DNS and 5GC connectivity. The EASDF facilitates selection
of an EAS closer to the edge, and it allows Dynamic ULCL/BP/Local PSA
insertion.
1\. The EASDF is dynamically configured with address records of the EAS
instances it is to handle so that it can respond appropriately when a local UE
attempts to resolve one of these FQDNs.
2\. The SMF selects the EASDF serving the PDU session and configures the UE to
use the EASDF as its DNS Server for that PDU Session.
3\. The EASDF maintains a PDU session context during the lifetime of the PDU
session and needs to be made aware of the release of the PDU Session.
4\. The EASDF is able to inform SMF with the IP address of an EAS resolved by
DNS, which that may trigger the SMF to perform local UPF insertion/relocation
if needed.
#### 4.3.3.5 Summary of DNS based EAS Discovery
The DNS-based EAS Discovery solution depends on DNS message parsing. The Core
Network can decide the location of the local PDU Session Anchor and can
deliver the DNS query message to DNS with UE's location indicated. Then the
DNS can return the IP address of EAS. Finally, the UE connects to the Edge
Application Server via the PDU Session.
When the UE moves, the 5GC (SMF) may change the user plane path according to
the UE's new location, i.e. TA granularity. Then the User Plane path change
notification may be sent to the AF and AF decides whether to trigger the EAS
relocation procedure or not.
NOTE: Currently, the DNS-based EAS discovery solution is only useful with
Operator-provided DNS Setting. If the DNS server is overwritten by a third
party, or if the application or application library uses DNS over TCP (DoT) or
DNS over HTTPS (DoH), the solution is still under development in SA2. The
Operated-provided DNS can also be the recursive DNS.
Editor's Note: Alternative solutions for the cases where enhanced/controlled
DNS resolution won't work will be up to SA2's WID conclusion.
#### 4.3.3.6 Discussion
With the concluded solutions in SA2, the application client can directly
discover and connect to the EAS before any application layer exchanges between
the client and EAS. There will be less impact for SA4 aspects without frequent
exchanges at the application layer.
However, without the exchanges between clients and application servers, which
capability does this application need? Especially when the capability of EAS
need to be determined based on the capability and requirements of clients. The
SA2 solutions may need to be enhanced for discovering EAS with specific
capabilities to avoid additional re-discovering the appropriate EAS.
### 4.3.4 Summary of EAS relocation solutions
Currently the concluded solutions in SA2 mainly focus on the following
aspects:
1\. EAS Rediscovery
\- The DNS-based EAS rediscovery procedure is triggered by UE to find the new
EAS. The triggers can be a new IP address assigned to the UE or the EAS
relocation indicator within the NAS message from SMF. Then UE can establish
the new connection to the new EAS.
\- The UE is informed via the application layer signaling, like HTTP REDIRECT,
which is out of 3GPP SA2 scope.
2\. For less packet loss, buffering the uplink data in the target PSA-UPF is
proposed when the EAS relocation begins.
3\. The User Plane latency can be taken into consideration by 5GC during the
user plane path change/selection. The AF can give a UP latency request during
the EAS relocation and 5GC can follow that requirement during the
change/selection of UP path.
4\. The Coordination indication can be provided by the AF to allow connections
to the source EAS and target EAS to coexist for a period of time.
5\. EAS IP replacement in the PSA UPF can be used to keep UE unaware of the
EAS change. However, this conclusion assumes the TCP/TLS/QUIC context transfer
between EAS can be handled by other solutions.
During the EAS relocation, how to transfer the EAS context including
application layer context and transport layer context is out the scope of the
SA2 study. Hence, the main concluded solutions seem like preparation work,
e.g. EAS rediscovery triggers different considerations during the EAS
relocation. How to define the context transfer is not defined yet.
Transfer of context between EAS instances is application- and deployment-
specific, but a 3GPP-defined API to initiate context transfer would enable the
5GMS AF to interface with different virtual infrastructure management systems.
NOTE: Certain applications may be sensitive to the speed of context transfer,
so it would be useful for a 5GMS AF to be able to obtain an estimate in
advance from the 5G System of how long a particular transfer might take.
## 4.4 SA5 Edge Management
SA5 has recently agreed a new study item [4] on the management aspects of edge
computing. The focus of the study item will be on the following scenarios:
\- How 3GPP management solutions support the third-party service provider to
deploy and manage the Edge Configuration Server.
\- How 3GPP management solutions support Edge Computing Service Provider(s) to
deploy and manage Edge Enable Server(s).
\- How 3GPP management solutions support Edge Application Provider(s) to
deploy and manage Edge Application Server(s).
As can be seen, SA5 has adopted the SA6 architecture and will study ways of
enabling it through providing the necessary management functions.
The scope has been set to the following items:
1\. The lifecycle management of EAS, EES and ECS needed to support edge
computing, by considering the various deployment scenarios.
2\. Deployment and provisioning of 5GC network functions needed to support the
edge computing.
3\. Provisioning of EES, and ECS needed to support edge computing.
4\. Performance assurance of EES, ECS and relevant 5GC functions needed to
support edge computing.
5\. Fault supervision of EES, ECS and relevant 5GC functions needed to support
edge computing.
6\. Mechanism(s) to enable and support EAS deployment on a particular edge
data network.
7\. Mechanism(s) to enable and support:
\- ECSP to deploy and manage EES and ECS.
\- ASP to deploy and manage EAS.
8\. Studying the need of providing management provisions to create and manage
communication service(s) at a particular edge data network.
## 4.5 5GMS Architecture
SA4 has developed a 5G Media Streaming (5GMS) architecture that is designed to
support media streaming sessions over 5G. The overall 5GMS architecture is
depicted in the following figure:
Figure 6: 5G Media Streaming within the 5G System
The 5GMS architecture consists of three main functions: the 5GMS AF, the 5GMS
AS and the 5GMS Client. These functions leverage the 5G System functionality
to support and assist media streaming sessions. The 5GMS architecture supports
both downlink and uplink streaming. It is also designed to support a wide
range of streaming services, from video streaming to VR/MR/XR.
5GMS specifies a set of interfaces and APIs to allow the Application Provider
and the UE to configure and request support for streaming sessions.
# 5 Use Cases for Edge Media Processing
## 5.1 General
In this clause, a set of relevant use cases for edge media processing is
presented.
## 5.2 Downlink Streaming Use Cases
### 5.2.1 Caching Downlink Streaming Content
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | A Mobile Network Operator that deploys a downlink streaming service | | or supports the delivery of media content from a third-party service | | wants to offer that content in the highest possible quality to all | | of its users. The MNO also notices that video streaming already | | accounts for a large part of the traffic on the backhaul network. | | For these reasons, the MNO wants to offload (part of the) content | | hosting from the CDN to caches near or within its network. Users of | | the service may access the content from the edge, allowing them to | | select higher quality renditions of the content (e.g., DASH | | representations) and play it back without interruptions. The MNO may | | improve the hit ratios of the cache by employing intelligent | | caching. Furthermore, to ensure that clients access the content from | | the optimal edge, the network operator may want to direct clients to | | this edge. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: CDN** | | | | **Delivery: Download, Live Streaming, On Demand Streaming** | | | | **Device: Phone, tablet, HMD, TV** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | End user devices should be able to stream, decode, and display the | | video streams. Modern smartphones already have these capabilities. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | The capabilities of edge nodes are similar to regular CDN nodes | | distributing video content, although at smaller scale. This means | | that edge nodes should have storage and HTTP serving capabilities, | | and UEs should have high-bandwidth connectivity to edge nodes. | | Higher video quality, less playback interruptions, and shorter | | loading times improve the QoE. | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | CDNs are a well-known and well-established technology. Mobile CDN is | | receiving the attention of various third-party CDN operators due to | | the increase of mobile users and the increased prevalence of | | applications and services that target mobile users. A recent report | | \"Mobile CDN Market\" | | ( | | https://www.transparencymarketresearch.com/mobile-cdn-market.html) | | lists different CDN operators operating a Mobile CDN, including: | | Cloudflare, Fastly, Akamai Technologies, Amazon Web Services and | | Ericsson. Cloudflare explains its reasons for supporting Mobile CDN: | | . | | | | This use case allows an MNO to offer services to third-party CDN | | providers or to improve the performance of its own Operator CDN (if | | the MNO offers CDN service itself) by enabling distributed CDN cache | | instances to run as Edge Application Servers (EAS). | | | | This use case relies on the network being able to select an edge | | cache that is closest to the UE client, as well as performing cache | | re-selection during mobility of the UE client. The architecture to | | support this is being worked on by SA2 in the Release 17 study item | | on enhancement of support for edge computing in 5GC under key issue | | 1 ('Discovery of Edge Application Server') and key issue 2 ('Edge | | relocation'). | +----------------------------------------------------------------------+ | **Nominal Cost Analysis** | +----------------------------------------------------------------------+ | Using edge computing for video content caching is the next step in | | distributing video delivery. It will allow MNOs and streaming | | services to further scale up and serve more users, while reducing | | load on the backhaul network. As in a regular CDN node, a node at | | the edge can be used by many users at the same time and servers | | scale horizontally. MNOs can use existing facilities at PoPs or | | points further in the network with serving capabilities. | +----------------------------------------------------------------------+ | **Benefits and Impact** | +----------------------------------------------------------------------+ | The major benefit is expected for MNOs and service providers, who | | are able to serve more users with high quality video while | | significantly reducing the load on the backhaul network, thus | | improving the efficiency of the network infrastructure. End-users | | are expected to benefit as it will increase the access to content in | | a high video quality, also enabling demanding streaming applications | | including VR, and delivering those applications with shorter loading | | times and with fewer interruptions. | +----------------------------------------------------------------------+ | **Potential Technical Requirements** | +----------------------------------------------------------------------+ | 1. It should be possible for edge caches to be operated either by | | the MNO or by a third-party service such as a 5GMSd Application | | Provider. | | | | 2. It should be possible for the network to steer clients to a | | certain edge or CDN. | | | | 3. It should be possible for (third-party) services to specify | | caching directives. | | | | 4. It should be possible for DASH clients to send hints (e.g., | | about anticipated upcoming requests) to the network enabling | | intelligent caching on the edge. | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | TBD | +----------------------------------------------------------------------+
### 5.2.2 Split Rendering
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | The system design for split rendering follows the discussion and | | requirements from TR26.928, clause 6.2.5. The architecture us shown | | in Figure 1. | | | | {width="6.383333333333334in" | | height="3.4347222222222222in"} | | | | Raster-based split rendering refers to the case where the XR Server | | runs an XR engine to generate the XR Scene based on information | | coming from an XR device. The XR Server rasterizes the XR viewport | | and does XR pre-rendering. | | | | According to Figure Figure 1, the viewport is pre-dominantly | | rendered in the XR server, but the device is able to do latest pose | | correction, for example by asynchronuous time-warping (see clause | | 4.1) or other XR pose correction to address changes in the pose. | | | | - XR graphics workload is split into rendering workload on a | | powerful XR server (in the cloud or the edge) and pose correction | | (such as ATW) on the XR device | | | | - Low motion-to-photon latency is preserved via on device | | Asynchronous Time Warping (ATW) or other pose correction methods. | | | | The following call flow highlights the key steps: | | | | 1) An XR Device connects to the network and joins XR application | | | | a) Sends static device information and capabilities (supported | | decoders, viewport) | | | | 2) Based on this information, the XR server sets up encoders and | | formats | | | | 3) Loop | | | | a) XR Device collects XR pose (or a predicted XR pose) | | | | b) XR Pose is sent to XR Server | | | | c) The XR Server uses the pose to pre-render the XR viewport | | | | d) XR Viewport is encoded with 2D media encoders | | | | e) The compressed media is sent to XR device along with XR pose | | that it was rendered for | | | | f) The XR device decompresses video | | | | g) The XR device uses the XR pose provided with the video frame and | | the actual XR pose for an improved prediction using and to correct | | the local pose, e.g. using Asynchronus Time Warp. | | | | According to TR 26.928 [6], clause 4.2.2, the relevant processing | | and delay components are summarized as follows: | | | | **\- User interaction delay** is defined as the time duration between | | the moment at which a user action is initiated and the time such an | | action is taken into account by the content creation engine. In the | | context of gaming, this is the time between the moment the user | | interacts with the game and the moment at which the game engine | | processes such a player response. | | | | **\- Age of content** is defined as the time duration between the | | moment a content is created and the time it is presented to the | | user. In the context of gaming, this is the time between the | | creation of a video frame by the game engine and the time at which | | the frame is finally presented to the player. | | | | The **round-trip interaction delay** is therefore the sum of the | | _Age of Content_ and the _User Interaction Delay_. If part of the | | rendering is done on an XR server and the service produces a frame | | buffer as rendering result of the state of the content, then for | | raster-based split rendering (as defined in clause 6.2.5) in cloud | | gaming applications, the following processes contribute to such a | | delay: | | | | - User Interaction Delay (Pose and other interactions) | | | | - capture of user interaction in game client, | | | | - delivery of user interaction to the game engine, i.e. to the | | server (aka network delay), | | | | - processing of user interaction by the game engine/server, | | | | - Age of Content | | | | - creation of one or several video buffers (e.g. one for each eye) | | by the game engine/server, | | | | - encoding of the video buffers into a video stream frame, | | | | - delivery of the video frame to the game client (a.k.a. network | | delay), | | | | - decoding of the video frame by the game client, | | | | - presentation of the video frame to the user (a.k.a. framerate | | delay). | | | | As Asynchronous Time Warp is applied the motion-to-photon latency | | requirements (of at most 20 ms) are met by XR device internal | | processing. What determines the network requirements for split | | rendering is time of pose-to-render-to-photon and the round-trip | | interaction delay. According to clause TR 26.928, clause 4.5, the | | permitted downlink latency is typically 50-60ms. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: XR, Cloud Computing, GPU** | | | | **Delivery: Interactive, Split, Gaming** | | | | **Device: Phone, HMD, Glasses** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the device, a gaming application may be installed | | | | On the network, an XR Server is installed, that runs a gaming | | application as well GPU based rendering and an encoding. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | Steam | | | | Boundless XR: | | https://zerolight.com/de/new | | s/press-releases/worlds-first-boundless-xr-over-5g-retail-experience | +----------------------------------------------------------------------+ | **Cost Analysis** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
### 5.2.3 User-generated live streaming
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | A social influencer starts a live captured media session similar to | | Facebook Live and publishes the content through 5G Media Uplink | | Streaming. The content is then distributed live to several or many | | viewers through 5G Media Downlink Streaming. | | | | The application provides several usage scenarios with various | | configuration options which may change during the live session: | | | | 1. The social influencer may: | | | | a) be static, occasionally moving or highly mobile, for example in | | a vehicle, on skis or on a bicycle, | | | | b) produce different quality of content, depending on lighting | | conditions, speed, as well as based on the quality of the camera and | | the available uplink bandwidth, | | | | c) produce highly-valuable content that requires extra content | | protection, | | | | d) want to capitalize on the stream by allowing ad-insertion in the | | content (targeted pre-roll and/or mid-roll). | | | | 2. The viewers may be quite diverse and changing because: | | | | a) they may be dynamically joining or leaving the live stream, | | | | b) their number might be just a few or they may quite many, in | | range of tens of thousands or more, for example for a popular | | influencer, | | | | c) they may be geographically spread with different densities in | | various areas, and their densities may change during the session, | | | | d) they may consume the service on different devices, for example | | on 4K TV sets, mobile phones, in-car receivers or tablets, with | | different operating systems, DRM capabilities as well as different | | codec hardware capabilities, | | | | e) some of them may be mobile, i.e on a car or public transport, | | | | they may react (smilies, comments, likes, audio dubs, images, | | avatars, and animations) to the content or previous reactions by the | | viewers who watched the content earlier. | | | | 3. The service requirements may be quite different. The content may | | need to be: | | | | a) available for live and/or on-demand consumption, | | | | b) only available for consumption after the end of the live uplink | | session, i.e. it is uploaded entirely before being made available to | | followers, | | | | c) available with a required target latency with ranges in between | | capture and display of as low as 1 second up to several tens of | | seconds, | | | | d) dubbed into the same or different language, | | | | e) provided with automatic extraction and addition of | | captions/subtitles from the audio, | | | | f) post-processed to improve the audio and/or visual quality, | | | | g) processed by adding overlays and content tags and other | | augmented material, | | | | h) indexed, including the addition of thumbnail navigation in real | | time, | | | | i) provided to regional proxies with specific metadata such as | | black-out information, ad insertion opportunities, language settings | | or other service metadata, | | | | j) profanity checked and appropriately altered before being | | distributed, | | | | k) available for viewing for some time period (from a few minutes | | to forever) after the end of the live session. | | | | In a simple reference scenario of 5G Media Uplink and Downlink | | Streaming, the following aspects are supported: | | | | 1. An application manages the service. The server application may | | be run by external application providers, by MNO, or by a joint | | collaboration of application provider and MNO. | | | | 2. Uplink streaming is provided through 5G media uplink streaming | | to the application. | | | | 3. The application may perform one or more of the following | | processes: | | | | a) It decodes the received content | | | | b) It applied the various processes the content such as: | | | | > i) Upscaling | | > | | > ii) Light correction | | > | | > iii) Stabilization | | > | | > iv) Dubbing | | > | | > v) Captioning | | > | | > vi) Overlaying and tagging | | > | | > vii) Indexing | | > | | > viii) Navigation improvements. | | | | c) It encodes the uploaded content to 5GMS downlink streaming | | formats. | | | | d) It packages the content and adds appropriate ad metadata. | | | | e) It applies content protection and DRM. | | | | 4. As soon as the content becomes available, the server application | | uses downlink streaming for distribution. | | | | a) It provisions a 5GMS downlink streaming service. | | | | b) It ingests the content into a 5GMS streaming service. | | | | c) It gets feedback from consumption reporting on what content is | | consumed and may change the encoded streaming formats. | | | | The following aspects may be critical for the service: | | | | 1. Can the service be provided throughout the session without any | | interruption considering the dynamic aspect of the service, for | | example when a highly mobile edge media streaming client makes a | | transition between two edge processing environments? | | | | 2. Can the desired end-to-end latency be met with the reference | | scenario and if not, what are possible ways to realize this? | | | | 3. Is the content generation flexible and fast enough to address | | different user population, yet highly utilized, i.e. the variations | | of the content is consumed by one or more viewers and is shared as | | much as possible by many viewers? | | | | 4. Is there a benefit to push certain processing closer to the | | influencer, certain viewers, or in-between (in terms of bandwidth, | | latency, and processing requirements)? | | | | NOTE: The meaning of flexible content generation needs to be | | explained. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: 2D** | | | | **Delivery: 5GMS uplink streaming, 5GMS downlink streaming, live | | media streaming** | | | | **Device: Phone, HMD, Glasses** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the sending UE, 5GMS Uplink streaming is provided. | | | | On every receiving UE, a 5GMS downlink streaming client is provided. | | | | An Application Service Provider supports network interfaces for 5GMS | | Uplink Streaming (M1u and M2u) as well as 5GMS Downlink Streaming | | (M1d and M2d). | | | | Extended functionalities in uplink streaming and downlink streaming | | may be supported such that the Application Service Provider can | | delegate certain tasks to the 5G Media Streaming System. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | Potential new required capabilities of 5G Media Streaming System: | | | | 1. Decoding of content received through uplink streaming. | | | | 2. Processing of the content with functionalities such as: | | | | a) Upscaling | | | | b) Light correction | | | | c) Stabilization | | | | d) Dubbing | | | | e) captioning | | | | etc. | | | | 3. Transcoding of the uploaded and processed content to 5GMS | | downlink streaming formats. | | | | 4. Packaging/Encrypting the content and adding appropriate ad | | metadata. | | | | Relevant KPIs: | | | | 1. Subjective/objective quality of the encoded streams in terms of | | bitrates/quality. | | | | 2. Latency for the end-to-end service. | | | | 3. Latency of each processing step. | | | | 4. Seamless integration of ads with the main content. | | | | 5. Scalability and handling of different number of devices. | | | | 6. Quality of the delivered service in terms of streaming metrics. | | | | 7. Computational efficiency in terms of: | | | | a) Encoding and Decoding workflow | | | | b) Encryption and D | | | | c) Manifest generation | | | | d) Target-based advertising | | | | 8. Seamless session and service continuity of media streaming when | | the user's high level of mobility causes a transition to a new edge | | processing environment. | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | Today, the above processing may be achieved by running cloud | | processing on the application server for all the functionalities | | mentioned above. Alternatively, third-party cloud-based transcoding | | services exist. | | | | The number of streams, support of multiple codecs, the amount of | | delay, the number of representations in the encoding ladder varies | | depending on the service. | | | | Codec support evolves with the availability of new codecs. | | | | Services like Facebook Live encode the content on demand and on the | | fly. | | | | Services like YouTube Live provide channels for professional content | | providers. They can insert advertisement clips, but the ad insertion | | occurs using two video elements. | | | | Services like TikTok allow the user to add a lip-sync to a song, to | | add his/her reactions on a small window over the video, and to make | | short movies using filter and speed change of the video. The user | | also can capture a video next to a pre-recorded video. | +----------------------------------------------------------------------+ | **Nominal Cost Analysis** | +----------------------------------------------------------------------+ | The cost of service increases linearly with the number of ingest | | streams. | | | | The cost of service increases less than linearly with the number of | | download streaming clients as the encoding and caching requirement | | will be common with the large number of viewers. | | | | Cost analysis needs to take into account if there a benefit or | | necessity to push certain processing closer to the users/edge (in | | terms of bandwidth, latency and processing requirements)? | +----------------------------------------------------------------------+ | **Benefits and Impact** | +----------------------------------------------------------------------+ | Potential Benefits and Impacts when running services within 5GMS | | network: | | | | Potential Benefits and Impacts when running services on the edge: | +----------------------------------------------------------------------+ | **Potential Technical Requirements** | +----------------------------------------------------------------------+ | Potential Requirements: | | | | 1. Establish workflows as defined in the use case with the addition | | of service parameters. | | | | 2. Distribute the tasks across 5G System and 5GMS components. | | | | 3. Seamless transition of application/service media streaming flows | | between different edge media processing environments. | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
### 5.2.4 Augmented Video Streaming
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | Augmented video streaming will help to understand the video and | | enhance the interest of the video. In live streaming scenes, it can | | analyze the video content with AI technology, refine the video | | information, understand the video content and enhance the video | | quality, such as improving the resolution and color. It may also | | superimpose AR effect to tag the identified video information | | interestingly, such as the AR effect of the pass path in a football | | game or the AR effect on human face or background during streaming, | | etc. Processing at the edge can reduce the time required for video | | enhancement processing and network transmission. | | | | 1. **Augmented video streaming with AI.** Due to limited shooting | | conditions or the need for new video features, augmented video | | streaming with AI can provide a service that edge nodes is used to | | enhance the captured video to improve the user experience. | | | | a) An encoded video streaming is compressed and uploaded to an edge | | node, and the video resolution, color gamut and other parameters | | should be specified in configuration. | | | | b) The edge node server decodes the video streaming, then with the | | installed AI capabilities, sets up the enhancement functions, such | | as resolution enhancement, color enhancement, signal-to-noise ratio | | enhancement, video feature recognition, subtitle, etc., for video | | editing. | | | | c) Augmented Video is re-encoded and distributed to users. | | | | 2. **Augmented video streaming with AR.** It can provide AR | | experience to its users. | | | | a) An encoded video streaming is compressed and uploaded to an edge | | node. | | | | b) The edge node server decodes the video streaming, identifies and | | understands the video features with AI capability, and loads the | | corresponding AR special effects on the understanding results. The | | AR special effects are overlapped with the video streaming. | | | | c) The edge node distributes it to users. | | | | 3. **Augmented video streaming with interaction.** AI augmented | | content may consider the user's preferences. AR augmented content | | will output according to the user\'s FOV. Therefore, the workflow of | | the edge node can involve interactions. According to the user\'s | | preference, the edge node server selects the corresponding augmented | | video streaming to distribute, or processes the video according to | | the user\'s FOV. | | | | When there is a high requirement for QoE of enhanced video, the | | terminal device cannot meet this requirement and cloud or edge | | servers are needed for processing. And in the case of local video | | streaming transmission, the video streaming can be processed | | directly at the edge. Compared with uploading to the cloud-based | | processing, it can reduce roundtrip time delay (RTT) of network and | | avoid the waste of resources on the core network. | | | | For AI video enhancement, users can choose the function of the video | | enhancement. If the AI video enhancement processing functions are | | deployed on the cloud, downlink transmission needs to involve | | multi-video streams with different enhancement effects for users to | | choose from. The pressure of the downlink will be multiplied. | | Therefore, it is better for edge nodes to support different video | | enhancement processing. | | | | For AR effects enhancement, users need to use AR devices to watch | | enhanced AR video and have higher requirement on delay, like MTP | | (Motion To Photons) latency requirement. It is necessary for split | | rendering of edge processing to ensure this. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: XR, AI, Cloud Computing** | | | | **Delivery: Interaction** | | | | **Device: Phone, HMD, TV** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the device side, a video application or a browser supporting XR | | player with interaction is needed. | | | | On the network side, a video server is installed for | | video data structuring process and its key techniques like deep | | learning, big data technology and cloud storage. Edge nodes need to | | store some AR effects in advance. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | Requirements: | | | | 1. Real-time adaptation of encoding and transcoding | | | | 2. Overlay graphics. | | | | 3. CDN and content caching | | | | 4. 6DOF interaction | | | | KPIs: | | | | 5. MTP | | | | 6. Operation response time | | | | 7. The number of users | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | Intel edge computing solutions | | | | At the 2018 China Mobile Global Partner Conference, China Mobile and | | Intel jointly released a set of video processing unit and | | intelligent video edge computing solution. | |  | | | | - Media Analytics | | | | {width="2.1145833333333335in" | | height="0.9895833333333334in"} | | | | - AR solutions | | | | {width="2.1458333333333335in" | | height="1.0208333333333333in"} | +----------------------------------------------------------------------+ | **Cost Analysis** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
### 5.2.5 Generalized Split and Cloud Rendering and Processing
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | See several use cases in TR 26.928 should be added to the already | | agreed split rendering use case by reference to TR 26.928 [6]. | | | | +----+----------+----------+----------+----------+----------+ | | | 3 | S | VR | 3DoF+, | St | HMD with | | | | | treaming | | 6DoF | reaming\ | a | | | | | of | | | Inte | co | | | | | I | | | ractive\ | ntroller | | | | | mmersive | | | Split | | | | | | 6DoF | | | | | | | +====+==========+==========+==========+==========+==========+ | | | 4 | E | 2D, AR | 2D, | St | Phone | | | | | motional | and VR | 3DoF+, | reaming\ | and HMD | | | | | S | | 6DoF | Inte | | | | | | treaming | | | ractive, | | | | | | | | | Split | | | | +----+----------+----------+----------+----------+----------+ | | | 5 | Un | VR | 6DoF | St | HMD with | | | | | tethered | | | reaming, | a Gaming | | | | | I | | | Inte | co | | | | | mmersive | | | ractive, | ntroller | | | | | Online | | | Split | | | | | | Gaming | | | | | | | +----+----------+----------+----------+----------+----------+ | | | 6 | I | VR | 6DoF | St | 2D | | | | | mmersive | | | reaming, | screen | | | | | Game | | | Split | or HMD | | | | | S | | | | with a | | | | | pectator | | | | co | | | | | Mode | | | | ntroller | | | +----+----------+----------+----------+----------+----------+ | | | 21 | I | VR and | 3DoF+, | St | XR5G-V3 | | | | | mmersive | Social | 6DoF | reaming\ | | | | | | 6DoF | VR | | Inte | XR5G-V4 | | | | | S | | | ractive\ | | | | | | treaming | | | Convers | | | | | | with | | | ational\ | | | | | | Social | | | Split | | | | | | Int | | | | | | | | | eraction | | | | | | | +----+----------+----------+----------+----------+----------+ | | | 22 | 5G | VR | 6DoF | St | XR5G-V3 | | | | | Online | | | reaming, | | | | | | Gaming | | | Inte | XR5G-V4 | | | | | Party | | | ractive, | | | | | | | | | Split, | | | | | | | | | D2D | | | | +----+----------+----------+----------+----------+----------+ | | | 23 | Spatial | AR | 6DoF | St | XR5G-AX | | | | | Shared | | | reaming\ | | | | | | Data | | | Inte | | | | | | | | | ractive\ | | | | | | | | | Convers | | | | | | | | | ational\ | | | | | | | | | Split | | | | +----+----------+----------+----------+----------+----------+ | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Nominal Cost Analysis** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Benefits and Impact** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Potential Technical Requirements** | +----------------------------------------------------------------------+ | See several use cases in TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | Edge/Cloud processing and rendering is a promising technology to | | support online gaming in power- and resource constrained devices. | | Relevant aspects for generalized cloud/split rendering include: | | | | 1. A generalized XR cloud and split rendering application framework | | based on a scene description. | | | | 2. Support for 3D formats in split and cloud rendering approaches. | | | | 3. Formats and protocols for XR Pose information delivery and | | possibly other metadata in the uplink at sufficiently high | | frequency. | | | | 4. Content Delivery protocols that support generalized split/cloud | | rendering. | | | | 5. Distributions of processing resources across different resources | | in the 5G system network, in the application provider domain (cloud) | | and the XR device. | | | | 6. Supporting the establishment of Processing Workflows across | | distributed resources and managing those. | | | | 7. 5QIs and other 5GS/Radio capabilities that support generalized | | split/cloud rendering by coordination with other groups. | | | | 8. Edge computing discovery and capability discovery based on work | | in SA2 and SA6 (see clause 4.3.6). | +----------------------------------------------------------------------+
### 5.2.6 Photo-realistic AR Rendering in Network
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | Bob wants to position a complex 3D object with significant amount of | | data (materials, roughness, texture, transparency) and place it into | | a real-world environment using an AR device. For this purpose, he | | uses a local rendering engine, but he is very unsatisfied as natural | | lights are not well handled and the object looks unrealistic. A | | cloud service offers a PBR-based cloud rendering, and he gives it a | | try. He is really happy with the rendering, he gets sparkling | | effects and starts to move around the object and wants to put it | | into different angles and positions. However, moving, rotating, | | interacting the object makes him annoyed again as the latency of the | | interaction is only executed after several hundred of milliseconds. | | | | However, he gets the offering from his 5G Operator that he can get | | cloud-based rendering in the edge, promising latencies that makes | | the 3D objects _present_ and _interactive_. | | | | The 5G Operator permits to ingest popular 3D objects into the | | network and provides an improved rendering for their consumers. | | Parts of the objects may be static, others may be timed. In certain | | cases, even several objects may be rendered at the same time. | | | | Example: | | | | {width="4.75in" height="3.9166666666666665in"} | | | | https://docs.microso | | ft.com/en-us/azure/remote-rendering/overview/features/pbr-materials | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: AR, 3D** | | | | **Delivery: Split rendering, edge rendering** | | | | **Device: Phone, AR devices** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the UE, a 5G modem is available, an AR rendering and a depth | | camera is available. | | | | In the network, advanced rendering functionalities are available | | that are accessible with the 5GS and 5G Edge enablers and also a | | data storage to host complex 3D objects. | | | | An Application Service Provider supports network interfaces for | | ingesting popular 3D objects into the network. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | Potential new required capabilities of 5G Media Streaming System: | | | | 1. Fast uplink streaming of natural environments including | | protocols and formats to included depth and light conditions. | | | | 2. Discovery and establishment of photo-realistic rendering | | functionalities that can work with uplink camera information. | | | | 3. Fast Downlink streaming to support interaction with objects | | including new light conditions, etc. | | | | 4. Formats and protocols that allow post-processing to the latest | | pose | | | | Relevant KPIs: | | | | 5. Quality of rendered scene. | | | | 6. Immersiveness and presence of the scene. | | | | 7. Latency of each processing step. | | | | For many details, please refer to TR 26.928 [6]. | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Nominal Cost Analysis** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Benefits and Impact** | +----------------------------------------------------------------------+ | Potential Benefits and Impacts when running services within 5GMS | | network: | | | | Potential Benefits and Impacts when running services on the edge: | +----------------------------------------------------------------------+ | **Potential Technical Requirements** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
### 5.2.7 Media Services in the Edge
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | In the media production and distribution, the use of cloud services | | get more and more popular. Examples for standardized approaches are | | for example documented here: | | | | - https://www.fims.tv/, | | | | - https://tech.ebu.ch/groups/mcma | | | | - | | https://www.smpte.or | | g/microservices-media-and-entertainment-key-benefits-and-challenges | | | | These applications include Artificial Intelligence (AI) enabled | | services, such as: speech-to-text, automatic subtitling, | | translation, text-to-speech, face recognition and identification, | | emotion detection, speech-to-text evaluation, FFMPEG media | | transformation. | | | | Is there a benefit to provide some applications on the edge rather | | than the cloud? | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: 2D** | | | | **Delivery: Cloud and edge processing** | | | | **Device: phone, TV, tablet** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | Potential new required capabilities of 5G Media Streaming System: | | | | - Ingest | | | | - Distribution | | | | Relevant KPIs: | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | Potential new required capabilities of 5G Media Streaming System: | | | | Relevant KPIs: | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | See above links | +----------------------------------------------------------------------+ | **Nominal Cost Analysis** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Benefits and Impact** | +----------------------------------------------------------------------+ | Potential Benefits and Impacts when running services within 5GMS | | network: | | | | Potential Benefits and Impacts when running services on the edge: | +----------------------------------------------------------------------+ | **Potential Technical Requirements** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
### 5.2.8 Partial delivery of 3D content (point cloud, mesh) for AR/MR device
+----------------------------------------------------------------------+ | **Use Case Name** | +======================================================================+ | Partial delivery of 3D content (point cloud and mesh) for AR/MR | | device | +----------------------------------------------------------------------+ | **Description** | +----------------------------------------------------------------------+ | Service provider provides various types of contents to be overlaid | | over real environment for augmented reality experience. Certain 3D | | content is huge as the earth, which is called digital twin of past, | | current and future of the world. The content is live and | | continuously updated even though it is past. Therefore, delivering | | one entire content doesn't make any sense nor is it possible. In | | this case, a partial delivery of 3D content serves user's demand. | | | | For example, the user wants to travel overseas. The user can select | | places to stay and place to visit, then a digital twin of the hotel | | room with a view and sightseeing points will be partially delivered | | to the user. More practically, only the viewport can be delivered | | then rendered upon user's position and view direction. | | | | Another example is as follows. Certain 3D content has hundreds of | | millions of vertices and faces to provide the finest detail | | possible. For online catalogues of cars, selecting options to try a | | look and feel of each individual order is always enjoyable. User may | | hear engine sound and touch dashboard through the playback of such | | content. Since the level of details for rendering of the vertexes | | depends on a distance from user's viewpoint, proper level of density | | and the only vertexes related with the view can be delivered. The 3D | | content is encapsulated for the purpose, and MEC does the required | | post processing to generate partial view then encoding the content. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: AR, MR, VR, XR, 2D, 3D, Cloud Computing** | | | | **Delivery: Downlink, Interactive, Live streaming, On Demand | | Streaming, Conversational** | | | | **Device: Phone, HMD, Glasses, Laptop** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the content provider side, delivery or live streaming of 3D | | content are available. | | | | On the UE side, consumption of 3D content and reporting of relevant | | viewport information are available. | | | | On the network side, an MEC server is installed. Performing partial | | extraction, encapsulation and encoding of the 3D content are | | available. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | Potential requirements: | | | | 1. Real-time partial extraction and control level of details of 3D | | content | | | | 2. Point cloud and mesh encoding/decoding | | | | 3. UE viewport information report | | | | Relevant KPIs: | | | | 4. The number of voxels and faces per second for partial extraction | | | | 5. The number of voxels and faces per second for encoding | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Cost Analysis** | +----------------------------------------------------------------------+ | Similar with split rendering since position and direction of user's | | viewport would require different part of the 3D content. | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | 1. How to exchange UE viewport information in 3D space. | | | | 2. How to define and signal delivered part out of the total 3D | | content space. | | | | 3. How to measure MEC performance index of the partial extraction, | | and quality of level of details. | +----------------------------------------------------------------------+
## 5.3 Uplink Streaming Use Cases
### 5.3.1 Multi-Camera Uplink Stream Processing
+----------------------------------------------------------------------+ | **Description** | +----------------------------------------------------------------------+ | Some streaming services need multi-camera based scene capture and | | post-processing. | | | | For example, two fisheye lenses or multiple wide-angle lenses used | | in VR 360 video streaming service can derive 360Â° uplink video | | stream by using stitching algorithms implemented in the camera or | | servers located near the camera. As an extension, the edge node can | | optimize the multi-camera uplink streaming depending on the viewport | | of the predominant users or the device capabilities that are | | consuming the content or the number of users. For instance, it can | | save uplink bandwidth previously occupied by non-highlighted | | regions. | | | | Another example is free angle live streaming, in which an arc-shaped | | row of time-synchronized cameras are used to collect the images of | | an object from different perspectives. Through the composition | | algorithm of adjacent servers, the uplink live stream can be | | generated for downlink users to freely choose the viewing angle. | | | | Another one is telepresence using AR/MR device. Multiple cameras are | | deployed to collect several streams, based on which the 3D mesh or | | 3D point cloud generation algorithms are followed. These algorithms | | are expected to run on edge using its computing power to meet | | real-time requirements and keep synchronized. | | | | The following key steps are highlighted for both of these use cases: | | | | 1. A camera group is set up in correct position and connects to the | | network, and calibration configurations which describe the relative | | position relationship are sent to the edge. Each camera's exposure | | values are also sent. | | | | 2. Edge nodes set up multiple decoders and algorithms to deal with | | the uplink streams and output the processed result. | | | | Mainly there are two reasons supporting the edge node necessity in | | this use case: | | | | 1. VR 360 stitching, free angle video composition, and 3D | | mesh/point cloud producing algorithms need strong computing CPUs and | | GPUs rather than those integrated on mobile platforms. Put these | | servers on edge node instead of capture worksite can reduce space | | need and transportation costs, more importantly, give mobility to | | capture device thus clear motion limitations during application. | | | | 2. Multiple cameras bring multiple video streams to uplink network. | | Taking VR 360 stitching for example, an 8K VR camera rig (KANDAO | | Obsidian) mostly adopted in China Mobile's service uses 6 cameras to | | be stitched and each of them are 4K resolution. That means nearly 6 | | Ã— 25Mbps bandwidth is the minimum requirement. Cloud-based | | architecture feels difficult to provide stable connection to support | | this requirement compared to an edge node, and even if it can be | | guaranteed, longer network latency makes it difficult for streams to | | be synchronized under given time threshold, which are very important | | to all following steps. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: VR 360, free angle viewing,** | | | | **Delivery: Uplink, Live Streaming** | | | | **Device: Phone, HMD** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On devices, 5G connection ability should be installed, and a | | built-in or external time clock may be used to keep multiple streams | | to be synchronized. | | | | On the network side, multiple decoders and at least one encoder are | | needed to deal with media streams input and output. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | Requirements: | | | | 1. 5G connection ability on each camera. | | | | 2. Real-time multiple decoding and encoding instrument on edge. | | | | 3. High CPU/GPU computing ability need on edge server to process | | multiple streams. | | | | 4. Real-time Stitching Algorithms for multiple streams and Image | | processing. | | | | Relevant KPIs: | | | | 5. Steady uplink bandwidth more than _N_ Ã— _k_ Ã—(single stream bit | | rate). | | | | NOTE: N is the number of streams, and k is the parameter of bitrate | | to network bandwidth, usually can be set to 1.5 or 2. | | | | 6. Scalability of the solution with the increase of cameras and/or | | sessions. | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | For VR 360 streaming service, China Mobile has tested cloud-based | | stitching using 5G SA uplink with professional VR camera system. And | | there are also some mature business solutions existing, for example | | cloud stitching product provided by StreamboxVR. | | | | Here is the link of introduction and demo: | | https://www.streamboxvr.com/cloud_stitching/ | | | | Using a Ricoh Theta S 360 camera, together with Avenir Micro or | | Drone, pre-stitched streams can be sent to Streambox | | Cloud, and users can | | directly get a VR 360 live streaming service. | | | | For free angle live streaming service, China Mobile has made a live | | streaming application used in "The 2^nd^ Youth Games of the People's | | Republic of China", together with partners including ZTE and | | Qualcomm. It uses 5GS and Edge computing to realize free angle | | viewing of wrestling matches. | | | | The link of this demo is: https://www.iqiyi.com/v_19rtgqhknc.html | | | | Users can choose their view angle freely at any time during | | streaming service. | | | | {width="3.5208333333333335in" | | height="1.4652777777777777in"} | | | | {width="3.486111111111111in" | | height="1.4722222222222223in"} | | | | {width="3.4652777777777777in" | | height="1.4722222222222223in"} | | | | For telepresence service using AR/MR device, there are also many | | implementations. | | | | https://m.youtube.com/watch?v=4oJJN2eH6U0 | | | | {width="2.826388888888889in" | | height="1.3055555555555556in"} | | | | For stitching streams reflecting highlight regions as follows: | | | | {width="5.909722222222222in" | | height="1.2916666666666667in"} | +----------------------------------------------------------------------+ | **Cost Analysis** | +----------------------------------------------------------------------+ | This use case mainly provides uplink solutions, generated media | | streams are served to subsequent operators, thus the cost for | | downlink stage and user side does not belong to its costs. | | | | For the service itself, it needs to pay for multiple 5G | | modem-integrated cameras, edge computing hardware and software. | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | 1. Functionality on the edge node. | | | | 2. Data transfer between UE and edge node. | | | | NOTE: Other processing may be added. | +----------------------------------------------------------------------+
### 5.3.2 Cloud/Split Rendering of Immersive Live Events
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | In Use Case 3 in TR 26.928 [6], Annex A.4, streaming and | | consumption of a recorded highlight of basketball match is | | considered, being technology agnostic in a sense that rendering may | | be done in the device only or may be done completely or at least | | partially in the network. In this use case, the aforementioned | | scenario is extended to streaming of immersive live events and | | rendering is done at least partially in the network. | | | | The immersive live event may be a basketball match that is produced | | by highly-professional multi-camera arrays, possibly several 100s of | | them and the information is provided to a cloud-environment for | | pre-processing that data. | | | | The immersive 6DoF live media content is offered and shared with a | | remote audience for streaming access can place the remote audiences | | within the context of a scene and give them immersive experiences: | | | | 1. Controlling the orientation of the scene and view direction, | | i.e. a 6DoF pose. For example, when a remote participant with an XR | | display (e.g., HMD, AR glass) rotates his head, the XR display can | | extract the 6DoF pose and provides it to a remote rendering. | | | | 2. The content is at least partially pre-rendered in the network | | according to the latest pose provided from the user in order to | | minimize the traffic being sent on the downlink as well as to adjust | | the rendering to the device capabilities. In order to control the | | immersive latency requirements properly, rendering in the network | | needs to be timely close to the latest user pose -- justifying the | | usage of an edge node. | | | | 3. The edge nodes process the latest 6DoF pose, and generate a | | pre-rendered version of the live scene for the user's predicted | | pose. This pre-rendered viewport is encoded, sent and decoded at the | | remote device. The XR display can finally render the scene that he | | is currently watching based on the received viewport, possibly | | taking into account local pose corrections to achieve a full | | immersive experience. | | | | 4. In addition, the content may further be augmented with overlays, | | graphics or other data. The data may either be provided for all | | users or may be user-targeted. For example, the director overlays | | some value-added information (e.g., the real-time game scores, the | | sponsor\'s advertisements) on top of the scene and then distributes | | the rendered scene to the remote audiences. Especially, if the | | director can dynamically plant the wonderful slow slots or 3D | | animated models in a certain region of the scene (e.g., the lower | | right), a remote viewer can use his finger to zoom or rotate them to | | look. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: VR, AR, Edge Computing, GPU** | | | | **Delivery: Downlink, Live Streaming, Split Rendering** | | | | **Device: HMD, AR glass, Smartphone** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the device: | | | | - Application is installed that permits to consume the scene. | | | | - The application uses existing HW capabilities on the device, | | including A/V decoders, rendering functionalities as well as | | sensors. Inside-out Tracking is available. | | | | On the network: | | | | - Cloud computation capabilities are available to produce the | | content | | | | - Cloud/edge computation capabilities are available to properly | | pre-render and encode the content | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | QoS requirements: | | | | 1. Bit rates and latencies in the uplink are sufficient to provide | | an up-to-date pose to the cloud computation. | | | | 2. Bit rates and Latencies that are sufficient to render the | | viewport within the immersive limits. | | | | 3. Sufficient bandwidth to deliver multiple media streams, | | | | QoE requirements: | | | | 1. Fast reaction to manual controller information. | | | | 2. Reaction to head and limited body movement within immersive | | limits. | | | | 3. Seamless experiences when moving across positions. | | | | 4. Providing sufficient AV experience to enable _presence_. | | https://xinreality.com/wiki/Presence | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Cost Analysis** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
### 5.3.3 Pandemic Stadium
+----------------------------------------------------------------------+ | **Description** | +======================================================================+ | In an extension to the preceding Use Case "Cloud/Split Rendering of | | Immersive Live Events", the stadium is empty because of a pandemic, | | but the remote users want to interact with the live event, and even | | more, the teams and competitors in the stadium get aggregated | | feedback based on the reactions from the remote users in real time. | | | | Due to XR technologies, a remote audience can interact with both the | | main characters of live events and the other remote audiences to get | | more immersive experiences as followed: | | | | 1. Interacting with the other remote audiences who are | | geographically distributed. For example, when a remote audience with | | his friends who are in the virtual environment are watching the same | | concert, they are able to have voice conversation with each other. | | They can even cheer the main singer to the echo which can be fed | | back into the stadium. A network processing server can aggregate the | | voices from the remote audiences and reflect them to the stadium. | | | | 2. Interacting with the main characters of live events (e.g., the | | signer in the concert) remotely. For example, if a remote audience | | with a mobile device (e.g., a tablet or smartphone) virtually | | watching the concert where there is a 3D body model of the singer on | | the top of the scene, he can apply a selected set of 2D/3D AR | | effects to this 3D body model. He is also able to select his | | reconstructed 3D model which can reflect his body movements and | | overlay it to the scene. It looks like he is with the main singer | | together. Furthermore, a cloud processing entity can distribute the | | rendered scene including the two 3D models to the other remote | | audiences. | | | | 3. In the cases documented above, latencies are critical in order | | to provide a "presence" feeling for both the audience and the | | actors/players. | | | | The use cases are the extensions to those discussed in clause 5.3.1, | | the media rendering procedures are similar to these ones described | | in clause 5.3.1. | +----------------------------------------------------------------------+ | **Categorization** | +----------------------------------------------------------------------+ | **Type: AR, VR, MR, Edge Computing, GPU, Social Interaction** | | | | **Delivery: Downlink, Live Streaming, Interactive, Split rendering** | | | | **Device: HMD, Glasses, smartphones** | +----------------------------------------------------------------------+ | **Preconditions** | +----------------------------------------------------------------------+ | On the device: | | | | 1. Application is installed that permits to consume the event and | | participate in the event. | | | | 2. The application uses existing hardware capabilities on the | | device, including A/V encoders and decoders, rendering | | functionalities as well as sensors. | | | | On the network: | | | | 3. Cloud computation capabilities are available to aggregate the | | user input. | | | | 4. Cloud/edge computation capabilities are available to render. | | | | At the live event: | | | | 5. Recording and playout functionalities to sense the remote | | audience. | +----------------------------------------------------------------------+ | **Requirements in terms of Capabilities and QoS/QoE Considerations** | +----------------------------------------------------------------------+ | QoS: | | | | 1. Bit rates and latencies in the uplink are sufficient to provide | | user interaction to the cloud computation. | | | | 2. Bit rates and latencies that are sufficient to render the | | viewport within the immersive limits. | | | | 3. Sufficient bandwidth to deliver multiple media streams. | | | | 4. Sufficiently low latencies end-to-end to provide a sense of | | presence. | | | | QoE: | | | | 5. Providing sufficient AV experience to enable _presence_. | | https://xinreality.com/wiki/Presence | | | | 6. Latencies low enough to provide a sense of crowd-reaction | | remote. | | | | 7. Synchronization of user voice communication with the | | corresponding actions. | +----------------------------------------------------------------------+ | **Feasibility and Industry Practices** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Cost Analysis** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+ | **Potential Standardization Status and Needs** | +----------------------------------------------------------------------+ | | +----------------------------------------------------------------------+
## 5.4 Analysis of Use Cases
### 5.4.1 Summary
Table 6 below summarises the key facets of the Use Cases presented in the
preceding subclauses as they relate to edge-enabled 5G Media Streaming.
\- The clauses in the present document where the Use Case description can be
found, where the Use Case is analysed and where a call flow for the Use Case
can be found are provided in the second, third and fourth columns of the table
respectively.
\- The party responsible for provisioning the Edge Application Server (EAS) is
characterised in the fifth column of the table as either the **5GMS-Aware
Application** ("Application"), following the generic call flow in clause
6.3.2, or the **5GMS Application Provider** ("Application Provider"),
following the generic call flow in clause 6.3.3.
\- The set of 5G Media Streaming features potentially relevant to the Use Case
is indicated in the last six columns.
NOTE: A particular realisation of a Use Case may not necessarily exploit all
indicated features.
Table 6: Summary analysis of Use Cases
Use Case | Description clause | Analysis clause | Call flow clause | 
> EAS provisioning party
| Relevant 5GMS features |  |  |  |  |   
---|---|---|---|---|---|---|---|---|---|---  
|  |  |  |  | 
> Content preparation
|
> Content hosting
|
> Consumtpion reporting
|
> Metrics reporting
|
> Dynamic policy
|
> Network assistance  
Use Cases requiring only downlink media streaming |  |  |  |  |  |  |  |  |  |   
Caching downlink streaming content | 5.2.1 | 5.4.2.1 |  | Application Provider | N | Y | Y | Y | Y |   
Split rendering | 5.2.2 | 5.4.2.2 | B.1 | Application | N? | Y? | Y | Y | Y? |   
Generalized split and cloud rendering and processing | 5.2.5 | 5.4.2.3 |  | ? |  |  |  |  |  |   
Cloud/split rendering of immersive live events | 5.3.2 | 5.4.2.4 |  | ? |  |  |  |  |  |   
Pandemic stadium | 5.3.3 | 5.4.2.5 |  | ? |  |  |  |  |  |   
Media services in the edge | 5.2.7 | 5.4.2.6 |  | ? | ? | ? | ? | ? | ? |   
Use Cases requiring only uplink media streaming |  |  |  |  |  |  |  |  |  |   
|  |  |  |  |  |  |  |  |  |   
Use Cases requiring both uplink and downlink media streaming |  |  |  |  |  |  |  |  |  |   
User-generated live streaming | 5.2.3 | 5.4.4.1 |  | Application | Y | Y | Y | Y | Y |   
Augmented video streaming | 5.2.4 | 5.4.4.2 |  | ? | Y | Y | Y | Y | Y |   
Photo-realistic AR rendering in network | 5.2.6 | 5.4.4.3 |  | ? |  |  |  |  |  |   
Partial delivery of 3D content (point cloud, mesh) for AR/MR device | 5.2.8 | 5.4.4.4 |  | ? |  |  |  |  |  |   
Multi-camera uplink stream processing | 5.3.1 | 5.4.4.5 |  | ? |  |  |  |  |  |   
The detailed analysis of the Use Cases in the following subclauses considers
whether and how each Use Case could potentially be realised using a
combination of 5G Media Streaming supported by edge processing.
### 5.4.2 Use Cases requiring only downlink media streaming
#### 5.4.2.1 Caching downlink streaming content
Edge caching of downlink media streaming is a close match for the existing
content hosting feature already specified in TS 26.512 [7]. As in the case of
centralised content hosting, clients may make use of dynamic policies and
network assistance to request a network Quality of Service to sustain the
desired end user Quality of Experience. Both consumption reporting and metrics
reporting remain in scope.
The main additional requirement is to specify that the 5GMS AS can be
instantiated in the Edge DN at the point of provisioning. Traffic steering is
expected to take advantage of whichever of the DNS-based solutions studied by
SA2 (see clause 4.3.2) is finally standardised.
Mapping this required feature set to the SA6 edge architecture summarised in
clause 4.2, the edge cache is realised as an instance of the EAS type "5GMSd
AS" offering the generic EAS feature "5GMS content hosting". When the content
hosting feature is provisioned at M1d, the 5GMS AF needs to
discover/instantiate an EAS of this type offering this feature and ensure it
is both correctly configured (via M3d) and correctly registered in the EES
database (via EDGEâ€‘3). In addition, the 5GMS AF/EES needs to continuously
monitor the load on the EAS instances it is managing (via EDGEâ€‘3) and expand
or contract the resources assigned to downlink media streaming according to
the level of client demand experienced at M4d.
#### 5.4.2.2 Split rendering
The split rendering use case covers scenarios where heavy graphics rendering
is performed at the edge with low latency. The end device receives a pre-
rendered representation of the viewport and may run some pose correction (e.g.
Asynchronous Time Warp) to adjust the view to the current user's viewport.
The real-time graphics rendering aspects of this Use Case are provided by an
XR Server running as an EAS instance at the network edge. These application-
specific aspects lie outside the scope of 5G Media Streaming.
1\. Whether 5GMS uplink streaming is used to supply UE pose data to the XR
Server is for study in TR 26.998 [7].
2\. The XR Server application is likely to be too complex to be described in a
generic Content Preparation Template, so the content preparation feature is
not required in this Use Case.
3\. The rendered results are bespoke for an individual UE, based on individual
pose data, and so a more sophisticated 5GMS content hosting configuration is
needed to describe unique downlink media distribution from the 5GMSd AS edge
instance to each 5GMSd Client via M4.
NOTE: If the required distribution media format is application-specific, it
may not be possible to use the 5GMS content hosting feature at all.
4\. Usage reporting is closely tied to the content hosting feature, so is only
relevant if the latter is also used.
5\. Metrics reporting remains relevant.
6\. Dynamic policies may be useful in assuring the network Quality of
Experience needed to support the desired end user Quality of Experience.
Mapping this required feature set to the SA6 edge architecture summarised in
clause 4.2, the XR Server could be realised as an instance of the EAS type
"5GMSd AS" offering the generic "XR Split Rendering" EAS feature, potentially
distinguished by some additional application-specific EAS feature name.
If 5GMS downlink media streaming is used to stream the rendered media to a
5GMS Client in the UE, each such client of the XR Server needs its own content
hosting configuration to be provisioned in the 5GMSd AS. Since it is not
possible for the 5GMS Application Provider to provision each individual
content hosting configuration, this responsibility may fall to the 5GMSd AF at
M3d.
#### 5.4.2.3 Generalized split and cloud rendering and processing
From the perspective of the study, this is similar to the Use Case on Split
Rendering analysed in the preceding clause.
#### 5.4.2.4 Cloud/split rendering of immersive live events
From the perspective of the study, this is similar to the Use Cases on Split
Rendering analysed in the preceding clauses.
#### 5.4.2.5 Pandemic stadium
From the perspective of the study, this is similar to the Use Cases on Split
Rendering analysed in the preceding clauses.
#### 5.4.2.6 Media services in the edge
Not enough detail is provided in this Use Case to enable detailed analysis of
potential requirements.
### 5.4.3 Use Cases requiring only uplink media streaming
No Use Cases requiring only uplink media streaming are documented in the
study.
### 5.4.4 Use Cases requiring both uplink and downlink media streaming
#### 5.4.4.1 User-generated live streaming
NOTE: Detailed analysis of this Use Case is the subject of a study in TS
26.804 [8].
The content preparation requirements for re-encoding user-generated content
seem a good candidate for realisation as an additional 5G Media Streaming
feature in a generic 5GMS AS edge instance. This transcoding feature will need
to be supported by a suitable transcoding configuration to specify the desired
content preparation manipulations, such as:
+----------------+----------------+----------------+----------------+ | Content | Content | Ch | | | preparation | preparation | aracterisation | | | step | activities | | | +================+================+================+================+ | 1. | Pre-processing | Video | Generic | | | of uplinked | upscaling | | | | media | | | | | | Light | | | | | correction in | | | | | video | | | | | | | | | | Image | | | | | stablisation | | | | | of video | | +----------------+----------------+----------------+----------------+ | 2. | Content | Audio dubbing | Applic | | | augmentation | | ation-specific | | | | Captioning | | +----------------+----------------+----------------+----------------+ | 3. | Distribution | Specification | Generic | | | configuration | of media | | | | for downlink | packaging | | | | media | format(s) | | | | streaming | | | | | | Specification | | | | | of bit rate | | | | | encoding | | | | | ladder | | +----------------+----------------+----------------+----------------+
Many of the content preparation tasks listed above are generic and could
therefore be provisioned in a standard content transcoding configuration.
However, some of the tasks (e.g. content augmentation in step 2 above) seem
more application-specific and may require vendor-specific configuration.
Therefore, the Content Preparation Template, in addition to supporting generic
functions, should either support the configuration of vendor-specific
functions, or else define a mechanism for vendors to add their own extensions
to the generic Content Preparation Template.
#### 5.4.4.2 Augmented video streaming
The content preparation requirements in this Use Case envisage the use of
Artificial Intelligence to process uplink video prior to downlink media
streaming. Because this Use Case involves downlink media streaming to a single
user based on unique video capture from the UE, a separate 5GMSd AS content
hosting configuration needs to be provisioned for each end user in a similar
manner to that described in clause 5.4.2.2 above for the Split rendering Use
Case.
#### 5.4.4.3 Photo-realistic AR rendering in network
This is similar to the "Augmented video streaming" Use Case analysed in the
preceding clause.
#### 5.4.4.4 Partial delivery of 3D content (point cloud, mesh) for AR/MR
device
This Use Case is similar to the augmented reality Use Cases described in the
preceding clauses.
The element of uplink streaming essential to augmented/mixed reality is
missing from the Use Case description, so no further analysis is possible.
#### 5.4.4.5 Multi-camera uplink stream processing
The main requirement in this Use Case is to stitch together video feeds from
multiple live camera sources. The realisation is therefore an EAS instance of
type "5GMSu AS" that provides a "VR 360" stitching feature. This could
potentially be standardised as a generic content processing feature, or it
could be implemented as an application-specific EAS that also makes use of M4u
uplink media streaming.
The Use Case lacks a description of the downlink media streaming envisaged for
distributing the result of the video stitctching, so no further analysis is
possible.
# 6 Potential 5GMS Architecture Extensions
## 6.1 General
Editor's Note: This clause will document the identified gaps. Identified gaps
may go beyond the scope of the SA4 work, in which case the responsible groups
will be contacted.
Editor's Note: The potential extensions are mainly based on the identified
relevant use cases in section 5.
## 6.2 EMSA Architecture
The EMSA architecture is an integration of the 5GMS architecture, the SA6 Edge
architecture and the SA5 management architecture. The EMSA architecture is
depicted in the following figure:
{width="6.71875in" height="4.760416666666667in"}
Figure 8: Reference edge-enabled 5GMS media architecture
The above architecture demonstrates how the edge-enabled 5GMS media
architecture leverages the edge functionality and architectural elements
specified in TS 23.558 [3]. In this illustration, the EEC, EES, and EAS are
shown as parts of the MSH, 5GMS AF, and 5GMS AS, respectively.
This architecture implies the following:
1\. A Media Session Handler (MSH) that is edge-enabled is required to
implement the EDGE-5 API.
2\. A 5GMS AF that is edge-enabled is required to support EES functionality
including:
\- EDGE-3 API towards the EAS function of 5GMS AS instances.
\- EDGE-6 API for registering with an ECS function.
\- EDGE-9 API for media session relocation.
\- EDGE-1 API for supporting registration and provisioning of EEC functions,
and discovery by them of EAS instances.
3\. A 5GMS AF that is edge-enabled may perform compute resource allocation
using the MnS-C interface.
4\. A 5GMS AS that is edge-enabled is required to support EAS functionality
including EDGE-3 API.
In general, in order to deploy edge support for the 5GMS application, each
5GMS function has to become edge-enabled and a union of each 5GMS function
with its corresponding edge function (MSH + EEC, AF + EES, AS + EAS) would
satisfy the requirements. In this regard, various deployment scenarios
including the standalone existence of the edge functions can be considered.
NOTE: Examples of the different deployment scenarios are given in Annex A.
This edge-enabled 5G media streaming architecture supports both client-driven
as well as AP-driven management of the edge processing session.
In the client-driven approach, the 5GMS-Aware Application is aware of the
support of edge processing in the network and takes steps, such as using the
EDGE-5 APIs, to discover and locate an application server in the edge DN.
In Application Provider (AP)-driven approach, the 5GMS Application Provider
provisions 5GMS features as normal within the scope of an M1 Provisioning
Session, but additionally requests the 5GMS System to accommodate the
provisioned features using edge computational resources, where appropriate.
The 5GSMS AF acts on behalf of the 5GMS Application Provider to allocate
processing resources based on the application's needs. In order for this
transparent resolution to work, SA2 is expected to define a solution to allow
the AF to influence the DNS resolution for the domain name(s) related to the
media distribution by the Application Provider as described in clause 4.3.2.
## 6.3 Generic Call Flows for Media Session Establishment
### 6.3.1 General
Two generic call flow for edge-enabled 5G media streaming session
establishment are demonstrated below.
### 6.3.2 Client-driven edge discovery
Figure 9 outlines a detailed call flow for client-driven session
establishment.
Figure 9: Client-driven session establishment
The **Edge Computing Provisioning** phase is a provisioning phase, that may be
repeated several times (e.g. to extend edge processing coverage to new
geographical areas or to increase the capacity of an already provisioned
area). All steps in this phase are optional and performed on need basis. The
steps are:
1\. **Spawn ECS:** In this step, a new ECS is instantiated to manage new or
increased demand for edge processing.
2\. **Spawn 5GMS AF:** In this step, a new 5GMS AF that is edge-enabled is
instantiated to handle new or increased demand for media sessions with edge
processing.
3\. **EES Configuration:** The EES is configured for a specific Edge Data
Network.
4\. **EES Registration with ECS:** The EES registers with the ECS that is in
authority over the target EDN.
The **5GMS Application Provider Provisioning** phase is performed prior to the
establishment of any related media streaming sessions by the 5GMS Application
Provider. Subsequent updates to the provisioning session are possible.
5\. **Create Provisioning Session:** In this step, the 5GMS Application
Provider creates a new provisioning session.
6\. **Provision 5GMS features:** In this step, the 5GMS Application Provider
may create different configurations such as Content Hosting, Reporting, Edge
Processing, etc.
During the **UE Edge Computing Discovery** phase, the UE discovers an EAS
instance offering 5GMS AS functionality.
7\. **Application Initialization:** The user launches the 5GMS-Aware
Application. The application performs any required initialization steps.
8\. **Locate EAS/5GMS AS:** The Application Client requests the location of
one or more suitable EAS instances offering the **\"** 5GMS AS**\"**
capability that are able to serve the application.
9\. **Locate local EES:** The EEC queries the ECS for a suitable EES.10.
Register with EES: The EEC registers with the selected EES.
**10\. Register with EES:** The EEC registers with the selected EES.
11\. **Request list of \"5GMS AS\" EAS instances:** The EEC contacts the EES
to query for one or more EAS instances offering the **\"** 5GMS AS**\"**
capability that can serve the session, using EAS discovery filters (see Table
8.5.4.2-2 in TS 23.558 [3]) provided by the Application Client, e.g. "5GMS AS"
for EAS type, appropriate values for service feature(s), and other EAS
characteristics.
The optional sub-flow is for provisioning an additional 5GMS AS instance if a
suitable EAS instance offering the **\"** 5GMS AS**\"** capability cannot be
located. The steps are:
12\. **Check resource template:** The 5GMS AF checks the provisioned edge
processing resource template for the related application to determine the
requirements of the application.
13\. **Instantiate new EAS/5MGS AS:** The 5GMS AF requests the MnS to
instantiate a new **\"** 5GMS AS**\"** EAS instance with the specified
requirements and considering parameters provided in the query by the EEC.
14\. **Spawn 5GMS AS instance:** The MnS creates a new instance of the EAS
offering **\"** 5GMS AS**\"** capability with the requested placement and
resources.
15\. **EAS configuration:** The newly instantiated **\"** 5GMS AS**\"** EAS
instance is configured.
16\. **Register EAS with EES:** The newly instantiated EAS instance registers
itself with the triggering EES.
17\. **Configure provisioned features:** This may include configuring and
launching the server-side application in the 5GMS AS.
Completion of UE Edge Computing Discovery phase:
18\. **List of suitable "5GMS AS" EAS instances:** The EES/5GMS AF responds to
the EEC with a list of "5GMS AS" EAS instances and their characteristics in an
EAS discovery response (see Table 8.5.3.3-1 in TS 23.558 [3]).
19\. **Select preferred "5GMS AS" EAS instance:** The AC and/or EC select(s) a
"5GMS AS" EAS instance from the provided list, based on the AC's desired
criteria.
After successful discovery of a "5GMS AS" EAS instance, the actual streaming
session may start in the **5GMS Session** phase:
20\. **Start session:** The 5GMS-Aware Application invokes the Media Streamer
with appropriate streaming access parameters (e.g. a Media Player Entry such
as a DASH MPD URL).
21\. **Session starting event:** The application informs the Media Session
Handler about the start of a new 5GMS session.
22\. **Retrieve service access information:** The Media Session Handler
retrieves Service Access Information from the 5GMS AF appropriate to the 5GMS
session.
23\. **Media transfer:** The 5GMS-Aware Application connects to the selected
EAS **\"** 5GMS AS**\"** and the streaming starts.
24\. **Method calls and notifications:** Supporting information about the 5GMS
session is passed from the Media Stream Handler to the Media Session Handler.
25\. **Reporting, network assistance, and dynamic policy:** The Media Session
Handler exchanges supporting information about the 5GMS session with the 5GMS
AF.
26\. **End session:** the 5GMS-Aware Application informs the Media Session
Handler that the 5GMS session has ended.
27\. **Session ending event:** The Media Streamer informs the Media Session
Handler about the end of the 5GMS session.
28\. **Final reporting:** The Media Session Handler performs any final
reporting to the 5GMS AF.
### 6.3.3 AP-driven management of 5GMS edge processing
Figure 10 outlines a detailed call flow for the AP-driven management of edge
processing. In the previous sequence, the optional provisioning of an
additional 5GMS AS instance occurs in response to an explicit call from the
Application Client to an on-board EEC, whereas in this sequence it occurs, if
needed, as part of and in response to Application Provider provisioning. It
may also be repeated at any time during the lifetime of the 5GMS Provisioning
Session in response to satisfy demand levels (not illustrated for brevity).
Figure 10: AP-driven management of 5GMS edge processing
The **Edge Computing Provisioning** phase is a provisioning phase, that may be
repeated several times (e.g. to extend edge processing coverage to new
geographical areas or to increase the capacity of an already provisioned
area). All steps in this phase are optional and performed on need basis. Steps
1--4 are identical to those described in clause 6.3.2 above.
The **5GMS Application Provider Provisioning** phase is performed prior to the
establishment of any related media streaming sessions by the 5GMS Application
Provider. Subsequent updates to the provisioning session are possible. Steps 5
--6 are identical to those described in clause 6.3.2 above.
The optional sub-flow to provision an additional 5GMS AS instance may be
repeated multiple times on need basis to add new capacity or to increase
existing capacity for edge processing. The edge processing capacity is
tailored for the specific 5GMS Application Provider based on the information
in the Provisioning Session. Steps 7--12 are identical to steps 11--16
described in clause 6.3.2 above.
After successful discovery, the actual streaming session may start in the 5GMS
Session phase. Steps 13--21 are identical to steps 19--27 described in clause
6.3.2 above.
NOTE: In this call flow, the Application Client (AC) and EEC are not used to
discover the 5GMS AS location. Instead, a Media Player Entry may be provided
to the Media Session Handler by the 5GMS AF in the Service Access Information
at M5 (step 15), or otherwise the location of the 5GMS AS is provided directly
to the 5GMS-Aware Application via (out of scope) interface M8.
### 6.3.4 Application Context Relocation for EAS instances
#### 6.3.4.1 General
There are generally two types of Application Context Relocation (ACR)
procedure depending on whether the Target EAS is instantiated in the same Data
Network (DN) as the Source EAS, or in a different DN:
1\. _ACR to a different DN:_ A relocation forced by a change to the DNAI. This
may be triggered by mobility of the UE, for instance. In this case, the DNN
and S-NSSAI are expected to be different for the target EAS instance. The PDU
session will have a different PDU Session Anchor for each DN as shown in
figure 11 below.
2\. _ACR within the same DN:_ A relocation within the same DN is requested,
e.g. by the AF or application, e.g. for load-balancing or to satisfy latency
requirements.
Figure 11: Application Context Relocation to a different Data Network
The following mechanisms may be used to support ACR to a different DN:
1\. Subscription to events related to the PDU session.
2\. Traffic influence through _Nsmf_EventExposure_AppRelocationInfo_ or
_Nnef_TrafficInfluence_AppRelocationInfo_.
3\. _IP address replacement:_ The AF may request that the UPF performs address
translation, replacing the IP address and port number of the Source EAS with
that of the Target EAS.
4\. _PSA buffering:_ The AF may request that data from the old PDU Session
Anchor (PSA) be buffered and forwarded to the new PSA prior to forwarding any
other data.
The AF (in the context of the present document, the 5GMS AF) is expected to
expose ACR event notifications to EAS instances as described in clause 8.6.3
of TS 23.558 [3]. The relocation of the EEC context between the Source EES and
the Target EES is described in clause 8.9.1.4 of [3].
Applications may be categorized into the following classes with regards to
ACR:
1\. _Relocation is transparent to the application:_ These applications
typically do not rely on the EAS maintaining context for the application.
For example, media streaming applications using HTTP expect transactional
processing per request, and subsequent requests may be processed by a
different EAS instance without reference to previous requests.
2\. _Relocation is tolerated by the application with relatively low
complexity:_ These applications typically require maintaining some session
state at the EAS. The application may tolerate interruptions or delays during
the relocation of the application context.
Examples are media applications that perform video processing tasks to create
AR overlays, or game spectator applications.
3\. _Relocation is disruptive to the application:_ These applications require
maintaining complex session state and rely on low-latency operation. A
decision on relocating these applications has to be carefully considered and
only performed on absolute need basis.
Examples are split rendering applications such as online gaming.
The AF is able through traffic influencing to indicate if an EAS instance may
be relocated or not. It is also able to select the set of tools that are
suitable to support relocation of application context for a particular EAS
instance. In the case of 5G Media Streaming, this configuration information
could be provided to the 5GMS AF through its M1 provisioning interface.
A representative selection of the EAS relocation scenarios summarised in
figure 11 may be further elaborated in the context of 5G Media Streaming, as
detailed in the following clauses.
#### 6.3.4.2 Scenario 1: EAS relocation decided by EEC
For the typical EAS relocation Scenario 1, a UE moves to a new location which
is outside the service area of the serving EAS. The EEC in this scenario
realizes that its location has changed and decides to initiate the EAS
relocation procedure to a more appropriate target EAS instance, including the
detection, decision and execution roles.
The detailed call flow in this scenario can be briefly detailed as shown in
figure 12 below:
Figure 12: Detailed call flow breakdown for EAS relocation Scenario 1
It is assumed that Edge Computing resources to support 5G Media Streaming have
already been provisioned, as described in clause 6.3.2.
It is assumed that 5G Media Streaming features have already been provisioned,
as described in clause 6.3.2.
The detailed breakdown of steps for this scenario is:
1\. The EEC detects UE mobility to a new location outside the service area of
the current EAS which may need an application context transfer.
2\. The EEC determines that EAS relocation is needed.
3\. The EEC initiates a Service Provisioning request (including details of the
application and the new UE location) with the ECS.
4\. The ECS derives a list of Target EES instances that are relevant to the
application indicated in the previous step and the new UE location.
5\. The ECS returns a Service Provisioning response to the EEC with a list of
candidate provisioned Target EES instances.
NOTE: Whether the ECS returns one or more Target EES instances is
implementation-dependent.
6\. The EEC performs EAS discovery by querying the Target EES instance.
NOTE: How the AC and/or EEC select the Target EES instance from multiple
candidates is implementation-dependent.
7\. The Target EES checks whether the EEC is authorized to discover the
requested EAS class and compiles a list of suitable candidate Target EAS
instance(s) via the EAS discovery filter mechanism and/or based on the UE
location.
8\. The EEC receives the EAS discovery response with one or multiple suitable
candidate Target EAS instance(s).
9\. If multiple candidate Target EAS instances were received in the EAS
discovery response, the AC and/or EEC select one.
NOTE: How the AC and/or EEC select the Target EAS instance from multiple
candidates is implementation-dependent.
10\. The EEC may send an Application Context Relocation request to the Source
EES with an ACR action included, e.g. influence application traffic between
the UE and the chosen Target EAS.
11\. The EES applies the AF traffic influence using the N6 routing information
of the target EAS instance in the 3GPP CN as described in clause 4.3.6 of TS
23.502 [10].
12\. The Source EES responds to the EEC's request with an Application Context
Relocation response message.
13\. The AC is triggered by the EEC to start the application context transfer
from the Source EAS instance to the Target EAS instance.
NOTE: Whether and how the AC initiates the application context transfer is
outside the scope of TS 23.558 [3].
14\. All required entities perform clean-up.
## 6.4 Identified Gaps in Architecture and Procedures
### 6.4.1 General
Based on the recommended EMSA architecture in clause 6.2 and the high-level
call flows defined in clause 6.3, we can identify the following gaps in the
existing 5GMS architecture:
**Gap 1** The procedures and services offered by the 5GMS AF and the 5GMS
Client need to be defined.
**Gap 2** Extensions to the M1 and M5 interfaces are required to provide
additional procedures for provisioning and edge processing request.
**Gap 3** Definition of the M3 interface between the 5GMS AF and 5GMS AS to
manage edge processing.
**Gap 4** Procedures in the 5GMS client and interactions with the application
in the UE to discover and select an appropriate EAS/5GMS AS for the media
processing needs of the application are only partially supported.
**Gap 5** Procedures to support session mobility and context transfer,
triggered by the UE or by the 5GMS AF. In particular, the application and
media-specific aspects of the Application Context Relocation would need to be
specified. Also, EAS relocation scenarios, conditions and triggers for such
relocation based on use cases documented in this TR and in TR 26.998.
**Gap 6** Definition of 5GMS AF context and procedures for 5GMS AF context
transfer need further study.
### 6.4.2 Justification of Identified Gaps
#### 6.4.2.1 Gaps in client-driven edge discovery
The following provides a reference to the gaps and the corresponding procedure
step in the call flow at clause 6.3.2:
1\. Gap 2: In step 12, "The 5GMS AF checks the provisioned edge processing
resource template for the related application to determine the requirements of
the application.".
How the EES embedded in the 5GMS AF gains access to the edge processing
resource template needs to be investigated, and whether M1 supports providing
this template during step 6 "Provision 5GMS features". Otherwise, the API that
the 5GMS AF uses to access this template needs to be identified and possibly
defined.
2\. Gap 4: In steps 18 and 19, if more than one EAS is expected to be provided
in the response, then one of the actors in the system needs to select the best
one.
This process is not defined. For example, if the 5GMS AF selects the best EAS
based on the template provided by the Application Provider during the
"Provision 5GMS features" step, and based on EAS discovery filters provided by
EEC, then this process must be indicated and required by "5GMS AF/EEC".
#### 6.4.2.2 Gaps in AP-driven management of 5GMS edge processing
The following provides a reference to the gaps and the corresponding procedure
step in the call flow at clause 6.3.3:
1\. Gap 2: In step 6, "Provision 5GMS features", the desired characteristics
of the EAS, such as geographical service area, service continuity support, and
service features (as indicated in the EAS discovery filter supplied by the
Application in the client-driven call flow) must be signalled to the 5GMS AF.
It is not clear whether an API and/or resource for such signalling is
supported by M1 in TS 26.512 [7].
#### 6.4.2.3 Gaps in Application Context Relocation
The following provides a reference to the gaps related to application context
relocation:
1\. Gap 5: different media applications may have different complexity and
needs when handling context relocation. The AF may restrict the allowed
relocation based on provisioning. The information that constitutes the
application context needs to be identified and means to exchange that
information need to be provided.
2\. Gap 6: context relocation may require transfer of the control session to a
new AF/EES.
# 7 Conclusions and Recommendations
Edge media processing is an enabler for a variety of immersive media streaming
services, such AR/MR and cloud gaming, which require stringent QoS guarantees
to operate properly. The 5GMS architecture has been developed to support media
streaming services by leveraging 5G System functionality to optimize the
streaming experience. Extensions to the 5GMS architecture are necessary to
leverage 5G edge computing capabilities and integrate them into media
streaming workflows.
The present document provides an overview of the different edge-related
activities that are taking place in 3GPP. It also collects together a set of
media streaming use cases that rely on or benefit from media processing at the
edge. Based on these, a recommended architecture for edge media processing is
derived and documented. The architecture is an integration of the 5G Media
Streaming architecture with the architectures and procedures for
establishment, control, and management of edge computing sessions that have
been developed elsewhere in 3GPP.
It is recommended that normative work be initiated with the following
objectives:
1\. Extend the 5GMS Architecture to support edge media processing according to
the recommended architecture in clause 6.2.
2\. Enhance the procedures and services that are offered by the 5GMS AF and
the 5GMS Client to enable establishment and management of media streaming
session with edge processing.
3\. Extend the M1 interface to support the provisioning of edge media
processing.
4\. Extend the M5 interface to support discovery and request of edge media
processing resources.
5\. Define the M3 interface between the 5GMS AF and 5GMS AS to manage edge
processing resources and sessions.
6\. Specify media and application context relocation information based on the
Application Context Relocation procedures for session continuity in edge media
processing, relocation scenarios, and conditions and triggers for relocation.
###### ## Annex A: Deployment Scenarios
# A.1 Deployment Scenario Option A
In one possible deployment option, the 5GMS functions and the SA6 MEC
functions are co-located together and the 5GMS functions would be special
instantiations of the corresponding SA6 MEC functions.
{width="6.65625in" height="3.0729166666666665in"}
Figure 13: Potential deployment architecture option A
5GMS entities in the media function layer runs over the top of the SA6 MEC
entities in the general function layer. Some parameter exchanges between these
layers may be needed to trigger or receive the outcome of Edge-related
procedures, i.e. the service provisioning, registration, EAS discovery,
Service Continuity. For instance, during the EAS relocation procedure, the EES
may help to find the target EAS instance and also to provide the selected
target AS instance to the media function layer.
# A.2 Deployment Scenario Option B
{width="6.645833333333333in" height="3.0in"}
Figure 14: Potential deployment architecture option B
The 5GMS functions and SA6 MEC functions are co-located and the SA6 MEC
functions are realized inside the 5GMS functions. This means that the 5GMS
functions also realize the SA6 MEC functionalities to enable the edge-based
5GMS service, including the necessary edge server management functionalities,
like registration, service provisioning, EAS discovery, etc.
###### ## Annex B: Selected Use Case Mapping
# B.1 Split Rendering
The split rendering use case covers scenarios where heavy graphics rendering
is performed at the edge with low latency. The device receives a pre-rendered
representation of the viewport and may run some pose correction (e.g.
Asynchronous Time Warp) to adjust the view to the current user's viewport.
The use case realization can be roughly described by the following
walkthrough:
1\. An XR Device connects to the network and connects to an XR application,
a. Sends static device information and capabilities (supported decoders,
viewport),
2\. Based on this information, the XR server sets up encoders and formats,
3\. Loop:
a. XR Device collects XR pose (or a predicted XR pose).
b. XR Pose is sent to XR Server.
c. The XR Server uses the pose to pre-render the XR viewport.
d. XR Viewport is encoded with 2D media encoders.
e. The compressed media is sent to XR device along with XR pose that it was
rendered for.
f. The XR device decompresses video.
g. The XR device uses the XR pose provided with the video frame and the actual
XR pose for an improved prediction using and to correct the local pose, e.g.
using Asynchronous Time Warp.
Steps 1 and 2 relate to the session setup. Step 3 is about the operation of
the service. Due to the nature of this use case, it is believed that the UE-
management session establishment and control is more appropriate. The
application is fully aware that the bulk of the rendering is to be performed
on the edge with low latency and as such will request the necessary resources
and the establishment of the edge session.
A break down of steps 1 and 2 is given to provide call flows for the session
setup. In this call flow, it is assumed that the Application Provider
provisions the 5GMSd AF with the processing configuration and resource needs
prior to session setup. The EEC in the Media Session Handler discovers the EAS
according to the client-driven discovery call flow documented in clause 6.3.2.
The 5GMSd AF is responsible for allocating the actual resources using the MnS
function, when an actual session is started.
The client-driven edge discovery call flow is used as a basis. The provided
call flow is a condensed version of that call flow. Other variations of this
walkthrough may be possible.
Figure 15: Call Flow for Split Rendering
The steps are provided here in detail:
1\. The provisioning step allows the Application Provider to configure
required resources for its application sessions.
a. The Application Provider sends a request to the 5GMS AF to create a new
Provisioning Session.
b. The 5GMS AF creates QoS and Compute resource templates. It may use services
offered by the MnS-C and PCF.
2\. The 5GMS-Aware Application is started on the UE, and it connects to the
Application Provider to create a new application session.
3\. The 5GMS-Aware Application informs the Media Session Handler about the
starting session.
4\. The Media Session Handler creates a new session with the 5GMS AF. The
Media Session Handler may provide EEC functionality to the 5GMS-Aware
Application. The Media Session Handler provides information to the 5GMS AF
about the required processing capabilities, application information, QoS
requirements, etc.
5\. The 5GMS AF verifies that the requested QoS and compute resources are
aligned with the resource templates provided in the Provisioning Session.
Through its EES functionality, it starts by checking the EAS instances that
registered with it and capable of running the service. If one or more suitable
EAS instances are not found, the 5GMS AF/EES may use the MnS-C interface to
allocate a new EAS instance for the application.
6\. The 5GMS AF confirms resource availability to the MSH and shares a list of
potential EAS/5GMS AS to the Media Session Handler through its EDGE-1
interface.
7\. The Media Session Handler may provide the list of suitable EAS/5GMS AS
instances to the Application. The Application picks one EAS/5GMS AS instance
and establishes a connection to it. Alternatively, the application may use DNS
resolution to discover the assigned EAS.
8\. Once the 5GMS-Aware Application is connected to the discovered EAS, it
starts exchanging rendered viewport and pose information with the EAS/5GMS AS.
NOTE: The Media Session Handler may throughout the lifetime of the session
update the processing and network QoS requirements based on the application's
request and changing needs.
# B.2 Edge Caching
The following call flow summarises the procedures for provisioning and using
an Operator CDN that automatically scales according to client load. This
follows the generic call flow in clause 6.3.3 that is driven by the 5GMSd
Application Provider. Consequently, the UE components are unaware that the
Content Hosting feature of the 5GMSd AS is deployed at the network edge, and
neither the AC nor the EEC play any role in the sequence.
Figure 16: Call flow for edge-enabled Content Hosting
The steps are as follows:
1\. The 5GMSd Application Provider provisions an edge-enabled Content Hosting
feature in the 5GMSd AF.
a. The 5GMSd Application provisions the Content Hosting feature by invoking
M1d calls on the 5GMSd AF. As part of this, it marks the Provisioning Session
as eligible for edge deployment.
b. The 5GMSd AF creates QoS templates and Compute resources templates suitable
for an edge-deployed 5GMSd AS with the Content Hosting feature.
c. The 5GMSd AF may at this point decide to spawn one or more 5GMSd AS
instances at various different edge locations to support the anticipated
demand, based on the contents of the QoS template and Compute Resource
template.
d. Any newly spawned 5GMSd AS instances configure their respective EAS
instances.
e. Any newly spawned EAS instance registers itself with its EES.
2\. The UE uses 5GMS downlink streaming session.
a. The 5GMSd-Aware Application may acquire Service Access Information from the
5GMSd Application Provider via M8d (out of scope).
b. The 5GMSd-Aware Application invokes the Media Stream Handler using an M7d
API call to inform it that a downlink streaming session is starting.
c. The Media Stream Handler invokes the Media Session Handler using an M6d API
call to inform it that a downlink streaming session is starting.
d. The Media Session Handler requests Service Access Information from the
5GMSd AF.
The 5GMSd AF and the EES collaborate to determine the most appropriate entry
point address to include in the Service Access Information for the requesting
Media Session Handler, based for example on its IP address. Alternatively, the
entry point may be generic domain name that resolves to the most appropriate
EAS instance providing the "5GMSd AS" capability and the "content hosting"
feature.
f. The Media Stream Handler commences downlink media streaming via M4d from
the 5GMSd AS edge instance indicated in the Service Access Information.
Content is acquired from the 5GMSd Application Provider via M2d as normal.
# B.3 User-generated live streaming
## B.3.1 Service provisioning
### B.3.1.1 Overview
The user-generated live streaming use case covers scenarios where various
processing of uplinked media is required. This processing may occur in the
cloud or at an edge close to the capturing device.
The set of media processing features needed by a particular application
service is first provisioned in the 5GMS AF by the 5GMS Application Provider.
The resource requirements of the corresponding 5GMS AS are expressed in a
resource template that is part of the resulting Provisioning Session.
Having provisioned the desired set of media processing features and the
resource template in the 5GMS AF, the 5GMS Application Provider points 5GMSu
Clients at the Service Access Information corresponding to the appropriate
Provisioning Session, in order to initiate new uplink streaming sessions.
### B.3.1.2 Example media processing features
Examples of relevant media processing features include, but are not limited
to:
1\. Quality improvement such as:
a. Video upscaling.
b. Image light correction.
c. Picture stabilization.
d. Audio quality improvement.
2\. Enriching and adding interactivity features such as:
a. Automated multilingual dubbing and captioning.
b. Overlaying and tagging.
c. Indexing and key feature detection.
d. Navigation improvements.
3\. Multi-rate encoding of content:
a. Content-aware encoding.
b. Low-latency packaging.
c. Just-in-time encoding and transcoding.
d. Multi-path encoding for on-demand content.
4\. Splicing and ad insertion:
a. Splicing content and manifest signaling.
b. Ad insertion queues and information.
c. Preferred language setting for ads and other service metadata.
5\. Applying content protection and DRM
### B.3.1.2 Example resource template aspects
The resource template for the 5GMS AS supporting the application service may
include one or more of the following aspects:
1\. EAS type.
2\. Hardware resources:
a. Compute.
b. Graphical compute.
c. Memory.
d. Storage.
3\. Connectivity to the UE:
a. Bit rate.
b. Latency.
c. Maximum request rate.
d. Maximum response time.
4\. Availability.
5\. Functional support such as:
a. Accelerated encoders/transcoders.
b. Quality improvement functions.
c. Content enriching and adding interactivity.
d. Splicing and ad-insertion tools.
e. Stabilization.
6\. The audience\'s geographical distribution and scale.
## B.3.2 High-level call flow
Figure 17 shows the high-level call flow for this use-case, which is based on
the client-driven edge discovery of clause 6.3.2.
Figure 17: User-generated live streaming walkthrough
The steps are:
1\. The 5GMS Application Provider creates a new Provisioning Session for"user-
generated live streaming" linked to a content hosting and distribution
configuration and a resource template for edge processing.
2\. The 5GMSu-Aware Application requests Service Access Information from the
5GMS Application Provider via M8.
3\. The 5GMS Application Provider, based on the requested service and the UE's
current location, creates an EAS Profile (as defined in clause 8.2.4 of TS
23.558 [3] and reproduced in table 4.2â€‘4 of the present document) and includes
it in the Service Access Information it returns to the 5GMSu-Aware
Application.
4\. The 5GMSu-Aware Application uses the EES to locate instances of the 5GMS
AS that can satisfy the requirements indicated in the EAS Profile acquired in
step 3.
5\. A new 5GMSu AS is instantiated and provisioned by the 5GMSu AF, if needed.
6\. The EES returns a list of suitable 5GMSu AS instances (and associated
information) to the EEC.
7\. The AC/EEC selects the best 5GMSu AS instance based on the EAS Profile
requirments and the current UE location.
8\. Uplink streaming starts. Media is uplink streamed to the 5GMSu AS, the
content is prepared according to the application service requirements and is
delivered to a 5GMSd AS for distribution (CDN).
## B.3.3 Service relocation considerations
In this use case, relocation of the 5GMS AS may be needed for any of the
following reasons:
1\. Relocation of the UE.
2\. Audience diversity/geographical change may require a rebalancing of edge
processing resources.
3\. Change of 5GMS Provisioning Session resource template which requires
allocation of more computational resource to a 5GMS AS instance than is
available on the current compute node.
In any of the above cases, the 5GMS AS supporting the application needs to be
transferred to a different edge compute node. The relocation may be performed
according to clause 6.4 using the ACR detection entity in Table 8.
Table 8: ACR detection entities for each relocation reason
Relocation reason ACR detection entity
* * *
UE relocation MSH/EEC AS load rebalancing 5GMS AS/EAS Change of resource
template Application/MSH/EEC
#