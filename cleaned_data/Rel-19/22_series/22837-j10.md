# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
In the present document, modal verbs have the following meanings:
**shall** indicates a mandatory requirement to do something
**shall not** indicates an interdiction (prohibition) to do something
The constructions \"shall\" and \"shall not\" are confined to the context of
normative provisions, and do not appear in Technical Reports.
The constructions \"must\" and \"must not\" are not used as substitutes for
\"shall\" and \"shall not\". Their use is avoided insofar as possible, and
they are not used in a normative context except in a direct citation from an
external, referenced, non-3GPP document, or so as to maintain continuity of
style when extending or modifying the provisions of such a referenced
document.
**should** indicates a recommendation to do something
**should not** indicates a recommendation not to do something
**may** indicates permission to do something
**need not** indicates permission not to do something
The construction \"may not\" is ambiguous and is not used in normative
elements. The unambiguous constructions \"might not\" or \"shall not\" are
used instead, depending upon the meaning intended.
**can** indicates that something is possible
**cannot** indicates that something is impossible
The constructions \"can\" and \"cannot\" are not substitutes for \"may\" and
\"need not\".
**will** indicates that something is certain or expected to happen as a result
of action taken by an agency the behaviour of which is outside the scope of
the present document
**will not** indicates that something is certain or expected not to happen as
a result of action taken by an agency the behaviour of which is outside the
scope of the present document
**might** indicates a likelihood that something will happen as a result of
action taken by some agency the behaviour of which is outside the scope of the
present document
**might not** indicates a likelihood that something will not happen as a
result of action taken by some agency the behaviour of which is outside the
scope of the present document
In addition:
**is** (or any other verb in the indicative mood) indicates a statement of
fact
**is not** (or any other negative verb in the indicative mood) indicates a
statement of fact
The constructions \"is\" and \"is not\" do not indicate requirements.
# Introduction
Wireless sensing technologies aim at acquiring information about a remote
object or environment and its characteristics without physically contacting
it. The perception data of the object and its surrounding can be utilized for
analysis, so that meaningful information about the object or environment and
its characteristics can be obtained.
# 1 Scope
The present document describes use cases and potential requirements for
enhancement of the 5G system to provide sensing services addressing different
target verticals/applications, e.g. autonomous/assisted driving, V2X, UAVs, 3D
map reconstruction, smart city, smart home, factories, healthcare, maritime
sector.
Use cases focus on NR-based sensing, while some use cases might make use of
information already available in EPC and E-UTRA (e.g. cell/UE measurements,
location updates). This study will not lead to impacts on EPC and E-UTRA. Some
use cases could also include non-3GPP type sensors (e.g. Radar, camera).
The aspects addressed in the present document include collecting and reporting
of sensing information, sensing related KPIs. Security, privacy, regulation
and charging are additional topics of concern.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] W. Favoreel, \"Pedestrian sensing for increased traffic safety and
efficiency at signalized intersections,\" 2011 8th IEEE International
Conference on Advanced Video and Signal Based Surveillance (AVSS), 2011, pp.
539-542, doi: 10.1109/AVSS.2011.6027406.
[3] Advances in Wildlife Crossing Technologies:
https://highways.dot.gov/public-roads/septoct-2009/advances-wildlife-crossing-
technologies.
[4] Protection Detection: Making Roads Safe for Drivers and Wildlife:
https://onlinepubs.trb.org/onlinepubs/webinars/201118.pdf.
[5] F. Liu et al., \"Integrated Sensing and Communications: Towards Dual-
functional Wireless Networks for 6G and Beyond,\" in IEEE Journal on Selected
Areas in Communications, doi: 10.1109/JSAC.2022.3156632.
[6] T. S. Rappaport, G. R. MacCartney, M. K. Samimi and S. Sun, \"Wideband
Millimeter-Wave Propagation Measurements and Channel Models for Future
Wireless Communication System Design,\" in IEEE Transactions on
Communications, vol. 63, no. 9, pp. 3029-3056, Sept. 2015, doi:
10.1109/TCOMM.2015.2434384.
[7] C. Han, Y. Bi, S. Duan and G. Lu, \"Rain Rate Retrieval Test From 25-GHz,
28-GHz, and 38-GHz Millimeter-Wave Link Measurement in Beijing,\" in IEEE
Journal of Selected Topics in Applied Earth Observations and Remote Sensing,
vol. 12, no. 8, pp. 2835-2847, Aug. 2019, doi: 10.1109/JSTARS.2019.2918507.
[8] IEEE 802.11-18/0611r16: "Wireless LANs, WiFi Sensing Uses Cases"
[9] TEM STANDARDS TEM STANDARDS AND RECOMMENDED PRACTICE:
https://unece.org/fileadmin/DAM/trans/main/tem/temdocs/TEM-Std-Ed3.pdf
[10] S. Saponaraet. al, \"Radar-on-Chip/in-Package in Autonomous Driving
Vehicles and Intelligent Transport Systems: Opportunities and Challenges,\"
inIEEE Sig. Proc. Mag., Sept. 2019.
[11] 3GPP TR 22.856, \"Localized Mobile Metaverse Services\".
[12] J. Hasch, E. Topak, R. Schnabel, T. Zwick, R. Weigel and C. Waldschmidt,
\"Millimeter-Wave Technology for Automotive Radar Sensors in the 77 GHz
Frequency Band,\" inIEEE Transactions on Microwave Theory and Techniques, vol.
60, no. 3, pp. 845-860, March 2012.
[13] "Velodyne™ LiDAR VPL-16 User Manual," 63-9243 Rev. E, Velodyne™ LiDAR,
https://velodynelidar.com/wp-content/uploads/2019/12/63-9243-Rev-E-
VLP-16-User-Manual.pdf.
[14] Liu, A., Huang, Z., Li, M., Wan, Y., Li, W., Han, T.X., Liu, C., Du, R.,
Tan, D.K.P., Lu, J. and Shen, Y., 2022. A survey on fundamental limits of
integrated sensing and communication.  _IEEE Communications Surveys &
Tutorials_,  _24_(2), pp.994-1034.
[15] https://medium.com/desn325-emergentdesign/s-l-a-m-and-optical-tracking-
for-xr-cfabb7dd536f.
[16] Dwivedi, S., Shreevastav, R., Munier, F., Nygren, J., Siomina, I.,
Lyazidi, Y., Shrestha, D., Lindmark, G., Ernström, P., Stare, E. and Razavi,
S.M., 2021. Positioning in 5G networks. IEEE Communications Magazine, 59(11),
pp.38-44.
[17] T. Murakami et al, "Wildlife Detection System Using Wireless LAN Signal,"
in NTT Technical Review vol.17, No.6, pp. 45-48, June 20019, https://www.ntt-
review.jp/archive/ntttechnical.php?contents=ntr201906fa13.pdf&mode=show_pdf.
[18] Eradication of elephant mortality and injury due to railway accidents
through automatic tracking and alert system in IEEE Conference Publication,
IEEE Xplore
[19] Impact of wild animals (deer and bears) on train operations
210616_KO_Animal2.pdf (jrhokkaido.co.jp) (in Japanese) [z] Rail Industry
Safety Induction Handbook:
https://railsafe.org.au/__data/assets/pdf_file/0009/32022/Rail-Industry-
Safety-Induction-RISI-Handbook-V5.1.pdf.
> [20] S. M. Patole, M. Torlak, D. Wang and M. Ali, \"Automotive radars: A
> review of signal processing techniques,\" inIEEE Signal Processing Magazine,
> vol. 34, no. 2, pp. 22-35, March 2017.
>
> [21] Society of Automotive Engineers (SAE), "Taxonomy and definition for
> terms related to Driving automation systems for on-Road Motor Vehicles",
> https://www.sae.org/standards/content/j3016_202104/.
[22] Census of Fatal Occupational Injuries Summary, 2020,
https://www.bls.gov/news.release/cfoi.nr0.htm.
[23] Javed MA, Muram FU, Hansson H, Punnekkat S, Thane H. Towards dynamic
safety assurance for Industry 4.0. Journal of Systems Architecture. 2021 Mar
1; 114:101914.
[24] American National Standards Institute/Industrial Truck Safety Development
Foundation, Safety standard for driverless, automatic guided industrial
vehicles and automated functions of manned industrial vehicles, December 2019,
2019, [Online] http://www.itsdf.org.
[25] Moore, Erik George, \"Radar Detection, Tracking and Identification for
UAV Sense and Avoid Applications\" (2019). Electronic Theses and
Dissertations. 1544.
[26] https://www.bosch-mobility-solutions.com/en/solutions/assistance-
systems/blind-spot-detection/.
[27] Soatti, Gloria, et al. \"Enhanced vehicle positioning in cooperative ITS
by joint sensing of passive features.\"  _2017 IEEE 20th International
Conference on Intelligent Transportation Systems (ITSC)_. IEEE, 2017.
[28] 5GAA_White_Paper_C-V2X Use Cases Volume II: Examples and Service Level
Requirements.
[29] https://www.ieee802.org/11/Reports/tgbf_update.htm.
[30] https://mentor.ieee.org/802.11/dcn/20/11-20-1712-02-00bf-wifi-sensing-
use-cases.xlsx.
[31] X. Liu, J. Cao, S. Tang and J. Wen, \"Wi-Sleep: Contactless Sleep
Monitoring via WiFi Signals,\" 2014 IEEE Real-Time Systems Symposium, 2014,
pp. 346-355, doi: 10.1109/RTSS.2014.30.
[32] Chen V C. The micro-Doppler effect in radar. Artech house, 2019.
[33] 3GPP TS 22.261: "Service requirements for the 5G system".
[34] A. Chebrolu, \"FallWatch: A Novel Approach for Through-Wall Fall
Detection in Real-Time for the Elderly Using Artificial Intelligence\", _2021
Third International Conference on Transdisciplinary AI (TransAI)_ , 2021, pp.
57-63, doi: 10.1109/TransAI51903.2021.00018,
https://ieeexplore.ieee.org/document/9565618.
[35] B. A. Alsaify et al., "A CSI-Based Multi-Environment Human Activity
Recognition Framework" _Applied Sciences 12,_ no. 2: 930, 2022.
https://doi.org/10.3390/app12020930.
[36] U. Saeed U et al., \"Discrete Human Activity Recognition and Fall
Detection by Combining FMCW RADAR Data of Heterogeneous Environments for
Independent Assistive Living\", Electronics 10(18):2237, 2021.
https://doi.org/10.3390/electronics10182237.
[37] C. Dou, H. Huan, \"Full Respiration Rate Monitoring Exploiting Doppler
Information with Commodity Wi-Fi Devices\". Sensors 21, 3505, 2021\.
https://doi.org/10.3390/s21103505.
[38] J. Pu, H. Zhang, \"RF-Heartbeat: Robust and Contactless Heartbeat
Monitoring Based on FMCW Radar\", 2021. TechRxiv Preprint.
https://doi.org/10.36227/techrxiv.15021645.v2.
[39] H. V. Habi and H. Messer, "Recurrent Neural Network for Rain Estimation
Using Commercial Microwave Links," in IEEE Transactions on Geoscience and
Remote Sensing, vol. 59, no. 5, pp. 3672-3681, May 2021, doi:
10.1109/TGRS.2020.3010305.
[40] Roberto Opromolla, etc., "Perspectives and Sensing Concepts for Small UAS
Sense and Avoid", 2018 IEEE/AIAA 37th Digital Avionics Systems Conference
(DASC).
[41] https://www.rwjbh.org/trinitas-regional-medical-center/treatment-
care/sleep-disorders/sleep-apnea/.
[42] https://my.clevelandclinic.org/health/articles/10881-vital-signs.
[43] 3GPP TR 22.855, \"Study on Ranging-based Services\".
[44] Guoxuan Chi, et. al., \"Wi-Drone: Wi-Fi-based 6-DoF Tracking for Indoor
Drone Flight Control\", MobiSys 22, Association for Computing Machinery, 2022.
[45] Report on Automated Valet Parking: technology assessment and use case
implementation description -- 5G Automotive Association (5gaa.org).
https://5gaa.org/news/report-on-automated-valet-parking-technology-assessment-
and-use-case-implementation-description/.
[46] Nie Y B , Zhang L . Main amendments to Working Safety Regulation of State
Grid Company(Dynamical Part for Hydrodynamic Power Plant)[J]. East China
Electric Power, 2008.
[47] Giuseppe Fragapane, René de Koster, Fabio Sgarbossa, Jan Ola Strandhagen,
Planning and control of autonomous mobile robots for intralogistics:
Literature review and research agenda, European Journal of Operational
Research, Volume 294, Issue 2,2021, Pages 405-426.
[48] Li S, Li X, Lv Q, et al. WiFit: Ubiquitous bodyweight exercise monitoring
with commodity wi-fi devices, 2018 IEEE SmartWorld, Ubiquitous Intelligence &
Computing, Advanced & Trusted Computing, Scalable Computing & Communications,
Cloud & Big Data Computing, Internet of People and Smart City Innovation,
IEEE, 2018: 530-537.
[49] https://www.synopsys.com/automotive/autonomous-driving-levels.html.
[50] R. Bosch, "LRR3 3rd Generation Long-Range Radar Sensor," Robert Bosch
GmbH, Germany, 2009.
[51] Continental, A.G., ARS 408-21 Premium Long RangeRadar Sensor 77 GHz.ARS,
pp.408-21.
[52] F. Engels et. al, \"Automotive Radar Signal Processing: Research
Directions and Practical Challenges,\" in IEEE JSTSP, June2021.
[53] I. Greshamet al., \"Ultra-wideband radar sensors for short-range
vehicular applications,\" inIEEE Transactions on Microwave Theory and
Techniques, vol. 52, no. 9, pp. 2105-2122, Sept. 2004.
[54] AinsteinAutomotive Safety Radar T-79 short-range radar:
https://ainstein.ai/vehicle-radar/short-range-wideband-high-resolution-
automotive-radar-sensor/.
[55] National Academies of Sciences, Engineering, and Medicine. 1995. Virtual
Reality: Scientific and Technological Challenges. Washington, DC: The National
Academies Press. https://doi.org/10.17226/4761.
# 3 Definitions of terms, symbols and abbreviations
## 3.1 Terms
For the purposes of the present document, the terms given in 3GPP TR 21.905
[1] and the following apply. A term defined in the present document takes
precedence over the definition of the same term, if any, in 3GPP TR 21.905
[1].
**3GPP sensing data** : data derived from 3GPP radio signals impacted (e.g.
reflected, refracted, diffracted) by an object or environment of interest for
sensing purposes, and optionally processed within the 5G system.
**5G Wireless sensing: 5GS feature providing capabilities to get information
about characteristics of the environment and/or objects within the environment
(e.g. shape, size, orientation, speed, location, distances or relative motion
between objects, etc) using NR RF signals and, in some cases, previously
defined information available in EPC and/or E-UTRA.**
**Human motion rate accuracy** describes the closeness of the measured value
of the human body movement frequency caused by part(s) (e.g. chest) of the
target object (i.e. human body) to the true value of the human body movement
frequency.
**non-3GPP** **sensing data: data provided by non-3GPP sensors (e.g. video,
LiDAR, sonar) about an object or environment of interest for sensing
purposes.**
**Sensing assistance information: information that is provided to 5G system
and can be used to derive sensing result. This information does not contain
3GPP sensing data.**
NOTE 1: Examples of sensing assistance information are map information, area
information, a UE ID attached to or in the proximity of the sensing target, UE
position information, UE velocity information and etc**.**
**Sensing contextual information** : information **that is exposed** with the
sensing results **by 5G system to a trusted third party** which provides
context to the conditions under which the sensing results were derived. This
information does not contain 3GPP sensing data.
NOTE 2: Examples includes map information, area information, time of capture,
UE location and ID. This contextual information can be required in scenarios
where the sensing result is to be combined with data from other sources
outside the 5GS.
**Sensing group** : a set of sensing transmitters and sensing receivers whose
location is known and whose sensing data can be collected synchronously.
**Sensing measurement process** : process of collecting sensing data.
**Sensing receiver:** a sensing receiver is an entity that receives the
sensing signal which the sensing service will use in its operation. A sensing
receiver is an NR RAN node or a UE. A Sensing receiver can be located in the
same or different entity as the Sensing transmitter.
**Sensing result** : processed 3GPP sensing data requested by a service
consumer.
**Sensing signals:** Transmissions on the 3GPP radio interface that can be
used for sensing purposes.
NOTE 3: The definition refers to NR RF signals and, in some cases, previously
defined information available in EPC and/or E-UTRA can be used, without
leading to impacts on EPC and E-UTRA.
**Sensing transmitter:** a sensing transmitter is the entity that sends out
the sensing signal which the sensing service will use in its operation. A
Sensing transmitter is an NR RAN node or a UE. A Sensing transmitter can be
located in the same or different entity as the Sensing receiver.
**Target sensing service area** : a cartesian location area that needs to be
sensed by deriving **characteristics of the environment and/or objects within
the environment** with certain sensing service quality from the impacted (e.g.
reflected, refracted, diffracted) wireless signals. This includes both indoor
and outdoor environments.
**Moving target sensing service area:** the case where a target sensing
service area is moving according to the mobility of a target from sensing
transmitter's perspective.
**Transparent sensing** : sensing measurements are communicated such that they
can be discerned and interpreted by the 5G system, e.g. the data is
communicated using a standard protocol to an interface defined by the 5G
system.
The following KPIs apply to the definition of the use cases on sensing
quantitative requirements:
**\- Accuracy of positioning estimate** describes the closeness of the
measured sensing result (i.e. position) of the target object to its true
position value. It can be further derived into a horizontal sensing accuracy
-- referring to the sensing result error in a 2D reference or horizontal
plane, and into a vertical sensing accuracy -- referring to the sensing result
error on the vertical axis or altitude.
\- **Accuracy of velocity estimate** describes the closeness of the measured
sensing result (i.e. velocity) of the target object's velocity to its true
velocity.
\- **Confidence level** describes the percentage of all the possible measured
sensing results that can be expected to include the true sensing result
considering the accuracy.
\- **Sensing** **Resolution** describes the minimum difference in the measured
magnitude of target objects (e.g. range, velocity) to be allowed to detect
objects in different magnitude.
**\- Missed detection probability** is the conditional probability of not
detecting the presence of target object/environment when the target
object/environment is present. This probability is denoted by the ratio of the
number of events falsely identified as negative, over the total number of
events with a positive state. It applies only to binary sensing results.
NOTE 4: An event with a positive state refers to the presence of the
characteristics of a target object or environment, including the event falsely
identified as being negative and truly identified as being positive
\- **False alarm probability** is the conditional probability of falsely
detecting the the presence of target object/environment when the target
object/environment is not present. This probability is denoted by the ratio of
the number of events falsely identified as being positive, over the total
number of events with a negative state. It applies only to binary sensing
results.
NOTE 5: An event with a negative state refers to the non-presence of the
characteristics of a target object or environment, including the event falsely
identified as being positive and truly identified as being negative
\- **Max sensing service latency** : time elapsed between the event triggering
the determination of the sensing result and the availability of the sensing
result at the sensing system interface.
\- **Refreshing rate** : rate at which the sensing result is generated by the
sensing system. It is the inverse of the time elapsed between two successive
sensing results.
## 3.2 Symbols
For the purposes of the present document, the following symbols apply:
\ \
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
\ \
# 4 Overview
5G Wireless sensing is a technology enabler to acquire information about
characteristics of the environment and/or objects within the environment, that
uses radio waves to determine the distance (range), angle, or instantaneous
linear velocity of objects, etc. The 5G wireless sensing service relies on
analyzing the transmissions, reflections, and scattering of wireless sensing
signals.
This technical report investigates the potential of integrated sensing and
communication technology for enabling new services and use cases for various
industries. 5G wireless sensing service, as part of a cellular network
provides new possibilities for enhanced usage of the telecommunication
infrastructure in areas of object detection and tracking, environment
monitoring and human motion monitoring. It provides input to various verticals
- UAVs, smart home, V2X, factories.
The use cases examined in the report cover a wide range of applications,
including:
  * Object and intruder detection for smart home, on a highway, for railways, for factory, for predefined secure areas around critical infrastructure
  * Collision avoidance and trajectory tracking of UAVs, vehicles, AGVs
  * Automotive maneuvering and navigation
  * Public safety search and rescue
  * Rainfall monitoring and flooding
  * Health and sports monitoring
Use cases focus is on 5G wireless sensing and some of the use cases could
include non-3GPP type sensors (e.g. Radar, camera).
5G wireless sensing service also brings challenges related to confidentiality
and privacy. There is a need to protect the sensing data from unauthorized
access, interception and eavesdropping, but also to make sure there is
compliance with regulation and user awareness.
In summary, it is considered beneficial for 3GPP specifications to address 5G
system support of different use cases and service requirements for Integrated
Sensing and Communication.
# 5 Use cases
## 5.1 Use case of intruder detection in smart home
### 5.1.1 Description
Sensing in smart home is a kind of the typical scenarios of indoor/local-area
sensing [8]. Considering people spends most of lifetime indoor, how to improve
the user experience for indoor scenario is important. Nowadays, various 5G
UEs, e.g. wearable device, sensor, smart phone and customer premise equipment
(CPE), are deployed at home. In order to enjoy more comfortable and convenient
indoor life, various devices are connected via wireless signals to build a
smart home platform.
In addition to communication purposes, wireless signals can also be used for
sensing, e.g., monitoring the home environment continuously.
For intruder detection in smart home scenario, due to the activities of indoor
object or human, the 3GPP signal measured by UE or network would be
influenced. By analysing and collecting the sensing information such as
Doppler frequency shift, amplitude change and phase change, the behaviour of
indoor object or human could be detected as shown in following figure 5.1.1-1
which takes sensing entity that transceives (transmits and receives) the
signal case as example.
. {width="3.959263998250219in" height="1.2460728346456693in"}
Figure 5.1.1-1 An example of sensing operation of UE
### 5.1.2 Pre-conditions
Mary and her husband Tom live in a house with little daughter Alice.
On every working day, Mary and Tom have to leave home to work, and Alice needs
to go to school. Since the community where the house is located is not stable,
Mary and Tom have concern on the safety of their property.
In order to address their concerns, considering protecting the personal
privacy and save family cost, Mary sets up some 5G CPEs (i.e. UE) in each room
at home, which support sensing functionalities.
### 5.1.3 Service Flows
Mary and all her family members travel to Hawaii in a holiday. At this time,
her house is empty. Since she worries about the safety of property, she
enables the sensing service on intruder detection of the 5G CPEs (i.e. UE) at
home.
Mary's CPE (i.e. UE) in the living room is activated to perform the sensing
operation. While the 5G CPE transmit 5G signals to provide communication
services at home, the reflected signals are also received and measured at the
CPE as sensing information. The CPE reports the sensing information to 5G
network or further process locally. Via the analysing the differences between
the 5G signals and the received reflected signals provided by sensing service
performed by 5G system, any potential intruder will not be missed.
Also, Mary's CPE in the living room can work with other 5G UEs in other rooms.
The CPE discovers that the living room has another 5G device (i.e. UE) which
could assist the sensing service as secondary device via direct device
connection. The connectivity used in this case is direct device connection,
and CPE and this 5G device play as the role of transmitter and receiver,
respectively. The receiver measures the 5G signal (e.g., number of detected
transmission paths), then provides sensing information to 5G network or
further process locally. Via the analysing the differences between the 5G
signals and the received reflected signals provided by sensing service
performed by 5G system, any potential intruder will not be missed.
An intruder breaks into Mary's house someday. The sensing service provided by
5G network system assists detecting that the presence of an intruder based on
analysing the change of collected signals is aligned with the known feature of
the activities of indoor human, and the alarm of intruder is sent to Mary's
smart phone. Mary calls the police for help, and the property is protected.
### 5.1.4 Post-conditions
Thanks to the sensing service provided by 5G UE and network, an intruder is
found when Mary is out of home.
### 5.1.5 Existing features partly or fully covering the use case
functionality
None.
### 5.1.6 Potential New Requirements needed to support the use case
[PR 5.1.6-1] The 5G network shall provide a mechanism for an operator to
authorize a UE for sensing, e.g., based on location.
[PR 5.1.6-2] The 5G system shall support a UE to perform sensing measurement
process based on the trusted third-party's request.
[PR 5.1.6-3] The 5G system shall provide mechanisms for an operator to only
collect or expose the sensing information requested by a trusted third-party
according to agreement.
[PR 5.1.6-4] The 5G system shall support UE to perform sensing measurement
process using signals received from other UE(s).
[PR 5.1.6-5] The 5G system shall support UE to perform sensing measurement
process in licensed or unlicensed band.
[PR 5.1.6-6] The 5G system shall be able to provide the sensing service with
following KPIs:
Table 5.1.6-1 Performance requirements of sensing results for intruder
detection in smart home
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency[ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Intruder detection in smart home | Indoor | 95 | ≤10 | ≤10 | N/A | N/A | N/A | N/A |  Missed detection [%]
|
> False alarm [%]
|  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | 
> | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Rainfall monitoring | outdoor | 95 | [1mm/h] NOTE 2 | N/A | N/A | N/A | N/A | N/A | N/A | 1 min | 10min, application configurable | 5 | 5  
NOTE 1: The terms in Table 5.3.6-1 are found in Section 3.1. NOTE 2: For rainfall rain rate >1 mm/h[39]. Rainfall estimation accuracy describes the closeness of the measured rainfall estimation to its true rainfall value. |  |  |  |  |  |  |  |  |  |  |  |  |   
NOTE: In this use case base station is acting as sensing transmitter and/or
sensing receiver. This is an example and other options can also be valid.
## 5.4 Use Case on Transparent Sensing Use Case
### 5.4.1 Description
In general, a UE senses using either or combination of the non-3GPP sensors
such as camera, Lidar, 3GPP-based sensing. In 3GPP 5G wireless sensing, the
Sensing transmitters and Sensing receivers sense for stationary and moving
Objects around them -- using time-difference-of-arrival (TDoA), angle-of-
arrival (AoA), angle-of-departure (AoD) measurements, RSSI etc. as shown in
Figure 5.4.1-1 [14]. Transparent sensing is a use case in which 3GPP sensing
data is captured by Sensing transmitter and/or Sensing receiver and
communicated so that the 5GS is aware of the 3GPP sensing data, while the
non-3GPP sensing data is the result of non-3GPP sensors and is transparent to
5GS. From this information, service enablers can be defined. One example of
such information is location data, whose corresponding service enabler is
Location Based Services.
{width="3.315384951881015in" height="2.4659919072615923in"}
Figure 5.4.1-1: BS and UE sensing Objects
In this use case, non-3GPP sensing data is made available to the 5GS, and the
requirements for this exposure are considered. The data so obtained can be
used for diverse purposes. One such purpose is Localization (identifying both
a three- dimensional position and orientation.) Transparent Sensing data used
for Localization is described in TR 22.856 [11].
{width="6.695138888888889in" height="2.1013888888888888in"}
Figure 5.4.1-2: Opaque and Transparent Sensing Data
The distinguishing characteristic of this use case is that the non-3GPP
sensing data is provided to the 5GS itself.
The application server receiving \'transparent non-3GPP sensing data\' as
shown in figure 5.4.1-2 can be operated by the MNO. This enables the MNO to
provide specific processing to produce \'combined sensing results as a
service,\' where the sensing data is supplied by non-3GPP sensors owned and
operated by third parties, subscribers, etc.
In this use case it is the 5GS that receives 3GPP and non-3GPP sensing data,
not a third party.
### 5.4.2 Pre-conditions
A UE has access to one or more sensors. In this use case. the UE has access to
four sensors: NR-based sensing, 3D LiDAR, an RGB Camera and a Smart Phone
Camera. The sensors\' physical configuration is known (e.g. the cameras are 10
cm apart). The NR-based sensing capabilities of the UE and its connected BS
are used to capture information about the nearby environment by the UE.
A mobile network MN supports the acquisition of non-3GPP sensing data. We term
this support by the network a \'non-3GPP sensing data consuming service\'.
### 5.4.3 Service Flows
The user U activates a mechanism to enable Non-3GPP sensing data acquisition
that can be collected at U\'s UE.
The user U provides this non-3GPP sensing data via the 5GS. This process is
analogous to activating or enabling a location tracking service.
MN acquires sensing data provided by U\'s UE, for a period of time.
MN can also acquire 3GPP sensing data. 3GPP-RF sensing data can be processed
only in 5GS to derive sensing results. The sensing results and the Non-3GPP
sensing data can be combined to produce a combined sensing result.
The user U deactivates the mechanism to provide non-3GPP sensing data to the
5GS.
### 5.4.4 Post-conditions
The non-3GPP sensing data acquired by the 5GS is processed in order to enable
other services. The processed information can for example provide \'Spatial
Localization\' information that can be exposed to authorized third parties, as
discussed in 22.856 [11]. \"Spatial Localization Use Case\".
### 5.4.5 Existing feature partly or fully covering use case functionality
Positioning in 5G Networks been proposed in 3GPP release-16, it specifies
positioning signals and measurements for the 5G NR. In release-16, 5G
Positioning architecture extends 4G positioning architecture by adding
Location Management Function (LMF) and Transmission reception points (TRP).
5GS provides new positioning methods based on multi-cell round-trip time
measurements, multiple antenna beam measurements, to enable downlink angle of
departure (DL-AoD) and uplink angle of arrival (UL-AoA) [15][16]. The Rel-17
5G system supports positioning of the device-based but not device-free \--
objects that do not radiate EM signals [14][15][16].
The 5GS already supports transport of non-3GPP sensor data. The table below
provides indicative performance requirements for media used for sensor
information communication.
+-----------------------+----------------+-------------------------+ | **Sensor Type** | **Uplink KPI** | **Remarks** | +=======================+================+=========================+ | 3D Lidar | 30 Mbps | An example 3D LiDAR: 16 | | | | channel, 0.3M data | | | | points, dual return | | | | mode | | | | | | | | 2 bytes distance, 1byte | | | | [13] | +-----------------------+----------------+-------------------------+ | Industrial RGB Camera | 16 \~ 800 Mbps | 2,592 x 2,048 x 10bits | | | | x 2.5 Hz x 6 EA, | | | | compression ratio 2% | +-----------------------+----------------+-------------------------+ | Smart Phone Camera | 4 \~ 200 Mbps | 2,160 x 2,880 x 8bits x | | | | 1 Hz x 4 EA, | | | | compression ratio 2% | +-----------------------+----------------+-------------------------+
Table 5.4.5-1: Performance Requirements (already possible to fulfill with the
5GS)
### 5.4.6 Potential New Requirements needed to support the use case
[PR 5.4.6-1] Subject to user consent and national or regional regulatory
requirements, based on operator policy, the 5GS shall support a mechanism to
receive uplink non-3GPP sensing data from authorized non-3GPP sensors.
NOTE 1: This requirement assumes there is some functionality in the 5GS to
discern and interpret the acquired 3GPP and non-3GPP sensing data.
[PR 5.4.6-2] Subject to user consent and national or regional regulatory
requirements, based on operator policy, the 5GS shall support a mechanism to
expose sensing results to trusted third parties.
[PR 5.4.6-3] Subject to user consent and national or regional regulatory
requirements, based on operator policy, the 5GS shall support a mechanism to
expose combined results to trusted third-parties.
[PR 5.4.6-4] Subject to user consent, network operator policy and national or
regional regulatory requirements, the 5GS shall support a mechanism to enable
Sensing transmitters and Sensing receivers to acquire 3GPP sensing data to
capture information about the nearby environment and for this to be combined
with Non-3GPP sensing data to produce a combined sensing result.
NOTE 2: This requirement does not imply or allow 3GPP sensing data to be
exposed to third parites. This data is considered confidential.
## 5.5 Use case on sensing for flooding in smart cities
### 5.5.1 Description
Due to the climate change in recent years, a larger amount of rain sometimes
falls within a short duration of time inside a small area. This result, in
particular in urban areas, in inundation and flooding even in areas where
these did not happen in the past. When flooding is about to happen on roads,
people might enter areas getting in danger without knowing it. Once flooding
really happens there, this might result in loss of human life. At places where
flooding is expected to occur, monitoring of flooding is performed using
cameras and other sensors. However, due to the recent climate change, it can
be difficult to recognize places where flooding is expected to occur. Using
radio waves, it is possible to recognize places where flooding occurs in an
efficient way.
NOTE: There has been a related trend, although a mobile communication is not
directly involved so far and it\'s monitoring of the river, not of the road as
this use case deals with. In Japan, MLIT (Ministry of Land, Infrastructure,
Transport and Tourism) takes care of the river administration and supervises
water level observation of rivers to prevent and predict flooding. In the
past, water-level gauges were only sparsely deployed along the river. Water
levels at places where those gauges were not placed were estimated based on
water levels observed some distance away where such gauges were placed.
Detailed degree of possibility of flooding at each place was not directly
understood. To improve this situation, MLIT has encouraged to develop a low-
cost water-level gauge and has started placing such gauges e.g., at places
that are relatively prone to flooding or show a specific water behavior due to
the form of the river, or that are close to hospitals or important facilities.
Disaster Information for River is now available at https://www.river.go.jp/e/
for public.
### 5.5.2 Pre-conditions
Good partnership and cooperation are established between Mobile Operator #A
and administrators of roads such as a local government in City #B. Mobile
Operator #A constantly senses the surface of the road and informs results of
sensing to the administrator of the road.
### 5.5.3 Service Flows
{width="3.441666666666667in" height="2.3916666666666666in"}
Figure 5.5.3-1: Sensing for flooding in smart cities
  1. Base stations owned by Mobile Operator #A are deployed around the > road. Mobile Operator #A carries out sensing of the surface of > the road in City #B. This sensing is performed using radio wave. > Results of sensing information, incl. whether flooding occurs on > the road, are informed to the administrator of the road in City > #B.
  2. The administrator of the road usually monitors the state of flooding > on the road using information from sensors including information > from Mobile Operator #A. In addition, in the case of heavy rain, > the administrator can request Mobile Operator #A to increase > frequency of monitoring of situation of roads and Mobile Operator > #A monitors the situation more frequently responding to this > request.
  3. If there is information received that flooding occurs, the > administrator advises people in the areas concerned to evacuate > the areas. The administrator advises via mobile networks.
  4. People who received the advice evacuate the areas or do not enter > such areas.
  5. Now City #B trusts Mobile Operator #A and allows it to advise > people about evacuation without City #B\'s intervention in case > of flooding. Next time a similar flooding occurs, Mobile Operator > #A sends advice for evacuation directly to people.
### 5.5.4 Post-conditions
Damage of the flooding has been kept at minimum.
### 5.5.5 Existing features partly or fully covering the use case
functionality
None.
### 5.5.6 Potential New Requirements needed to support the use case
[PR 5.5.6-1] Subject to operator policy, the 5G system shall be able to
provide sensing result indicating disasters or other emergencies (e.g.,
flooding) in a given geographic area to authorized third parties in a timely
manner.
[PR 5.5.6-2] Subject to regional or national regulatory requirements and
operator policy, the 5G system shall be able to provide its public warning
system with a warning notification based on sensing result indicating
disasters or other emergencies (e.g., flooding) in a given geographic area in
a timely manner.
[PR 5.5.6-3] Subject to operator policy, it shall be possible for an
authorized third party to configure the 5G system to initiate sensing for
disasters or other emergencies (e.g., flooding) in a given geographic area.
[PR 5.5.6-4] The 5G system shall be able to support the following KPIs:
Table 5.5.6-1 Performance requirements of sensing for flooding in smart cities
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency[ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
sensing for flooding in smart cities | Outdoor | 95 | ≤10 | [≤0.2] NOTE 2 | N/A | N/A | N/A | N/A | ≤ 1min NOTE 3 |  in the outdoor or in the indoor and monitor 3GPP signals which are > influenced by outdoor objects such as humans and animals. In > addition, the UEs communicate with base stations of the mobile > operator and monitor the radio wave state between the UEs and the > base stations.
  2. When an intruder enters the site, the radio signals are changed. The > core network processes the data and yields sensing result > indicating detection of the intruder.
NOTE: Cases that such an intruder or an animal is already indoor are addressed
in the use case in clause 5.1.
  1. The residents are informed of detection of the intruder.
### 5.6.4 Post-conditions
The residents report to the police or the security service and request them to
take an appropriate action.
### 5.6.5 Existing features partly or fully covering the use case
functionality
None.
### 5.6.6 Potential New Requirements needed to support the use case
[PR 5.6.6-1] Subject to operator policy, the 5G system shall be able to
collect 3GPP sensing data and yield sensing result from the data for detection
of outdoor objects.
[PR 5.6.6-2] The 5G system shall be able to support the following KPIs:
Table 5.6.6-1 Performance requirements of intruder detection in surroundings
of smart home
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency[ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
intruder detection in surroundings of smart home | Outdoor | 95 | ≤2 | N/A | N/A | N/A | N/A | N/A | ≤1000 |  Missed detection [%]
|
> False alarm [%]
|  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | 
> | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Sleep monitoring | Outdoor (bedroom) | 95 | 0.033 NOTE 2 | N/A | N/A | N/A | N/A | N/A | N/A | 60s | 60 | 5 NOTE 3 | 5 NOTE 3  
NOTE 1: The terms in Table 5.15.6-1 are found in Section 3.1. NOTE 2: Respiration rate = 18 times/min as reference, any detected value in [16,20] satisfies accuracy requirements, 0.033Hz corresponds to 2 times/min. NOTE 3: Detect event = “breathing stoppages duration >= 10 seconds” as reference. |  |  |  |  |  |  |  |  |  |  |  |  |   
NOTE: In this use case base station and UE is acting as sensing transmitter
and/or sensing receiver. This is an example and other options can also be
valid.
## 5.16 Use case on Protection of Sensing Information
### 5.16.1 Description
This use case re-uses the scenario where a UE performs sensing to detect
intruders in the home, as per use case 5.1 (intruder detection in smart home).
The additional aspect introduced in this use case is that there is an
unauthorised user that is attempting to collect sensing information from
Mary\'s home.
### 5.16.2 Pre-conditions
Refer to use case 5.1 where 5G CPEs (i.e. UEs) are set up to detect intruders
when Mary\'s home is vacant as her family is on holiday.
### 5.16.3 Service Flows
An unauthorised user is in the vicinity of Mary\'s home.
In Mary\'s home, the 5G CPE transmits 5G signals, and the reflected signals
are used by the unauthorised user\'s device to collect sensing information.
As the 5G signals from the CPEs in Mary\'s home are protected, the
unauthorised user\'s device fails to derive any sensing information.
### 5.16.4 Post-conditions
The privacy of sensing information in Mary\'s home is preserved.
The unauthorised user cannot use the 5G signals to detect that the family is
not at home.
### 5.16.5 Existing features partly or fully covering the use case
functionality
None
### 5.16.6 Potential New Requirements needed to support the use case
[PR 5.16.6-1] The 5G system shall provide a mechanism to protect identifiable
information that can be derived from the 3GPP sensing data from eavesdropping.
## _5.17_ Use _case on health monitoring at home_
### 5.17.1 Description
Tom is an elderly person living in his house. Since he has become weaker, he
has subscribed to a wireless sensing service of his MNO so that his health
state (including e.g. lack of movement, detection of falls, breathing rate)
can be monitored 24/7 when he is at his home. Wireless sensing is a promising
technology for health monitoring [34] [35] [36] [37] that does not require a
person to wear a health monitoring device on his/her body (which people may
forget, requires recharging, and can be uncomfortable to wear over long
periods of time).
A single base station is not capable of covering Tom's home with good
coverage. Thus, multiple base stations capable of acting as wireless
transmitters and/or receivers cooperate to ensure excellent coverage.
Furthermore, the received reflected radar signal is sometimes weak, and thus,
the MNO offers the possibility of using a phone with wireless sensing
receiving capabilities. The usage of the phone also allows more accurate
measurements of certain vital signs (e.g. breathing rate) since the phone is
close to Tom. The usage of the phone also allows the MNO to offload the
workload from the base station to the phone. Also other UEs in vicinity of Tom
could take part in the sensing.
Fig. 5.17.1.1 shows a schematic illustration of how such system could look
like, whereby the blue arrow indicates transmitted wireless sensing signals
from Base Station A, and the green dashed arrows indicate reflected wireless
sensing signals received by Base Station B and Tom's phone.
{width="6.451388888888889in" height="2.811777121609799in"}
Figure 5.17.1-1: Example of a distributed sensing system (incl. two base
stations, a UE and a Sensing function).
### 5.17.2 Pre-conditions
1\. Tom has subscribed to the sensing service offered by an MNO.
2\. The MNO has deployed two RAN entities (e.g. base station A and base
station B) that are capable of wireless communication and sensing. The base
stations can act as wireless sensing transmitters and/or wireless sensing
receivers. These two base stations are sufficiently close to Tom\'s house to
provide good coverage in and around Tom\'s house in the frequency bands used
for wireless sensing. Tom's subscription includes a phone with wireless
sensing capabilities for more accurate sensing.
3\. Tom has a mobile phone that is capable of detecting wireless sensing
signals. Tom can use it to directly and/or more accurately sense his health
state.
4\. The 3GPP sensing data from the RAN and UEs is collected and processed by a
sensing function that can be deployed in the 5G network or provided by an
external application or a combination thereof. The exact separation of
functionalities between those entities is not explored further in this use
case. The sensing function is assumed to be capable of extracting health state
information, e.g. lack of movement, detection of falls, breathing rate from
this 3GPP sensing data, determine the sensing requirements (e.g. accuracy),
and determine the criteria/thresholds (e.g. lack of movement) on when to
create an alert.
### 5.17.3 Service Flows
1\. Based on Tom's sensing subscription, information about a user (in this
case Tom) is obtained including information about where he lives and sensing
requirements that are needed (e.g. sensing of movements which can be used to
detect falls or sufficient activity of Tom).
2\. Base station A starts transmitting the wireless sensing signal.
3\. Tom is currently located in the living room. If Tom is at this location,
base station A can hardly receive the reflection of its transmitted sensing
signal. However, base station B can receive a strong reflection of that
sensing signal. Base station A and B coordinate with each other so that Base
Station B is capable of processing the received reflected wireless sensing
signal, generating 3GPP sensing data that is sent to a sensing function for
further processing. In this manner, movements of Tom in and around the house
can be monitored, and it can be detected if Tom falls.
4\. Tom feels a bit weak today and decides to measure his health state in more
detail. Tom was told that he needs to carry his phone to enable this. Tom
picks up his phone and uses it as a wireless sensing receiver capable of
picking up and processing the reflected wireless sensing signal transmitted by
Base station A. This requires the phone to coordinate wireless sensing with
Base station A, which includes for example exchanging of capabilities (since
the sensing capabilities can differ per phone) and coordinating of
timing/frequencies of sensing signals. Since Tom's phone is very close to Tom,
Tom can use his phone for more accurate sensing of certain vital signs, such
as breathing rate and heart rate. The phone sends measurements to a sensing
function for further processing. When Tom goes to sleep, he puts his phone
next to him to monitor his vital signs also during the night.
5\. When Tom's health state is determined to be in danger, e.g., when Tom
falls or stops moving, the family or emergency services gets alerted of such
event.
### 5.17.4 Post-conditions
The sensing service/application receives accurate 3GPP sensing data about Tom
and can generate alerts if an adverse event happens to Tom.
### 5.17.5 Existing features partly or fully covering the use case
functionality
None.
### 5.17.6 Potential New Requirements needed to support the use case
[PR 5.17.6-1] The 5G system shall be able to coordinate wireless sensing among
a set of RAN entities and UEs.
[PR 5.17.6-2] The 5G system shall support a mechanism for the 5G network to
retrieve the wireless sensing capabilities from UEs and RAN entities, and for
the UEs and RAN entities to exchange capabilities amongst each other.
[PR 5.17.6-3] The 5G system shall support a mechanism for two or more
authorized UEs and/or RAN entities to take part in the wireless sensing of a
target, whereby the authorization may be provided based on location.
[PR 5.17.6-4] The 5G system shall support a mechanism to provide wireless
sensing capable UEs and RAN entities with information of which network entity
to send the 3GPP sensing data to.
## _5.18 Use case on service continuity of unobtrusive health monitoring._
### 5.18.1 Description
An elderly home has installed a new 5G system capable of providing
communication and sensing capabilities through the facilities as illustrated
in Figure 5.18.1-1. The deployed 5G system includes multiple sensing devices,
e.g., base stations, providing connectivity and sensing capabilities. These
sensing devices can perform wireless sensing of a target, in this case, health
monitoring (e.g. fall/activity detection [34][35][36] or wireless sensing of
vital signs such as heart rate [38] or breathing rate [37] of one or more
persons). Since elderly people move through the facilities, it is important to
provide health monitoring independently of the base station used for sensing.
The staff of the elderly home really likes this new 5G wireless sensing
feature because it is unobtrusive and offers various advantages over the old
system that they use with body worn sensors. For example, they don't need to
recharge or replace the batteries of body worn sensors anymore and remind
people or help people to wear them after they took them off (for example to
take a shower). The elderly people themselves also like it more, since the
body worn sensors often made them feel uncomfortable, especially during sleep
or during hot days. Installing cameras was not seen as a good alternative
because of the privacy concerns.
In the provided use case, base stations cooperate with each other to ensure
service continuity for sensing of a 'target' user. In this particular
scenario, a user, Robert, is considered who moves through the facilities.
Robert\'s health is quite frail and requires continuous monitoring of his
health state _without interruption_. Robert is currently sensed by means of
(indoor) base station A located near his room and is moving out of the sensing
area of base station A and approaching the sensing area of base station B
covering the recreation/eating area and part of the hallway. Base station A
and base station B cooperate in such a way that it is ensured that base
station B has started wireless sensing of Robert before base station A stops
its wireless sensing of Robert. When Robert is in range of both base station A
and B, both base stations can cooperate to perform simultaneous wireless
sensing. Similarly, when Robert decides to go for a walk to the garden that is
covered by Base Station C, the sensing of Robert is seamlessly continued by
Base Station C. The 3GPP sensing data is collected and processed by the 5G
network (e.g. to detect certain movement patterns) and then sensing results
are exposed to a sensing application that is automatically monitoring health
anomalies. If a health anomaly is detected (e.g. Robert falls down), an alarm
is triggered indicating the health condition as well as the location of the
monitored user.
{width="6.590200131233596in" height="3.6361920384951882in"}
Figure 5.18.1-1: Example of service continuity between Base stations A, B and
C.
### 5.18.2 Pre-conditions
1\. MNO operates a 5GS providing wireless sensing capabilities through a set
of base stations installed in the elderly home and its garden, as illustrated
in Figure 5.18.1-1.
2\. Robert has subscribed to the wireless sensing service offered by the 5GS
in cooperation with an external application provider. Robert provided some
identification information, e.g. which room he resides in, the identity of his
mobile phone and/or some physical characteristics (e.g. length). The
application provider has no knowledge of the RAN infrastructure operated by
the MNO.
### 5.18.3 Service Flows
1\. Robert is currently located in his room in the elderly home. The closest
nearby base station, i.e. base station A infers, based on the identification
information provided by Robert, that Robert is in his room. Base station A
starts wireless sensing of Robert, whereby it sends the 3GPP sensing data to
the 5GC for further processing, after which the sensing results are sent to a
sensing application to detect health anomalies
2\. Robert starts moving toward the garden.
3\. When leaving his room and entering the hallway, the wireless sensing
signal conditions of base station B become better than those of base station
A.
4\. The 5G system coordinates the responsibility of sensing Robert from base
station A to base station B. During this time, both base station A and B might
sense Robert.
5\. Base station B is used for sensing Robert
6\. Base station A can stop sensing Robert.
7\. When leaving the elderly home and entering the garden, Base Station C
continues the sensing of Robert.
### 5.18.4 Post-conditions
Robert's vital signs are monitored without interruption independently of his
location.
### 5.18.5 Existing features partly or fully covering the use case
functionality
None.
### 5.18.6 Potential New Requirements needed to support the use case
[PR 5.18.6.1] The 5G system shall support continuity of sensing of a target
that may move across a sensing area that may be bigger than the coverage area
of a single sensing transmitter.
[PR 5.18.6.2] The 5G system shall support simultaneous wireless sensing of a
target by means of multiple sensing devices.
[PR 5.18.6-3] Subject to operator's policy, the 5G network may provide secure
means for the operator to expose information on sensing service availability
(e.g., if sensing service is available and the supported KPIs) in a desired
sensing service area location to a trusted third-party.
## 5.19 Use case on Sensor Groups
### 5.19.1 Description
Sensing has been considered in this technical report in terms of interaction
between a UE and a base station. This information however is only partial, as
it extends along a limited UE-base station axis. This information however can
be considered a component of a scene that, when gathered with other available
sensor data, can be synthesized into more comprehensive information.
Where the sensor is video, LiDAR, sonar, etc., (that is, it operates in some
other way than 3GPP defined radio access technology,) it is still valuable to
gather simultaneous sensor data and combine it. Only this way can sensor data
capturing a _scene_ (such as the front _and_ back _and_ sides of an object of
interest, etc.) be obtained.
In the Localized Mobile Metaverse Services use case 5.1 in [11], includes the
following text \"His mobile device begins to collect information about his
surroundings. The collected information can include information that is
obtained by interacting with nearby devices (e.g. sensors and other mobile
devices).\"
This use case explores the implications of this function. Specifically, how
can a UE identify sensors that are present that can provide information sought
by the UE?
In this particular use case, on a construction site, a crane is lifting a
large object near a tower. Construction worker safety, efficient pursuit of
tasks and other situational awareness to prevent disasters are important
tasks. Instead of merely relying on the crane operator, this use case allows
the 5G system to model and track the tower, crane and payload as it is in
motion.
Figure 5.19.1-1: Group Sensing, to provide sensing services
In Figure 5.19.1-1, the UE is on a construction site. It seeks to identify
sensors available at that site to provide sensing data potentially relevant to
obtaining information for the user. These sensors - in the UE\'s proximity and
available to provide sensor data (that is, this service is authorized,)
comprise a sensor group.
Correspondence between Sensor Groups and other groups defined in stage 2 are
neither implied by this use case nor excluded. There is no correspondence
between Sensor Groups and other groups defined in stage 1.
The use case assumes that sensors that can form a sensor group are either UEs
or communicate by means of a UE (as a kind of \'split terminal equipment
(TE)\' UE.)
It is essential to capture a \'synchronous\' group of sensors and their
movements in 3 dimensions in order to optimally combine the sensor data for
the purpose of localization computations. This is particularly important when
the viewer is near a large object or any non-static object must be modeled on
all sides. This is an active area of research, for example in 6DoF Tracking
and sensing. [44] The techniques described in this paper concern how to
determine the 3D position and orientation of drones with synchronization, but
it is clear that this is a fundamental requirement of a group of sensors
providing input on a single physical object in (absolute or relative) motion.
The synchronous group of sensors form a logical set of devices whose data
acquisition is critical for a particular task. The handling of this group is
unique to this problem domain because (i) the need to synchronize the uplink
transmissions of sensor measurement data of members of the group, so they can
be combined in a timely way to produce a meaningful sensor measurement result
of an object in motion, (ii) the dynamic nature of this group as the set of
sensors that are appropriate to use can change often: the set of sensors
prepared to obtain sensor measurement data of moving objects will change over
time.
In this use case, a user\'s UE identifies a sensor group, through interaction
with an AS. Part of identification of the sensors in the group is obtaining
sufficient information that the user can become authorized to obtain sensor
data, and the relevant service access information is obtained. The goal of the
use case is to _enable_ the acquisition of sensor data in a UE\'s proximity.
The communication of the sensing data itself is out of scope of this use case.
Discovery of the kind described here can potentially be accomplished by
different radio technologies, e.g. NR ProSe, UWB, IEEE 802.11, etc.
### 5.19.2 Pre-conditions
Benoît inspects various construction sites. He has a UE equipped with a set of
surveillance and appraisal applications.
On construction sites he visits, there are sensors deployed. Some are UEs,
e.g. using NR-based sensing. Other sensors include video cameras, LiDAR
equipment and passive infrared sensors. These are not, generally, installed
directly in the terminal equipment, but rather use the terminal equipment to
communicate, as shown in figure 5.19.2-1.
{width="5.785714129483814in" height="2.633307086614173in"}
Figure 5.19.2-1: Sensors available to become a sensing group
In the scenario above, (a) is a UE that serves various sensors that are
themselves not UEs. The means by which these sensors communicate with the UE
is out of scope of this use case. They could be e.g. connected by means of a
physical cable. (b) is a UE that is capable of 3GPP defined sensing. (c) is a
UE that can operate the UE camera for sensing purposes.
As the RF measurement data contains sensitive information (e.g. location of
sensing transmitter/receiver, information about objects) from the 3GPP system
it is processed in the 5G network to produce sensing results. 3GPP sensing
data is not shared outside of 5G network. Application enabler layer combines
these results with other data like non-3GPP sensing data to produce combined
sensing results.
In this example (a) and (b) are authorized and ready to send mobile originated
sensing data to an AS.
The non-3GPP sensing data from UEs and sensing results from 3GPP network
acquired by the AS can be combined in software in a manner that is out of
scope of the 5G standard. In this use case, the combination is performed by
the AS.
Benoît\'s UE, (c), is authorized to access the media (the sensing result
output of the AS produced by taking account of the non-3GPP sensing data from
(a) and (b), sensing results from 3GPP network) provided by the AS.
Benoît, using UE (c), monitors the construction site for safety and
efficiency.
### 5.19.3 Service Flows
Benoît\'s UE (c) uses functionality provided by the 5G system to seek to
determine the existence of UEs (a) and (b), referring to Figure 5.19.2-1.
UE (c) has knowledge of the AS that accumulates sensor information that could
be of interest.
UE (c) requests of the AS that accumulates sensor information for a sensor
group: what sensors are in the proximity?
UE (c) is able to become authorized to receive information concerning the
sensor group.
The Application Server (AS) requests the 5G system obtain a sensing group.
The 5G system will identify the set of sensing group members that provide the
AS with sensor information that are in the proximity of UE(c). The 5G system
will strive to synchronously locate 4 or more devices, to be localized within
10cm of accuracy, with accuracy of measurement within 5 ms of synchronization.
NOTE: It is impractical for the AS to continuously track the location of each
of these UEs because their location can change and this information is needed
only on demand. The group needs to be captured _together, at the same time,_
since the sensor data of the group needs to be interpreted by UE (c) together.
The AS provides UE (c) with sufficient information to _identify the sensing
group_ that are ready to provide non-3GPP sensing data and sensing results as
well as _how to get sensing data from the sensing group_ from the AS.
UE (c) requests to obtain combined sensing results from the AS/sensing group.
The sensors must be within proximity and their locations are known with great
accuracy (within 10cm in 3D), with accuracy of measurement within 5 ms of
synchronization.
UE (c) is authorized to obtain combined sensing results from the AS/sensing
group.
UE (a), UE (b) provide non-3GPP sensing data and the network provides sensing
results. These are received by the AS and combined. This combined sensing
result is provided to UE (c) by the AS.
UE (b) is mobile and its position varies. UE (c) must identify its position
with sufficient accuracy to interpret the sensing result meaningfully. Since
UE (b) is mobile, its position and movements must be tracked to provide
accuracy up to 10 cm, with accuracy of measurement within 5 ms of
synchronization.
UE (b) leaves the proximity of UE (c). UE (c) identifies that UE (b) has left
the sensing group.
Later, UE (b) returns to proximity of UE (c). UE (c) identifies that UE (b)
has joined the sensing group, including its position within 10 cm, with
accuracy of measurement within 5 ms of synchronization.
The crane operations are monitored by sensors (a) and (b), providing different
perspectives by means of non-3GPP sensing data from non-3GPP sensors and
sensing results from the 3GPP network to the AS.
### 5.19.4 Post-conditions
Benoît, making use of UE (c), is able to ascertain with very high accuracy the
location and movement of the entire group of UEs that can form a sensor group.
The ability of UE (c) to identify the position and membership of the group
continues over time, so that the _current_ membership of the group is known,
and that membership can change.
The AS is able to combine the non-3GPP sensing data acquired by non-3GPP
sensors and sensing results acquired by 3GPP network from different
perspectives and produce a useful 3D representation of the site to the site
supervisor, who receives the combined sensing result by means of media
delivered from the AS to the Benoît\'s UE (c).
### 5.19.5 Existing feature partly or fully covering use case functionality
There are requirements specified in 22.261, 6.37.2 to support ranging services
that are relevant to this use case. These were developed in the FS_Ranging
study. [43]
\- The 5G system shall be able to support for a UE to discover other UEs
supporting ranging.
\- The 5G system shall be able to start ranging and stop ranging according to
the application layer's demand.
\- The 5G system shall be able to provide mechanisms for a MNO, or authorized
third-party, to provision and manage ranging operation and configurations.
\- The 5G system shall be able to support ranging enabled UEs to determine the
ranging capabilities (e.g. capabilities to perform distance and/or angle
measurement) of other ranging enabled UEs.
\- The 5G system shall be able to allow a ranging enable UE to determine if
another ranging enabled UE is stationary or mobile, before and/or during
ranging.
\- The 5G system shall allow ranging service between 2 UEs triggered by and
exposed to the application server.
Differences between this use case and the above ranging requirements, and
ranging in general include:
\- Sensing data is not acquired \'between UEs\' but by means of different
sensing technologies.
\- It is not sufficient to discover other UEs that support sensing: these must
be in the discovering UE\'s proximity and the discovered UE\'s precise
location must be ascertained.
\- In this use case, a \'sensing group\' is formed, where in Ranging, all
range information was acquired through interactions directly (or indirectly if
relayed) between UEs.
### 5.19.6 Potential New Requirements needed to support the use case
[PR 5.19.6-1] Based on third-party request, the 5G system shall be able to
discover a suitable sensing group where sensing transmitters and receivers are
within 100m range to be localized within 10cm of accuracy, with accuracy of
sensing measurement process within 5 ms of synchronization.
[PR 5.19.6-2] Based on third-party request, the 5G system shall be able to
discover a sensing group in the proximity of the UE that is requesting the
service from the AS.
NOTE: This requirement assumes that a UE requests an AS to discover a set of
sensing group members that have sensing functions that can provide sensing
service.
## 5.20 Use case of Sensing for Parking Space Determination
### 5.20.1 Description
Sensing technology can improve the user experience in parking garage via
enabling the vehicle and parking garage to get more information, e.g.
information whether a parking space is available or not. The
indoor/underground parking garage can install multiple Sensing receivers and
Sensing transmitters throughout the concrete structure for detecting the
availability of the parking space. The outdoor parking garage can also exploit
multiple Sensing receivers and Sensing transmitters for detecting the
availability of the parking space.
Another related use case is automated parking e.g. AVP (Automated Valet
Parking) and AFP (Automatic Factory Parking) [45] where cars are provided with
drive-path information to do automated parking in a given parking lot
facility. Connectivity is an important component in automatic parking, and the
3GPP sensing technology can serve as the way to determine available parking
spaces and the best route for a car to reach it.
The coverage could be either a public network or a private network
specifically for the parking garage. For the Sensing receiver(s) and Sensing
transmitter(s) indoor, see figure 5.20.1-1, one deployment scenario is that
Sensing receiver(s) and Sensing transmitter(s) can be ceiling-mounted and
located in such a way as to provide sensor coverage for the parking bays
within the structure, where the Sensing transmitter and Sensing receiver can
be co-located. Another deployment method is that some Sensing receiver(s) and
Sensing transmitter(s) can be ceiling-mounted and some can be mounted on the
floor or wall, where the Sensing transmitter and Sensing receiver can be
separately located. For the Sensing receiver(s) and Sensing transmitter(s)
outdoor, see figure 5.20.1-2, Sensing receiver(s) and Sensing transmitter(s)
can be deployed at a relative high place to guarantee the coverage of the
parking garage.
{width="3.3465277777777778in"
height="1.8020833333333333in"}{width="3.3465277777777778in"
height="1.801388888888889in"}
Figure 5.20.1-1: Parking space determination (indoor deployment)
{width="6.695138888888889in" height="2.8222222222222224in"}
Figure 5.20.1-2: Parking space determination (outdoor deployment)
Multiple methods can be used via using the sensing signals emitted from the
Sensing transmitter to detect the target object/area and the sensing signals
bounced/reflected. For example, the Sensing receiver can measure the reflected
signal power of the target area [8]. Since the cars are usually made of metal
materials and the ground is, on the contrary, covered by cement or plastic
cement, these objects can vary significantly on the reflected signal power,
thus the Sensing receiver can distinguish whether a parking space is taken by
simply measuring the reflected signal power difference. Another example method
is that the Sensing receiver(s) and Sensing transmitter(s) can identify a
parking space availability by monitoring the target movements. Comparing with
the stationary objects such as ground and poles, the Sensing receiver(s) and
Sensing transmitter(s) can easily distinguish a car when a car is parking or
leaving, thus by measuring the distance/angle/velocity, the Sensing
receiver(s) and Sensing transmitter(s) can record that a parking space is
occupied when a car is parking, and that a parking space is free when a car is
leaving. Or the Sensing receiver(s) and Sensing transmitter(s) can also detect
a parking space availability by generating a 3-D point cloud [9], then both
the stationary and moving target can be easily detected in a 3-D point cloud
especially with some backend data processing skills such as machine
learning/deep learning.
### 5.20.2 Pre-conditions
This use case is about a public multi-storey parking garage who has installed
Sensing receiver(s) and Sensing transmitter(s) throughout the concrete
structure to detect the positions of people, objects, and vehicles within the
garage. The concrete structure can make coverage difficult and, especially in
underground levels, coverage provided by external transmitters can be very
poor. This parking garage can provide the information to the entering vehicles
about the availability of the parking space.
Consider an example scenario shown in Fig. 5.20.2-1. A typical parking space
is with length 5 m and width 2.5 m. So, from the horizontal dimension, the
resolution requires to distinguish different parking spaces. The results can
be aggregated by the parking garage operator and the parking state can be
updated in seconds even when the coverage of the parking garage is poor, which
helps avoid a wasting of time for the entering vehicles.
{width="4.580555555555556in" height="2.3270833333333334in"}
Figure 5.20.2-1: Example of sensing scenario
### 5.20.3 Service Flows
  1. James wants to park his car at the public parking garage in floor #B2. His vehicle, on entering the public parking garage, queries the parking garage service for availability of a parking bay in floor #B2.
  2. The parking garage operator can activate the sensing devices in floor #B2 for sensing. Sensing receiver(s) and Sensing transmitter(s) sense the parking spaces without interfering each other or with bearable interference. The sensing results can be aggregated by the parking garage operator.
  3. With the aggregated sensing results, the parking garage operator can send sensing results back with an addition to the dynamic map corresponding to the floor #B2 which shows the current status of parking bays in the structure.
  4. James can see the available parking bays on his in-car display and choose a suitable one.
### 5.20.4 Post-conditions
Thanks to sensing, James has found a parking space on the correct floor
without issue, making his life easier during daily travel.
### 5.20.5 Existing features partly or fully covering the use case
functionality
None.
### 5.20.6 Potential New Requirements needed to support the use case
[PR 5.20.6-1] The 5G system shall be able to provide sensing services in
licensed and unlicensed spectrum.
[PR 5.20.6-2] The 5G system shall be able to authorize Sensing receiver(s) and
Sensing transmitter(s) to participate in a sensing service.
[PR 5.20.6-3] Based on operator's policy, the 5G system shall enable a trusted
third-party to request the activation of the sensing service with specific KPI
requirement, as well as deactivation of the same service.
[PR 5.20.6-4] The 5G system shall be able to support charging for the sensing
services (e.g. considering service type, sensing accuracy, target area,
duration).
[PR 5.20.6-5] The 5G system shall be able to provide a sensing service
considering the interference to the Sensing service caused by the sensing
operations between multiple Sensing transmitter(s) and Sensing receiver(s).
[PR 5.20.6-6] The 5G system shall be able to provide sensing with following
KPIs.
Table 5.20.6-1 Performance requirements of sensing results for parking space
determination
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Parking space determination | Indoor/ outdoor | 95 | 0.5 | 0.5 | 0.1 | N/A | 2.5m perpendicular to the parking space 5m parallel to the parking space | N/A | 1000 | 1 | 1 | 5  
NOTE: The terms in Table 5.20.6-1 are found in Section 3.1. |  |  |  |  |  |  |  |  |  |  |  |   
## 5.21. Use case of Seamless XR streaming
### 5.21.1 Description
Extended Reality (XR) is an important 5G use case. Split-rendering
architectures, where the heavy XR video rendering computation is done at the
application server based on control information received from the UE, poses
strict Quality-of-Service (QoS) requirements in terms of round-trip latency
and throughput for delivering the video and control info.
It is therefore crucial to always maintain a high-quality wireless link for
XR. Thus, it is critical to predict and adapt fast to wireless channel
changes. This is especially true in Millimeter wave bands in which the channel
and propagation characteristics are very sensitive to user and environment
changes such as blockages, user motion or rotation.
To adapt fast to the wireless channel changes, an understanding of the
wireless channel dynamics is required. The channel dynamics depend on
understanding the surrounding environment such as the transmitter and receiver
locations, geometry of the buildings, moving scatterers, location and material
of blockers, etc.
Interestingly, most of the XR streaming devices (e.g., 5G phones, AR/VR
headsets) and third-party entities that support 5G (i.e., 3GPP sensors) also
support non-3GPP sensors, such as RF sensors, Inertial Measurement Units (IMU)
sensors, RGB cameras, position sensors, and others.
In light of the availability of 3GPP and non-3GPP sensors and the need of
environment understanding, it is therefore natural to utilize the overall
sensing information to acquire an understanding of the surrounding
environment.
To this end, a "Sensing RF Map Service" can be envisioned that enables the
collection of sensing information from 3GPP and non-3GPP sensors, process and
provide that information to a sensing service.
  * The input to this "Sensing RF Map" service could be 3GPP sensing data and non-3GPP sensing data from multiple sensors, e.g., RF sensing data, XR user position, camera images, depth maps, hand tracking, motion type, etc. Such input could be produced by a 5GS entity (e.g,, UE or RAN entities) or by a third-party (e.g., surveillance camera). It is essential to note that the collection of this sensing should be done with appropriate user consent and adherence to regional and national regulations.
  * The processing of 3GPP and non-3GPP sensing data can be performed within the 5G system or outside the 5GS (for example on an application server). In this use case, we are focus on processing in the 5G system.
  * The output of this service (i.e., sensing result) is some understanding of the environment and/or impact to communication performance of a service consumer, e.g., RF environment mapping, etc. When sensing result is shared outside of the 5GS, the appropriate consent and permissions for sharing this information is required.
  * The consumer of this service could be a third-party application or other entities in the 5GS.
It is important to note that while this service is provided by 5GSor edge
server, business model for the monetization of this service would need to
consider factors such as the entities involved in sensing, the transfer of the
non-3GPP sensing data and the value of sensing RF Map information produced by
these entities as well as the value to the consumer of the service. These
considerations are also required for scenarios involving 3GPP only sensing
operations but additional considerations are indeed required for non-3GPP
sensing data which is generated outside the 5G system.
### 5.21.2 Pre-conditions
Jose is playing a game inside a gaming arena using a VR headset that is
connected to a RAN entity. The VR headset, RAN entity and third-party
surveillance system are configured to provide "3GPP sensing data and non-3GPP
sensing data" to the "Sensing RF Map Service".
The VR headset is equipped with 3GPP sensors and non-3GPP sensors such as, IMU
sensors and cameras, and it can provide sensing inputs e.g., 3GPP sensing
data, headset pose and location, velocity, images of the environment and
processed images (such as motion pattern and maps). Also, the VR headset can
provide communication reference signal measurements or reports to the Sensing
RF Map Service.
RAN entity has 3GPP NR RF capabilities and can provide 3GPP sensing data to
the 5GS, which processes and provides sensing results to the sensing RF Map
service.
The gaming arena also has cameras deployed by a trusted third-party
surveillance camera company and can provide images of the environment and
processed images (such as motion pattern and maps) to the 5GS.
### 5.21.3 Service Flows
1\. Jose is playing a game using a VR headset in an arena with some obstacles
and other gamers in the environment. Jose moves through the arena and
approaches a communication blocker which could potentially impact the
performance of the wireless communication between VR headset and the RAN
entity.
2\. Jose's VR headset, RAN entity and the third-party surveillance system
provide 3GPP sensing data, and non-3GPP sensing data to the Sensing RF Map
Service. The Sensing RF Map Service combines the 3GPP and non-3GPP sensing
data to produce a sensing result which is a comprehensive RF map of the
environment surrounding the headset (e.g. information such as the location of
RAN entities, reflectors, static blockers, etc. and an indication of wireless
link blockage event, e.g., people walking by blocking the 5G link).
NOTE: An RF map is a spatial/geographical representation of environmental
characteristics (e.g., wireless propagation and objects such as RF signal
reflectors, blockers in the environment). This map enables improvements in
areas such as radio resource management, beam management, mobility and user
applications.
  1. 5GS uses the RF map to predict that Jose's communication link is about to be blocked if he comes close to the blocker and such prediction is sent to communication and/or the application layers of the game~~.~~ For example, the application layer adjusts the content of rendered video frames accordingly (e.g., lowers the frame rate, adds a virtual obstacle in the rendered video to prevent Jose from coming close to the blocker.)
### 5.21.4 Post-conditions
Jose enjoys seamless XR gaming application without video frame drops, i.e., no
video glitches. This is because Sensing RF map Information was leveraged to
assist both the communication service as well as the application.
### 5.21.5 Existing features partly or fully covering the use case
functionality
None.
### 5.21.6 Potential New Requirements needed to support the use case
[PR 5.21.6-1] Subject to user consent and regulatory requirements, based on
operator policy, the 5G system shall be able to support secure means for RAN
entities and authorized UEs to provide 3GPP sensing data to a 5G network for
processing.
[PR 5.21.6-2] Subject to user consent and regulatory requirements, based on
operator policy, the 5G system shall be able to collect non-3GPP sensing data
from trusted parties.
[PR 5.21.6-3] Subject to user consent and regulatory requirements, based on
operator policy, the 5G system should be able to support the combination of
the 3GPP sensing data and non-3GPP sensing data to derive combined sensing
result.
[PR 5.21.6-4] Subject to user consent and regulatory requirements, based on
operator policy, the 5G system shall be able to expose the combined sensing
results to a trusted third-party service provider.
## 5.22 Use case of UAVs/vehicles/pedestrians detection near Smart Grid
equipment
### 5.22.1 Description
In the future, there will be more and more autonomous driving devices, such as
drones and self-driving cars. These devices have a strong ability to affect
the surrounding environment, which may have an impact on the operating
equipment in Smart Grid.
For example, vehicles, such as UAVs and engineering vehicles, may affect the
operation safety of multiple links such as power generation, power
transmission, and power transformation.
At present, multiple scenarios of power transmission and transformation in the
Smart Grid industry have potential combination with integrated sensing and
communication technology. Among them, there are related accidents caused by
hooking or damaging transmission lines by vehicles in the power transmission
process. Thus, the transmission stations need to identify and warn vehicles.
In the process of power transformation, there are security risks such as
candid photography and attack by drones, getting electric shock when
approaching, etc. In a word, there are requirements for perimeter intrusion
detection and UAV detection in substations.
### 5.22.2 Pre-conditions
There are existing 5G base stations deployed near the transmission stations
and substations, which can provide constant remote sensing of the location of
intruders in the coverage area including UAVs, engineering vehicles and
pedestrians. Network operator A can use these 5G base stations to provide 5G
sensing service for the Smart Grid operator X, including sensing the motion
trail of the UAVs, vehicles and pedestrians in their working area.
The Smart Grid Operator X uses the 5G sensing service provided by 5G network
Operator A to detect potential intrusion/approaching of UAVs, vehicles and
pedestrians near the transmission stations and substations.
The Smart Grid operator sets the border of restricted area for the
transmission stations/lines and substations in which no UAVs, vehicles or
pedestrians can be access, and define a warning distance value. Once a UAV,
traffic vehicle, or pedestrian is detected that its distance from the border
is less than the warning distance value, the 5G system will report the event
to the Smart Grid operator to send the alerting message.
The 5G base stations can sense the location of the UAV/traffic
vehicle/pedestrian constantly and send these data to the 5G core network. Then
the sensing node and computing node can analyse and predict the path of the
UAV or pedestrian according to a large amount of data and give early warning
of potential security risks.
### 5.22.3 Service Flows
1\. The Smart Grid Operator X requests sensing service from network operator A
to collect sensing data in the defined area (i.e., the park covering
transmission stations and substations). The network operator A configures the
base stations located in the defined area to perform sensing.
2\. The 5G RAN constantly collects 3GPP sensing data of the location of
UAVs/vehicles/pedestrians in the defined area and send the sensing data to the
5G core network with a defined frequency to obtain the sensing result (i.e.,
the distance between the UAV/traffic vehicle/pedestrian and the border or
motion trail).
3\. The 5G system will send notification to UAVs/vehicles/pedestrians with UE
that they are near a restricted area. 5G system will also report the sensing
results to the Smart Grid operator. The Smart Grid operator determines to send
the alerting message to the intruding/approaching UAVs/vehicles/pedestrians
based on the sensing results. In addition, the staffs working in the park
respond to the emergency and prepare to intercept the intruding/approaching if
the UAVs/vehicles/pedestrians are not away.
### 5.22.4 Post-conditions
The UAVs/vehicles/pedestrians are away from the defined area. Potential
security risks are avoided. Thanks to the wide-area and constant sensing
capability of the 5G base station, and the precise data processing and
prediction by the 5G core network, the safety supervision of the Smart Grid is
improved.
### 5.22.5 Existing features partly or fully covering the use case
functionality
In TS22.261, there are existing requirements on information exposure:
In clause 6.10:
_The 5G system shall be able to:_
_\- provide a third-party with secure access to APIs (e.g. triggered by an
application that is visible to the 5G system), by authenticating and
authorizing both the third-party and the UE using the third-party\'s service._
_\- provide a UE with secure access to APIs (e.g. triggered by an application
that is not visible to the 5G system), by authenticating and authorizing the
UE._
_\- allow the UE to provide/revoke consent for information (e.g., location,
presence) to be shared with the third-party._
_\- preserve the confidentiality of the UE\'s external identity (e.g. MSISDN)
against the third-party._
_\- provide a third-party with information to identify networks and APIs on
those networks._
### 5.22.6 Potential New Requirements needed to support the use case
[PR 5.22.6-1] Subject to operator policy, the 5G system shall enable the
network to expose a suitable API to a authorized third party to provide the
information regarding sensing results.
[PR 5.22.6-2] Based on operator policy, the 5G system may be able to utilize
sensing assistance information exposed by a trusted third-party to derive the
sensing result.
[PR 5.22.6-3] The 5G system shall be able to support the following KPIs:
Table 5.22.6-1 Performance requirements of sensing results for
UAVs/vehicles/pedestrians' detection near Smart Grid equipment
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Sensing for the use case in Smart Grid NOTE 2 | Outdoor | 95 | ≤0.7 | N/A | UAV: ≤25 Pedestrian: ≤1.5 Vehicle: ≤15 | N/A | N/A | N/A | ≤5s | ≥10Hz | [≤5] | [≤5]  
NOTE 1: The terms in Table 5.22.6-1 are found in Section 3.1. NOTE 2: The typical size (Length x Width x Height) of UAV is 1.6m x 1.5m x 0.7m, the typical size of pedestrian is 0.5m x 0.5m x 1.75m, and the typical size of engineering vehicle is 7.5m x 2.5m x 3.5 m. The size of the park of Smart Grid depends on the real environment. NOTE 3: The safe distance between pedestrian/vehicle and transmission station/line is 0.7m/0.95m [46]. |  |  |  |  |  |  |  |  |  |  |  |   
## 5.23 Use case on AMR collision avoidance in smart factories
### 5.23.1 Description
Autonomous mobile robots (AMR) are currently being introduced in many
logistics operations, e.g. manufacturing, warehousing, cross-docks, terminals,
and hospitals. Compared to an automated guided vehicle (AGV) system in which a
central unit takes control of scheduling, routing, and dispatching decisions
for all AGVs, AMRs are robots built with intelligence to autonomously move and
perform tasks. AGVs is expected to further be evolved into intelligent AMR to
meet the demand of intelligent factory.
Compared to AGVs which move on transport paths guided by rails, magnetic
markers etc. AMRs can travel automatically without derivatives or guides. AMRs
don't rely on predetermined paths, they can easily adjust routes as user
demands change, so AMRs have wider mobile range and more flexibility. AMRs can
not only stop on time to avoid humans and other obstacles, but also adjust its
route for its destination. However, during the AMR working process, the
sensing range of a single AMR is limited and the AMR surrounding environment
status may be not detected in time. For example, People or other machines that
suddenly appear from behind the large factory equipment can affect the driving
safety of the AMR. So, it is very challenge for AMR to get accurate and
continuous sensing information along its route.
5G base stations can be deployed in a factory not only to provide
communication capabilities for equipments in the factory but also sense the
surrounding environment e.g. obstacles or people in the trajectory of AMRs.
Base stations transmit the sensing signals and receive the reflected signals
to get sensing information, then reports the real-time 3GPP sensing data to
the core network. The core network can process and analyze the 3GPP sensing
data for outputting the sensing result. Such sensing result can be exposed to
a trusted third-party e.g. automation platform of the factory to enables AMRs
to know more information about the surrounding environment to improve
efficiency and driving safety.
In addition, when there are obstacles (e.g., the large factory equipment) to
block the transmission of radio signals or AMR trajectory is across indoor and
outdoor, multiple base stations with sensing capability can work together to
improve the sensing accuracy and sensing service continuity.
### 5.23.2 Pre-Conditions
5G Network operator 'MM' provides 5G sensing service in the factory of Company
A. Its 5G system has been deployed covering the factory to provide continuous
sensing service indoor and outdoor.
Company A has placed two AMRs (AMR 1 and AMR2) in its factory for moving goods
from workshop A to workshop B. At the same time, there are people moving
around in both workshops, and other goods or tools may be temporarily placed
on the route of the AMRs. The people walking in the workshop and the goods may
block the AMR route, jeopardizing production safety. In addition, the two AMRs
may collide considering their flexible routes.
The AMRs of Company A uses '5G Sensing Service' provided by 5G network
Operator 'MM' during they are working. In order to ensure data security, the
related sensing data is not permitted to be delivered outside Company A.
### 5.23.3 Service Flows
Figure 5.23.3-1 shows the route change of AMR1 in the process of carrying
goods.
{width="6.695138888888889in" height="3.188888888888889in"}
Figure 5.23.3-1: Sensing People or obstacles detection in smart factory
  1. The AMR#1 is delivering the car parts from workshop A to Sam who is near the assembly line in workshop B.
  2. The 3GPP sensing data collected by Base station #1/RAN, the 5G network processes the 3GPP sensing data to obtain sensing results and detects the proximity of obstacles along the trajectory of AMR#1. 5G system provides the sensing result to the AMR#1, and AMR#1 then re-route and bypass the obstacles based on the sensing result.
  3. AMR#1 is leaving the Workshop A and across from indoor to outdoor.
  4. The 3GPP sensing data is collected by Base station #2/RAN, the 5G network processes the 3GPP sensing data to obtain sensing results and detects the proximity of Daming who is walking across the trajectory of AMR#1. 5G system provides the sensing result to the AMR#1, then AMR#1 stops to wait for Daming to leave.
  5. AMR#1 enters the Workshop B.
  6. The 3GPP sensing data is collected by Base station #3/RAN, the 5G network processes the 3GPP sensing data to obtain sensing results and detects the AMR#2 near AMR#1. 5G system provides the sensing result to AMR#1, then AMR#1 re-routes and bypasses the obstacles based on the sensing result.
  7. When AMR#1 enters the coverage of Base Station #4, using the 3GPP sensing data from Base station #4/RAN, the 5G network processes the data to obtain sensing results and detects the proximity of John who is behind a large machine. 5G system provides the sensing result to AMR#1, then AMR#1 stops and waits for John to leave.
AMR#1 successfully delivers the car parts to Sam in workshop B.
### 5.23.4 Post-Conditions
Based on the communication and sensing services provided by the 5G network,
the AMRs in the factory operate normally and reduce safety incidents.
### 5.23.5 Existing features partly or fully covering the use case
functionality
None.
### 5.23.6 Potential New Requirements needed to support the use case
[PR 5.23.6-1] The 5G system shall be able to provide the continuity of sensing
service for a specific target object, across indoor and outdoor.
[PR 5.23.6-2] The 5G system shall be able to provide a secure mechanism to
ensure sensing result data privacy within the sensing service area.
[PR 5.23.6-3] The 5G system shall be able to support the following sensing
related KPIs:
Table 5.23.6-1 Performance requirements of sensing results for AMR collision
avoidance in smart factories
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
AMR collision avoidance in smart factories | indoor/outdoor | 99 | ≤1 | N/A | 1 | N/A | 1 | 1.5 | ˂500 | 0.05 | N/A | 5  
NOTE 1: The terms in Table 5.23.6-1 are found in Section 3.1. NOTE 2: The KPI values are sourced from [47]. |  |  |  |  |  |  |  |  |  |  |  |   
## 5.24 Use case on roaming for sensing service of sports monitoring
### 5.24.1 Description
Sports monitoring application describes the case of a human being monitored
when doing exercise via utilizing wireless signals instead of cameras, or
wearable devices. With enhanced privacy preservation, wireless signals that
propagated in the 5G system (e.g. between 5G UE and 5G UE, and between the
radio access network and device) can be further reused and processed to
retrieve the target sensing object's characteristics [48]. In a sports
monitoring situation, the target object is human and the target object's
characteristic is human body gesture. By comparing the detected body gesture
with the correct body gesture when people are doing exercises like sit-ups,
and push-ups, this sport monitoring application will give feedback, for
example, it can count the number of the exercise e.g. sit-ups, and calculate
calories.
### 5.24.2 Pre-conditions
The sports monitoring application provider has a service agreement with mobile
operator A in country X and mobile operator B in country Y.
Mobile operator A in country X and Mobile operator B in country Y has roaming
agreements.
Bob installs a sports monitoring application on his mobile phone and
subscribes to the sensing service with mobile operator A.
### 5.24.3 Service Flows
1\. Bob is a sports fan and does exercise every day. He travels to country Y
and gets accommodation in hotel M, where mobile operator B's sensing service
is available. Bob triggers the application and selects his favorite sport,
sit-up.
2\. The sensing request is received by Mobile operator B and Mobile operator B
then authorize whether the sensing request can be satisfied or allowed, e.g.
by verifying the sensing system availability (infrastructure, sensing
modalities), the location of the sensing service, local privacy restrictions,
the roaming agreement with Bob's home mobile operator A in country X, the
identity of Bob and etc.
3\. If the authorization succeeds, mobile operator B authorizes and provides
such 5G sensing service to Bob with required performance targets and
requirements and Bob pays for the sensing service to mobile operator B.
  * Mobile operator executes sensing measurement process (e.g. micro doppler shift) with the sensing entities (e.g. RAN entities and the roaming UE, or CPE and the roaming UE) to obtain 3GPP sensing data;
  * Mobile operator processes the 3GPP sensing data to derive sensing result and expose it to the application server.
4\. If the authorization fails, mobile operator B does not provide such 5G
sensing service to Bob and potentially, Bob or the sports monitoring
application server will receive the reason of why mobile operator B cannot
provide such sensing service.
5\. Later, Bob left the hotel to run around the area near the hotel. When Bob
runs near a restricted area where sensing service is not allowed, the Mobile
operator B revokes the authorization and terminates the sensing service.
Potentially, Bob or the sports monitoring application server will receive the
reason of why mobile operator B cannot provide such sensing service.
### 5.24.4 Post-conditions
Bob can enjoy the sports monitoring application even when he travels in
another country.
### 5.24.5 Existing features partly or fully covering the use case
functionality
Roaming-related authentication and charging may refer to existing requirements
as defined in Clause 9 in TS22.261:
The following set of requirements complement the requirements listed in 3GPP
TS 22.115. The requirements apply for both home and roaming cases.
The 5G core network shall support collection of charging information for
alternative authentication mechanisms
The 5G system shall be able to generate charging information regarding the
used radio resources e.g. used frequency bands.
### 5.24.6 Potential New Requirements needed to support the use case
[PR 5.24.6-1] Based on operator policy, the 5G System shall be able to provide
the 5G wireless sensing services in case of roaming.
[PR 5.24.6-2] 5G network shall provide means for mobile operator to provide /
revoke authorization for the operation(s) of a 5G wireless sensing service
based on location, time, specific KPI level and the origin of the request.
[PR.5.24.6-3] The 5G system shall be able to provide 5G wireless sensing
service with the following KPIs:
Table 5.24.6-1 Performance requirements of sensing results for sports
monitoring
Scenario | Sensing service area | Confidence level [%] | Human motion rate accuracy [Hz] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency[ms] | Refreshing rate [s] | 
> Missed detection [%]
|
> False alarm [%]
|  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | 
> | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Sports monitoring | Indoor (living room) | 95 | 0.05 NOTE 2 0.07 NOTE 3 | N/A | N/A | N/A | N/A | N/A | N/A | 60s | 1min | N/A | N/A  
NOTE 1: The terms in Table 5.24.6-1 are found in Section 3.1. NOTE 2: Sit-up rate = 30 times/min as reference, 0.05Hz corresponds to 3 times/min. NOTE 3: Push-up rate = 40 times/min as reference, 0.07Hz corresponds to 4 times/min. |  |  |  |  |  |  |  |  |  |  |  |  |   
## 5.25 Use Case on immersive experience based on sensing
### 5.25.1 Description
Sensing based on the 5G signals is a technology using the difference between
wireless signals and its reflective signals including the Doppler frequency
shift, time of flight (ToF), amplitude variation and so on, to sense the
surroundings. The information collected during sensing cannot be directly
understood by human beings, providing good privacy protection. Along with 5G
stepping into the home, more interesting functions can be introduced based on
the sensing using 5G signals.
It will be fantastic to have an immersive audio and light experience when
watching movies and listening to music in the home. The speakers can provide
this kind of audio experience if they can know the position of each other and
also the user. Usually, to have immersive audio experience, several speakers
are needed. Ranging technology can help the speakers to determine position
relative to each other and this gives a chance for speakers to provide a
fantastic experience together to a listener by adjusting the audio field at a
place when the listener stays at that special place.
Different from ranging service where only the UE's position can be identified,
sensing can identify the relative position of the reflector even the reflector
is not a UE. If the speakers can obtain the sensing results, this will give a
chance to the speakers to follow the listener and provide an immersive audio
experience, even when the listener is moving around. The speakers can follow
the position of the human and adjust the audio field anytime anywhere. Similar
to the audio case, if the smart light can obtain the sensing results, the
light can also track the user anytime anywhere to provide an immersive
experience.
For the immersive experience scenario, the audio field and light adjustment
should be based on the user's position. For example, the smart screen, lights
and speakers can provide immersive sound and light experience for the user who
sits at the sofa area (around 2\~3m^2^ area) and at the same time lower the
sound volume and turn down the light at other places of the home avoiding the
interference on others. The sensing node (e.g., smart screen, i.e., a UE) can
perform sensing operations to track the user's movement using RF signals [29]
and provide the information to the speakers and lights for adjustment. Then
both the lights and speakers can provide a cosy zone around the user.
In home, there is usually a mixed deployment of smart screen, lights, and
speakers. We take smart screen as the sensing node as an example. Assume that
the smart screen, the smart lights, and the speakers are placed in the
drawing-room, and the smart screen can sense the object in the room as shown
in Fig. 5.25.1-1. The smart screen (i.e., UE) can receive the reflected
sensing signals transmitted by UEs in the room, or by the gNB to perform
sensing operation on the user in the room.
{width="3.0305555555555554in" height="1.926388888888889in"}
Figure 5.25.1-1: Example deployment of the smart screen, speakers and lights
The smart screen can track the user's position via sensing operation. Each
user is assumed to occupy an area 0.5m * 0.5m and move with a speed lower than
2m/s in horizontal dimension. Then the audio field and light can be adjusted
based on the user position (e.g. an area 1.5m * 1.5m) to avoid the experience
deterioration even when the user is walking around.
To identify multiple users in the room, in the horizontal dimension, the
resolution requires to distinguish objects as large as 0.5m. With higher
accuracy on distance, each user in the room can be identify with a more
accurate location such as 0.2m, the light and audio can target the user better
[30]. If the results are accurate but out of date due to the movement of the
user, this will also degrade the experience as the cosy zone is lagging the
movement of the user. Consider the audio field and lights are adjusted in an
area with 1.5m * 1.5m, to avoid the experience deterioration, the service
latency should smaller than 0.5m/2m/s, i.e., 250ms. To track the user's
movement, the results need to be refreshed in 250ms, i.e., 4 times per second
(4 Hz).
{width="3.5027777777777778in" height="2.251388888888889in"}
Figure 5.25.1-2: Example of accuracy required for the use case
### 5.25.2 Pre-conditions
This use case is about Tom's home theatre plan. Tom bought a set of speakers,
and placed them in his home to create an immersive audio experience. Tom also
bought a set of smart lights to create an immersive light experience. Together
with a smart screen in home, these smart devices compose the home theatre.
According to the instruction of the speakers, and also based on the
availability of audio and power wiring Tom distributed the speakers in his
living room. The smart lights are installed on the ceiling of the room. After
detecting the position of each distributed speakers, the home theatre system
can adjust the audio field in Tom's home. After detecting the position of
smart lights, the home theatre system can control the light variation in home.
This detection mechanism of the speakers and smart lights is outside the scope
of this document.
There exists a sensing device in the home, which can sense Tom's position
without requiring Tom to take a UE with him. For example, the sensing node is
the smart screen belonging to the home theatre system at Tom's home. Based on
the sensing results from the sensing node, the home theatre system can adjust
the audio field and light based on the sensing results.
The home theatre system can be deployed by user where the smart screen, lights
and speakers communicate with each other via direct device communication using
unlicensed band. As an alternative, the home theatre system can be deployed
with the help of operator using licensed band when the units of the home
theatre system are in coverage. In this case, operator can control the
performing of sensing operation based on the location of the deployment of the
home theatre.
### 5.25.3 Service Flows
Tom activates his home theatre and the speaker begin to play music based on
the audio on demand. The sensing device in the room (i.e., Smart screen)
performs sensing operation and the sensing results begin helping adjust the
audio field.
{width="6.0in" height="1.8958333333333333in"}
Figure 5.25.3-1 Immersive experience with tracking light and sound
Tom immerses himself in music and begins to dance. The sensing device (e.g.,
smart screen) tracks Tom's position via the processing of the receiving
sensing signals, the Sensing result is calculated, and the Sensing result is
sent to the control unit of the home theatre system.
Based on the sensing results, the home theatre system can adjust the audio
field and lights according to Tom's movement.
Thanks for the sensing service provided by the sensing node (e.g. smart
screen), no matter where Tom stands, he always experiences the best surround
sound and tracking light.
### 5.25.4 Post-conditions
Thanks to the sensing service provided in the intelligent home, Tom can have
an immersive experience via his home theatre.
### 5.25.5 Existing features partly or fully covering the use case
functionality
None.
### 5.25.6 Potential New Requirements needed to support the use case
[PR 5.25.6-1] The 5G system shall be able to configure and authorize sensing
for a Sensing device or a group of Sensing devices when using licensed
spectrum based on the Sensing device's location.
[PR 5.25.6-2] The 5G system shall be able to enable a Sensing device to
perform sensing with licensed band under operator's control based on the
Sensing device's location.
[PR 5.25.6-3] The 5G system shall be able to enable UEs without 5G coverage to
use unlicensed spectrum to perform sensing.
[PR 5.25.6-4] Subject to user consent and national or regional regulation,
based on operator policy, the 5G system shall be able to allow a Sensing
device to provide sensing results to a trusted third party.
[PR 5.25.6-5] The 5G system shall be able to provide sensing with following
KPIs:
Table 5.25.6-1 Performance requirements of sensing results for immersive
experience
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Immersiveexperience | Indoor | 95 | 0.5 | 0.5 | 0.1 | N/A | 0.5 | N/A | 250 (granularity of field is 1.5m x 1.5m) | 0.25 | 5 | 5  
NOTE: The terms in Table 5.25.6-1 are found in Section 3.1. |  |  |  |  |  |  |  |  |  |  |  |   
## 5.26 Use case on accurate sensing for automotive manoeuvring and navigation
service
### 5.26.1 Description
It is forecasted that there will be approximately 8 million autonomous or
semi-autonomous vehicles on the road by 2025 [49]. NR wireless sensing will
assist with automotive manoeuvring and navigation, especially in scenarios
where single car-mounted sensors collecting information is not enough for
making safe and reliable decisions, e.g. to avoid a collision, pedestrians,
etc.
This scenario reuses the use case as defined in section 5.8, where NR wireless
sensing is utilized to assist automotive manoeuvring, i.e. sensing results
play an important role in making the manoeuvring decisions. However, the
sensing environment when RAN entities and UEs execute the sensing measurement
process may be subject to high interference (e.g. interference caused by
adjacent RAN entities, radars, fake base stations) and cause the sensing
information as collected to be wrong.
The sensing information provided to the Automated Driving System (ADS) server
needs to be fully trustworthy: reliability, integrity, high confidence level
and protection against tampering are key aspects. Users (and third parties)
should not be able to fraud the ADS Server by tampering with the sensing
information in order to influence the manoeuvring decision.
### 5.26.2 Pre-conditions
Refer to 5.8, where Bob's vehicle is detected to be blocked by other vehicle
and cannot do the decision for autonomous driving with sensors collected data
(e.g. from lidar, radar, camera, etc). Bob recognizes the needs of 5G system
assistance and requests 5G System for coordination of the sensing service.
### 5.26.3 Service Flows
1\. Bob drives in downtown, and is approaching a crossroad with regulatory
signs, where the sensors on Bob's vehicle are blocked by other vehicles. Bob's
vehicle cannot see the surroundings and Bob sends the sensing request to 5G
system.
2\. The 5G system gives instructions about how to proceed the sensing to Bob's
vehicle and Bob's vehicle selects Joe's vehicle to assist the sensing service.
Joe's vehicle transfers the sensing contextual information to Bob's ADS
server.
3\. Bob's ADS server utilizes the sensing contextual information to do the
decision, Bob decelerates before the traffic light.
4\. Bob continues the journey and drives in a tunnel (10km length), the
sensors on Bob's vehicle are detected to be blocked by a big truck. Bob sends
the sensing request to 5G system.
5\. The 5G system selects RAN entities (e.g. road side units) to assist the
sensing service. The 5G system transfer the sensing information collected by
RAN entities to Bob's ADS server.
6\. Bob's ADS server utilizes the sensing information to do the decision, and
Bob accelerates to overtake the big truck.
7\. Bob continues the journey and drives in a desert area and some sensors on
Bob's vehicle are detected to be broken (e.g. because of heat). Bob's vehicle
sends the sensing request to 5G system.
8\. The 5G system selects RAN entities (sparsely deployed in desert area) to
assist the sensing service. With the feedback from RAN entities, the 5G system
transfer the sensing information together with the indication of confidence
level as 60% to the ADS server.
9\. Bob's ADS server utilizes the indication and sensing information, and
decides to return to Level 0 driving for safety.
### 5.26.4 Post-conditions
Bob's vehicle is able to drive with high reliability by utilizing accurate 5G
sensing service.
### 5.26.5 Existing features partly or fully covering the use case
functionality
None.
### 5.26.6 Potential New Requirements needed to support the use case
[PR 5.26.6-1] The 5G system shall be able to determine the confidence level of
the sensing results.
## 5.27 Use case public safety search and rescue or apprehend
### 5.27.1 Description
The ability to quickly locate an individual that is either missing (search and
rescue) or is a suspect in an illegal activity (apprehend) is very important
for public safety. Statistics show that the quicker a missing person can be
found the higher the possibility they can be found in good condition.
Similarly for a suspect in an illegal activity, the quicker they can be
located the less likely they can hide or commit another illegal activity.
These activities can be in both an outdoor environment and indoors.
Leveraging the sensing capability of a 3GPP network and integrating the
feature with other 5G capabilities (e.g., metaverse, augmented reality,
location, network relay, etc.) can provide a huge advantage to public safety.
In an outdoor example, an elderly person with Alzheimer's Disease wanders off
into the woods and does not know how to return. The longer it takes for public
safety to locate this person the more likely they may suffer injuries or
medical issues, such as dehydration, cuts, bruises, broken bones, or worse,
death. Another example is an individual who robs a bank and escapes into the
nearby forest and swamps. The longer it takes to track down and find the
individual, the more difficult it becomes and the bigger the risk of them
taking hostages, hurting others, or escaping completely.
With the density of base station deployments and with large numbers of 5G
enabled UE's, the 5G coverage includes a large amount of the territory of most
countries. These base station signals and the signals of UE's can also be used
to sense the environment for object detection.
Assumptions for this use case:
  * Trusted third-party applications for interpreting and presenting the data to public safety is required,
  * Devices must be trusted and communicate information togethers; and
  * Precision 3-axis location is needed.
An indoor example would be a firefighter entering a building with limited or
no visibility using sensing integrated with firefighter heads-up displays/UEs
(metaverse/AI/ML) sensing can better allow the firefighters to locate possible
people trapped inside and allow them a better view of the rooms as they work
through the building.
Indoor 5G coverage can be challenging but leveraging features like UE-to-UE
relay, UE-to-Network Relay, UE-to-Network multi-hop relay and UE-to-UE multi-
hop relay and allowing the devices to work together can provide good coverage
and capability to provide indoor sensing services in this challenging
environment.
Assumptions for this use case:
  * The use of UE-to-Network Relay and UE-to-UE relay can provide a more reliable connectivity.
  * Devices must be trusted and communicate information togethers; and
  * Precision 3-axis location is needed.
### 5.27.2 Pre-conditions
1) Operator A's network supports sensing capability with their base stations
and have 3GPP sensing enabled UEs on their network.
2) Local public safety officials have a relationship with Operator A allowing
them to access the networks sensing capability and service.
3) Appropriate security and privacy requirements are in place between the
operator and the public safety organization.
### 5.27.3 Service Flows
1) Public safety is notified of a need to search for an individual. This could
be either a search and rescue, or an apprehend scenario and could involve both
indoor and outdoor environments.
2) Operator A's network is 3GPP sensing enabled and public safety's UEs are
3GPP sensing enabled.
3) Public safety personnel begin searching for the individual using both
traditional methods, UAVs and UE's with 3GPP sensing capabilities.
4) Depending on coverage there may be a need to leverage indirect network
connections.
5) Using the 3GPP sensing data and non-3GPP sensing data public safety can
quickly locate the person of interest.
6) The individual is located using the combinations of capabilities.
### 5.27.4 Post-conditions
The individual is located faster than without 3GPP sensing capability. The
additional harm that might have occurred to the individual or community is
avoided.
### 5.27.5 Existing features partly or fully covering the use case
functionality
TBD
### 5.27.6 Potential New Requirements needed to support the use case
[PR.5.27.6-1] The 5G system shall support exposing the information of sensing
result (e.g., location, relative location, velocity vectors, relative
headings, etc.) to the trusted and secure mission critical applications.
[PR.5.27.6-2] The 5G system shall support mechanisms for combining 3GPP
sensing data and non-3GPP sensing data (e.g., body cameras.) depending on
location, availability of non-3GPP sensing data, and public safety
applications.
[PR.5.27.6-3] The 5G system shall support security and protection of the 3GPP
sensing data, non-3GPP sensing data, and sensing results.
[PR.5.27.6-4] The 5G system shall provide a secure sensing service for Mission
Critical Services.
[PR.5.27.6-5] The 5G system shall be able to provide the sensing service with
the following KPIs:
Table 5.27.6-1 Performance requirements of sensing results for public safety
search and rescue or apprehend
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Search and Rescue/Apprehend | Outdoor/Indoor | 99 | ≤ 0.5 | ≤ 1.0 | Pedestrian: ≤1.5 | Pedestrian: ≤1.5 | 3 | Horiz: 5 Vert: 5 | ≤1s | ≥10Hz | [≤3] | [≤3]  
NOTE: The terms in Table 5.27.6-1 are found in Section 3.1. |  |  |  |  |  |  |  |  |  |  |  |   
## 5.28 Use case on Vehicles Sensing for ADAS
### 5.28.1 Description
Advanced Driving Assistance System(ADAS) uses various sensors (Wireless
Sensing millimeter wave radar, lidar, monocular / binocular camera and
satellite navigation) installed on the vehicle to sense the surrounding
environment at any time during the driving process, collect data, identify,
detect and track static and dynamic objects, and carry out systematic
calculation and analysis in combination with navigation map data, so as to
make the driver aware of the possible dangers in advance, and effectively
increase the comfort and safety of driving.
{width="4.95in" height="3.183333333333333in"}
Figure 5.28.1-1 ADAS overview
There is an opportunity for 3GPP New Radio (NR) based sensing technologies to
be added into ADAS. 5G based wireless sensing service could improve the ADAS
reliability and quality.
The ADAS has the map information, the real time location/ trajectory of the
car and can assist the car driving, e.g. stop the car for avoiding collision.
The car (as 3GPP UE) is equipped with 3GPP NR based sensing technology. When
the UE initially accesses the 5G network, the UE is authorized by the 5G
network to participate in sensing under the operator's control. The 3GPP
sensing data is from the NR based sensor, and the sensing result is sent to
the ADAS system of the car. Collaborating with other non-3GPP sensing
devices/technologies, NR based sensing result as input to ADAS could improve
the comfort and safety of driving.
The vehicle as a 3GPP UE based sensing sensor is important for automotive use
cases, it can operate under network control & complements network-based
sensing. Network based sensing alone cannot fully address the automotive use
case needs, e.g.:
  1. There may be a blockage from the network (base station) to the sensed target.
  2. ADAS concerns more on relative positioning other than absolute position. Network based sensing introduces additional errors (due to compounding errors of two separate positions).
  3. Automobiles applications may determine sensing priority/performance requirements locally (not visible to gNB).
UE based sensing resources allocations can be under the control of the network
(e.g. base station). For UEs inside the coverage of enhanced network for
sensing, resources can be directly controlled. Sensing results of the
automobiles can be shared via 3GPP connections (Uu or PC5).
It is expected that the 3GPP NR sensing service for ADAS should meet the
requirement and level of commercial ADAS radar sensing performance. Based on
requirements for existing automotive sensors, the RF based sensing
requirements for automotive applications are as the following table.
Table 5.28.1-1 RF based sensing requirements for automotive applications of
existing automotive sensors
+----------------------+----------------------+----------------------+ | Parameter | Typical Automotive | | | | Radar KPIs | | +----------------------+----------------------+----------------------+ | | Long Range Radar | Short Range Radar | | | [10][12][20 | [10][12][20 | | | ][50][51][52] | ][52][53][54] | +----------------------+----------------------+----------------------+ | Maximum range | 250-300m | 30-100m | | | | | | | (for RCS of 10dBsm | | | | with >90%detection | | | | probability) | | +----------------------+----------------------+----------------------+ | Range resolution | 10-75cm | 5-20cm | +----------------------+----------------------+----------------------+ | Range accuracy | ±10 to ±40cm | ±2 to 10cm | +----------------------+----------------------+----------------------+ | FOV azimuth | ±9-15deg | ±60-85deg | +----------------------+----------------------+----------------------+ | Azimuth resolution | 1-3deg | 3-9deg | +----------------------+----------------------+----------------------+ | Azimuth accuracy | ±0.1-0.3deg | ±0.3-5deg | +----------------------+----------------------+----------------------+ | Update rate | 5 to 20 fps | 20 to 50 fps | +----------------------+----------------------+----------------------+ | Max one-way velocity | ±50m/s to ±70m/s | ±30m/s | +----------------------+----------------------+----------------------+ | Velocity resolution | 0.1 --0.6 m/s | 0.1 - 0.6 m/s | +----------------------+----------------------+----------------------+ | Velocity accuracy | ±0.03m/s to ±0.12 | ±0.03m/s to ±0.12 | | | m/s | m/s | +----------------------+----------------------+----------------------+
Although all vehicles on the road are expected to be equipped with NR radio,
but not necessarily utilizing them for 100 percent of time. Enabling NR radio
based sensing for ADAS can be a better utilization of the capability and radio
resources.
### 5.28.2 Pre-conditions
The 3GPP UE in the car has 3GPP subscription and is authorized by the operator
to perform sensing.
### 5.28.3 Service Flows
Figure 5.28.3-1 ADAS
1\. Tom buys a new car with the latest ADAS equipped.
2\. Tom wants to drive the car from home to the company in the morning of a
working day. Tom drives from home to the road. The 3GPP NR based sensor in
Tom's car transmits the 3GPP NR signal to the other car(s) in the same road,
and receives the reflected signal to detect the distance and speed of the
other car(s) to feed to the ADAS in Tom's car.
3\. While the car is driving on the highway, suddenly a car is stopped before
the Tom's car due to an accident, fortunately it is timely detected by the NR
based sensor.
4\. The NR based sensors send the collision warning to the ADAS, the ADAS
stops the car immediately.
5\. Finally, Tom's car avoids a collision accident and leaves the highway
safely.
### 5.28.4 Post-conditions
With the safely driving experience provided by ADAS, Tom arrives in the
company safely and easily. Tom starts the daily work in the office.
### 5.28.5 Existing features partly or fully covering the use case
functionality
There are features of Sidelink positioning for the car moving along the LOS
road (e.g., using Sidelink positioning for car ranging on the same road),
which requires the participant cars are 3GPP UEs.
### 5.28.6 Potential New Requirements needed to support the use case
[PR 5.28.6-1] The 5G system shall be able to configure and authorize UEs
supporting V2X applications to perform sensing.
[PR 5.28.6-2] The 5G system shall be able to collect charging information for
UEs supporting V2X applications when performing sensing.
[PR 5.28.6-3] The 5G system shall be able to support the following KPIs:
Table 5.28.6-1 KPIs for Vehicles Sensing for ADAS
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency[ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
ADAS [long range Radar] | Outdoor | [95] | [≤1.3] NOTE 2 | ≤0.5 | [≤ 0.12] NOTE 4 | N/A | [0.4] NOTE 5 | [≤ 0.6] NOTE 4 | [50] | [≤ 0.2] | [≤ 10] | [ {width="3.0709919072615923in" | recognition | | > height="1.5484700349956255in"} | | | | - Human motion recognition | | | | | | - Keystroke detection | | | | | | - Touchless control | | | | | | - Sign language recognition | +----------------------------------+----------------------------------+
Figure 5.29.1-1 Gesture Recognition
In this use case, we focus on application of gesture recognition for touchless
control and immersive (i.e. XR) application.
For touchless control, the identified gestures are then interpreted to
specific behaviours or operations of the device, including locking/unlocking a
screen, increasing/decreasing volume, and navigating forward/backward web
pages.
For XR application, the position tracking and mapping of the human body is a
basic requirement that permeates XR application to provide the immersive
experience [55]. Hereby a variety of sensors are integrated in the XR devices
to measure the movement of the human body (e.g., head, eye, hand, arm, etc) in
order to simulate normal human mimicry. Besides, the hand tracking goes beyond
the simulation and enables a natural and intuitive way of the interaction
between the human and the machine compared with the use of the physical
controller. The gesture recognition and hand tracking becomes a vital function
in XR applications, especially when the human and the controlled object stay
in physical and virtual world separately.
For both touchless control and XR application, NR-based RF sensing is suitable
for gesture recognition because certain RF signals can detect coarse body
movements and the RF signals are not susceptible to the ambient illumination
condition and occlusions in the environment. In addition, NR-based RF sensing
allows for coarse hand tracking in a lower-complexity and economic manner.
### 5.29.2 Pre-conditions
There are two roommates, Jose and Bob, both of whom subscribed to MNO A, which
has deployed RAN entity (e.g., an indoor base station) supporting NR-based
sensing.
Jose subscribes to the touchless user interface service and his mobile device
has NR sensing capability.
Bob subscribes to the immersive interaction service, provided by both MNO A
and XR application (e.g. game, sports training) provider AppX on the access
rights of the interaction information relevant to Bob's hands. Bob's UEs (e.g.
smartphone, XR device such as headset) are capable of NR-based sensing and
Bob's XR device also have other sensors (e.g. IMU) embedded on the device.
### 5.29.3 Service Flows
**Social Media Navigation service with Gesture Recognition**
**Step 1** : Sitting in this room, Jose is reading through social media posts
using his smartphone, to navigate to either the previous or next posts. Jose
waves his hand in the air from left to right or from right to left.
**Step 2** : Jose's smartphone detects the hand gesture using 5G wireless
sensing using the RAN entity, UE or both. The smartphone and RAN entity can
send sensing data (with extracted gesture features such as range and Doppler
of the detected gesture) to the 5G network.
**Step 2b** : Alternatively, the Jose's smartphone detects the hand gesture
using sensing signals and process those signals to generate 3GPP sensing data
and sensing results. Also, the 3GPP sensing data can be further combined and
processed with non-3GPP sensing data at the UE to generate a combined sensing
result.
**Step 3** : 5G network then aggregates and processes the information
collected from the UE and RAN entity to detect Jose's gesture and provides the
sensing results to Jose's smartphone which is shared with the social media
application and used for the navigation of the post.
**Immersive interaction service with Gesture Recognition**
**Step 1** : Bob launches the XR application in his room, at which moment one
avatar is generated to represent him in the virtual world of the XR
application, and the immersive interaction service is activated as shown in
Fig 5.29.3-1.
**Step 2:** When Bob sees a basketball flying toward him, he catches the ball
and throws it back. The characteristics of the gesture (e.g. range, doppler
shift) are detected using NR sensing signals of UEs, the RAN entity or both.
**Step 3:** 5G network (e.g. 5GC) collects the 3GPP sensing data from UEs, RAN
entity or both, process the data and exposes the sensing result (e.g. 3D
position, velocity) to XR application. In parallel, the non-3GPP sensing data
obtained from the XR device is transmitted to the application platform
transparently through UE to 5GC.
**Step 3b** : Alternatively, 5G network can combine and process the 3GPP
sensing data and non-3GPP sensing data obtained from XR device for the same
posture, and then expose the combined sensing result(e.g. 3D position,
velocity) with the contextual information(e.g. time) to XR application
platform.
**Step 4:** The gesture and hand movement are recognized and the basketball
bounces to another direction as a sensing result. The entire course will be
presented on Bob's headset as that the basketball is caught by one hand of
Bob's avatar and thrown back.
{width="2.995398075240595in" height="1.5121719160104987in"}
Figure 5.29.3-1 Hand Tracking in XR applications
### 5.29.4 Post-conditions
Due to the RF sensing capability in Jose's mobile device and a nearby RAN
entity, Jose's gestures are detected and used to navigate the social media
posts on his phone.
Similarly, due to the RF sensing capability in Bob's smartphone, XR device and
a nearby RAN entity, Bob's coarse gesture and the motion of his hands will be
recognized and tracked correctly. The avatar in XR application will show the
correct gesture and execute the correct action triggered by the gesture.
### 5.29.5 Existing features partly or fully covering the use case
functionality
None.
### 5.29.6 Potential New Requirements needed to support the use case
[PR 5.29.6-1] The 5G system shall be able to provide sensing with the
following KPIs:
Table 5.29.6-1 Performance requirements of sensing results for gesture
recognition
Scenario | Sensing service area | Confidence level [%] | Motion rate accuracy | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency[ms] | Refreshing rate [s] | 
> Missed detection [%]
|
> False alarm [%]
|  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | 
> | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Gesture recognition | Indoor | 95 | N/A | 0.2 NOTES 4 and 5 | 0.2 NOTES 4 and 5 | 0.1 | 0.1 | 0.375 NOTES 1 and ,2 and 5 | 0.3 | 5 – 50 NOTE 3 | ≤0.1 | ≤5 | ≤5  
NOTE 1: Due to the resolution allowed by the KPIs above, the use of pre-defined gestures for determining a user’s basic hand gestures is assumed. NOTE 2: Assuming bandwith of 400 MHz, Tthe range resolution can beis determined using the formular C/2*B where C is the speed of light, B is the bandwidth (assuming B = 400 MHz which is supported in 5G mmWave networks.) NOTE 3: The value is derived from TS22.261 [33] clause 7.11 about max allowed end-to-end latency for immersive multi-modal KPIs. NOTE 4: Positioning accuracy KPIs are based on minimum supported positioning accuracy in 5G systems [TS 22.261] NOTE 5: By combining non-3GPP sensing data (if available) with 3GPP sensing data, some of these KPIs may be improved. |  |  |  |  |  |  |  |  |  |  |  |  |   
## 5.30 Use case on sensing for automotive manoeuvring and navigation service
when not served by RAN
### 5.30.1 Description
Consider the scenario defined in section 5.8, where NR wireless sensing is
utilized to assist automotive manoeuvring, i.e. sensing results play an
important role in making the manoeuvring decisions. However, in this section
the vehicles are not served by RAN when the Sensing activity is expected to
occur, where UE is not served by RAN and therefore RAN entities are unable to
be involved. UEs performing the sensing measurement process in this scenario
have to be able to operate when UE is not served by RAN.
### 5.30.2 Pre-conditions
Refer to 5.8, where Bob's vehicle determines the need for sensing service.
Bob's vehicle integrates a UE supporting V2X application i.e., Bob's vehicle
supports V2X. Sensing can be performed by 5G Wireless sensing. Unlike in
section 5.8, the vehicles are not served by RAN and perform 5G Wireless
sensing without help of the network entities. Bob's vehicle has been
provisioned by his home operator to be able to perform 5G Wireless sensing
when not served by RAN. There may be other vehicles or RSU (road side unit)
helping the 5G Wireless sensing of the Bob's vehicle.
### 5.30.3 Service Flows
1\. Bob is driving from urban to rural countryside. As his vehicle is
operational, in motion, and attempting to assist his driving using ADS, Bob's
vehicle is performing sensing using 5G Wireless sensing.
2.Bob drives his vehicle outside the coverage area of its mobile network. The
5G Wireless sensing continues providing assistance to Bob's driving.
3\. Bob's vehicle approaches Joe's vehicle.
4\. Bob's vehicle becomes aware of Joe's vehicle by Bob's onboard Sensing
receiver(s) receiving 5G Wireless sensing reflected by Joe's vehicle.
5\. Bob's vehicle applies this new object information to the local ADS
function to ensure a safe, collision-free, drive.
### 5.30.4 Post-conditions
Bob's vehicle is able to drive with high reliability by utilizing 5G sensing
service when not served by RAN.
### 5.30.5 Existing features partly or fully covering the use case
functionality
None.
### 5.30.6 Potential New Requirements needed to support the use case
[PR 5.30.6-1] The 5G system shall be able to provide mechanisms for an MNO to
configure UEs supporting V2X application for 5G Wireless sensing operation
when not served by RAN.
[PR 5.30.6-2] Subject to regulation, the 5G system shall enable UEs supporting
V2X application to perform 5G Wireless sensing when not served by RAN using
the allowed ITS spectrum and unlicensed spectrum.
## 5.31 Use case on blind spot detection
### 5.31.1 Description
Blind spot detection reduces the risk of accidents during lane changes by
monitoring the dangerous blind spot area [26]. The blind spot area is a
typically a moving target area that changes when car moves if we take the road
infrastructure as reference point. Currently, the blind spot detection system
operates via a variety of external sensors located on a car's bumpers and wing
mirrors, which can detect if a person or vehicle enters your blind spot,
notifying you via an audible or visual cue - typically, a warning light
located in the car's wing mirror.
{width="4.6in" height="1.1742147856517935in"}
Figure 5.31.1-1: blind spot detection system, a moving target area.
Wireless sensing technology can be utilized to detect obstacles that presents
in car's blind spot area:
  * Case I: Base stations on the roadside are already used to provide 5G coverage for communication, and the radio signals that are reflected can be used to sense the blind spot area of a car.
  * Case II: Base stations on the roadside are already used to provide 5G coverage for communication, and the radio signals that are received by the UE (i.e. the car is a 3GPP UE, or there is a 3GPP UE such as smartphone on the car) can be used to sense the blind spot area of the car.
Any obstacle that presents in the car's blind spot area, no matter the
obstacle is moving (e.g. car, motorcycle, walking human, animal etc) or static
(building, tree), will affect the reflected/received signals. By deriving the
characteristics of the affected signals, obstacle can be detected, and danger
can be avoided. It is convenient to utilize current deployed 5G network system
to achieve this blind spot detection.
This use case is to reuse 5.8 to describe the blind spot detection aspects.
### 5.31.2 Pre-conditions
MNO provides blind spot detection sensing service to different kinds of
subscribers:
\- Bob's car is a 5G UE and subscribes to this sensing service. His car has
NR-based sensing technology and capabilities such as NR-based sensing
capabilities, sensing processing capabilities are also provided to the MNO.
\- Juan's car is not a 5G UE, but his 5G UE (smartphone) subscribes to this
sensing service, where an application is installed on the 5G UE.
\- Alex's car is not a 5G UE, an application installed on his car subscribes
to this sensing service.
Laura has no subscription to the blind spot detection sensing service.
### 5.31.3 Service Flows
Step 1: Bob, Juan, Alex and Laura are friends and driving together to Alps
skiing resort. At 8:00am, Bob starts from Street A, Juan and Alex start from
Street B and Laura start cars from Street C. Bob, Juan and Alex trigger the
blind spot detection sensing service separately.
Step 2: When received the service request, 5G system discovers and configures
sensing transmitter(s) and sensing receiver(s) to track and monitor the moving
car's blind spot area (from sensing transmitter's perspective), e.g.:
  * Bob's car is a 5G UE and has NR-based sensing capabilities, 5G system configures base station(s) as sensing transmitter and Bob's car as the sensing receiver. The moving blind spot area is tracked by Bob's 5G UE.
  * Juan's car and Alex's car are not 5G UE. 5G system configures base station(s) as sensing transmitter and sensing receiver. Juan's car's moving blind spot area and Alex's car's moving blind spot area are separately tracked by 5G base station.
Step 3: 3GPP sensing data is collected by sensing receiver and transferred to
the network sensing processing entity to derive the sensing result, which is
then exposed to the service consumer to fetch out whether there is obstacle
presence in the blind spot area, e.g.
  * Bob's car is a 5G V2X UE and has processing capabilities, 5G system authorizes 5G UE as sensing processing entity.
  * Juan's car is not a 5G V2X UE, but Juan has his smartphone (5G UE) carried in car, 5G system authorizes 5G UE as sensing processing entity.
  * Alex has no 5G UE on board, 5G network processes the 3GPP sensing data to derive sensing result.
Step 4: A car is moving very fast from Street A to Street B to Street C and
presents sequentially in Bob's, Juan's Alex's and Laura's blind spot area.
  * Bob is changing lane, the moving car is detected and Bob safely changed lane.
  * Juan and Alex turning left, the moving car is detected and they safely turned right.
  * Laura is overtaking a truck, the moving car suddenly presents in the blind spot area, Laura forgets the over-shoulder view and hits the moving car.
### 5.31.4 Post-conditions
Bob, Juan and Alex drive safely to the Alps skiing resort and enjoy their
holiday thanks to the blind spot detection sensing service.
Laura is in hospital.
### 5.31.5 Existing features partly or fully covering the use case
functionality
None.
### 5.31.6 Potential New Requirements needed to support the use case
[PR 5.31.6-1] The 5G System shall be able to provide sensing service to track
a moving target sensing service area.
## 5.32 Use case of integrated sensing and positioning in factory hall
### 5.32.1 Description
Autonomous Mobile Robots (AMR)s and automated guided vehicle (AGV) are
enabling solutions for a smart factory environment, in which a diversity of
logistic tasks are done with an autonomous and efficient implementation, with
minimal direct human engagement. In order to achieve a safe and efficient
operation to serve a desired goal (e.g., transfer of construction materials
with minimal risk, delay and energy consumption), a command center may take
over the task of collecting the information of the involved facilities and
performing a coordinated planning of the device operations. Nevertheless, a
safe and efficient operation of the mobile devices may be only achieved on the
condition of an accurate awareness of the environment (e.g., obstacles,
humans) and the device positioning/tracking information (e.g., AGV/AMR
position and velocity).
In view of the above, the 5G system shall serve the implementation of a smart
factory by means of a reliable data connectivity (e.g., the low-latency and
reliable AGV/AMR to command center connection) and positioning of the involved
AGV/AMR UE devices. Furthermore, the 5G system sensing services can be
utilized to augment the environment awareness by means of detecting and
locating the non-connected objects (e.g., obstacles such as trash box, or
safety-sensitive objects such as human, etc.).
In addition to the detection of the non-connected objects, the 5G system
sensing enables a higher positioning and tracking accuracy of a target UE at
the 5G system, by means of augmenting the positioning and sensing capabilities
[27]. In case of an AMR/AGV, the positioning measurement of a device can be
augmented at the 5G system with the 3GPP sensing data obtained from the
reflections of the sensing signal from the AMR/AGV physical body, in the
interest of a higher environment awareness and positioning accuracy, as well
as the additional information obtained via sensing of the AMR/AGVs (e.g.,
orientation of an AMR). In particular, when both 5G system sensing and
positioning services are activated, the same 5G system nodes (e.g., sensing Tx
nodes) and 5G system signals (e.g., positioning or sensing signals) can be
reused to efficiently generate and process the desired sensing and positioning
measurements, see Figure 5.32.1-1 as an example of a joint sensing and
positioning of a UE.
{width="5.569767060367454in" height="2.0059492563429573in"}
Figure 5.32.1-1 The 5G system obtains position estimate of a UE, utilizing
3GPP sensing data of the UE obtained from the 5G wireless sensing service, in
combination with the positioning measurement of the UE
The obtained higher positioning accuracy of an AGV/AMR is particularly
valuable for coordination of multiple AGVs and AMR with indeterministic
movement paths, wherein the situations involving sudden break and/or velocity
change may lead to a high delay, damage risk, and interruption energy loss.
5.32.2 Pre-conditions
Multiple AMR/AGVs are deployed in a factory hall belonging to the company
**X**. The AMR/AGVs are coordinated by a command center to perform a
collaborative construction task. The command center coordinates the AMR/AGVs'
movements to improve safety and to avoid energy loss (due to an AMR/AGV break)
and delay as much as possible.
To facilitate this, the factory hall is equipped with the 5G system sensing
services provided by the Mobile Network Operator (MNO) **A**. Moreover, the
AMR/AGVs are equipped with the 5G system communication and positioning
modules.
The company **X** has provided the MNO with the physical type/characteristics
of the deployed AMR/AGVs, as well as the installed camera data of the factory
hall to assist detection and positioning of the AMR/AGVs via sensing.
### 5.32.3 Service Flows
**Step 1:** [AMR/AGV is deployed to deliver goods]
AMR/AGV **Y** is assigned with a task for delivering needed material to a
construction site within the factory hall. The AMR/AGV is loaded with the
materials and departs from its initial location.
**Step 2:** [AMR position is obtained via 5G system positioning]
AMR/AGV moves from its initial position towards the construction site. The
position information of the AMR/AGV is obtained by the MNO **A** via the 5G
system positioning module of the AMR/AGV and reported to the command center.
The command center determines that the provided positioning accuracy of the
MNO **A** is sufficient since the AMR/AGV currently moves in the low-traffic
area of the factory hall. Based on the received positioning information of the
AMR/AGV, the command center recommends that AMR/AGV keeps its velocity towards
the construction site.
**Step 3:** [AMR/AGV position is obtained via a joint 5G system sensing and
positioning]
**_As the_** AMR/AGV **_moves towards the construction site, more objects
(other_** AMR/AGVs** _, humans, tools) appear in the vicinity. The command
center identifies that the_** AMR/AGV **_is now in a high-traffic area and a
higher positioning accuracy is desired._**
> **_The command center requests the MNO A to activate 5G system sensing
> service during the 5G system positioning service for positioning of the
> AMR/AGV UEs._**
**_MNO A activates sensing of the desired_** AMR/AGV areas to enhance
positioning of the AMR/AGV devices. **_MNO A identifies UE and/or gNBs capable
of sensing in the vicinity of the_** AMR/AGV **_and starts sensing measurement
process jointly with the 5G positioning measurements of the_** AMR/AGVs** _.
The 5G network obtains 3GPP sensing data of the identified nodes and generates
a high accuracy position estimate and/or additional sensing information of the
AMR/AGVs, based on the collected 3GPP sensing data in addition to the_**
AMR/AGV** _'s positioning measurements. The obtained positioning estimate of
the_** AMR/AGV is reported to the command center.
**_Based on the obtained high-accuracy positioning information of the_**
AMR/AGVs **_the command center adjusts the velocity of the_** AMR/AGVs** _._**
**Step 4:** [AMR reaches the construction site]
The AMR/AGV reaches the construction site and offloads the goods.
### 5.32.4 Post-conditions
Thanks to the 5G system based sensing service enabling an enhanced AMR/AGV
positioning and sensing of the environment, the involved AMR/AGVs are
coordinated to arrive at their destination with minimal risk and interruption
loss.
### 5.32.5 Existing feature partly or fully covering use case functionality
A UE equipped with 5G positioning module may obtain positioning information of
the UE based on the 5G positioning services. Moreover, the 5G system sensing
services shall support detection and positioning of an object. Nevertheless,
interpretation of an object's position as a UE's position (e.g., among
multiple detected objects), as well as a joint positioning and sensing of a UE
device as a physical object by the 5G system (when both 5G system services are
available to the UE) has not been enabled by the current requirements.
### 5.32.6 Potential New Requirements needed to support the use case
[PR 5.32.6-1] Based on operator's policy, the 5G system may provide a
mechanism for a trusted third party to provide sensing assistance information
about a sensing target.
[PR 5.32.6-2] The 5G system shall be able to provide sensing results with the
following KPIs:
Table 5.32.6-1 Performance requirements of the sensing results exposed to the
third party
Scenario | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |   
Indoor Factory | 100 m2 | 99 | [≤0.5] | N/A | 0.5 | N/A | [0.5] | [0.5] | ≤100 | 0.1 | N/A | N/A  
NOTE: The terms in Table 5.32.6-1 are found in Section 3.1. |  |  |  |  |  |  |  |  |  |  |  |   
# 6 Considerations
## 6.1 Considerations on confidentiality, integrity and privacy
### 6.1.1 General
When introducing sensing technology, new aspects on confidentiality,
integrity, and privacy need to be considered, to ensure that these aspects are
considered already when proposing service requirements.
For instance, with sensing technology by-standers can be affected in a
completely new way, previously only UEs have been able to be tracked but now
sensing capabilities may enable tracing and potentially identification of
anything in the environment, including humans that do not carry a UE, or any
objects. This has implications for privacy. Obviously humans should have a
right to privacy.
For privately owned areas, respective permission is required for sensing
operation from such as the homeowner for in-home sensing or the building
management for the in-building sensing.
For public areas, such as a public road, park and airport, it is required to
obtain the permission of the respective public area management.
It is important to have the user consent before the network uses UEs in
providing sensing service. If the sensing results and user ID are brought
together for further processing, user consent is also needed.
Of course, factors such as resolution, updating frequency, and type of
application influence the security implications.
Requirements to minimize the risk of unwanted usage and awareness of the usage
needs to be considered in stage 1. These are captured in the next chapter.
### 6.1.2 Potential New Requirements
A set of general new requirements can be identified:
[PR 6.1.2-1] The 5G system shall limit sending the sensing results only to
third party authorized to receive that sensing results.
[PR 6.1.2-2] The 5G system shall support encryption and integrity protection
of the sensing result, to protect the data inside the 5G system and when used.
[PR 6.1.2-3] The 5G system shall support appropriate level of sensing for both
situations where consent can be obtained from the sensing targets, and where
it cannot.
[PR 6.1.2-4] Subject to regulation, the 5G system shall obtain user consent
when sensing results and user identification are brought together for further
processing.
## 6.2 Considerations on Regulatory, Mission Critical and other priority
services
### 6.2.1 General
The sensing operation in Operator's network can support commercial services
(e.g. use case described in section 5.8 on sensing assisted automotive
manoeuvring and navigation). There could be areas where the network resources
are limited and prioritization (according to operator's decision) would be
needed among the resources used for sensing service and resources used for
other services (e.g. communication service).
In addition, sensing operation could also be used to support services such as
MCS (e.g. public safety, Utilities, Railways) and MPS with requirements for
priority treatment. The 5G system can provide flexible means for priority
treatment to the users of sensing services subject to regional/national
regulatory rules and operator policy.
### 6.2.2 Potential New Requirements
[PR 6.2.2-1] Subject to regulation and operator's policy, 5G system shall
provide prioritization among sensing services.
# 7 Consolidated potential requirements and KPIs
## 7.1 Consolidated functional requirements
## 7.1.1 General
Table 7.1.1-1 General Consolidated Requirements
+--------------+--------------------+----------------+---------+ | CPR # | Consolidated | Original PR # | Comment | | | Potential | | | | | Requirement | | | +==============+====================+================+=========+ | CPR 7.1.1-1 | The 5G system | PR 5.2.6-1 | | | | shall be able to | | | | | provide 5G | PR 5.9.6-1 | | | | wireless sensing | | | | | service in a | PR 5.11.6-1 | | | | sensing service | | | | | area location | P.R 5.14.6-1 | | | | using sensing | | | | | transmitters and | PR 5.1.6-2 | | | | sensing receivers. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-2 | Subject to | P.R 5.14.6-3 | | | | regulation and | | | | | operator policy, | P.R 5.13.6-7 | | | | the 5G network | | | | | shall be able to | PR 5.8.6-6 | | | | activate, | | | | | configure, and | | | | | deactivate 5G | | | | | wireless sensing | | | | | based on | | | | | parameters such as | | | | | location and | | | | | network conditions | | | | | (e.g. network | | | | | load). | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-3 | Subject to user | PR.5.4.6-1 | | | | consent, | | | | | regulation, and | PR 5.21.6-2 | | | | operator's policy, | | | | | the 5G system | | | | | shall be able to | | | | | collect non-3GPP | | | | | sensing data from | | | | | authorized | | | | | non-3GPP sensors | | | | | and securely | | | | | provide it to 5G | | | | | network. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-4 | The 5G system | PR 5.23.6 -1 | | | | shall support | | | | | continuity for 5G | PR 5.18.6.1 | | | | wireless sensing | | | | | service (e.g. for | | | | | sensing a moving | | | | | object). | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-5 | Subject to | PR 5.24.6-1 | | | | operator's policy, | | | | | the 5G System | | | | | shall be able to | | | | | provide the 5G | | | | | wireless sensing | | | | | service in case of | | | | | roaming. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-6 | Subject to user | PR 5.21.6-3 | | | | consent, | | | | | regulation, and | PR 5.4.6-4 | | | | operator's policy, | | | | | the 5G system | PR 5.27.6-2 | | | | should support the | | | | | combination of the | | | | | 3GPP sensing data | | | | | and non-3GPP | | | | | sensing data to | | | | | derive a combined | | | | | sensing result. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-7 | Subject to | PR 6.2.2-1 | | | | regulation and | | | | | operator's policy, | | | | | 5G network shall | | | | | provide | | | | | prioritization | | | | | among 5G wireless | | | | | sensing services | | | | | (e.g. prioritizing | | | | | between | | | | | communication and | | | | | sensing services). | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-8 | The 5G system | PR 5.25.6-3 | | | | shall be able to | | | | | enable UEs without | PR 5.1.6-5 | | | | 5G coverage to use | | | | | unlicensed | PR 5.25.6-2 | | | | spectrum to | | | | | provide 5G | | | | | wireless sensing | | | | | service. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-9 | Subject to | PR 5.30.6-2 | | | | regulation, the 5G | | | | | system shall | | | | | enable UEs | | | | | supporting V2X | | | | | application to | | | | | perform 5G | | | | | Wireless sensing | | | | | when not served by | | | | | RAN using the | | | | | allowed ITS | | | | | spectrum and | | | | | unlicensed | | | | | spectrum. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-10 | The 5G system | PR 5.12.6-2 | | | | shall be able to | | | | | provide sensing | PR 5.10.6-1 | | | | service to detect, | | | | | identify and/or | | | | | track one or more | | | | | objects (e.g., | | | | | UAVs, birds) and | | | | | their environment. | | | | | | | | | | Note: There is a | | | | | need to clarify | | | | | "identify" during | | | | | normative phase. | | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-11 | Based on | PR 5.2.6-4 | | | | operator's | | | | | policies, | PR. 5.3.6-1 | | | | operator's control | | | | | and regulation, | PR. 5.6.6-1 | | | | the 5G system | | | | | shall be able to | PR. 5.7.6-1 | | | | collect 3GPP | | | | | sensing data from | PR 5.8.6-2 | | | | sensing receivers | | | | | for processing. | PR.5.1.6-4 | | | | | | | | | | PR 5.9.6-3 | | | | | | | | | | PR 5.11.6-2 | | | | | | | | | | PR 5.13.6-3 | | | | | | | | | | PR 5.17.6-4 | | | | | | | | | | PR 5.2.6-5 | | | | | | | | | | PR. 5.3.6-2 | | | | | | | | | | PR 5.13.6-1 | | | | | | | | | | PR 5.21.6-1 | | +--------------+--------------------+----------------+---------+ | CPR 7.1.1-12 | Subject to | PR 5.22.6-2 | | | | operator's policy, | | | | | the 5G system may | | | | | be able to use | | | | | sensing assistance | | | | | information to | | | | | derive the sensing | | | | | result. | | | +--------------+--------------------+----------------+---------+
### 7.1.2 Configuration and authorization
Table 7.1.2-1 Configuration and authorization Consolidated Requirements
+-------------+---------------------+----------------+---------+ | CPR # | Consolidated | Original PR # | Comment | | | Potential | | | | | Requirement | | | +=============+=====================+================+=========+ | CPR 7.1.2-1 | The 5G system shall | PR 5.30.6-1 | | | | be able to provide | | | | | mechanisms for an | | | | | MNO to configure | | | | | UEs supporting V2X | | | | | application for 5G | | | | | Wireless sensing | | | | | service when not | | | | | served by RAN. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.2-2 | Subject to | PR 5.2.6-3 | | | | regulation and | | | | | operator's | PR 5.15.6-1 | | | | policies, the 5G | | | | | network shall be | PR 5.9.6-2 | | | | able to configure | | | | | and/or authorize or | PR 5.20.6-2 | | | | revoke | | | | | authorization of | PR 5.8.6-1 | | | | sensing service, | | | | | sensing | PR 5.8.6-4 | | | | transmitter(s) and | | | | | sensing receiver(s) | PR 5.28.6-1 | | | | for 5G wireless | | | | | sensing service. | PR 5.1.6-1 | | | | | | | | | NOTE: Such | PR 5.5.6-3 | | | | configuration and | | | | | authorization can | PR 5.11.6-4 | | | | be based on sensing | | | | | transmitter or | P.R 5.13.6-8 | | | | sensing receiver | | | | | location, specific | P.R 5.10.6-2 | | | | time, sensing | | | | | duration, sensing | PR 5.17.6-3 | | | | accuracy, target | | | | | sensing | PR 5.24.6-2 | | | | geographical area, | | | | | establishing of | | | | | communication to | | | | | transfer sensing | | | | | data, etc. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.2-3 | Based on location, | PR 5.25.6-1 | | | | the 5G network | | | | | shall be able to | PR 5.20.6-1 | | | | ensure that sensing | | | | | transmitters and | | | | | sensing receivers | | | | | use licensed | | | | | spectrum only in | | | | | network coverage | | | | | and under the full | | | | | control of the | | | | | operator who | | | | | provides the | | | | | coverage. | | | | | | | | | | NOTE 1: The above | | | | | requirement does | | | | | not apply for | | | | | public safety and | | | | | V2X networks with | | | | | dedicated spectrum, | | | | | where 5G wireless | | | | | sensing can be | | | | | allowed out of | | | | | coverage or in | | | | | partial coverage as | | | | | well. | | | +-------------+---------------------+----------------+---------+
### 7.1.3 Network exposure
Table 7.1.3-1 -- Network exposure Consolidated Requirements
+-------------+---------------------+----------------+---------+ | CPR # | Consolidated | Original PR # | Comment | | | Potential | | | | | Requirement | | | +=============+=====================+================+=========+ | CPR 7.1.3-1 | Subject to | PR 5.13.6-6 | | | | operator's policy, | | | | | the 5G network | | | | | shall be able to | | | | | provide secure | | | | | means to report | | | | | sensing result to a | | | | | trusted third-party | | | | | requesting | | | | | information about a | | | | | target object when | | | | | specific requested | | | | | conditions are met. | | | | | | | | | | NOTE: These | | | | | conditions could be | | | | | e.g. the target | | | | | object distance | | | | | from the restricted | | | | | area border or | | | | | entering restricted | | | | | area. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.3-2 | Subject to | PR 5.19.6-2 | | | | operator's policy, | | | | | the 5G network | | | | | shall be able to | | | | | provide secure | | | | | means to enable | | | | | trusted third-party | | | | | to request | | | | | discovering a | | | | | sensing group in | | | | | the proximity of | | | | | the UE that is | | | | | requesting a 5G | | | | | wireless sensing | | | | | service from | | | | | application server. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.3-3 | Subject to | PR 5.11.6-3 | | | | operator's policy | | | | | and regulation, the | PR 5.13.6-4 | | | | 5G network shall | | | | | provide secure | PR 5.12.6-3 | | | | means for a trusted | | | | | third-party to | PR 5.12.6-5 | | | | request 5G wireless | | | | | sensing service | PR 5.12.6-4 | | | | based on specific | | | | | parameters (e.g. | PR 5.5.6-1 | | | | refresh rate, | | | | | period of time, | PR 5.5.6-2 | | | | sensing KPIs, | | | | | geographical | PR 5.25.6-4 | | | | location) and to | | | | | receive the | PR 5.2.6-6 | | | | corresponding | | | | | sensing results. | PR 5.9.6-4 | | | | | | | | | | PR 5.7.6-2 | | | | | | | | | | PR 5.15.6-2 | | | | | | | | | | PR 5.14.6-2 | | | | | | | | | | PR 5.10.6-3 | | | | | | | | | | PR 5.13.6-5 | | | | | | | | | | PR 5.22.6-1 | | | | | | | | | | PR 5.27.6-1 | | | | | | | | | | PR 5.1.6-3 | | | | | | | | | | PR 5.4.6-2 | | | | | | | | | | PR 5.4.6-3 | | +-------------+---------------------+----------------+---------+ | CPR 7.1.3-4 | Subject to | PR 5.8.6-5 | | | | operator's policy, | | | | | the 5G system shall | PR 5.3.6-3 | | | | be able to provide | | | | | secure means for a | | | | | trusted third-party | | | | | to receive sensing | | | | | results with | | | | | contextual | | | | | information. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.3-5 | Subject to user's | PR 5.21.6-4 | | | | consent, regulation | | | | | and operator's | | | | | policy, the 5G | | | | | network may provide | | | | | secure means to | | | | | expose to a trusted | | | | | third-party the | | | | | combined sensing | | | | | result derived from | | | | | the joint | | | | | processing of the | | | | | 3GPP sensing data | | | | | and non-3GPP | | | | | sensing data. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.3-6 | Subject to | PR 5.2.6-8 | | | | operator's policy, | | | | | the 5G network may | PR 5.10.6-5 | | | | provide secure | | | | | means for the | PR 5.18.6-3 | | | | operator to expose | | | | | information towards | | | | | trusted third-party | | | | | on whether a given | | | | | sensing service is | | | | | available and the | | | | | estimated quality | | | | | of the given | | | | | service for a | | | | | certain geographic | | | | | area and time. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.3-7 | Subject to | PR 5.32.6-1 | | | | operator's policy, | | | | | the 5G network may | | | | | enable secure means | | | | | for a trusted third | | | | | party to provide | | | | | sensing assistance | | | | | information. | | | +-------------+---------------------+----------------+---------+
Table 7.1.4-1 Security Consolidated Requirements
+-------------+---------------------+----------------+---------+ | CPR # | Consolidated | Original PR # | Comment | | | Potential | | | | | Requirement | | | +=============+=====================+================+=========+ | CPR 7.1.4-1 | The 5G system shall | PR 5.16.6-1 | | | | provide a mechanism | | | | | to protect | | | | | identifiable | | | | | information that | | | | | can be derived from | | | | | the 3GPP sensing | | | | | data from | | | | | eavesdropping. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.4-2 | The 5G system shall | PR 6.1.2-1 | | | | limit the exposure | | | | | of the | | | | | sensing results | | | | | only to third party | | | | | authorized to | | | | | receive that | | | | | sensing results. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.4-3 | The 5G system shall | PR 5.27.6-4 | | | | support encryption, | | | | | integrity | PR 5.27.6-3 | | | | protection, privacy | | | | | of the 3GPP sensing | PR 5.23.6 -2 | | | | data, non-3GPP | | | | | sensing data and | PR 6.1.2-2 | | | | sensing results, to | | | | | protect the data | | | | | inside the 5G | | | | | system. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.4-5 | The 5G system shall | PR 6.1.2-3 | | | | support appropriate | | | | | sensing KPIs of 5G | | | | | wireless sensing | | | | | for both situations | | | | | where consent can | | | | | be obtained from | | | | | the sensing | | | | | targets, and where | | | | | it cannot. | | | +-------------+---------------------+----------------+---------+ | CPR 7.1.4-6 | Subject to | PR 6.1.2-4 | | | | regulation and | | | | | user's consent, the | | | | | 5G network may | | | | | associate sensing | | | | | results and | | | | | identity of the | | | | | user together for | | | | | further processing | | | | | for a sensing | | | | | target that has a | | | | | UE and the UE is | | | | | subscribed in the | | | | | same network. | | | +-------------+---------------------+----------------+---------+
### 7.1.5 Charging
Table 7.1.5-1 Charging Consolidated Requirements
+-------------+---------------------+----------------+---------+ | CPR # | Consolidated | Original PR # | Comment | | | Potential | | | | | Requirement | | | +=============+=====================+================+=========+ | CPR 7.1.5-1 | The 5G system shall | PR 5.20.6-4 | | | | be able to support | | | | | charging for the 5G | PR 5.2.6-7 | | | | wireless sensing | | | | | service (e.g. | PR 5.28.6-2 | | | | considering sensing | | | | | KPIs, duration). | | | +-------------+---------------------+----------------+---------+
## 7.2 Consolidated potential KPIs of sensing results
Scenario | Sensing service category | Sensing service area | Confidence level [%] | Accuracy of positioning estimate by sensing (for a target confidence level) | Accuracy of velocity estimate by sensing (for a target confidence level) | Sensing resolution | Max sensing service latency [ms] | Refreshing rate [s] | Missed detection [%] | False alarm [%] | Example Services |  |  |   
---|---|---|---|---|---|---|---|---|---|---|---|---|---|---  
|  |  |  | Horizontal [m] | Vertical [m] | Horizontal [m/s] | Vertical [m/s] | Range resolution [m] | Velocity resolution (horizontal/ vertical) [m/s x m/s] |  |  |  |  |   
Object detection and tracking | 1 (use cases 5.1; 5.13 – level1) | Object to be detected indoor: Human, object to be detected outdoor: UAV | 95 | 10 | 10 | N/A | N/A | 10 NOTE 2 | 10 NOTE 3 | 1000 | 1 | 5 | 2 | intruder detection in smart home, UAV intrusion detection  
| 2 (use cases 5.13 – level2, 5.6, 5.14) | Object to be detected outdoor: Human, UAV | 95 | 5 | 5 | N/A | N/A | 10 NOTE 2 | 10 NOTE 3 | 1000 | 1 | 5 | 5 | UAV flight route intrusion detection, intruder detection in surroundings of smart home, tourist spot monitoring  
| 3 (use cases 5.2, 5.7, 5.10, 5.11, 5.12, 5.23) | Factory (100m2), crossroad, highway, railway [air] NOTE 4 Object to be detected: Animal, Human, UAV, Vehicle | 95 | 1 | N/A | 1 NOTE 5 | N/A | 1 NOTE 5 NOTE 8 | 1 x 1 NOTE 9 | 100 NOTE 6 1000 NOTE 10 | 0.1 NOTE 11 | 2 | 2 | pedestrian/animal intrusion detection on a highway/railway, sensing at crossroads with/without obstacle, UAV flight trajectory tracing UAV collision avoidance, AMR collision avoidance in smart factories  
| 4 (use cases 5.20, 5.22, 5.25, 5.32) | factory Object to be detected: Animal, Human, UAV, AGV/AMR, Vehicle | 95 | 0.5 | 0.5 | 0.1 Vehicle: 15 | N/A | 0.5m | 5 x 5 for factories: 0.5 x 0.5 | 250 | 0.25 | 1 | 5 | Parking Space Determination, UAVs/vehicles/pedestrians detection near Smart Grid equipment (NOTE 7), immersive experience based on sensing, integrated sensing and positioning in factory hall  
| 5 (use cases 5.27, 5.28) | ADAS Object to be detected: Vehicle Public area safety, | 95Public safety: 99 | 0.1short-range radar:r 0.02 | 0.5 | 0.03Pedestrian: 1.5 | N/A; Pedestrian: 1.5 | 0.4 | 0.1x 0.6 | 50 | 0.05 | 1 | 1 | public safety search and rescue or apprehend, ADAS  
|  |  |  |  |  |  |  |  |  |  |  |  |  |   
Environment monitoring | 6 (use cases 5.3 and 5.5.) | Rainfall monitoring and flooding NOTE 14 Object to be detected: Rain | 95 | 10 | 0.2 NOTE 15 | N/A | N/A | N/A | N/A | 60000 | 1<10min, application configurable | 10 | 3 | rainfall monitoring, flooding monitoring  
Motion monitoring | 7 (use cases 5.15, 5.24) | Indoor human motion -sleep monitoring NOTE 12, sports monitoring NOTE 13, | 95 | N/A | N/A | N/A | N/A | N/A | N/A | 60000 | 60 | 5 | 5 | sleep monitoring, sports monitoring  
| 8 (use case 5.29) | Hand gesture recognition | 95 | 0.2 | 0.2 | 0.1 | 0.1 | 0.375 | 0.3 | 5 | 0.1 | 5 | 5 | Hand gesture recognition  
NOTE 1: The terms in Table 7.2-1 are found in Section 3.1. NOTE 2: To detect the UAV existance (e.g., for intrusion detection), the sensing resolution of distance is 10m [25]. NOTE 3: To detect the UAV existence, the sensing resolution of velocity is 10m/s [25]. NOTE 4: The typical size (Length x Width x Height) of UAV is 1.6m x 1.5m x 0.7m, the typical size of pedestrian is 0.5m x 0.5m x 1.75m, and the typical size of engineering vehicle is 7.5m x 2.5m x 3.5 m. NOTE 5: The KPI values for UAVs are sourced from [25] and [40] and for factories are sourced from [47]. NOTE 6: The value 100 ms is sourced from [28] and is valid for sensing at crossroads. NOTE 7: The safe distance between pedestrian/vehicle and transmission station/line is 0.7m/0.95m [46]. The size of the park of Smart Grid depends on the real environment. NOTE 8: To track the UAV flying (e.g., for collision detection and warning), the sensing resolution of distance is 1m [25]. NOTE 9: To track the UAV flying, the sensing resolution of velocity is 1m/s [25]. NOTE 10: To realize 1m granularity tracking, when the velocity resolution is 1 m/s, the maximum corresponding sensing service latency is 1s. NOTE 11: Echodyne MESA-DAATM has approximate 1Hz scan rate [40]. NOTE 12: Additional KPI on human motion rate accuracy of 2 times/min (0.033 Hz). NOTE 13: Additional KPI on human motion rate accuracy of 3 times/min (0.05Hz) and 4 times/min (0.07 Hz) NOTE 14: Rainfall estimation accuracy is1 mm/h[39] and describes the closeness of the measured rainfall estimation to its true rainfall value. NOTE 15: This value is for the water level. Description related to NOTE in clause 5.5.1 suggests 0.01 m. [≤0.2] is derived from the water level where people feel difficulty in walking. |  |  |  |  |  |  |  |  |  |  |  |  |  |   
# 8 Conclusion and recommendations
This TR analyses a number of use cases for integrated sensing and
communication enabled by the 5G system.
The potential new requirements for each use case are compiled into a set of
potential consolidated requirements, including functional requirements and
performance requirements, wherein a set of KPIs are defined.
Clause 7 contains consolidated potential requirements and KPIs for 5G wireless
sensing service. It is recommended that these be considered for normative
phase.
#