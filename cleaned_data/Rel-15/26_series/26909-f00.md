# Foreword
This Technical Report has been produced by the 3^rd^ Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
The present document describes the enhancement of Quality of Experience (QoE)
for operator managed streaming service, 3^rd^ party managed streaming service
and Over-The-Top (OTT) streaming service.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] Yiting Liao, et al. \"Achieving high QoE across the compute continuum: How
compression, content, and devices interact.\" 7th International Workshop on
Video Processing and Quality Metrics for Consumer Electronics, Scottsdale,
Arizona, USA. 2013.
[3] ITU-T SG12 \"T13-SG12-150505-TD-GEN-0671!R1!MSW-E-P.NATS Terms of
Reference (ToR)\".
[4] 3GPP TS 26.247: \"Transparent end-to-end Packet-switched Streaming Service
(PSS); Progressive Download and Dynamic Adaptive Streaming over HTTP (3GP-
DASH)\".
[5] 3GPP TS 26.233: \"Transparent end-to-end packet switched streaming service
(PSS); General description\".
[6] 3GPP TR 26.938: \"Packet-switched Streaming Service (PSS); Improved
support for dynamic adaptive streaming over HTTP in 3GPP\".
[7] 3GPP TS 26.244: \"Transparent end-to-end packet switched streaming service
(PSS); 3GPP file format (3GP)\".
[8] Recommendation ITU-R BT.500: \"Methodology for the subjective assessment
of the quality of television pictures\".
[9] DASH-IF Position Paper: \"Proposed QoE Media Metrics standardization for
segmented media playback\": http://dashif.org/wp-
content/uploads/2016/10/ProposedMediaMetricsforSegmentedMediaDelivery-r12.pdf
[10] ISO/IEC 23001-10: \"Information technology -- MPEG systems technologies
-- Part 10: Carriage of timed metadata metrics of media in ISO base media file
format\".
[11] 3GPP TS 32.422: \"Telecommunication management; Subscriber and equipment
trace; Trace control and configuration management\".
# 3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply.\ An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
A/V MOS Audio/Video Mean Opinion Score
IQoE Improved Quality of Experience
DASH Dynamic Adaptive Streaming over HTTP
KPI Key Performance Indicators
KQI Key Quality Indicator
MDT Minimization of Drive Tests
MNO Mobile Network Operator
MOS Mean Opinion Score
MOS-AVQO Audio-Visual-Quality-Objective
MPD Media Presentation Description
OTT Over The Top
PSS Packet Streaming Server
TCE Trace Collection Entity
VSSQM Video Streaming Service Quality Monitoring
# 4 A/V Quality Monitoring Support for 3GPP PSS
## 4.1 WebTV Quality Monitoring
### 4.1.1 Use case
Over-The-Top video streaming is increasingly dominating the traffic in the
networks. An increasing number of services employing a variety of streaming
formats are appearing. In addition, movie services are increasingly causing
traffic in mobile networks.
It is crucial for mobile network operators to manage the video traffic in
their networks and services in an optimal manner. A major objective is to
ensure that the customers remain satisfied. Hence monitoring the users QoE
with an appropriate quality indicator is of fundamental importance.
The derivation of quality indicators for the streaming quality may be
supported by the service to a lesser or greater extend. Further dedicated
agreements between mobile operator and service provider would help to obtain
better quality indicators. The level of accuracy on the quality indicator
would depend on the level of agreement between the mobile network operator and
the service provider.
The main Key Performance Indicators (KPIs) for characterizing insufficient
video streaming performance as perceived by the user are:
\- initial stalling of the playout;
\- periods of stalling and freezing of the video while playing;
\- interruption of the audio while playing;
\- low coding quality appearing as blurring, macroblocking or mosquito
artefacts;
\- varying coding quality while playing.
Beside these KPIs the monitoring system will also provide a Key Quality
Indicator (KQI) characterizing the user\'s quality experience.
Quality is fundamentally related to the subjective assessment of the
considered aspect. The KQI will be related to corresponding subjective quality
assessments. The quality often is rated as an opinion score on a 5-point scale
ranging from \"bad\" (1), \"poor\" (2), \"fair\" (3), \"good\" (4) to
\"excellent\" (5). The average of these scores calculated from a group of
subjects is the Mean Opinion Score (MOS).
For operational tasks instrumental measurement tools are required. Hence, the
subjective test results are used to develop instrumental methods that
replicates the MOS scores obtained in subjective tests. Ideally, the derived
quality model will be established as internationally agreed standard
specification, for increasing the confidence that the measured quality results
are reliable and comparable. The estimated MOS values will be labelled as
result stemming from an objective model. For example, the estimated AV-
streaming MOS could be named MOS-AVQO (Audio-Visual-Quality-Objective).
The use of a KQI, estimating the MOS of a video streaming session has the
major advantage of combining the quality impact of occurring stalling and
coding effects in a single number. By this means the service can be monitored
efficiently.
In addition to the KPIs and KQI, further the related data such as time,
location, service and network will be collected for each considered streaming
session.
The use case \"WebTV Quality Monitoring\" demands for means that allow
collecting accurate KPIs and the audio-visual KQI for supporting the quality
management of the networks and customer services. The collected KPI and KQI
data supports a wide range of utilizations such as the short-term detection of
problems and the long term quality monitoring. With additional other
monitoring data sources, the complete delivery chain, from server, via
networks, to the user\'s terminal can be observed. Data analytics methods can
be applied to reveal inherent quality dependencies. The detection of critical
combinations of KPIs with the help of a KQI focuses on the user\'s quality
experience and is therefore very efficient. In conclusion, the MOS-AVQO is
foreseen as mean to increase the usefulness of the quality monitoring systems
significantly.
### 4.1.2 Potential Recommended requirements
The proposed potential requirements for implementing the WebTV Quality
Monitoring use case are based on the assumption that the user\'s end device is
collecting and aggregating the QoE-related data. The collected QoE-related
data then is further processed and forwarded to a central QoE monitoring
server in a next step:
\- The monitoring software of the end device can provide a generic applicable
subsystem for Video Streaming Service Quality Monitoring (VSSQM).
\- The VSSQM subsystem provides an API for logging QoE related events. The API
provides a handler for receiving and digesting QoE related events and for
retrieval of QoE-related data to be reported to a QoE Server using an
appropriate communication channel.
\- VSSQM subsystem provides an API for third party QoE monitoring applications
running on the end device. This API allows retrieving the aggregated QoE-
related data. The QoE monitoring application may transmit the QoE-related data
to a third party QoE Monitoring Service.
Figure 4.1-1 illustrates the Video Streaming Service Quality Monitoring
subsystem with the provided API\'s for QoE-related event logging and for QoE
data digestion.
{width="6.688888888888889in" height="2.7402777777777776in"}
Figure 4.1-1: Proposed subsystem for logging and digesting QoE-related data
for Video Streaming Service Quality Monitoring
**Detailed proposed requirements for the VSSQM Logging API**
  1. The VSSQM subsystems provides an interface for registering video streaming service and its player for monitoring the play-out performance
  2. The player of the streaming service is recommended to support the sending of following events:
  3. AnouncementOfVideoStreamingSession (ServiceProvider)
  4. InitialisingPlayer (AudioCodec, VideoCodec, Profile)
  5. ChangeProfile (Profile)
  6. LoadingContent (SourceIP)
  7. Playing
  8. BitrateReport(Audio,Video)
  9. Stalling
  10. Pause
  11. ScrollForward
  12. ScrollBackward
  13. The mobile clients provides additional related information such as:
  14. Time
  15. Location
  16. Network: 2G, 3G, 4G, Cell-ID, WLAN
  17. Route: Source IP, destination IP, ...
  18. Device: brand, screen parameters, headphones, processing power, battery usage
The VSSQM subsystem would collect this information via the appropriate API\'s
in that moment when the player event is processed.
  1. The QoE Logging API supports the retrieval of the raw QoE data with different aggregation levels. A QoE data retrieval module forwards these reports to a QoE server using an appropriate communication channel.
  2. Video streaming traffic may be monitored also with a traffic analysis tool operating on the client network interface. Such a tool would register at the VSSQM in the same manner as streaming services. The tool may help to observe video streams that do not register and provide QoE related monitoring events.
**Detailed proposed requirements for the QoE Monitoring API**
  1. The QoE Monitoring API allows deriving aggregated QoE reports. A third party monitoring application can process the data and forward derived QoE reports to a third party QoE server.
  2. The QoE Monitoring Application may support to derive the following metrics:
  3. Initial stalling of the playout
  4. Periods of stalling and freezing of the video while playing
  5. Interruption of the audio while playing
  6. Statistics on coding quality
  7. Statistics on varying coding quality while playing
  8. Estimation on overall audio-visual quality (MOS-AVQO)
## 4.2 ITU-T P.NATS Quality Assessment Model for HTTP Adaptive Streaming
ITU-T P.NATS project ([3]) will develop the objective assessment model for
progressive download and adaptive type media streaming. It supports both the
OTT and operator managed video service. The supported protocol scope includes
HTTP/TCP/IP, RTMP/TCP/IP, HLS/HTTP/TCP/IP, and DASH/HTTP/TCP/IP. It supports
3GPP, MP4 and other file format, and the model is agnostic to the type of file
format.
It will support sequence duration of 60 sec to 5 min for quality evaluation.
The supported video resolution is 240p, 360p, 480p, 720p and 1080p. The
supported frame rate range is 8 to 50 fps.
ITU-T P.NATS phase 2 aims at extending the quality model for supporting 2K and
4K.
The current working model agreed in P.NATS project is depicted in figure
4.2-1.
{width="6.533333333333333in" height="3.4902777777777776in"}
Figure 4.2-1: Building blocks of the P.NATS model
As shown in table 4-1, P.NATS will support 4 modes.
Table 4-1: Different modes defined in P.NATS
* * *
Mode Encryption Input 0 Encrypted media payload and media frame headers Meta-
data 1 Encrypted media payload Meta-data and frame header information 2 No
encryption Meta-data and up-to 2% of the media stream 3 No encryption Meta-
data and any information from the video stream
* * *
The P.NATS model will receive media information and prior knowledge about the
media stream or streams. The model receives the following input signals
regardless of the mode of operation:
\- I.GEN: display resolution and device type
\- I.11: audio coding information
\- I.13: video coding information
\- I.14: Stalling events
The P.NATS model input parameters are provided in table 4-2 below.
Table 4-2: ITU-T P.NATS model input parameters.
+------------+-------------+-------------+-------------+-------------+ | ID | Description | Values | Frequency | Modes | | | | | | available | +------------+-------------+-------------+-------------+-------------+ | _I.GEN_ | | | | | +------------+-------------+-------------+-------------+-------------+ | 0 | The | Number of | Per media | All | | | resolution | pixels | session | | | | of the | (WxH) in | | | | | image | displayed | | | | | displayed | video | | | | | to the user | | | | +------------+-------------+-------------+-------------+-------------+ | 1 | The device | pc or | Per media | All | | | type on | mobile | session | | | | which the | | | | | | media is | | | | | | played | | | | +------------+-------------+-------------+-------------+-------------+ | **_I.11_** | | | | | +------------+-------------+-------------+-------------+-------------+ | 7 | Target | Bit-rate in | Per media | All | | | Audio | kbps. | segment | | | | bit-rate | | | | +------------+-------------+-------------+-------------+-------------+ | 8 | Segment | Duration in | Per media | All | | | duration | seconds | segment | | +------------+-------------+-------------+-------------+-------------+ | 9 | Audio frame | Integer, | Per media | 1,2,3 | | | number | starting | segment | | | | | with 1 | | | +------------+-------------+-------------+-------------+-------------+ | 10 | Audio frame | Size of the | Per audio | 1,2,3 | | | size | frame in | frame | | | | | bytes | | | +------------+-------------+-------------+-------------+-------------+ | 11 | Audio frame | Duration in | Per audio | 1,2,3 | | | duration | seconds | frame | | +------------+-------------+-------------+-------------+-------------+ | 12 | Audio codec | One of: | Per media | All | | | | AAC-LC, | segment | | | | | AAC-HEv1, | | | | | | AAC-HEv2, | | | | | | AC3 | | | +------------+-------------+-------------+-------------+-------------+ | 13 | Audio | In Hz | Per media | All | | | sampling | | segment | | | | frequency | | | | +------------+-------------+-------------+-------------+-------------+ | 14 | Number of | 2 | Per media | All | | | audio | | segment | | | | channels | | | | +------------+-------------+-------------+-------------+-------------+ | 15 | Audio | Encoded | Per audio | 2,3 | | | bit-stream | audio bytes | frame | | | | | for the | | | | | | frame | | | +------------+-------------+-------------+-------------+-------------+ | **_I.13_** | | | | | +------------+-------------+-------------+-------------+-------------+ | 16 | Target | Bit-rate in | Per media | All | | | Video | kbps. | segment | | | | bit-rate | | | | +------------+-------------+-------------+-------------+-------------+ | 13 | Video | Frame rate | Per media | All | | | frame-rate | in frames | segment | | | | | per second. | | | +------------+-------------+-------------+-------------+-------------+ | 14 | Segment | Duration in | Per media | All | | | duration | seconds | segment | | +------------+-------------+-------------+-------------+-------------+ | 15 | Video | Number of | Per media | All | | | encoding | pixels | segment | | | | resolution | (WxH) in | | | | | | transmitted | | | | | | video | | | +------------+-------------+-------------+-------------+-------------+ | 16 | Video codec | One of: | Per media | All | | | and profile | H26 | segment | | | | | 4-baseline, | | | | | | H264-high, | | | | | | H264-main | | | +------------+-------------+-------------+-------------+-------------+ | 17 | Video frame | Integer, | Per video | 1,2,3 | | | number | starting at | frame | | | | | 1, denoting | | | | | | the frame | | | | | | sequence | | | | | | number in | | | | | | encoding | | | | | | order. | | | +------------+-------------+-------------+-------------+-------------+ | 18 | Video frame | Duration of | Per video | 1,2,3 | | | duration | the frame | frame | | | | | in seconds | | | +------------+-------------+-------------+-------------+-------------+ | 19 | Frame | The frame | Per video | 1,2,3 | | | p | p | frame | | | | resentation | resentation | | | | | timestamp | timestamp | | | +------------+-------------+-------------+-------------+-------------+ | 20 | Frame | The frame | Per video | 1,2,3 | | | decoding | decoding | frame | | | | timestamp | timestamp | | | +------------+-------------+-------------+-------------+-------------+ | 21 | Video frame | The size of | Per video | 1,2,3 | | | size | the encoded | frame | | | | | video frame | | | | | | in bytes | | | +------------+-------------+-------------+-------------+-------------+ | 22 | Type of | \"I\" or | Per video | 1,2,3 | | | each | \"Non-I\" | frame | | | | picture | for mode 1 | | | +------------+-------------+-------------+-------------+-------------+ | 23 | Video | Encoded | Per video | 2,3 | | | bit-stream | video bytes | frame | | | | | for the | | | | | | frame | | | +------------+-------------+-------------+-------------+-------------+ | **_I.14_** | | | | | +------------+-------------+-------------+-------------+-------------+ | 22 | Buffering | The start | Per | All | | | event start | time of the | buffering/ | | | | | bufferi | stalling | | | | | ng/stalling | event | | | | | event in | | | | | | seconds | | | | | | relative to | | | | | | the start | | | | | | of the | | | | | | original | | | | | | video clip, | | | | | | expressed | | | | | | in media | | | | | | time (not | | | | | | wall clock | | | | | | time) | | | | | | | | | | | | Note: This | | | | | | is 0 for | | | | | | initial | | | | | | buffering. | | | +------------+-------------+-------------+-------------+-------------+ | 23 | Event | The | Per | All | | | duration | duration of | buffering/ | | | | | the | stalling | | | | | bufferi | event | | | | | ng/stalling | | | | | | event in | | | | | | seconds. | | | +------------+-------------+-------------+-------------+-------------+
The P.NATS model outputs are as follows:
  * O.21: Audio coding quality per output sampling interval
```{=html}
``` \- Multiple segment scores provided per session and on a 1-5 quality
scale.
```{=html}
``` \- O.22: Video coding quality per output sampling interval
```{=html}
``` \- Multiple segment scores provided per session and on a 1-5 quality
scale.
```{=html}
``` \- O.23: Perceptual buffering indication
```{=html}
``` \- Single score on a 1-5 quality scale for the session.
```{=html}
``` \- O.34: Audiovisual segment coding quality per output sampling interval.
```{=html}
``` \- Multiple segment scores provided per session.
  * Window-size same as for/synced with O.21, O.22
```{=html}
``` \- O.35: Final audio-visual coding quality score
```{=html}
``` \- Single score for the session, on a 1-5 quality scale.
  * Includes aspects of temporal integration.
```{=html}
``` \- O.46: Final media session quality score
```{=html}
``` \- Single score for the session, on a 1-5 quality scale.
  * Includes initial buffering and stalling aspects.
## 4.3 Gap analysis of PSS QoE metrics for support of ITU-T P.NATS
### 4.3.1 Supported Mode
For operator managed streaming service, media information, prior knowledge
about the media stream and/or stream is visible to the operator, which mode
can be configured by the operator. The P.NATS mode selection is the tradeoff
between quality assessment accuracy and processing complexity.
For OTT streaming service, stream information is not visible to the operator
any more especially if HTTPs is in place. P.NATS mode 1 to 3 does not apply to
OTT streaming service any more.
It is proposed to introduce Mode 0 for both OTT and operator managed streaming
service. Other Mode is FFS.
### 4.3.2 Supported Input parameter
In order to support Mode 0 quality assessment, the required parameter is
listed in table 4-3 below.
Table 4-3: ITU-T P.NATS model input parameter for Mode 0.
+-------+--------------+--------------+--------------+--------------+ | ID | Description | Values | Frequency | Modes | | | | | | available | +-------+--------------+--------------+--------------+--------------+ | I.GEN | | | | | +-------+--------------+--------------+--------------+--------------+ | 0 | The | Number of | Per media | All | | | resolution | pixels (WxH) | session | | | | of the image | in displayed | | | | | displayed to | video | | | | | the user | | | | +-------+--------------+--------------+--------------+--------------+ | 1 | The device | pc or mobile | Per media | All | | | type on | | session | | | | which the | | | | | | media is | | | | | | played | | | | +-------+--------------+--------------+--------------+--------------+ | I.11 | | | | | +-------+--------------+--------------+--------------+--------------+ | 7 | Target Audio | Bit-rate in | Per media | All | | | bit-rate | kbps. | segment | | +-------+--------------+--------------+--------------+--------------+ | 8 | Segment | Duration in | Per media | All | | | duration | seconds | segment | | +-------+--------------+--------------+--------------+--------------+ | 12 | Audio codec | One of: | Per media | All | | | | AAC-LC, | segment | | | | | AAC-HEv1, | | | | | | AAC-HEv2, | | | | | | AC3 | | | +-------+--------------+--------------+--------------+--------------+ | 13 | Audio | In Hz | Per media | All | | | sampling | | segment | | | | frequency | | | | +-------+--------------+--------------+--------------+--------------+ | 14 | Number of | 2 | Per media | All | | | audio | | segment | | | | channels | | | | +-------+--------------+--------------+--------------+--------------+ | I.13 | | | | | +-------+--------------+--------------+--------------+--------------+ | 16 | Target Video | Bit-rate in | Per media | All | | | bit-rate | kbps. | segment | | +-------+--------------+--------------+--------------+--------------+ | 13 | Video | Frame rate | Per media | All | | | frame-rate | in frames | segment | | | | | per second. | | | +-------+--------------+--------------+--------------+--------------+ | 14 | Segment | Duration in | Per media | All | | | duration | seconds | segment | | +-------+--------------+--------------+--------------+--------------+ | 15 | Video | Number of | Per media | All | | | encoding | pixels (WxH) | segment | | | | resolution | in | | | | | | transmitted | | | | | | video | | | +-------+--------------+--------------+--------------+--------------+ | 16 | Video codec | One of: | Per media | All | | | and profile | H2 | segment | | | | | 64-baseline, | | | | | | H264-high, | | | | | | H264-main | | | +-------+--------------+--------------+--------------+--------------+ | I.14 | | | | | +-------+--------------+--------------+--------------+--------------+ | 22 | Buffering | The start | Per | All | | | event start | time of the | buffering/ | | | | | buffer | stalling | | | | | ing/stalling | event | | | | | event in | | | | | | seconds | | | | | | relative to | | | | | | the start of | | | | | | the original | | | | | | video clip, | | | | | | expressed in | | | | | | media time | | | | | | (not wall | | | | | | clock time) | | | | | | | | | | | | Note: This | | | | | | is 0 for | | | | | | initial | | | | | | buffering. | | | +-------+--------------+--------------+--------------+--------------+ | 23 | Event | The duration | Per | All | | | duration | of the | buffering/ | | | | | buffer | stalling | | | | | ing/stalling | event | | | | | event in | | | | | | seconds. | | | +-------+--------------+--------------+--------------+--------------+
TS 26.247 ([4]) develops QoE metrics used for quality evaluation, in order to
support video MOS calculation by 3GPP system. The mapping and check between TS
26.247 and P.NATS are provided below.
Table 4-4: mapping between QoE metrics defined in TS 26.247 and input in
P.NATS model for video stream
+--------------+--------------+---------+--------------+--------------+ | Video | QoE metrics | Remark | | | | Metrics | defined in | | | | | needed for | TS 26.247 | | | | | P.NATS model | | | | | +--------------+--------------+---------+--------------+--------------+ | Description | Value | Metric | Description | | +--------------+--------------+---------+--------------+--------------+ | Target Video | Bit-rate in | Mpdinfo | Provides the | Target Video | | bit-rate | kbps. | | MPD | bit-rate has | | | | | information | been | | | | | for the | supported by | | | | | re | * | | | | | presentation | \@bandwidth _| | | | | or | attribute. | | | | | subre | | | | | | presentation | Video | | | | | identified | frame-rate | | | | | by | and Video | | | | |_ repre | codec and | | | | | sentationid _| profile have | | | | | and | been | | | | |_ s | supported by | | | | | ubreplevel _, |_ @__ codec _| | | | | if present. | attribute. | | | | | | | | | | | Related |_ Segment | | | | | attributes: | duration _| | | | | | has been | | | | |_ \ | supported by | | | | | @bandwidth _, |_ \@duration _| | | | |_ \@width _, | attribute. | | | | |_ \@height _, | | | | | | * |_ Video | | | | | \@duration _, | encoding | | | | | and | resolution_ | | | | | _\@codecs_. | has been | | | | | | supported by | | | | | Note: codec | _\@width_ | | | | | attribute | and | | | | | includes | _\@height_ | | | | | video codec | attributes. | | | | | profile | | | | | | information | | | | | | and video | | | | | | frame rate | | | | | | information | | +--------------+--------------+---------+--------------+--------------+ | Video | Frame rate | | | | | frame-rate | in frames | | | | | | per second. | | | | +--------------+--------------+---------+--------------+--------------+ | Segment | Duration in | | | | | duration | seconds | | | | +--------------+--------------+---------+--------------+--------------+ | Video | Number of | | | | | encoding | pixels (WxH) | | | | | resolution | in | | | | | | transmitted | | | | | | video | | | | +--------------+--------------+---------+--------------+--------------+ | Video codec | One of: | | | | | and profile | H2 | | | | | | 64-baseline, | | | | | | H264-high, | | | | | | H264-main | | | | +--------------+--------------+---------+--------------+--------------+
Table 4-5: mapping between QoE metrics defined in TS 26.247 and input in
P.NATS model for audio stream
+--------------+--------------+---------+--------------+--------------+ | Audio | QoE metrics | Remark | | | | Metrics | defined in | | | | | needed for | TS 26.247 | | | | | P.NATS model | | | | | +--------------+--------------+---------+--------------+--------------+ | Description | Value | Metric | Description | | +--------------+--------------+---------+--------------+--------------+ | Target Audio | Bit-rate in | Mpdinfo | Provides the | _Target | | bit-rate | kbps. | | MPD | Audio | | | | | information | bit-rate_ | | | | | for the | has been | | | | | re | supported by | | | | | presentation | * | | | | | or | \@bandwidth _| | | | | subre | attribute. | | | | | presentation | | | | | | identified |_ Audio | | | | | by | codec _, | | | | | repr |_ Audio | | | | | esentationid | sampling | | | | | and | frequency _| | | | | subreplevel, | and_ Number | | | | | if present. | of audio | | | | | | channels _| | | | | Related | have been | | | | | attributes: | supported by | | | | | |_ @__ codecs _| | | | |_ \ | attribute. | | | | | @bandwidth _, | | | | | | * |_ Segment | | | | | \@duration _, | duration_ | | | | | and | has been | | | | | _\@codecs_. | supported by | | | | | | _@_ | | | | | Note: codec | _duration_ | | | | | attribute | attribute. | | | | | includes | | | | | | audio codec | | | | | | profile | | | | | | information, | | | | | | audio | | | | | | sampling | | | | | | frequency | | | | | | and Number | | | | | | of audio | | | | | | channels | | | | | | information | | +--------------+--------------+---------+--------------+--------------+ | Segment | Duration in | | | | | duration | seconds | | | | +--------------+--------------+---------+--------------+--------------+ | Audio codec | One of: | | | | | | AAC-LC, | | | | | | AAC-HEv1, | | | | | | AAC-HEv2, | | | | | | AC3 | | | | +--------------+--------------+---------+--------------+--------------+ | Audio | In Hz | | | | | sampling | | | | | | frequency | | | | | +--------------+--------------+---------+--------------+--------------+ | Number of | 2 | | | | | audio | | | | | | channels | | | | | +--------------+--------------+---------+--------------+--------------+
Table 4-6: mapping between QoE metrics defined in TS 26.247 and input in
P.NATS model for stalling
+-------------+-------------+-------------+-------------+-------------+ | Metrics | QoE metrics | Remark | | | | needed for | defined in | | | | | P.NATS | TS 26.247 | | | | | model | | | | | +-------------+-------------+-------------+-------------+-------------+ | Description | Value | Metric | Description | | +-------------+-------------+-------------+-------------+-------------+ | Buffering | The start | _InitialPl | The playout | It is only | | event start | time of the | ayoutDelay_ | delay for | for initial | | | bufferi | | media | buffering | | | ng/stalling | | start-up is | delay event | | | event in | | measured as | | | | seconds | | the time in | | | | relative to | | m | | | | the start | | illiseconds | | | | of the | | from the | | | | original | | time | | | | video clip, | | instant of | | | | expressed | | DASH player | | | | in media | | receives | | | | time (not | | play | | | | wall clock | | -back-start | | | | time) | | trigger to | | | | | | the instant | | | | Note: This | | of media | | | | is 0 for | | playout. | | | | initial | | | | | | buffering. | | If the MPD | | | | | | has been | | | | | | delivered | | | | | | earlier | | | | | | before the | | | | | | user | | | | | | clicks, it | | | | | | may include | | | | | | the process | | | | | | time of | | | | | | MPD, the | | | | | | fetch time | | | | | | of some | | | | | | media | | | | | | segments | | | | | | which are | | | | | | required | | | | | | for media | | | | | | pr | | | | | | esentation, | | | | | | the process | | | | | | time of | | | | | | segments, | | | | | | and the | | | | | | time for | | | | | | media | | | | | | decode and | | | | | | render to | | | | | | the user. | | | | | | | | | | | | If no MPD | | | | | | has been | | | | | | fetched | | | | | | earlier, it | | | | | | also needs | | | | | | to add the | | | | | | fetch time | | | | | | of MPD. | | +-------------+-------------+-------------+-------------+-------------+ | Event | The | Play List | A list of | For the | | duration | duration of | | playback | buffering | | | the | | periods. A | event | | | bufferi | | playback | afterwards | | | ng/stalling | | period is | | | | event in | | the time | | | | seconds. | | interval | | | | | | between a | | | | | | user action | | | | | | and | | | | | | whichever | | | | | | occurs | | | | | | soonest of | | | | | | the next | | | | | | user | | | | | | action, the | | | | | | end of | | | | | | playback or | | | | | | a failure | | | | | | that stops | | | | | | playback. | | +-------------+-------------+-------------+-------------+-------------+
The buffering event defined in P.NATS includes initial buffering and stalling
information. Initial buffering delay in P.NATS is defined as the start time of
the buffering/stalling event in seconds relative to the start of the original
video clip and can map to the \'_InitialPlayoutDelay_ \' in TS 26.247.
For stalling information, P.NATS model requires the start time and end time of
a stalling event. In TS 26.247, QoE metric \'_Play List_ \' logs a list of
playback periods of continuous delivery triggered by a user action (e.g.,
play, seek or resume action) till the stop of playout either due to re-
buffering event, a user action, the end of the content, or a permanent
failure. The stalling duration can be derived through those collected logged
information.
As shown in figure 4.3-1, the \'_Play List\'_ logged information includes
T1,T2,T3, and T4 with associated information. The re-buffering duration equals
to T2-T1.
Figure 4.3-1: Logging information in Play List
Table 4-7: other input for P.NATS
* * *
Metrics needed for P.NATS model QoE metrics defined in TS 26.247 Remark  
Description Value Metric Description  
The resolution of the image displayed to the user Number of pixels (WxH) in
displayed video N/A It is not specified in TS 26.247. For operator managed
streaming service, it may be obtained via other way, which is outside of
scope. For OTT streaming service, the enhancement of QoE metrics is required.
The device type on which the media is played pc or mobile N/A \'Visual size\'
is adopted in ITU-T P.NATS, it needs to be reflected in TS 26.247.
* * *
Based on the above analysis, required inputs I.11, I.12, I.13 and I.14 for
P.NATS are supported by QoE metrics in TS 26.247 already. I.GEN input for
P.NATS may require enhancement to TS 26.247.
### 4.3.3 Further Parameters for Supporting Video Quality Monitoring
#### 4.3.3.1 Additional Input Parameters
Two additional input parameters in consideration with potential benefit for
enhancing video MOS estimation are provided in table 4-8 below.
Table 4.8
* * *
ID Description Values Frequency Modes available A1 Visual size Diagonal size
of the viewed video area in cm Per media session All A2 Video QP Average QP
value Per media segment See Note NOTE: This parameter is not currently
applicable to Mode 0. Applicability to other modes is TBD.
* * *
Clauses 4.3.3.2 and 4.3.3.3 provide subjective quality evaluation results
demonstrating the dependency of video quality MOS on these input parameters.
#### 4.3.3.2 Dependency of Video Quality Test Results on Visual Size
Nowadays, with the variety of devices such as 2-in-1 laptops, tablets,
phablets emerge in the market, it becomes more and more difficult to cut a
fine line between PC and mobile. Meanwhile, the size of the display could vary
from 4in to 100+ in. Using a simple PC vs. mobile device type may not capture
the perceptual video quality impact introduced by the device form factor. As
shown in Table 4-9, when same videos are displayed on different devices with a
similar resolution, the video quality MOS varies because of the visual size of
the viewed video area (The subjective experiments are conducted following
ITU-R BT.500 standard [8]. More details about the subjective testing can be
found in [2]). When displayed on a 10.1\" screen, the video MOS is 0.8 lower
than on a 4.8\" screen on average. Since the screen size, more specifically
the visual size of the viewed video area, has a great impact on the video
quality MOS, it is desirable to consider it as an additional input parameter
for video MOS estimation.
Table 4-9: Video Quality MOS on different devices (encoded at 1.5 Mbps with
768x432 resolution)
+-----------------+---------------------------+-------------------------+ | Video clip name | Video Quality MOS | Video Quality MOS | | | | | | | (10.1\" tablet, 1280x800) | (4.8\" phone, 1280x720) | +-----------------+---------------------------+-------------------------+ | Aspen | 2.2 | 3.5 | +-----------------+---------------------------+-------------------------+ | Crowdrun | 2.0 | 3.1 | +-----------------+---------------------------+-------------------------+ | Redkayak | 2.2 | 3.4 | +-----------------+---------------------------+-------------------------+ | westwindeasy | 3.4 | 3.9 | +-----------------+---------------------------+-------------------------+ | Backsneak | 3.4 | 4.2 | +-----------------+---------------------------+-------------------------+ | Bbscore | 3.5 | 4.1 | +-----------------+---------------------------+-------------------------+ | controlledburn | 3.5 | 4.3 | +-----------------+---------------------------+-------------------------+ | Tractor | 3.7 | 4.4 | +-----------------+---------------------------+-------------------------+ | Frontend | 3.9 | 4.6 | +-----------------+---------------------------+-------------------------+ | pedestrianarea | 3.6 | 4.3 | +-----------------+---------------------------+-------------------------+ | Speedbag | 4.2 | 4.6 | +-----------------+---------------------------+-------------------------+ | Sunflower | 4.4 | 4.8 | +-----------------+---------------------------+-------------------------+ | AVERAGE | 3.3 | 4.1 | +-----------------+---------------------------+-------------------------+
#### 4.3.3.3 Relation between Video Quality MOS and QP Parameter
Video resolution, frame rate, encoding bitrate, etc. play an important role in
video quality modeling. In addition to those parameters, video encoding QP is
also very critical for video MOS estimation, because different video segments
could have very different content characteristics and they yield to a wide
range of video quality MOS even when encoded at the same bitrate. For example,
table 4-10 shows quality and QP values (mean luma QP averaged over the segment
duration) of different video clips encoded at the same bitrate. When the
videos share the input parameters such as resolution, frame rate, bitrate,
etc. and are displayed on the same device, the MOS still varies in a wide
range due to the content characteristic difference and the difference is well
captured by the QP value. Table 4-11 shows the correlation of the bitrate/QP
and the video quality scores. For videos encoded at the same bitrate, their
estimated video MOS has a strong correlation to QP value, which indicates the
video content complexity.
Table 4-10: Videos Encoded at the Same Bitrate with a Wide Range of Video
Quality MOS
* * *
Video clip name Bitrate (kbps) QP PSNR (dB) MS-SSIM Video Quality MOS (10.1\"
tablet) aspen 1454 35.9 26.9 0.834 2.2 crowdrun 1482 39.3 23.9 0.745 2.0
redkayak 1451 36.5 31.1 0.829 2.2 westwindeasy 1467 35.9 28.0 0.880 3.4
backsneak 1459 32.5 35.0 0.930 3.4 bbscore 1466 29.7 32.4 0.907 3.5
controlledburn 1476 29.1 31.5 0.924 3.5 tractor 1456 32.2 32.6 0.917 3.7
frontend 1429 23.7 30.8 0.946 3.9 pedestrianarea 1463 27.6 35.7 0.944 3.6
speedbag 1455 25.8 38.5 0.971 4.2 sunflower 1460 25.9 38.2 0.975 4.4
* * *
Table 4-11: Correlation between Bitrate/QP and Video Quality Scores
* * *
Correlation PSNR MS-SSIM Video Quality MOS Bitrate -0.25 -0.39 -0.27 QP -0.75
-0.90 -0.87
* * *
From Table 4-10 it also becomes obvious the video quality MOS for different
video clips with the same encoding parameters, such as video resolution, frame
rate and encoding bitrate, as used for P.NATS Mode 0 may lead to quite
different video quality MOS . A video quality MOS estimator that uses, only
the P.NATS Mode 0 parameters will produce the same MOS score for all the video
clips in Table 4-10. However, Table 4-10 has shown that those clips have MOS
scores varying in a very large range (2.0 \~ 4.4), which is due to the quality
dependency on the video content. The video content complexity is well captured
by the QP parameter as shown in Table 4-11.
## 4.4 Calculation of A/V MOS estimation
### 4.4.0 General
There are 2 options: Calculation done in the client and Calculation done in a
QoE server based on the \"raw\" QoE metrics data reported by the client. The
detail comparison of those 2 options and conclusion are provided in following
clauses.
### 4.4.1 Network Optimization
To do advanced network optimization requires that you understand not only the
final MOS values for the video streaming sessions, but also can see the
underlying raw metrics. For instance, some sessions might simply have a low
MOS value due to the content not having high enough original quality, while
other sessions might have problems with rebuffering. Understanding the root
cause requires access to the basic metrics, not only the final MOS values.
### 4.4.2 MOS Models
The MOS models standardized in ITU-T typically develop over time. For
instance, P.NATS will have several phases, with later phase adding e.g.
support for more codecs. Each time the ITU-T MOS model is updated, the
corresponding updates will be done to the implemented calculations as well.
Having the calculation done in the client means that when a new ITU-T model is
released, it will take substantial time before all, or even the majority, of
the clients have this implemented. On the other hand, updating the MOS model
calculation in a single QoE server is very easy (of course provided that the
raw QoE metrics reported are sufficient for the calculation).
### 4.4.3 MOS Windowing
Even if ITU-T standardizes the P.NATS MOS models, the standard does not define
how often such a MOS value will be calculated. For instance, it could be
calculated every minute, every two minutes, or just for the complete session.
This windowing decision is more or less up to the operator, and is much easier
to handle if the windowing is done in the QoE server rather than by
configuring window lengths towards all of the clients. It would also easily be
possible to calculate MOS values for several windowing lengths in parallel in
the server, while handling this in the client becomes rather complex.
One reason for using different windowing for calculating the MOS scores is
that P.NATS models the human memory effects when watching video. Thus if a
person is asked about his opinion regarding the media quality, and there has
been a very recent problem, such as a buffering or low-resolution content, he
will remember this, and lower his score. On the other hand, if similar
problems were happening longer back in time, say several minutes, and the last
part of the session had very good quality, he will give a higher score.
This is typically handled in P.NATS by weighting the short-term media quality
differently over time, so that the weight is high for the most recent time,
and then starts to drop for media which is placed longer back in memory.
Figure 4.4-1 below illustrates this for an example 4-minute session, where
either four 1-minute MOS scores are evaluated (red lines), or one 4-minute MOS
score (dashed blue line). For the 1-minute scores the weight is almost not
decreasing at all, while for the 4-minute score the weight is going down more
for the older parts. Note that the figure is only illustrative and not an
accurate representation of the final P.NATS algorithm.
{width="4.509722222222222in" height="2.5097222222222224in"}
Figure 4.4-1: Weighting of media quality to model the human memory effect
Thus depending on the operator targets, different MOS windowing can be used.
With shorter windowing the resulting MOS scores are more representative of the
short-term quality, without almost any memory effect. With longer windowing,
the results include more memory effects, and is more representative of the
session quality. As stated earlier, if the MOS score is calculated in the QoE
server several different windowing can be done in parallel, to facilitate
different kind of operator analysis.
### 4.4.4 Conclusion
While MOS calculation in the client is possible, it severely limits the use of
advanced network optimization, use of flexible MOS windowing, and also
introduces problems when the MOS model calculation needs to be updated. A
better solution is to make sure that the raw reported QoE metrics are enough
to be able to calculate the final MOS value in the QoE server.
The Packet Streaming Server (PSS) client collects required metrics and reports
it to the PSS server. The PSS server calculates A/V MOS using the model
developed in P.NATS. The operator and/or OTT 3^rd^ party can evaluate network
delivery performance based on the result A/V MOS with following benefit:
  * Avoid different interpretation of DASH QoE metrics by the Mobile Network Operator (MNO) for different UEs consuming the same streaming content with same encoding scheme.
  * Avoid different interpretation of DASH QoE metrics by the OTT 3^rd^ party for different UEs consuming the same streaming content with same encoding scheme over different MNO\'s network.
It is proposed to introduce A/V MOS developed by P.NATS for 3GPP PSS.
A/V MOS estimation and associated information (encoding information,
InitialPlayoutDelay, etc.) may be used by the operator to evaluate network
delivery performance in case:
  * The streaming content is encoded with different coding schemes; advanced encoding scheme consumes less network bandwidth.
  * DASH player implementation prefers downloading more data before playing.
## 4.5 Options for applying higher P.NATS Modes
The ITU-T P.NATS quality model will support four modes (see clause 4.1). Mode
0, Mode 1 and Mode 3 are of special interest for client-based QoE monitoring.
Mode 0 supports estimating the quality based on metadata information such as
audio codec, video codec and bitrates. This quality estimation requires very
low processing power and the meta information is typically available even for
media streams encrypted at the chunk level.
Mode 1 uses in addition information on the GOP structure and frame sizes. This
is possible for unencrypted streams or streams encrypted only on elementary
stream level. It requires low processing power and the estimation of video
quality is better over mode 0.
Mode 3 takes the bitstream itself into account. The video quality model
considers the, quantization parameters and further coding-related features in
addition to the codec\'s profile, video framing and bitrates for getting a
significant better estimation of the video coding quality. A tradeoff is that
Mode 3 requires more processing power and an unencrypted bitstream. Therefore,
is deploying P.NATS Mode 3 on the user end devices is unlikely, but Mode 3 can
be applied by splitting the processing for the model in one part processing
the coding quality on the server side and another part processing the stalling
and overall quality integration part on the client side.
As shown in figure 4.2-1, the P.NATS quality model is composed of separate
modules for estimating the audio quality (Pa), video quality (Pv) and for
integrating audio, video and stalling quality (Pq). This modular approach
allows separating the quality estimation into a server-side estimation of the
audio and video coding quality and a client-side integration of the coding
quality in combination with stalling events that may have occurred on the
client. The outputs of the audio module (O.21) and the video module (O.22) are
provided with a sampling frequency of 1 Hz. The integration module Pq takes
the samples of the audio and video coding quality output for an appropriate
measurement interval and combines them with the occurred stalling events. The
result is an estimate for the audio-visual quality of the stream, named \"MOS-
AVQO\". It is to be noted that the Pq integration model is identical for all
modes.
Figure 4.5-1 illustrates different possible scenarios for applying the P.NATS
quality model for monitoring HTTP Adaptive Streaming services.
{width="6.492361111111111in" height="4.152083333333334in"}
a) Mode 0: Deriving codec info and bitrate from the meta information
b) Mode 3: Deriving the coding related quality at server attaching to the
media description,
c) Possible extended mode: Deriving coding related quality with a full
reference model
Figure 4.5-1: Possible scenarios for applying the ITU-T P.NATS quality model
for monitoring HTTP Adaptive Streaming services
a) Mode 0 implements a simple efficient quality estimation. The input
parameters to estimate audio-visual quality are taken from the metadata
description of the audio-visual stream (codecs, bitrate).
b) Mode 3 uses the unencrypted bitstream to derive the coding quality. Beside
the codec information, video resolution, framerate, bitrate, GOP structure,
also the QP parameters and further coding features are derived and considered.
As the required processing (bitstream parsing) may be computationally
intensive for terminals, it is appropriate to derive O.21(m) and O22(m) for
all possible representations of the adaptive stream already at the server
side. As explained above, P.NATS Mode 3 foresees a sample frequency of 1 Hz of
the output of the audio and video quality estimation module. Hence, for
example, for a segment with a length of 6 seconds, one would calculate 12
quality scores (6 audio, 6 video) and transmit them along with the audio-
visual data to a client device, which then calculates the integrated MOS-AVQO.
Note: The coding quality information could be attached with enhancement of
timed metadata track, as described in clause 16 of TS 26.244 [7], clause 6.17
of TR 26.938 [6] -- this approach relies on MPEG\'s ISO/IEC 23001-10 [10].
c) In future, standardized quality models for HTTP adaptive streaming may
support a full-reference quality model. This way, the quality monitoring would
take also the possibly varying quality of the encoder into account. The Phase
2 for the P.NATS development (\"AVHD / P.NATS Phase 2\") foresees the
additional support of a full-reference pixel-based model for video quality
estimation.
As discussed in e.g. clause 4.4 in the present document, it may be an
advantage to calculate the P.1203 (P.NATS) scores at the server responsible
for QoE monitoring.
Thus to be able to divide the P.NATS model execution as described, it is
imperative that this can be done in such a way that the final P.NATS score can
still be calculated on the network side. This would mean that the Pa and Pv
scores which are sent to the client, would also be needed at the QoE Server.
Then these scores (together with the other client QoE reported metrics, such
as buffering info), can then be used in the QoE Server to finally calculate
the P.NATS score.
If the CDN (and thus the Pa/Pv scores) is accessible for the operator owning
the QoE Server, then this is not a major problem, as the Pa and Pv scores can
then potentially be communicated between the CDN and the QoE Server. There
will be a need for some kind of synchronization to know which Pa and Pv scores
belong to which QoE reports, but in principle it is possible to handle.
However, if the CDN is not accessible then the Pa and Pv scores, which are
sent from the CDN to the client, will be reported back from the client to the
QoE Server. Otherwise the QoE Server cannot calculate the P.NATS score. This
situation is also the reason for the existing \"MPD Information\" in TS 26.247
(see clause 10.2.8), to make the needed MPD information available to a QoE
Server which does not have MPD access.
Note that the use of distributed P.NATS calculation is most straightforward
for non-live content, as live content puts additional requirements on the Pa
and Pv calculations. Thus the use for live content needs further study.
# 5 QoE metrics support for managed streaming service
## 5.1 Use case: Managed Streaming Service QoE Improvement
### 5.1.1 Introduction
Managed streaming service refers to a service for which the MNO and the
service provider have some agreement in order to exchange information,
specifically the streaming service provider allows meta-data (e.g., MPD) of
the streaming content can be collected by the operator and the service
provider provides certain metrics of the streaming service to the MNO in real-
time.
### 5.1.2 Use case #1
The operator #1 offers mobile broadband service to the subscriber. The
subscribers of operator #1 access different managed streaming services offered
by different streaming service providers which content is compliant to DASH
format.
**Sub case #1**
The operator #1 wants to ensure that the subscriber\'s experience of streaming
service is consistent from network delivery perspective without the assistance
of managed streaming service provider. The operator #1 collects relevant QoE
metrics available from either UE or network, maybe both to evaluate the QoE of
managed streaming service.
**Sub case #2**
In a business area #CBD, several subscribers encounter stalling while they
access managed streaming service. These subscribers complain to the operator
#1. Operator #1 cares about those subscribers and starts to investigate what
is the cause. The operator #1 collects QoE metrics of managed streaming
service within a geographic area covering that business area, QoE metrics from
neighbour cells are also collected by the operator #1. Through analysis,
operator #1 does not find any network problem based on the collected QoE
metrics and other internal network information. Operator #1 derives that the
problem may be caused by the server owned by Content Delivery Network (CDN)
providers or managed streaming service provider. Operator #1 works with
managed streaming service provider closely; the problem of a server, which
serves the business area, in the CDN network is identified and fixed. The
operator #1 receives no further complaints of managed streaming service
afterwards.
**Sub case #3**
In a metro station, several subscribers encounter stalling while they access a
managed streaming service. These subscribers complain to the operator #1.
Operator #1 cares about those subscribers and starts to investigate what is
the cause. The operator #1collects QoE metrics of managed streaming service
within a geographic area covering the transportation hub, QoE metrics from
neighbour cells are also collected by the operator #1. Operator #1 identifies
it is a network problem. To further locates the problem, Operator #1 collects
QoE metrics and associated radio measurement information in a timely manner
for ongoing managed streaming services. It is found that the surging managed
streaming service consuming along with other non-streaming service access
degrade the user experience. Operator #1 performs access control for certain
type of traffic, and diverts some type of traffic or users to a spare carrier
and the problem is addressed.
### 5.1.3 Use case #2
The operator #2 offers a mobile broadband service to the subscriber. The
subscribers of operator #2 access different managed streaming services offered
by different streaming service provider which content is compliant to DASH
format. The streaming service provider allows meta-data (e.g., MPD) of the
streaming content can be collected by the operator.
**Sub case #1**
Streaming service provider #Streaming #A expects Operator #2 to support QoE of
network delivery for all or selected managed streaming service of #Streaming
#A. Operator #2 collects relevant QoE metrics available from either UE or
network, maybe both, for all or selected streaming services of #Streaming #A
in order to verify that the QoE expectations of Streaming #A are fulfilled.
## 5.2 Managed streaming service deployment model consideration
### 5.2.1 Introduction
PSS architecture defined in TS 26.233 [5] supports both progress download and
3GPP-DASH, and is depicted in figures 5.2-1 and 5.2-2 respectively.
Figure 5.2-1: Architecture for Progressive Download over HTTP
{width="5.991666666666666in" height="2.8444444444444446in"}
Figure 5.2-2: Architecture for 3GP-DASH
**The QoE feature is optional for both PSS server and clients.** Once QoE
feature is supported, the PSS server can configure the QoE metrics collected
by PSS client via PSS signalling (e.g., MPD, RTSP) or OMA-DM. Current
architecture model assumes that the PSS server collecting QoE metrics delivers
the streaming content too. This assumption is valid when the streaming service
is hosted by the operator. This assumption cannot apply to managed streaming
service case.
### 5.2.2 Managed streaming service deployment model
A typical managed streaming service deployment model is provided in figure
5.2-3.
Figure 5.2-3: Managed streaming service deployment model
It is assumed the PSS client is able to collect and report meta-data of
streaming service operated by 3^rd^ party. PSS Client retrieves streaming
content from the 3^rd^ party streaming server shown as **solid blue line**.
The streaming content is 3GPP streaming file format complied. Streaming server
can configure the PSS client to report QoE metrics by itself. The PSS client
reports QoE metrics to 3^rd^ party QoE server shown as **solid purple line**.
Besides the 3^rd^ party evaluation of QoE of streaming service, it is of great
importance for the operator to evaluate the network performance of managed
streaming service support without the access of streaming content itself. QoE
server in operator domain could be a PSS server containing QoE reporting
functionality only. It is expected that the QoE server in operator domain is
able to configure and receive QoE metrics for streaming service operated by
3^rd^ party.
OMA-DM server is used for QoE metrics configuration, and it is an optional
entity. If OMA-DM server does not exist in some operator\'s network, then the
configuration of QoE metrics for streaming service operated by 3^rd^ party
need enhancement.
Note: PSS client may interact with application running in the UE to collect
relevant QoE metrics which are out of control of operator.
## 5.3 Recommended requirements
The recommended requirements are summarized below:
\- The 3GPP network needs to be able to collect QoE metrics of managed
streaming service for user experience and 3GPP network performance evaluation
purpose.
\- The 3GPP network needs to be able to allow the operator to collect QoE
metrics of managed streaming service within a certain geographic area
designated by the operator.
\- The 3GPP network needs to support a mechanism to allow the operator to
configure the QoE metrics of a managed streaming service collection for
network problem identification purpose.
Note: The co-ordination with RAN group may be needed.
\- The 3GPP network need to be able to allow the operator to collect QoE
metrics of any managed streaming service.
## 5.4 GAP Analysis and Evaluation
### 5.4.1 Introduction
The QoE metric reporting feature can be configured by either OMA-DM or MPD,
and the configuration includes:
\- Activation/deactivation of the QoE feature
\- QoE metric
\- ReportingServer information
\- ReportingInterval
\- Other configurations, such as APN, Samplepercentage, etc.
In order to allow the QoE metrics of 3^rd^ hosted streaming service collected
by the MNO, the MNO needs to be able to configure QoE metrics to the DASH
client.
### 5.4.2 Analysis of Activation/Deactivation of QoE reporting
When the MNO is configured with OMA-DM server, DASH client is configured with
OMA DM QoE MOs by OMA-DM. When QoE reporting is triggered via the MPD or OMA
DM QoE Management Object, the DASH client collects quality metrics according
to the QoE configuration. Current OMA-DM approach allows the MNOs to collect
QoE metrics of 3^rd^ party hosted streaming service. No gap is identified.
When the MNO is not configured with OMA-DM server, MPD is one possible way to
configure QoE metrics to DASH client. However, it requires the MNO to request
3^rd^ party to configure QoE metrics in each MPD. The MNO has no knowledge of
which streaming service hosted by any 3^rd^ party in advance. The feasibility
and scalability issues are big challenge to the MNO, so MPD approach is not
feasible. A new approach is needed.
## 5.5 Assumptions
The following assumptions are considered during the development of this
project:
\- QoE server owned by the operator locates inside of 3GPP network and is
different from the QoE server inside the 3^rd^ party streaming server.
\- The PSS client is able to collect meta-data (e.g., MPD) of streaming
service operated by 3^rd^ party.
\- Subject to the agreement between the operator and 3^rd^ party, QoE metrics
of streaming service operated by 3^rd^ party visible to the operator is able
to be collected by the operator.
\- QoE metrics collected by the QoE server owned by operator is supposed to
work for both non OMA-DM and OMA-DM cases.
\- QoE metrics collected by operator for managed streaming service can work
for both HTTP and HTTPs options.
\- The meta-data (e.g., MPD) of the streaming service owned by 3^rd^ party can
be collected by the operator.
\- The service provider provides certain metrics of the streaming service to
the MNO in real-time.
## 5.6 Solution
### 5.6.1 Possible Candidate Options
Option 1: DASH proxy approach
A PSS proxy located behind the P-GW is introduced into the MNO network. The
PSS proxy is able to intercept HTTP: request message for MPD initiated by DASH
client, it forwards HTTP: request message to 3^rd^ party streaming server. The
PSS proxy receives HTTP: response message including MPD. The PSS proxy
modifies MPD with QoE metrics and forwards it to DASH client. The DASH client
collects QoE metrics to the QoE server configured by the PSS proxy.
Option 2: RAN network assisted approach
Trace Collection Entity (TCE) is specified in TS 32.422 [11] for control and
configuration of the Trace, Minimization of Drive Tests (MDT) and Radio Link
Failure (RLF) reporting functionality. Considering the MNO expects the
collected QoE metrics result to be used for network performance evaluation and
problem identification purpose, enhancement of MDT mechanism is proposed here.
The concept of MDT enhancement is depicted in figure 5.6-1.
Figure 5.6-1: MDT enhancement for supporting QoE reporting
The TCE uses MDT configuration method to configure the QoE metrics to the DASH
client. There are 2 options for QoE reporting. Option a) is QoE metrics is
collected by DASH client, and the DASH client uses QoE reporting protocol
specified in TS 26.247 and reports to the QoE server. Option b) is QoE metrics
is collected by DASH client and reported to TCE via MDT procedure, the TCE
then forwards the QoE results to QoE server.
Option 1 requires the PSS proxy to intercept all traffic from the UE, the high
processing loading of PSS proxy used only for QoE configuration purpose needs
more justification, it also does not work for HTTPs based streaming service
since the PSS proxy is unable to intercept HTTPs message, so option 1 is not
recommended. Option 2 works for HTTPs encrypted streaming service and it is
feasible. It is recommended to adopt option 2.
Within option 2, RAN2 agrees that option b) is feasible from RRC signalling
perspective. Considering the RAN2 input, following criteria are further
considered:
(1) **QoE metrics**
3GPP Network can achieve not only the final evaluation result of streaming
services (e.g. A/V MOS estimation), but also the related metrics for
evaluation (e.g. reported QoE measurements from the UE side), which can be
combined with radio measurements for well understanding of UE experience
\- The network optimization related metrics
\- Whether the terminal or the streaming original quality of the network which
impacts
(2) **3GPP Network control**
Operators could control when, where and how often to collect QoE measurements
in order for A/V MOS estimation, for the need might vary from place to place
and the A/V MOS estimation is the trade off of UE/network burden and
usefulness.
(3) **Unified QoE measurements**
Unified QoE measurements and a unified interpretation of A/V MOS estimation
are beneficial for operators to evaluate the real user experience for
streaming services.
(4) **Network optimization**
Operators can optimize the 3GPP networks for better streaming service
experience according to the collected QoE measurements combining with radio
measurements.
In table 5-1, comparison between both option a) and option b) in option 2
according to above criteria are listed:
Table 5-1: comparison of QoE reporting option a and option b in option 2
* * *
                                                                                                                                                                                            Option a                                                                                                              Option b
QoE metrics No. QoE measurements are reported from UE to QoE server via HTTP
protocol, and thus 3GPP Network is \"transparent\" Yes 3GPP Network control
Yes Yes Unified QoE measurements Yes Yes Network optimization No. QoE
measurements are reported from UE to QoE server via HTTP protocol, and thus
3GPP Network is \"transparent\" Yes Note: Yes means that this option meets the
corresponding criterion. No means that this option does not meet the
corresponding criterion and the reasons are also provided as following.
* * *
Option b) could meet all above aspects because the QoE measurements are known
at 3GPP network side (e.g. RAN or TCE) when OMA-DM is not supported in
operator\'s network. Option b) is agreed in SA4 and relevant working groups
(i.e., RAN2, RAN3 and SA5) are asked to specify option b).
The recommended solution of QoE reporting when OMA-DM is not supported is
summarized in figure 5.6-2.
Figure 5.6-2: MDT enhancement for supporting QoE reporting when OMA-DM is not
supported
The TCE uses MDT configuration method to configure the QoE metrics to the DASH
client. QoE metrics is collected by DASH client and reported to TCE via MDT
procedure, the TCE then forwards the QoE results to QoE server.
Note 1: Existing MDT metrics are RAN aware. Whether QoE metrics is RAN aware
or RAN transparent is up to RAN2 own decision.
Note 2: Configuration accuracy for large area may need consideration with MDT
based approach.
### 5.6.2 QoE metrics collection within a certain geographic area
This scenario is to allow the MNO to collect QoE metrics of 3^rd^ party hosted
streaming service within a certain geographic area, the geographic area
information is missing in current QoE metrics configuration. The format of
geographic area could be one or more cell-IDs. It is proposed to add
geographic area information into QoE metrics configuration.
### 5.6.3 QoE metrics collection of a streaming service of a specific 3rd
party
This scenario is to allow the MNO to collect QoE metrics of a streaming
service of a specific 3^rd^ party, the streaming service identifier and/or the
3^rd^ party identifier are missing in current QoE metrics configuration. The
format of streaming service identifier and 3^rd^ party identifier could be URL
format.
It is proposed to add the streaming service identifier and/or the 3^rd^ party
identifier information into QoE metrics configuration.
## 5.7 QoE Handler API Considerations
There can be a number of DASH streaming clients in the UE, both clients
provided by the UE vendor, and clients installed by the user. Each of these
will have the capability to communicate with the QoE management functionality
in the network, to receive QoE configurations, and to report QoE metrics. Thus
the UE will have some kind of lower-layer QoE Handler which typically would be
implemented by the UE vendor. This QoE Handler exposes an API to allow for the
needed client functionality.
To make this API as simple as possible it needs to be minimalistic and based
on the existing QoE configuration and metrics reporting. Basically the
following API primitives need to be available:
\- QoE Client Registration: A client which supports QoE measurements registers
towards the QoE Handler when it starts.
\- QoE Configuration: When new QoE configurations are received by the QoE
Handler from the network, these are sent to all registered clients. The format
of the QoE configuration is recommended to re-use the XML format specified in
TS 26.247, clause 10.4.
\- QoE Metrics: Each client sends QoE metrics to the QoE Handler according to
the latest received configuration. The format of the QoE reports is
recommended to re-use the XML format specified in TS 26.247, clause 10.2.
\- QoE Client De-registration: Before exiting, a client de-registers from the
QoE Handler.
However, it is expected that the data volume and sending frequency will be
much higher for the QoE metrics reporting than for the QoE configuration, and
in some cases the extra control plane load due to QoE reporting might be large
enough to cause potential problems for the network. This is extra problematic
as there are few mechanisms for down-prioritizing certain content in the
control plane.
While the QoE configuration does need to use the control plane to allow full
operator control, the same restriction does not necessarily apply to the QoE
metrics reporting. For instance, an operator which only use the QoE metrics
for statistical performance measurements does not really benefit from having
the QoE metrics reports sent over the control plane.
To handle this case, the QoE configuration received over the control plane
contains a CP/UP flag. The flag will not change the API towards the DASH
clients, but controls in which way the QoE Handler in the UE will send back
the QoE metrics. If the flag is set to \"UP\", the reporting is done via the
user plane instead of the control plane. In this case, the flag would also be
accompanied by an IP address, which indicates the receiving node for the user-
plane reporting.
This is illustrated in the figure 5.7-1:
Figure 5.7-1: QoE Handler Concept
In this way the operator can easily decide which metrics reporting mechanism
that will be used, either globally, for a certain cell area or even for
individual UEs. If the operator would like to take RAN actions on the QoE
reports, but due to control plane capacity reasons still use UP reporting, the
operator would have to relay a copy of the UP QoE reports to relevant RAN
node(s). Such relaying could be handled either in a proprietary way, or
possibly later be standardized.
Note: The QoE handler is RAN relevant and RAN investigation is required.
## 5.8 Privacy issue on QoE metric collection
### 5.8.1 Analysis
The current QoE metrics in TS 26.247 includes the possibility of requesting
detailed HTTP information in the HttpList metric. However, as this metric
contains the URL to the media, this could be seen as sensitive information,
and a possible breach of privacy.
For almost all relevant QoE-related use-cases there is no need to request the
detailed HttpList metric, as this does not help in understanding the end-user
quality. It can possibly be somewhat useful for specific trouble-shooting, but
such trouble-shooting can probably be handled by other means (specific test
clients, etc.).
Activating detailed HttpList reporting would also mean that the QoE reports
from the client would become pretty large, taking valuable capacity in the
uplink on either the user-plane or (worse) the control plane.
The non-usefulness of detailed HTTP metrics for QoE purposes has also been
recognized in other foras, such as DASH-IF in their position paper \"_Proposed
QoE Metrics...\"_ (see [9]), where they state that \"_Low-level metrics, such
as HTTP and TCP session-related data, or decoding data, are out of scope._ \"
### 5.8.2 Solutions
There are several possible different ways of handling this privacy issue:
1) Each user could be requested to give his active consent before any QoE
metrics can be reported.
2) Each user could be requested to give his active consent before any HttpList
metrics can be reported.
3) Each user could be requested to give his active consent before any URL
entries can be reported.
4) The URL entries can be hashed by the client (so that access to the same URL
will give the same anonymized hash value), and only this hash value is
reported (this would at least enable correlation between different requests
for the same URL).
5) The URL entries can be removed from the HttpList report.
6) The total HttpList metric is removed from TS 26.247.
Adding a requirement for active consent (options 1-3) would mean additional
administrative issues, as well as an unnecessary and possibly worrying
decision needed by the end-user. It is also likely that many end-users would
not give their consent, which at least for option 1 would severely decrease
the coverage and usefulness of the complete QoE reporting concept.
To avoid the need for any type of active consent implies that one of options
4-6 are recommended. As the practical usage of the HttpList metrics can be
questioned, the simplest solution would be to totally remove the HttpList
metric from TS 26.247, as proposed in option 6.
# 6 Conclusion
The gap analysis of PSS QoE metrics for support of ITU-T P.NATS mode 0 is
presented in clause 4, and the analysis of enhanced streaming configuration
and reporting is presented in clause 5. Based on the studies, the following
conclusions can be drawn:
\- To support calculation of the P.1203 mode 0 model for video streaming, the
existing PSS QoE metrics \"MpdInfo\", \"InitialPlayoutDelay\" and \"PlayList\"
specified in TS 26.247 need to be collected. A new metric
\"DeviceInformation\" is also recommended to be added to support the P.1203
model.
\- To enhance reporting of PSS QoE metrics, the following functionalities are
recommended:
\- QMC (QoE Measurement Collection) is recommended to be used to support
control and configuration of QoE reporting. QMC is based on the MDT concept,
so QoE Configuration is done over the control plane, and QoE Reporting from
the DASH client is also sent back via the control plane, for further
forwarding towards the QoE Server.
\- Enable operators to specify collection of QoE metrics only for certain
geographic area , or only for certain streaming services.
#