# Foreword
This Technical Report has been produced by the 3^rd^ Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
The present document provides an analysis of the future video capability
requirements of streaming and multicast/broadcast services. The purpose of the
present document is two-fold. On the one hand, it studies the options to
upgrade the minimal requirements for video reception and decoding. On the
other hand, it studies use cases for support of more advanced UEs. The
ultimate target of this study item is to recommend solutions for efficiently
providing video support commensurate with UE and user capabilities and needs
in PSS and MBMS services.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TS 26.346: \"Multimedia Broadcast/Multicast Services (MBMS);
Protocols and Codecs\".
[2] 3GPP TS 26.234: \"Transparent End-to-End Packet Switched Streaming Service
(PSS); Protocols and Codecs\".
[3] ITU-T Recommendation H.264 (03/09), \"Advanced video coding for generic
audiovisual services\" \| ISO/IEC 14496- 10:2009 Information technology---
Coding of audiovisual objects--- part 10: Advanced Video Coding\".
[4] T. Schierl, Y. Sanchez de la Fuente, C. Hellge, and T. Wiegand:
\"Priority-based Transmission Scheduling for Delivery of Scalable Video Coding
over Mobile Channels,\" 3rd European Symposium on Mobile Media Delivery
(EUMOB), London, 2009.
[5] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[6] 3GPP TR 25.814 (V7.1.0): \"Physical layer aspects for evolved Universal
Terrestrial Radio Access (UTRA) (Release 7)\".
[7] H.264/AVC Reference Software,
[http://iphome.hhi.de/suehring/tml/download/jm17.2.zip.]{.underline}
[8] KTA Software, [http://iphome.hhi.de/suehring/tml/.]{.underline}
[9] Nokia MVC Software, http://research.nokia.com/page/4988.
[10] M. Luby, T. Gasiba, T. Stockhammer, M. Watson, \"Reliable multimedia
download delivery in cellular broadcast networks,\" Broadcasting, IEEE
Transactions on, Vol. 53, Issue 1, Part 2, pp235-246, March 2007.
[11] O. A. Lotfallah, M. Reisslein, and S. Panchanathan, \"A framework for
advanced video traces: evaluating visual quality for video transmission over
lossy networks,\" _EURASIP Journal_ _on Applied Signal Processing_ , vol.
2006, Article ID 42083, 21 pages, 2006.
[12] A. P. Couto da Silva, P. Rodrıguez-Bocca, and G. Rubino, \"Optimal
quality-of-experience design for a P2P multi-source video streaming,\" in
_Proceedings of the IEEE International_ _Conference on Communications (ICC
\'08)_ , pp. 22--26, Beijing, China, May 2008.
[13] Cornelius Hellge, Thomas Schierl, Jörg Huschke, Thomas Rusert, Markus
Kampmann, Thomas Wiegand: Graceful degradation in 3GPP MBMS Mobile TV services
using H.264/AVC temporal scalability; Eurasip Journal on Wireless
Communications and Networking; August 2009.
[14] JSVM reference software, version 9.17, available via CVS from
\"garcon.ient.rwth-aachen.de:/cvs/jvt\".
[15] VCEG-AJ10r1: \"Recommended Simulation Common Conditions for Coding
Efficiency Experiments\".
[16] R. Skupin, C. Hellge, T. Schierl and T. Wiegand, \"Fast Application-level
Video Quality Evaluation for Extensive Error-Prone Channel Simulations\",
_15th International Workshop on Computer-Aided Modeling Analysis and Design of
Communication Links and Networks (CAMAD)_ , Miami, 2010.
[17] G. Liebl et al., \"Simulation platform for multimedia broadcast over DVB-
SH\", _3rd International ICST Conference on Simulation Tools and Techniques
(SIMUTools)_ , Malaga, 2010
[18] H. Schwarz, D. Marpe, and T. Wiegand, \"Overview of the scalable video
coding extension of the H.264/AVC standard,\" _IEEE Transactions on Circuits
and Systems for Video Technology_ , vol. 17, no.9, pp 1103--1120, 2007.
[19] H. Hoffmann (EBU), T. Itagaki (Brunel University, UK), D. Wood (EBU),
\"Quest for Finding the Right HD Format: A New Psychophysical Method for
Subjective HDTV Assessment,\" _SMPTE Motion Imaging Journal_ , Issue: 04
April, 2008.
[20] 3GPP TR 26.902: \"Video Codec Performance (Release 7)\", June 2007.
[21] D. Hong, D. De Vleeschauwer, F. Baccelli, \"A Chunk-based Caching
Algorithm for Streaming Video\", _Proceedings of the 4th Workshop on Network
Control and Optimization_ , Ghent (Belgium), November 29 -- December 1, 2010.
[22] Y. Sanchez, T. Schierl, C. Hellge, T. Wiegand, D. Hong, D. De
Vleesschauwer, W. Van Leekwijck, Y. Lelouedec, \"Improved caching for HTTP-
based Video on Demand using Scalable Video Coding, \" _Consumer Communication
& Networking Conference 2011 (CCNC 2011)_, Special Session on IPTV and
Multimedia CDN, Las Vegas, Nevada, USA, 9-12 January 2011.
[23] Laurent Chauvier, Kevin Murray, Simon Parnall, Ray Taylor, James Walker,
\"Does size matter: the challenges when scaling stereoscopic 3D content\",
_Proc. IBC 2010 Conference_ , http://www.nds.com/pdfs/3DTV-
DoesSizeMatter_IBC2010Award.pdf
# 3 Definitions and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
TR 21.905 [5] and the following apply. A term defined in the present document
takes precedence over the definition of the same term, if any, in TR 21.905
[5].
## 3.2 Abbreviations
For the purposes of the present document, the abbreviations given in TR 21.905
[5] and the following apply. An abbreviation defined in the present document
takes precedence over the definition of the same abbreviation, if any, in TR
21.905 [5].
AVC Advanced Video Coding
BLER BLock Error Rate
CDN Content Delivery Network
CGS Coarse Grain Scalability
ESR Erroneous Seconds Ratio
GOP Group Of Pictures
JSVM Joint Scalable Video Model
KTA Key Technical AreasMBSFN Multicast Broadcast Single Frequency Network
MCS Modulation and Coding Scheme
MGS Medium Grain Scalability
MVC Multi-view Video Coding
NAL Network Abstraction Layer
PBTS Priority Based Transmission Scheduling
PLR Packet Loss Rate
PSNR Peak Signal to Noise Ratio
SVC Scalable Video Coding
TTI Transmission Time Interval
UCC Used Cell Capacity
UEP Unequal Error Protection
# 4 General
## 4.1 Introduction
This Technical Report studies use cases and solutions for both video
scalability and 3D stereoscopic video and investigates their performance in a
variety of setups using 3GPP\'s streaming and multicast/broadcast services.
Subclause 5.1 introduces use cases on 2D service, and the codec solutions
enabling the use cases are described in subclause 6.1.1. Subclause 6.1.2
introduces some applications integrating the 2D solutions and codecs, and the
performance of the solutions is evaluated in subclause 6.1.3. Stereoscopic 3D
use cases are introduced in subclause 5.2. Enabling codecs for the 3D use
cases are described in subclause 6.2.1, and the performance is evaluated in
subclause 6.2.2. This document includes two attachment files which are the
config files used in the evaluations of codecs. Annexes for helping
understanding the simulation conditions are also included. Finally conclusion
based on the study of this TR is presented in subclause 7.
# 5 Use Cases
## 5.1 2D Video Use Cases
### 5.1.1 Adaptive HTTP Streaming and Caches
This use case considers HTTP-based streaming delivery of video content.
Caching of popular content can significantly decrease the average and peak
load within a 3GPP backbone. Using HTTP streaming, caching can be performed by
standard HTTP caches.
{width="6.4944444444444445in" height="1.2673611111111112in"}
Figure 1: System architecture for adaptive HTTP streaming [2].
In this use case the media coding, especially the video coding (e.g. multi-
layered SVC compared to multi bitrate versions of H.264/AVC single layer
coding), and its integration into HTTP Streaming framework will be evaluated
with respect to improvement in usage of originating server, backbone and
caches, and in general its impact on the system, including the impact on
encoders and clients. Furthermore the effect of rate adaptation will be
evaluated in such scenarios.
### 5.1.2 UE Power Saving and Fast Stream Switching in MBMS
Efficient power usage is an important criterion in providing MBMS TV service.
When the TV stream is transmitted continuously, UE should receive data
continuously in active mode, as a result, battery power is consumed. Typical
method used for UE power saving is scheduling the transmission and sleep
period that UE may turn-off radio component during the sleep interval. This
requires discontinuous transmission of MBMS streams. However, a trade-off is
that user may experience long delay when switching between streams, if the
sleep interval is increased Therefore, it should be able to support efficient
power usage of UE as well as fast content switching.
### 5.1.3 Graceful Degradation
#### 5.1.3.1 Rate Adaptation in PSS When Entering Bad Reception Conditions
A mobile TV service may have to cope with varying reception conditions at the
UE to avoid service interruptions. A desired behaviour would be to apply by
rate adaptation of the video stream to the achievable service bit rate. Since
a reduced media rate results in a reduced video play out quality, such a video
stream adaptation should be performed in a graceful way. Therefore, the
service should allow a fine granular rate adaptation to avoid abrupt quality
changes in an efficient way
#### 5.1.3.2 Graceful Degradation in MBMS Services When Entering Bad Reception
Conditions
In contrary to a PSS service, an MBMS service cannot adapt to individual
receivers need. That is, users entering difficult reception conditions may
experience sudden service interruption instead of soft degradation of e.g.
video quality. To keep users satisfied when switching from PSS services to
MBMS, a Graceful Degradation of the broadcast service is a desired feature.
Such a feature can be applied to a broadcast service by allowing
differentiation transmission robustness for different parts of the video
stream. The service should allow minimum acceptable quality to the user
perception at the service coverage configured by operator.
#### 5.1.3.3 Graceful Degradation in Traffic Congestion
In a situation where multiple service users converge in a cell, available
bandwidth of the cell depletes quickly. In such case, service to lately
incoming UEs may be refused, or all UEs in the cell may suffer severe quality
degradation. The situation can be improved when bandwidth of the streams can
be reduced with graceful quality degradation using IVS. The service quality is
recovered as congestion state of the cell is relieved.
#### 5.1.3.4 Combined Support of Heterogeneous Devices and Graceful
Degradation
It is expected, that there will be a coexistence of a variety of device
capabilities within 3GPP system and each of these devices may be in different
reception conditions. Therefore to cope with both of these challenges in an
efficient way, a service should be able to support the heterogeneous devices
and to provide Graceful Degradation behaviour at the same time.
## 5.2 Stereoscopic 3D Video Use Cases
### 5.2.1 Stereoscopic 3D Video Delivery
Stereoscopic 3D video content is becoming increasingly available. A steadily
growing share of professionally produced content is captured in stereoscopic
3D format. On the other hand, mobile devices with 3D rendering capabilities
will gradually enter the market. Since capturing clean stereoscopic 3D video
is extremely challenging, it is expected that the main short-term usage of
these device capabilities will be for the consumption of professionally
produced stereoscopic 3D content. Figure 2 depicts an example setup for the
distribution of stereoscopic 3D content. While 3D capable devices will enjoy
the stereo video, it should be possible to author so that legacy devices can
consume the same content in 2D.
{width="6.207638888888889in" height="2.917361111111111in"}
Figure 2: Example scenario of distribution of 2D and stereoscopic 3D video
Services such as PSS and MBMS provide the right channels for distributing the
content to 3D capable mobile devices. The specified delivery options include
multicast, RTP streaming, adaptive HTTP streaming and progressive download.
This use case may be enabled through different video coding solutions such as
H.264/MVC [3] and frame-compatible H.264/AVC (with SEI signaling). These
solutions will be studied and their performances will be evaluated.
It is in the scope of the study to consider not only coding and backwards-
compatibility, but also the suitability of mobile devices in general for
viewing 3D content (considering issues such as screen size, viewing distance,
and resolution, for example). It is also in scope to consider whether 3D
content from other domains could be re-targeted or whether the mobile
environment might need custom 3D content preparation. Finally, consideration
of whether different mobile devices might need different content (not just,
for example, different encodings or resolutions), is in scope.
### 5.2.2 External Viewing 3D Experience
#### 5.2.2.1 Introduction
The following use cases are based on the same access conditions as presented
in 5.2.1. They propose the ability to decode a 3D video content directly on
the UE with using an external display to provide the 3D experience.
#### 5.2.2.2 Video Eyewear 3D Experience
This use case describes a 3D experience provided thanks to video glasses (also
called video eyewear headsets) compatible with stereoscopic video. During the
recent years, progress has been achieved on the ability to use such video
glasses in order to simulate large screen viewing experience. When connected
to a mobile terminal receiving a stereoscopic video the video glasses display
the left view on the left eye and the right view on the right eye. Each eye
receiving a different view, the depth is provided to the user.
Figure 3 illustrates the current use case.
{width="4.68125in" height="1.5743055555555556in"}
Figure 3: Use case of 3D content viewed on video glasses
#### 5.2.2.3 Mobile Terminal Connected to a 3DTV Set
This use case can be associated to the mobile 3D concept in the way it enables
3D experience when receiving a video content over the 3GPP access network. A
user wants to watch a 3D movie on its 3D compatible TV set at home. He may
take advantage of its LTE coverage to get the streamed video which is decoded
in its mobile terminal. The terminal has a digital connectivity which enables
the connection with a 3DTV display (e.g. via a micro-HDMI/HDMI cable). In this
use case the mobile terminal acts as a mobile Set top box.
Figure 4 hereafter illustrates the current use case.
{width="4.659722222222222in" height="2.415277777777778in"}
Figure 4: Use case of 3D content viewed on a 3D TV set
# 6 Evaluation of Solutions
## 6.1 2D Use Cases
### 6.1.1 Enabling Codecs and Formats
#### 6.1.1.1 Scalable Video Coding
##### 6.1.1.1.1 Introduction
Scalable Video Coding (SVC) [3] has been defined as an extension to the
H.264/AVC [3] video coding standard. SVC enhances H.264/AVC with a set of new
profiles and encoding tools that may be used to produce scalable bitstreams.
SVC supports three different types of scalability: spatial scalability,
temporal scalability, and quality scalability. Temporal scalability is
realized using the already existing reference picture selection flexibility in
H.264/AVC [3] as well as bi-directionally predicted B-pictures. The prediction
dependencies of B-pictures are arranged in a hierarchical structure.
Furthermore, appropriate rate control is used to adjust the bit budget of each
picture to be proportional to its temporal importance in a procedure called
quantization parameter cascading. The slightly and gradually reduced picture
quality of the hierarchical B-pictures has been shown not to significantly
impact the subjective quality and the watching experience, while showing high
compression efficiency. Figure 5 shows an example of the realization of
temporal scalability using hierarchical B-pictures. The example shows 4
different temporal levels, resulting in one base layer and 3 temporal
enhancement layers. This allows the frame rate to be scaled by a factor up to
8 (e.g. from 60Hz to 7.5Hz). This approach has the drawback that it incurs a
relatively high decoding delay that is exponentially proportional to the
number of temporal layers, since the pictures have to be decoded in a
different order than their display order. As the coding gain also diminishes
with the increasing number of hierarchy levels, it is not appropriate to
generate a high number of temporal layers. An alternative to the above
mentioned approach for temporal scalability is the use of low-delay uni-
directional prediction structures, hence avoiding the out-of-display-order
decoding at the cost of reduced coding efficiency.
{width="6.065972222222222in" height="2.6993055555555556in"}
Figure 5: Temporal scalability with hierarchical B-picture structure in SVC
Spatial scalability is the most important scalability type in SVC. It enables
encoding a video sequence into a video bit stream that contains one or more
subset bit streams and where each of these subsets provides a video at a
different spatial resolution. The spatially scalable video caters for the
needs of different consumer devices with different display capabilities and
processing power. Figure 6 depicts an example for a prediction structure for
spatial scalability (QCIF to CIF resolution). The spatial scalability layer is
enhanced with an additional temporal scalability layer that doubles the frame
rate at the CIF resolution.
{width="5.895138888888889in" height="3.1729166666666666in"}
Figure 6: Example prediction structure for spatial scalability
SVC defines three different inter-layer prediction modes that are designed to
enable the single-loop low complexity decoding at the decoder. In other words,
motion compensation is performed only once at the target layer at the decoder.
The inter-layer prediction tools are inter-layer INTRA (texture) prediction,
inter-layer motion prediction, and inter-layer residual prediction.
Inter-layer INTRA prediction enables texture prediction from the base layer at
co-located macro-blocks (after upsampling). It is restricted to INTRA coded
macroblocks at the lower layer. The up-sampling of the macroblock texture is
performed using well-specified up-sampling filters (a 4-tap filter for Luma
samples and bi-linear filter from chroma samples). Inter-layer motion
prediction implies prediction of the base layer motion vector from the co-
located INTER-coded macro-block (after upsampling) of the lower layer. The
prediction involves all components of the motion vector: the macro-block
partitioning structures, the reference picture indices, and the x- and y-
components representing the motion direction. Finally, the inter-layer
residual prediction allows inter-layer prediction from the residual after
INTER-prediction at the lower layer. At the decoder side, the residual
information of the target layer is built up by summing all correctly up-scaled
residuals of the lower dependent layers.
The third prediction type in SVC is quality scalability. Quality scalability
enables the achievement of different operation points, each yielding a
different video quality. Coarse Grain Scalability (CGS) is a form of quality
scalability that uses the same tools as the spatial scalability, hence
operating in the spatial domain. Alternatively, Medium Grain Scalability (MGS)
may be used to achieve quality scalability performing the inter-layer
prediction at the transform domain. Two techniques are advocated for MGS
scalability: splitting number of transform coefficients and encoding
difference of transform coefficients quantized using different quantization
parameters. MGS significantly reduces the complexity at encoder and decoder.
CGS may be seen as a variant of spatial scalability where the spatial scaling
factor is set to one. Quality scalability may be used to address different use
cases such as rate adaptation or for offering a high quality pay service.
SVC MGS scalability offers an increased flexibility for bit stream adaptation
and error robustness. Scalable streams providing a variety of bit rates can be
effectively encoded. For MGS coding in SVC, two new features have been
introduced: _motion-compensated prediction for the base layer from the
enhancement_ layer and the supported of so-called _key pictures_.
These concepts are illustrated in Figure 7.
{width="3.522222222222222in" height="1.63125in"}
Figure 7: Key picture concept of SVC for hierarchical prediction structures
The first feature enables a simple but effective drift control for
hierarchical prediction structures. For each picture it is signalled whether
the base layer representation (when available) or the enhancement layer
representation of the reference pictures is employed for motion-compensated
prediction. Pictures that use the base layer representation for motion-
compensated prediction are called _key pictures_ (see Figure 7). This has the
advantage that if any enhancement layer data are lost, no drift occurs between
encoder and decoder reconstruction.
##### 6.1.1.1.2 Solution Configuration
For the purposes of improved video support in 3GPP services, a profile of SVC
[3] is selected that allows backwards compatibility to basic terminals. This
is inherently provided by SVC by requesting the base layer to be H.264/AVC [3]
compatible. Furthermore, it has to be ensured that the base layer also
conforms to the minimal requirements for basic services. In order to ensure
the conformance with the constrained baseline profile of H.264/AVC [3]. SVC
has to be used according to the Scalable Baseline profile with the same
constraints.
Additionally, the level selection for a base layer has to be aligned with the
minimal level requirements for 3GPP services. For enhancement layers, the
level selection is proposed to be set to level 3, which has the following
characteristics:
Table 1: Limitations of the proposed SVC level 3
* * *
Maximum macroblocks/second Maximum Frame Size in MBs Maximum Bitrate  
40500 1620 10 _Mbps_  
Format Luma Width Luma Height Frame Rate QCIF 176 144 172 QVGA 320 240 135
WQVGA 400 240 108 CIF 352 288 102.3 HVGA 480 320 67.5 nHD 640 360 45 VGA 640
480 33.8 525 SD 720 480 30 625 SD 720 576 25
* * *
The proposed solution should be optional for service provider and for UE.
Appropriate mechanisms to properly announce and setup the session (either
including or excluding enhancement layers) are available or should be
extended. If UE supports SVC and it detects that the service also provides SVC
enhancement layer(s), then the UE is able to consume the service at an
improved quality/resolution.
### 6.1.2 Solution Integration Approaches
#### 6.1.2.1 Rate Adaptation for PSS using SVC with Priority-Based
Transmission Scheduling
This solution integration is related to the use case \"Rate adaptation in PSS
when entering bad reception conditions\" (subclause 5.1.3.1).
In order to overcome outages and phases with reduced bit rate, a priority-
based transmission scheduling (PBTS) algorithm is proposed to be used to pre-
buffer larger amounts of more important data for longer playouts than data
with less importance for the resulting video playout quality. The adaptation
of the transmission scheduling and the media rate is only based on buffer
status reports from client to PSS server as depicted in Figure 8.
{width="6.729861111111111in" height="1.5069444444444444in"}
Figure 8: Transmission scheduling and media rate adaptation based on priority
based buffer status reports
Typically, the size of a UEs buffer is fixed which is assumed in this
scenario. The maximum buffering time is depicted in Figure 8 for a standard
buffer with one media quality and a priority based buffer with exemplary two
quality levels, either temporal, spatial or quality levels or combination of
those.
{width="2.292361111111111in" height="2.2416666666666667in"}
Figure 9: Priority (PBTS) buffer using different qualities (_Q1_ and _Q2_) vs.
standard buffer with one quality (Q), with _t+y_ respectively _t_ being the
maximum sustainable outage time
In this example, the maximum buffer time for the standard buffer is _t,_ which
is dependent on the bit rate of the video stream (Q). The priority buffer
allows to prebuffer a longer time of the lowest quality level (Q1) _t+y_ by
reducing the prebuffer time of the higher quality level (Q2) to _t-x_ , where
_t+y_ and _t-x_ depend on the bit rate of the quality levels.
To fill up a standard buffer, the PSS server uses a transmission scheduling in
decoding order of the video stream. Whereas to fill up a priority based
buffer, the PSS server uses a priority based transmission scheduling, where it
first fills up the lowest quality level to _t+y_ and after that the higher
quality layer to _t-x_. After that it switches to the standard transmission
scheduling in decoding order.
When the UE enters difficult reception conditions, the available bit rate may
no longer be sufficient for the transmission of the highest quality. Having a
standard buffer, in such a case users would experience a video outage. In case
of having a buffer filled with a priority scheduling algorithm, the high
quality data in the buffer runs out earlier than lower qualities. Using SVC,
the PSS server would adapt the media stream bit rate to the available service
bit rate by dropping quality layers, which still allows to keep the buffer
state of the lowest quality level fully filled. Compared to the use of a
standard buffer, the highest quality runs out even faster with the priority
based approach. Nevertheless, the priority based scheduling allows for keeping
the playout alive during longer outages than in the standard case.
Dependent on the buffer reports, the PSS streaming server adapts the media
stream bit rate to the quality of the available service bit rate. If the
clients\' reception condition allows a higher quality, the transmission
scheduling is adapted to allow rebuffering of the priority buffer to the
maximum quality of the available service bit rate.
Although PBTS can be based on H.264/AVC temporal scalability (AVC-PBTS), SVC
has the handy advantage to allow a bit rate reduction using quality or spatial
scalability instead of relying on pure temporal scalability as described in
[4].
#### 6.1.2.2 Rate Adaptation using SVC MGS Scalability
##### 6.1.2.2.1 Rate Adaptation Approach
The SVC bit rate adaptation approach is based on multiple Operation Points
within the same MGS-encoded scalable stream. An Operation Point (OP) is
defined as a unique combination of temporal and quality levels, where
reasonable combinations of different pairs of Temporal ID and Quality ID are
selected in a way so that OPs can be dropped from the bit stream one after the
other. An SVC MGS bit-stream consists of different NAL (Network Abstraction
Layer) units with different importance for the decoding process. A Quality ID
indicating the quality level and a Temporal ID indicating the temporal level
are included in the NAL unit SVC header extension of each SVC NAL unit.
Tables 3 and 4 show for example a number of reasonable combinations of
different pairs of Temporal ID and Quality ID regarding SVC encoding of a
video sequence with 2 MGS quality layers and respectively 4 (GOP 8) and 5 (GOP
16) temporal levels. Operation points are chosen in such a way that at least
the base layer stream remains and the frame rate of a stream isn\'t reduced.
If necessary, streams with reduced frame rates can be also built.
From one row to the next row below, exactly one additional pair of {T, Q} is
dropped from the SVC bit stream. The bit rate of a video stream is decreased
by choosing of the next highest Operation Point (OP) for this stream and
dropping all packets which are not needed for decoding the content at this OP.
In this way an efficient bit rate adaptation is achieved.
Table 2: Reasonable operation points with SVC MGS scalability (T, Q layer
combination)\ (GOP 8, 2 MGS quality layers)
* * *
**OP** **T:** 0 1 2 3  
**Q:** 0 1 0 1 0 1 0 1 0 ● ● ● ● ● ● ● ● 1 ● ● ● ● ● ● ● **x** 2 ● ● ● ● ●
**x** ● **x** 3 ● ● ● **x** ● **x** ● **x** 4 ● **x** ● **x** ● **x** ● **x**
* * *
Table 3: Reasonable operation points with SVC MGS scalability (T, Q layer
combination)(GOP 16, 2 MGS quality layers)
* * *
**OP** **T:** 0 1 2 3 4  
**Q:** 0 1 0 1 0 1 0 1 0 1 0 ● ● ● ● ● ● ● ● ● ● 1 ● ● ● ● ● ● ● ● ● **x** 2 ●
● ● ● ● ● ● **x** ● **x** 3 ● ● ● ● ● **x** ● **x** ● **x** 4 ● ● ● **x** ●
**x** ● **x** ● **x** 5 ● **x** ● **x** ● **x** ● **x** ● **x**
* * *
Figure 10 shows an example for the composition of each frame within a GOP for
the OPs highlighted in the Table 2. It becomes apparent that dropping the
quality layers Q1 of the temporal levels T2 and T3 reduces the video rate from
x to y (OP2). Further, dropping the quality layer Q1 of all temporal levels
results to the video bit rate of _z_ (OP4) where _z \ = 0.1 \|\|
\- Lost audio play out >= 0.1
To get an overview of the received quality in a transmission cell, we define
the \"Coverage\" metric which shows the percentage of users receiving at least
a certain quality.
Example**:** 250 out of the total of 500 users achieve constraints of medium
quality à Coverage of simulated transmission scheme at medium quality is 50 %
coverage.
##### 6.1.3.4.6 Simulation Results
For SVC, two layer transmission schemes are applied whereas audio and video
base layer belong to one transmission layer (with higher FEC protection and/or
higher transmission power) and the video SNR layer to another transmission
layer.
For the different transmission schemes, FEC code rates (in the range between
0.4 and 1.0) and transmission power levels are varied. The plots in this
subclause show coverage at the y-axis and Ucc at the x-axis.
Results are given for the sequence \"Reuter\". Figures 41 to 43 show the
results for all transmission settings for each quality category.
{width="4.711111111111111in" height="3.3090277777777777in"}
Figure 41: Coverage of maximum quality sorted by transmission schemes
{width="4.629861111111111in" height="3.2465277777777777in"}
Figure 42: Coverage of medium quality sorted by transmission schemes
{width="4.966666666666667in" height="3.475in"}
Figure 43: Coverage of minimum quality sorted by transmission schemes
#### 6.1.3.5 Coding Results using KTA
##### 6.1.3.5.1 Experimental Setup
In this subclause, QVGA/VGA encoding using SVC and an optimized H.264/AVC
encoder is compared.
For the experiments, the publicly available JSVM 9.17 and KTA 2.3 software
packages [14] and [8] are used. The simulation settings were aligned with the
VCEG recommended simulation conditions [15].
Four publicly available test sequences were used (Table 17). For each sequence
a basis resolution (QVGA) and an enhanced resolution (VGA) is used, so as to
compare SVC spatial scalability against H.264/AVC coding.
Table 17: Test sequences
* * *
Sequence Basis resolution Enhanced resolution CrowdRun QVGA, 12.5 _Hz_ VGA, 25
_Hz_ Seeking  
Crew QVGA, 15 _Hz_ VGA, 30 _Hz_ Soccer
* * *
For SVC encoding, the scalable baseline profile is used. For H.264/AVC
encoding, baseline profile for encoding of the basis resolution and high
profile for encoding of the enhanced resolution is used. The common coding
tools that were used in the SVC and H.264/AVC simulations are shown in Table
18. (A complete description of the coding settings for JSVM and KTA are
provided in attachment A). Note that KTA was operated in H.264/AVC mode, which
means that only H.264/AVC compliant coding tools were used.
Table 18: Common coding settings
+-----------------------+--------------------+-----------------------+ | Coding options | Basis resolution | Enhanced resolution | +-----------------------+--------------------+-----------------------+ | B pictures | No | Yes | +-----------------------+--------------------+-----------------------+ | 8x8 transform and | No | Yes | | intra prediction | | | +-----------------------+--------------------+-----------------------+ | Entropy coding | CAVLC | CABAC | +-----------------------+--------------------+-----------------------+ | Number of active | 2 | 2 | | reference pictures | | | | for list 0 | | | +-----------------------+--------------------+-----------------------+ | Number of active | Na | 2 | | reference pictures | | | | for list 1 | | | +-----------------------+--------------------+-----------------------+ | Deblocking filter | Yes | Yes | +-----------------------+--------------------+-----------------------+ | Weighted prediction | No | No | +-----------------------+--------------------+-----------------------+ | Prediction structure | IPP | IbBbP | +-----------------------+--------------------+-----------------------+ | Intra period | 12 frames for\ | 24 frames for 25 fps | | | 12.5 fps sequences | sequences | | | | | | | 14 frames for\ | 28 frames for 30 fps | | | 15 fps sequences | sequences | +-----------------------+--------------------+-----------------------+ | Search range | 64 | 64 | +-----------------------+--------------------+-----------------------+
For KTA simulations, a QP range of 22-37 was used. For JSVM simulations, {37,
33, 29, 25} was used as base layer QPs, and a QP offset of 2, i.e. the
corresponding enhancement layer QPs were {39, 35, 31, 27}.
##### 6.1.3.5.2 Results
Figures 44 to 51 and Table 19 \~ Table 22 show the results for the four test
sequences.
{width="5.330555555555556in" height="3.734027777777778in"}
Figure 44: Sequence CrowdRun: PSNR results for QVGA SVC and QVGA AVC. JSVM was
used for SVC encoding and KTA for AVC encoding
{width="5.038888888888889in" height="3.7743055555555554in"}
Figure 45: Sequence CrowdRUN: PSNR results for VGA SVC, VGA AVC and AVC
simulcast (QVGA+VGA). JSVM was used for SVC encoding and KTA for AVC encoding
{width="4.968055555555556in" height="3.48125in"}
Figure 46: Sequence Seeking: PSNR results for QVGA SVC and QVGA AVC. JSVM was
used for SVC encoding and KTA for AVC encoding
{width="5.133333333333334in" height="3.6055555555555556in"}
Figure 47: Sequence Seeking: PSNR results for VGA SVC, VGA AVC and AVC
simulcast (QVGA+VGA). JSVM was used for SVC encoding and KTA for AVC encoding
{width="5.2375in" height="3.6694444444444443in"}
Figure 48: Sequence Crew: PSNR results for QVGA SVC and QVGA AVC. JSVM was
used for SVC encoding and KTA for AVC encoding
{width="5.245138888888889in" height="3.6770833333333335in"}
Figure 49: Sequence Crew: PSNR results for VGA SVC, VGA AVC and AVC simulcast
(QVGA+VGA). JSVM was used for SVC encoding and KTA for AVC encoding
{width="4.5777777777777775in" height="3.2020833333333334in"}
Figure 50: Sequence Soccer: PSNR results for QVGA SVC and QVGA AVC. JSVM was
used for SVC encoding and KTA for AVC encoding
{width="4.529166666666667in" height="3.1819444444444445in"}
Figure 51: Sequence Soccer:PSNR results for VGA SVC, VGA AVC and AVC simulcast
(QVGA+VGA). JSVM was used for SVC encoding and KTA for AVC encoding
Table 19: Results for sequence CrowdRun. JSVM was used for SVC encoding and
KTA for AVC encoding
* * *
QVGA SVC VGA SVC Simulcast AVC  
Bitrate [_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate
[_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate [_kbps_] SVC
gain over AVC simulcast [%] 440.8 27.5 420.4 4.85 1797.8 27.7 1408.9 27.60
1829.3 1.72 718.5 30.4 677.0 6.13 3018.0 30.3 2396.0 25.96 3073.1 1.79 1106.6
33.7 1047.1 5.68 4847.9 33.2 3878.9 24.98 4926.0 1.59 1597.9 37.0 1501.7 6.40
7425.9 36.1 5930.6 25.21 7432.3 0.09 Average 5.76 25.94 1.30
* * *
Table 20: Results for sequence Seeking. JSVM was used for SVC encoding and KTA
for AVC encoding
* * *
QVGA SVC VGA SVC Simulcast AVC  
Bitrate [_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate
[_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate [_kbps_] SVC
gain over AVC simulcast [%] 262.2 28.9 256.1 2.41 1003.6 29.4 795.7 26.14
1051.7 4.57 442.3 31.5 429.9 2.88 1718.5 31.9 1376.5 24.84 1806.4 4.87 718.2
34.6 704.3 1.97 2871.1 34.7 2333.8 23.02 3038.1 5.50 1101.6 37.6 1082.5 1.77
4599.6 37.4 3732.6 23.23 4815.1 4.47 Average 2.26 24.31 4.85
* * *
Table 21: Results for sequence Crew. JSVM was used for SVC encoding and KTA
for AVC encoding
* * *
QVGA SVC VGA SVC Simulcast AVC  
Bitrate [_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate
[_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate [_kbps_] SVC
gain over AVC simulcast [%] 165.3 32.0 148.7 11.21 543.8 32.9 400.2 35.90
548.8 0.91 278.7 34.4 256.5 8.65 917.7 35.1 684.1 34.15 940.6 2.43 463.3 37.0
432.6 7.09 1554.8 37.3 1181.8 31.56 1614.4 3.69 744.8 39.5 697.2 6.82 2633.7
39.3 1994.6 32.05 2691,7 2.15 Average 8.44 33.41 2.30
* * *
Table 22: Results for sequence Soccer. JSVM was used for SVC encoding and KTA
for AVC encoding
* * *
QVGA SVC VGA SVC Simulcast AVC  
Bitrate [_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate
[_kbps_] PSNR Y AVC bitrate [_kbps_] cost over AVC [%] Bitrate [_kbps_] SVC
gain over AVC simulcast [%] 140.5 31.4 128.9 9.02 500.3 31.9 390.2 28.20 519.1
3.62 230.9 33.6 215.2 7.26 845.1 34.2 656.5 28.72 871.7 3.06 382.6 36.1 365.9
4.58 1425.6 36.8 1106.5 28.84 1472.4 3.17 606.9 38.9 588.7 3.09 2361.6 39.2
1832.9 28.85 2421.6 2.48 Average 5.99 28.65 3.08
* * *
On average, SVC induces average bit rate costs of 5.6% and 28.1% over non-
scalable H.264/AVC at QVGA and VGA resolution, respectively. The average SVC
bit rate reduction over H.264/AVC simulcast is 2.9%.
#### 6.1.3.6 Coding Results using JSVM
##### 6.1.3.6.1 JSVM
The JSVM (Joint Scalable Video Model) software is the reference software for
the Scalable Video Coding (SVC) project of the Joint Video Team (JVT) of the
ISO/IEC Moving Pictures Experts Group (MPEG) and the ITU-T Video Coding
Experts Group (VCEG). JSVM can be used to encode standard compliant H.264/AVC
streams as well as scalable video streams.
##### 6.1.3.6.2 Experimental Setup
In the conducted experiments, we used the JSVM software package version 9.17
[14].
The presented encodings are comprised of a 2-layer SVC based stream with SNR
or resolution scalability. The respective resolutions used in our tests were
320x240 to 320x240 (QVGA/QVGA) for SNR scalability (Configuration 1 and
configuration 2).
##### 6.1.3.6.3 Sequences
For the QVGA test the Sequences and their corresponding configurations are
depicted in Table 23.
Table 23: Sequences and their configurations for QVGA SNR scalability
+--------------------------+--------------------------+--------------+ | **Configuration 1** | **Configuration 2** | **Sequence** | +--------------------------+--------------------------+--------------+ | - AVC: QVGA @ 12.5 fps | - AVC: QVGA @ 25 fps | AlohaWave | | | | | | High Profile | High Profile | | | | | | | - AVC: QVGA @ 25 fps | - AVC: QVGA @ 25 fps | | | | | | | High Profile | High Profile | | | | | | | - SVC BaseLayer: QVGA | - SVC BaseLayer: QVGA | | | \@12.5 fps | \@25 fps | | | | | | | High Profile | High Profile | | | | | | | (Identical to AVC QVGA) | (Identical to AVC QVGA) | | | | | | | - SVC Enh. Layer: QVGA | - SVC Enh. Layer: QVGA | | | @ 25 fps | @ 25 fps | | | | | | | Scalable High Profile | Scalable High Profile | | +--------------------------+--------------------------+--------------+ | | | CrowdRun | +--------------------------+--------------------------+--------------+ | | | ParkJoy | +--------------------------+--------------------------+--------------+ | | | Umbrella | +--------------------------+--------------------------+--------------+
##### 6.1.3.6.4 Coding Tools
Tables 24 and 25 display the coding tools used for Single Layer, and SVC
encoding.
Table 24: Coding tools for single layer coding
* * *
**Coding tools for single layer coding ( & simulcast)** **High profile** B
pictures Yes 8x8 transform & intra pred. Yes entropy coding CABAC GOP size 16
Random Access Point distance 1,28 s
* * *
Table 25: Coding tools for SVC coding
* * *
**Coding tools for SVC Scalable High Profile** **Enhancement Layer** B
pictures Yes 8x8 transform & intra pred. Yes entropy coding CABAC GOP size 16
Random Access Point distance 1,28 s
* * *
##### 6.1.3.6.5 Results
The Rate-Distortion (RD) curves for the selected sequences are shown in
subclauses 6.1.3.6.5.1 and 6.1.3.6.5.2
The plots show the performance of SVC and AVC encodings. Each plot shows the
Rate-Distortion (RD) curve for the base layer (AVC 0) and the enhancement
layer (SVC 1) as well as for the corresponding single layer (AVC 1) providing
the same quality level as the SVC enhancement layer and the accumulated
simulcast curve.
Sample configuration files used to generate these results can be found in the
Attachment B.
The video sequences used in this subclause are publicly available.
###### 6.1.3.6.5.1 320x240 (QVGA) SNR Scalability (Configuration 1)
320x240 Scalable High Profile (SVC) vs. AVC 320x240 High Profile with CGS SNR
-- scalability.
Base-layer at half frame-rate and a quantization point difference of 4:
{width="3.575in" height="3.575in"}
Figure 52: AlohaWave
{width="3.7333333333333334in" height="3.7333333333333334in"}
Figure 53 : CrowdRun
{width="4.258333333333334in" height="4.258333333333334in"}
Figure 54 : ParkJoy
{width="3.95in" height="3.95in"}
Figure 55 : Umbrella
Table 26: Results of AlohaWave
* * *
**SVC** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 129.92
32,48 113,08 14.90 163.01 20.30 227.81 35,39 203,08 12.18 298.48 23.68 404.69
38,08 373,08 8.47 544.94 25.74 803.18 41,29 753,08 6.65 1074.54 25.25
* * *
Table 27: Results of CrowdRun
* * *
**SVC** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 610.09
28,13 542,40 12.48 745.45 18.16 1112.98 31,52 1022,40 8.86 1434.41 22.41
1914.16 35,37 1812,40 5.61 2579.12 25.78 3090.84 39,41 2972,40 3.98 4257.29
27.40
* * *
Table 28: Results of ParkJoy
* * *
**SVC** ** ** ** ** ** ** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 403.02
28,68 356,55 13.03 491.69 18.03 761.35 31,83 696,55 9.30 975.43 21.95 1399.41
35,44 1316,55 6.29 1868.36 25.10 2436.78 39,41 2326,55 4.74 3328.81 26.80
* * *
Table 29: Results of Umbrella
* * *
**SVC** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 619.64
28,82 538,79 15.01 760.13 18.48 1071.74 32,20 968,79 10.63 1377.07 22.17
1790.63 35,84 1668,79 7.30 2391.58 25.13 2895.69 39,66 2758,79 4.96 3967.15
27.01
* * *
###### 6.1.3.6.5.2 320x240 (QVGA) SNR Scalability (Configuration 2)
320x240 Scalable High Profile (SVC) vs. AVC 320x240 High Profile with CGS SNR
-- scalability.
Base-layer at full frame-rate and a quantization point difference of 4.
{width="4.025in" height="4.025in"}
Figure 56: AlohaWave
{width="4.016666666666667in" height="4.016666666666667in"}
Figure 57: CrowdRun
{width="3.925in" height="3.925in"}
Figure 58: ParkJoy
{width="3.9833333333333334in" height="3.9833333333333334in"}
Figure 59: Umbrella
Table 30: Results of AlohaWave
* * *
**SVC** ** ** ** ** ** ** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 136.88
32,48 113,08 21.05 180.66 24.23 238.33 35,39 203,08 17.36 331.21 28.04 419.94
38,08 373,08 12.56 601.27 30.16 831.84 41,29 753,08 10.46 1180.72 29.55
* * *
Table 31: Results of CrowdRun
* * *
**SVC** ** ** ** ** ** ** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 638.78
28,13 542,40 17.77 840.31 23.98 1159.17 31,52 1022,40 13.38 1629.82 28.88
2001.61 35,37 1812,40 10.44 2980.79 32.85 3211.44 39,41 2972,40 8.04 4986.23
35.59
* * *
Table 32: Results of ParkJoy
* * *
**SVC** ** ** ** ** ** ** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 421.77
28,68 356,55 18.29 551.61 23.54 789.90 31,83 696,55 13.40 1099.49 28.16
1451.64 35,44 1316,55 10.26 2121.56 31.58 2528.89 39,41 2326,55 8.70 3807.23
33.58
* * *
Table 33: Results of Umbrella
* * *
**SVC** ** ** ** ** ** ** **Simulcast AVC**  
**Bitrate [_kbps_]** **Y-PSNR [_dB_]** **AVC bitrate [_kbps_]** **cost over
AVC [%]** **Bitrate [_kbps_]** **SVC gain over AVC simulcast [%]** 643.72
28,82 538,79 19.47 857.53 24.93 1115.75 32,20 968,79 15.17 1568.79 28.88
1864.75 35,84 1668,79 11.74 2760.56 32.45 3009.03 39,66 2758,79 9.07 4612.60
34.76
* * *
#### 6.1.3.7 Caching Efficiency Improvement with SVC for Adaptive HTTP VoD
##### 6.1.3.7.1 Overview
Adaptive HTTP streaming in a VoD system takes advantage of the widely deployed
network caches to relieve video servers from sending the same content to a
high number of users in the same access network. Since the connection
characteristics may vary over the time, with adaptive Streaming over HTTP, a
technique that has been recently proposed, video clients may dynamically adapt
the requested video quality for ongoing video flows, to match their current
download rate as good as possible. One possibility to provide adaptive
streaming over HTTP is to encode multiple representations of each of the
videos with H.264/AVC at the server and offer them side-by-side. Another is
offering all these representations embedded in one file via Scalable Video
Coding (SVC). The presented simulations compare the impact of multiple chunk
based content representations on the caching efficiency either using H.264/AVC
or SVC. Similar simulation results within an HTTP based progressive download
scenario have already been presented in [22].
Figure 60 schematically shows a network over which a video library is offered
by a Video on Demand (VoD) service. The operator of the access network (i.e.,
the cloud in the figure), offers connectivity to its customers via access
links and connects to the Internet (where the content library is offered on an
origin server by a third party) over a \"transit\" link, in the following
referred to as the cache feeder link. In that way the customers of the access
network operator can access video content, in particular the movies on the
origin server. The network operator deploys a proxy and a cache in its network
to minimize the amount of transmitted data through the \"transit\" link
relieving the server of having to send an extremely high amount of video data.
Since the cache is usually too small to host the complete video library and
the content library on the origin video server often changes, the video files
that are stored in the cache at every moment need to be carefully selected.
This is accomplished by an appropriate caching algorithm.
{width="2.426388888888889in" height="2.3513888888888888in"}
Figure 60: A typical network, hosting a cache, over which content is offered.
There are many different cache replacement algorithms that have been proposed
over the last years that optimize the caching performance based on some
special criteria. Most algorithms make decisions based either on how recently
an object has been requested or on how frequently an object has been requested
over a time period or a combination thereof. In [21] the chunk-based delivery
(video files downloaded in smaller parts thereof, i.e. chunks/segments) is
exploited in a caching context. In this work the chunks that will be consumed
in a near future with a high probability are predicted, assuming that it is
very likely that a user playing chunk n of a given video file at the current
moment will play chunk **_n+k_** of the same video file **_k_** time instants
later.
##### 6.1.3.7.2 Effect of Multiple Representations on the Caching Efficiency
In this contribution, we consider the scenario where users may request a
certain video clip in one of a possible set of resolutions or quality
versions. Hence, each video offered by the origin server must be encoded in a
given number (N) of bit rates. These N versions can be encoded separately with
AVC and offered side by side, a scenario we refer to as \"Multi-Representation
VoD (MR-VoD)\", or can be embedded in a multi-layer representation which
allows for further separation into file subsets (layers) using SVC, a scenario
we refer to as \"SVC-VoD\". We discuss the impact of the former first and
comment on the latter.
Compared to the scenario in which only one version is offered (which we refer
to as the \"Single-Representation VoD (SR-VoD)\" scenario), in the MR-VoD
scenario, the requests for a particular video clip are distributed over its
_N_ versions.
{width="3.2840277777777778in" height="2.567361111111111in"}
Figure 61: Caching efficiency reduction result of offering a higher variety of
representations\ (e.g. 4) for each file
If each of the versions associated with a video clip is requested with more or
less equal probability, the ranking in the MR-VoD scenario is almost the same
as in the scenario with only one version: instead of occurring only once, each
video clip occurs N times in that ranking, but with high probability in a
block of N consecutive ranks. A consequence of this is that if a certain
version of a video is cached it is highly likely that all other versions need
to be cached as well. Consequently, in order to attain the same cache-hit-
ratio in the MR-VOD scenario as in the SR-VOD scenario, the cache should be
able to store all N versions of the video instead of just one. Since storing N
versions side by side requires more storage, a larger cache size/capacity is
needed to attain the same hit ratio. Conversely, if the same cache capacity is
used, a lower cache-hit-ratio results, as illustrated in Figure 61. Note that
based on a similar reasoning (and as described in more detail in clause
6.1.3.7.3) the SVC-VoD scenario could attain the same hit ratio with
practically the same cache size.
##### 6.1.3.7.3 Scalable Video Coding and Impact on the Caching Efficiency
The main difference between MR-VoD and SVC-VoD is illustrated in Figure 62\.
It can be seen that by using SVC much more video clips at different
representations can be stored in the cache, while with MR-VoD many files have
to be removed from the cache to obtain additional space for the new incoming
files or versions of them.
{width="3.0034722222222223in" height="2.341666666666667in"}
Figure 62: Caching performance comparison for MR-VoD and SVC-VoD
When considering a VoD service with multiple available representations based
on layers of SVC, first the amount of data that has to be transmitted to and
stored in the cache is reduced compared to the MR-VoD case, and second, more
clients request the same data (layers) since clients requesting different
representations of a same video clip are expecting to receive a set of layers,
where some layers are common for all of those requests, e.g. the base layer.
Thus, the HTTP request for a certain quality results in a multiple HTTP
request for each of the mentioned layers and all requests for a single content
incorporate at least the base layer representation. Consequently, the
probability of a cache-hit for files containing the lowest layers of SVC
streams, which most of the users are interested in, is increased.
Note that requesting multiple layers for each segment could be done in twofold
manner. One is within one single TCP connection requesting each layer after
the other. The first approach (single TCP connection) introduces additional
buffering requirement (for lower layer segments) at the clients, in addition
to the playout delay, since client has to wait until highest layer segment is
received before playout can start. Another possibility could be to setup
parallel TCP connections. The second approach (parallel TCP connections) would
reduce (but not eliminate) this buffering and playout delay but introduces
additional HTTP overhead (new connection per layer). The simulation results
analyze the effect of different video codings on the caching efficiency.
Therefore, the impact on the buffering requirements at the clients and the
additional HTTP overhead is not considered here.
##### 6.1.3.7.4 Caching Algorithm
The performance of the cache is here analyzed for two different caching
algorithms (operating on chunks):
> • LRU: where the most recently requested chunks are kept in the cache.
>
> • CC: An algorithm described in [1] that takes into account the number of
> guaranteed hits of chunks (if the HTTP streaming client keeps on selecting
> the same version as it currently does), which uses an improved movie content
> scoring algorithm that combines the LRU and LFU basics.
In case of considering SVC there are n chunks per time interval, where n
corresponds to the number of layers. In other words, the layers are
transmitted and stored in the cache separately and therefore count as
different objects for the cache-hit-ratio evaluation. In case of offering the
n version side by side via AVC, each time interval has n independent versions,
in the sense that if one version is cached and another is requested no cache
hit can be counted.
##### 6.1.3.7.5 Congestion Control
Clients (on the same access network) of a multimedia service typically share
(transport and caching) resources with other multimedia clients and/or users
downloading any type of data from the Internet, which produces some cross-
traffic in the network causing congestion. This results in a temporarily
reduced available download rate for the clients of the service.
These clients (HTTP streaming-clients) detect these variations in the
connection rate available to them and adapt the bit rate at which they
download their ongoing video stream, by requesting the following
chunks/segments in an appropriate version. Therefore, every time a user
requests a new chunk of a video an additional decision has to be made with
respect to which version it will be download. This choice depends on:
• The capability of the terminal of the user.
• The congestion state between the cache and the end user (i.e., the access).
If requesting the version that a user wants to download would congest the
link, this request is downgraded as many times as needed to alleviate
congestion.
On the access link other services run (i.e., a user may be downloading a large
file, may be browsing the web, etc.) besides the HTTP streaming video client
streaming a video. This type of congestion can occur any time of the day and
is not necessarily restricted to peak hours. The model for this type of
congestion that we have simulated in this paper is shown in Figure 63. This
figure illustrates a Markov-chain with four states corresponding to four
possible download rates and selected OPs.
{width="3.1222222222222222in" height="1.0743055555555556in"}
Figure 63: Model for congestion due to cross-traffic
In fact we assume that the cross traffic on the access link which is the
result of sharing this link with one or more HTTP streaming clients or any
other client requesting data from the Internet is such that the HTTP streaming
client requesting the version in the next slot, can be described by a Markov
chain.
As seen in Figure 63 this Markov chain consists of four states where the
transition probabilities **_p~ij~_** of the transition matrix
**_P=_[_p~ij~_]** with **_\| j-i \| >1_** are set to zero, i.e. it is only
possible to go from a state to its neighbour states. The rest of the
parameters (represented in the figure) were set to values that lead to
realistic situations.
The most important parameters to take into account to consider whether the
selected values correspond to a realistic situation or not are the mean state
sojourn time (mean duration of being in a state: **_E_[_t~i~_]**) and average
percentage of time in each of the states (**_p~i~_**), which can be derived
easily from the transition probabilities, as shown in **_Eq.(4)_** and
**_Eq.(5)_**.
{width="2.6638888888888888in" height="0.575in"} (4)
{width="0.9638888888888889in" height="0.35in"} (5)
where, **_π={p~1~,p~2~,p~3~,p~4~}_** is the left eigenvector of **_P_**
(associated with eigenvalue 1), a.k.a. steady state vector, which fulfils
{width="0.6354166666666666in" height="0.5159722222222223in"} (6)
The simulation time step in the presented Markov-chain model corresponds to
the selected chunk size, since the adaptation is performed by the HTTP
streaming clients on a chunk basis.
##### 6.1.3.7.6 Performance Targets
In order to compare the system where the different version of a video are
offered encoded in AVC side by side with the system in which the versions are
embedded in one SVC stream, we consider cache-hit-ratio and cache capacity:
• The cache-hit-ratio: calculated on a chunk basis, or when SVC is considered
on smaller objects, corresponding to each of the layers of each of the chunks.
It represents the percentage of these objects that can be served from the
cache and do not need not to be transported over the cache feeder link.
> • The cache capacity is measured in media units, which are equivalent to the
> size of a video clip of 90 minutes at 500 _kbps_ (1 media unit=337.5 MB).
##### 6.1.3.7.7 Simulation Results
The results presented in the following show the performance of the system
comparing both multiple representations encoded with AVC (MR-VoD) offered
side-by-side and multiple representations encoded with SVC (SVC-VoD). The rate
distribution for the different video representations is summarized in the
table below with an SVC overhead of 10% using bit rate adaptation with quality
scalability and one quality layer as similarly shown in [22].
Each of the video clips is offered at four different encoding bitrates. The
bitrate assumptions for AVC and SVC encodings are summarized in Table 34.
Table 34: Rate distribution for the video representations
* * *
        Rep. 1       Rep.2         Rep.3         Rep. 4
AVC 500 _kbps_ 1000 _kbps_ 1500 _kbps_ 2000 _kbps_ SVC 500 _kbps_ 1066 _kbps_
1633 _kbps_ 2200 _kbps_
* * *
The chunk length is 10s.
The results shown in Table 3 correspond to the case where the bottleneck is
the access link, as a consequence of some cross-traffic produced by other
users. The transition probabilities can be found in the following transition
matrix.
{width="1.9166666666666667in" height="0.7833333333333333in"}
The shown transition probabilities correspond to an adaptive HTTP client that
spend on average an equal percentage of time in each state of 25%, in the
following referred to as heavy cross traffic.
Table 35: Cache-hit-ratio for congestion in access links
+----------------+--------+-----------------+--------+-----------------+ | Cache capacity | LRU | CC | | | | | | | | | | (media units) | | | | | +----------------+--------+-----------------+--------+-----------------+ | | AVC | SVC | AVC | SVC | +----------------+--------+-----------------+--------+-----------------+ | 500 | 30.9 % | 45.6 % (+14.7%) | 42.9 % | 56.6 % (+13.7%) | +----------------+--------+-----------------+--------+-----------------+ | 1000 | 42.1 % | 58.2 % (+16.1%) | 52.0 % | 64.5 % (+12.5%) | +----------------+--------+-----------------+--------+-----------------+ | 2000 | 54.6% | 69.0% (+14.4%) | 61.5% | 72.0% (+11.5%) | +----------------+--------+-----------------+--------+-----------------+
The results in Table 35 show the difference between the use of AVC and SVC for
both caching algorithms LRU and CC. Different versions of the requested videos
are stored in the cache which leads to a spoilage of the available storing
capacity of the cache when a single layer codec is considered, whereas when
SVC is used the available resources are much more efficiently used.
Furthermore, the hit-ratio increases due to the fact that many users make
requests for the same data since, even though they may be interested in
different version of the same video, their requests are split into multiple
request, one associated with each layer that they are requesting. Since the
layers built on top of each other, a user requesting layer **_k_** , needs to
request layer 1 to **_k-1_** too. In particular the base layer is requested by
everyone.
Since the difference between both AVC and SVC are more disparate for this case
we have conducted the simulations for a higher range of values for cache
capacity (**_C_**) only focusing on the LRU caching algorithm, leading to the
results shown in Figure 64.
{width="3.325in" height="2.588888888888889in"}
Figure 64: Congestion due to heavy cross traffic
In this figure, the cache-hit-ratio over cache capacity is depicted. It can
clearly be seen how the use of SVC improves the performance of the system in
terms of cache-hit-ratio compared to the use of MR-VoD. It is also noticeable
that the cache-hit-ratio for the AVC case is even lower than for the highest
layer (layer 4) when SVC is used almost for all cache capacity values, since
the storage capacity at the cache runs out faster with the higher diversity in
requested files due to using the MR-VoD approach. Furthermore, the caching
performance for the base layer is significantly higher compared to the other
files and layers as the number of request for this is higher than for the
other layers or different representations when AVC is considered.
The increased cache hit ratio leads to an reduced traffic through the
\"transit\" link, which is shown in Figure 65 for SVC-VoD and MR-VoD for heavy
cross traffic and LRU algorithm.
{width="3.2840277777777778in" height="2.567361111111111in"}
Figure 65: Average traffic through the \"transit\" link
The number of representations influences the saved traffic on the transit link
as shown in Figure 66.
{width="3.3027777777777776in" height="2.563888888888889in"}
Figure 66: Saved traffic in the transit link with the use of SVC for different
number of representations
In Figure 67 it is shown how the SVC penalty influences the performance of the
cache hit-ratio.
{width="3.5229166666666667in" height="2.736111111111111in"}
Figure 67: Cache hit-ratio for different SVC encoding overhead (0% to 20 %)
Figure 68 shows the cash-hit-ratio for a different set up of the simulation,
simulating a situation with less heavy cross traffic, resulting in the HTTP
streaming client residing in the highest state (4) more often. In this case,
the percentage of time in each state is unequal with **_p_ _={9.1%, 9.5%,
19.1%, 62.3%}_ , as well as the mean state sojourn time
**_E_[_t~i~_]**_=(approx.){2s, 2s, 10s, 40s}_ , which may be closer to that
which may happen in the reality. The correspondent transition matrix is shown
below:
{width="1.9166666666666667in" height="0.7833333333333333in"}
{width="3.325in" height="2.588888888888889in"}
Figure 68: Cache hit-ratio for congestion due to light cross traffic
Although the variety of versions requested for this set up is supposed to be
lower than in the case before, the gains of SVC-VoD compared to MR-VoD are
still noticeable. Due to this reduced variability the MR-VoD performs slightly
better than before but still quite poorly when compared to SVC-VoD. It can be
also clearly seen how the cache-hit-ratio for the base layer is reduced (layer
1) and the cache-hit-ratio for the highest layer is increased (layer 4). If we
keep on reducing the congestion all lines would converge.
The SVC penalty influences the traffic on the last mile. It is influenced by
the SVC coding penalty itself but also by the congestion behaviour, since the
base layer does not involve any overhead. Table 36 shows the average overhead
for the two scenarios for two different assumed SVC overheads. With the
assumed SVC overhead of 10% for heavy congestion it is 6.4% since the base
layer is requested more often and 8.6% with light congestion, since the
highest quality is requested more often. With an assumed SVC overhead of 20%
the last mile overhead for the heavy congestion case is 12.7% and the light
congestion of 17.2%.
Table 36: SVC last mile overhead
* * *
                        Heavy congestion   Light congestion
Last mile overhead\ 6.4% 8.6% (10% SVC overhead)
Last mile overhead\ 12.7% 17.2% (20% SVC overhead)
* * *
## 6.2 Stereoscopic 3D Video
### 6.2.1 Enabling Codecs and Formats
#### 6.2.1.1 Introduction
There are 2 major ways of formatting the views of a stereoscopic video:
spatial compression and temporal interleaving. Other formats such color
shifting and 2D+Depth are possible but are either outdated or still subject to
research and development.
Finally, the left and right views may also be encoded as separate views,
possibly exploiting redundancies between the two views to enhance the
compression efficiency. This technique is standardized by MPEG as part of the
H.264/AVC standard.
#### 6.2.1.2 Packing Formats
##### 6.2.1.2.1 Frame Compatible Video
This technique uses spatial compression to pack the two views of the
stereoscopic video into a single frame (thus the name frame compatible). This
allows the usage of deployed encoding and transport infrastructure and keeping
similar bandwidth requirements at the cost of information loss. The two views
are first down-sampled and then packed. The down-sampling may be performed
horizontally, vertically, or diagonally. The packing may use a side-by-side,
top-bottom, interleaved, or checkerboard format. The different alternatives
are illustrated in the following figures.
{width="4.16875in" height="6.156944444444444in"}
Figure 69: Spatial packing formats
##### 6.2.1.2.2 Temporal Interleaving
In temporal interleaving, the video is encoded at double the frame rate of the
original video. Each pair of subsequent pictures constitutes a stereo pair
(left and right view). The rendering of the time interleaved stereoscopic
video is typically performed at the high frame rate, where active (shutter)
glasses are used to blend the incorrect view at each eye. This requires
accurate synchronization between the glasses and the screen.
{width="4.358333333333333in" height="2.248611111111111in"}
Figure 70: Temporal interleaving
#### 6.2.1.3 Multi-view Video
MVC [3] has recently been standardized for the compression of multiple view
video as an addition to the H.264/AVC standard family. In MVC, the views from
different cameras are encoded into a single bit-stream that is backwards
compatible with single view H.264/AVC. MVC introduces new coding tools to
exhibit the spatial redundancy among the different views.
MVC is able to efficiently compress stereoscopic video in a backwards
compatible manner and without compromising the view resolutions. The NAL units
from the secondary view are ignored by legacy decoders as the NAL unit type
will not be recognized. If the server is aware of the UE capabilities, it can
omit sending NAL units from the secondary view to a device that does not
support 3D or does not have enough bitrate to deliver both views.
The following figure depicts a possible prediction chain for a stereoscopic
video.
{width="4.627777777777778in" height="1.6256944444444446in"}
Figure 71: MVC encoding with inter-view prediction
### 6.2.2 Performance Evaluation
#### 6.2.2.1 Performance Evaluation of the Compression Efficiency
##### 6.2.2.1.1 Simulation Setup
The following formats for stereoscopic 3D video are compared:
\- Side-by-Side frame packing
\- Top-Bottom frame packing
\- Vertical Interleaving frame packing
\- Horizontal Interleaving frame packing
\- Separate Left and Right view encoding
\- Multi-view Video Coding (MVC)
For the different frame packing formats, the left and right views are sub-
sampled to yield a packed frame that has the same resolution as the original
view resolution.
For the AVC encoding of the packed formats, JM [7], KTA [8], as well as the
Nokia AVC encoder have been used. The open source Nokia MVC [9] encoder has
been used to encode the MVC sequences.
The following encoding parameters have been used:
\- No B pictures to maintain compatibility with Baseline profile
\- Fixed QP for I and P pictures: 20-34
\- Reference Frames: 2
\- GOP period: 30 pictures
\- Baseline profile conformance
\- Motion estimation search range: 16
The test sequences that have been used are:
\- Alt Moabit: 432x240, 100 pictures
\- Book Arrival: 432x240, 100 pictures
\- Door Flowers: 432x240, 100 pictures
\- Leaving Laptop: 432x240, 100 pictures
All sequences may be downloaded from the MPEG FTP server.
For the down-sampling, the tool from the JSVM and JMVM reference software has
been used. The tool implements a dyadic down-sampling filter.
For evaluating the performance, PSNR has been calculated over the different
sequences. For the case of frame packing, the PSNR is calculated compared to
the original frame-packed video sequence. For MVC and the separate view
encoding, the PSNR is calculated for the left and right views separately and
then averaged.
##### 6.2.2.1.2 Performance Evaluation
The following figures depict the Rate-Distortion curves for the different
frame packing and compression configurations and for the different video
sequences.
Figure 72 depicts the results for the Alt Moabit video sequence.
{width="5.190277777777778in" height="3.2666666666666666in"}
Figure 72: Alt Moabit video sequence
Figure 73 depicts the results for the Book Arrival video sequence.
{width="4.8590277777777775in" height="2.625in"}
Figure 73: Book arrival
Figure 74 depicts the results for the Door and Flowers video sequence
{width="4.8590277777777775in" height="3.0in"}
Figure 74: Door and flowers
Figure 75 depicts the results for the Leaving Laptop video sequence
{width="4.8590277777777775in" height="3.209722222222222in"}
Figure 75: Leaving laptop
# 7 Conclusions
This Technical Report provides a set of use cases for video services in PSS
and MBMS environments. The 2D use cases have been selected in order to
highlight the potentially added value of scalable video coding. The 3D use
cases provide initial considerations of video formats and codecs to be used in
order to convey stereoscopic 3D video to a 3D capable device.
In the MBMS context, scalable video coding is compared to single layer H.264
AVC as recommended in TS26.346. Specifically, the potential benefits of SVC
have been evaluated when combined with transport layer features, e.g. unequal
error protection modes, layer aware transmission, in order to provide graceful
degradation behaviour at client side.
In the PSS context, the ability to optimize caching and CDN traffic load has
been discussed when SVC is used for adaptive HTTP streaming services.
Despite potential gains having been shown for selected use cases, some
drawbacks have also been reported regarding the coding efficiency of SVC. Some
concerns were raised on the implementation complexity of SVC, however this is
out of the scope of the TR. More detailed analysis would be needed in order to
evaluate this complexity issue on both the codec and transport level.
All the SVC performance results are either based on theoretical simulation
models or make use of the SVC reference software. At the time this report was
generated SVC was facing a lack of available commercial encoding/decoding
solutions.
The evaluation tools collected in the TR for SVC may serve as a basis for more
detailed investigations in the future.
There are no changes expected on the 3GPP specifications as a result of this
TR.
Regarding the mobile 3D use cases, different representation formats have been
considered in this study, such as full resolution per view, and several frame-
packing arrangements, such as side-by-side or top-and-bottom (also called
\"frame compatible\") formats. The video codecs under consideration included
H.264 AVC and its 3D extension called MVC. The performance evaluation
highlighted the coding efficiency of MVC. However, beyond coding efficiency
other aspects, such as the rendering technology need to be taken into account
(e.g. parallax barrier, lenticular network, external display device, etc.).
The first 3D capable mobile devices are expected to be available in the market
in 2011. They will allow further study of the video formats (codec, bitrate,
source representation format) and (most important) evaluate their associated
quality of experience. Backward compatibility with 2D services and devices may
have to be considered. Additional work in 3GPP is encouraged in this area to
identify the potential areas and interfaces where 3GPP can provide relevant
specifications to support 3D services in the context of 3GPP services. This
technical report should be considered as the basis for such future work on 3D.
###### ### Annex A: Assumptions for Simulation Method for Solutions on MBMS
Services
This Annex A presents assumptions for simulation study for solutions within
MBMS services (i.e. MBSFN). The information in the present document has been
collected with the best knowledge that was available at the time when the
present document was produced and may not necessarily represent a realistic
MBMS deployment. It is up to the reader of the TR to identify if the
parameters in this Annex are relevant for their use. Note that the packet loss
pattern proposed in this Annex A is time uncorrelated model.
The cell layouts frequently found in performance studies in RAN working groups
are similar as Figure A.1. These layouts are composed of 19 cells of which
each cell consists of 3 sectors. Therefore, total number of sectors is 57.
Figure A.1 shows 4 cases of MBSFN sector deployments over 57 sectors. The
sectors of MBSFN transmission mode are synchronized in transmission time,
frequency band, modulation and channel coding rate. The effect of synchronized
MBSFN transmission is increased spectral efficiency. Therefore UEs surrounded
by MBSFN cells achieve good signal quality as the size of MBSFN area becomes
large. Other surrounding sectors are all interference sectors.
In Figure A.1, MBSFN participating sectors are increased from single sector
(1/57 case), 7 sectors which is a formation of a centre sector surrounded by a
ring of MBSFN cooperating sectors (7/57 case), 19 sectors (19/57 case) and 37
sectors (37/57 case).
The performance metric measured in this layout is coverage versus BLER. The
\"coverage\" denotes normalized ratio of measured area to the size of entire
MBSFN area (i.e. total size of MBSFN sectors). Therefore, 50% coverage in
single sector deployment usually means only half area of a sector size.
However, 50% coverage in an area consists of 37 MBSFN sectors may encompass
the area of 7 sectors. The signal strength degrades gradually from centre of
the MBSFN area to the edge because the interference from surrounding cells is
increased. Therefore BLER (Block Error Rate) is generally increased as the
coverage is increased. Figures in A.1 show scatter graphs of BLER level in
different MBSFN layouts and channels. In the figures, it is illustrated that
64 QAM signal of 10% loss rate (purple dots) may only cover less than 20% area
in single sector layout, however in 7 sector layout, the coverage of 10% loss
rate increases to 45%, and it becomes 65% in 19 sectors layout, 75% in 37
sectors layout. The red dots\' area is high-loss rate area due to strong
interference. BLER figures of 16QAM and QPSK channel in the case of 19 sector
layout are also described.
{width="2.6569444444444446in"
height="2.941666666666667in"}{width="2.615972222222222in" height="2.95in"}
{width="2.65in" height="2.9in"}{width="2.566666666666667in"
height="2.890972222222222in"}
Figure A.1: MBSFN layouts composed of 1, 7, 19, 37 sectors in 57 sector area
Table A.1 is the configuration for channel level simulation. These are also
generally accepted assumptions in RAN WG1 documents.
Table A.1: Simulation Configuration
+----------------------------------+----------------------------------+ | Parameter | Value | +----------------------------------+----------------------------------+ | Number of Cells | 19 cell wraparound layout (3 | | | sectors each) | +----------------------------------+----------------------------------+ | The number of MBSFN cooperation | 1, 7 19, 37 | | cells | | +----------------------------------+----------------------------------+ | Interference | 2 tier interfering cells except | | | MBSFN cells | +----------------------------------+----------------------------------+ | Number of users per cell | 10 | +----------------------------------+----------------------------------+ | Bandwidth | 5 _MHz_ | +----------------------------------+----------------------------------+ | Number of Rx Antennas | 2 | +----------------------------------+----------------------------------+ | Number of Tx Antennas | 1 | +----------------------------------+----------------------------------+ | TTI | 1 _ms_ | +----------------------------------+----------------------------------+ | FFT Size | 512 | +----------------------------------+----------------------------------+ | Number of guard carriers | 212 | +----------------------------------+----------------------------------+ | Number of pilot sub-carriers per | 50 | | symbol | | +----------------------------------+----------------------------------+ | Number of data sub-carriers per | 250 | | symbol | | +----------------------------------+----------------------------------+ | Number of OFDM symbols per TTI | 12 | +----------------------------------+----------------------------------+ | Cyclic prefix | 128 (16.6 _µs_) | +----------------------------------+----------------------------------+ | BS power | 43 _dBm_ | +----------------------------------+----------------------------------+ | MCS | QPSK 1/6, 1/2 | | | | | | 16QAM 1/2 | | | | | | 64QAM 1/2, 4/5 | +----------------------------------+----------------------------------+ | Channel estimation loss | 1 _dB_ | +----------------------------------+----------------------------------+ | Channel Model | SCM -- urban macro 8 degree | +----------------------------------+----------------------------------+ | ISD | 500m, 1732m | +----------------------------------+----------------------------------+ | Link-to-System Mapping | Constrained Capacity Effective | | | SNR | +----------------------------------+----------------------------------+
Two types of cell density models are considered. The urban macro dense
deployment model uses inter-site distance (ISD) 500m, and the sparse model
uses _ISD = 1732m_. The pedestrian mobility speed of UE is limited to
_3km/hr_.
There are 4 combinations of channel modulation and coding schemes (MCS) tested
to generate the BLER trace. Table A.2 summarizes the MCS settings, information
data rates (i.e. channel throughput) available to application layer and
physical block size. Note that a physical block in LTE channel corresponds to
subframe of _1 msec_. Therefore the size of block may range from _125
bytes/block_ to _1125 bytes/block_ respectively to each MCS level. If a block
contains corrupted bit, the block is counted as error.
Only the downlink performance is measured and uplink feedback channel is not
defined in this broadcast channel model.
Table A.2: MCS levels, data rates and physical block size
+-----+------------+-----------+-------------------+-------------+ | MCS | Modulation | Code Rate | Data rate | Block Size | | | | | | | | | | | (_Mbps_ in 5 MHz) | (Bytes/BLK) | +-----+------------+-----------+-------------------+-------------+ | 1 | QPSK | 1/6 | 1.0 | 125 | +-----+------------+-----------+-------------------+-------------+ | 2 | QPSK | 1/2 | 3.0 | 375 | +-----+------------+-----------+-------------------+-------------+ | 3 | 16QAM | 1/2 | 6.0 | 750 | +-----+------------+-----------+-------------------+-------------+ | 4 | 64QAM | 1/2 | 9.0 | 1125 | +-----+------------+-----------+-------------------+-------------+
Figures A.2 to A.6 show the BLER curves of the 4 MCS channels in various cell
layouts. Figure A.2 is the BLER curves in single MBSFN sector (_ISD=500m_).
The graph shows that almost _90%_ of the single sector area can be guaranteed
less than _0.1%_ of BLER, if MCS-1 channel of 1 _Mbps_ throughput (i.e. QPSK
and 1/6 rate coding) is used for application. If one wants to increase the
channel throughput to 3 _Mbps_ (i.e. QPSK and 1/2 rate coding), the coverage
drops to 65%. The highest throughput channel of 9 _Mbps_ (i.e. 64QAM and 1/2
rate coding) may only cover 10% area if BLER is less than 0.10%.
{width="4.1090277777777775in" height="2.7743055555555554in"}
Figure A.2: BLER in Single Sector (ISD=500m)
{width="4.1819444444444445in" height="2.8180555555555555in"}
Figure A.3: BLER in 7 Sector (ISD=500m)
{width="4.307638888888889in" height="2.717361111111111in"}
Figure A.4: BLER in 19 Sector (ISD=500m)
{width="4.191666666666666in" height="2.979861111111111in"}
Figure A.5: BLER in 37 Sector (ISD=500m)
{width="4.472916666666666in" height="3.426388888888889in"}
Figure A.6: BLER Curves in Different Layouts (9 _Mbps_ and 3 _Mbps_)
The presented results so far within Annex A assumed that the MBSFN area is
equal to the MBMS service reception area. An alternative for the simulation
setup include an increase of the MBSFN area beyond the intended MBMS service
reception area. The MBSFN area can be made equal to the size of the intended
reception area plus one or more ring of cells.
Figure A.7 shows the simulation setup with an MBSFN area size of 19 cells
surrounded by interfering cells. For the moment we assume that the surrounding
cells transmit unicast data. 3 reference circles close to the border of the
MBSFN area are also shown in Figure A.7. Figure A.8 shows the scatter plot of
SINR (_dB_ -averaged over frequency domain) from the simulation scenario in
Figure A.7. The radius of the 3 reference circles is shown as vertical lines.
It can be seen that below 500m distance the mean of the SINR distribution
versus the distance is quite constant. At a distance larger than 500m a strong
drop of the SINR is noted. This strong drop can be avoided if the MBSFN area
is extended beyond the service reception area resulting in a more uniform SINR
within the reception area. In order to get similar simulation results,
locations in the border cells of the MBSFN area may be excluded from the
evaluation of reception locations.
{width="3.18125in" height="3.0756944444444443in"}
Figure A.7: Simulation scenario: 19 cells in MBSFN area
{width="3.688888888888889in" height="3.575in"}
Figure A.8: SINR versus distance from MBSFN center; interfering unicast cells
In another simulation setting the cells surrounding the considered MBSFN
reception area are assumed to belong to another MBSFN. In this case,
techniques such as interference rejection combining (IRC) in the UE are more
efficient, because the signals from all the cells of the adjacent MBSFN area
coherently aggregate (as long as they arrive within the cyclic prefix) and
thereby the adjacent MBSFN area is seen as one single large interfering cell.
IRC is most efficient in this case of a dominant single interferer. Figure A.9
shows the SINR results for this scenario. Compared with Figure A.8 the SINR is
significant higher. Therefore, the assumptions of simulations should
distinguish whether the cells outside of the considered MBSFN area transmit
unicast data or belong to another MBSFN area.
{width="3.902083333333333in" height="3.7506944444444446in"}
Figure A.9: SINR versus distance from MBSFN center; interfering cells from a
second MBSFN
###### ### Annex B: Impact of Screen Size on Stereoscopic Video
# B.1 Geometry of Stereoscopic Video
In case of stereoscopic video, two separate images (one for the left eye and
one for the right eye) are provided. Figure B.1 shows the basic geometry in
case of stereoscopic video and how the depth of an object is perceived.
{width="5.704861111111111in" height="1.9916666666666667in"}
Figure B.1: Geometry of stereoscopic video
Using simple geometry, the following formula using the symbols from Figure B.1
is derived
{width="0.7833333333333333in" height="0.4409722222222222in"} (**_._** B.1)
The formula shows that the perceived depth is inversely proportional to the
separation of the renditions. Scaling the separation (as in the case of a
display size reduction) does not have a linear impact on the depth at which
the object is perceived.
# B.2 Depth Range
Figure B.2 shows the perceived depth placement for several objects based on
the separation of the left and right rendition of the objects. Each object is
also labelled with the separation of its left and right renditions on the
screen as a multiple of eye separation. From (**_Eq._** B.1), it can be noted
that an object with rendition separation **_s=e_** would appear at infinite
depth.
Typically, objects in a scene appear in a certain depth range. Placing objects
at the border or outside the depth range will limit the comfort of the viewing
experience.
{width="4.749305555555556in" height="2.290277777777778in"}
Figure B.2: Depth placements of objects and the related left-right separations
(from [23])
# B.3 Effect of Display Size Changes
Now, the stereoscopic image pair is displayed on a screen with a reduced size.
Since the screen size scales, the separations of the object renditions scale,
and so the perceived depth of the objects.
Figure B.3 shows the effect on the depth range when the objects are displayed
on a screen half of the size, showing the objects at their newly labelled
positions. One result of this scaling is that objects that were previously at
infinity are moved to a depth of **_2t~2~_** (this is shown as **∞** in Figure
B.3), where **_t~2~_** is the viewing distance from the scaled screen.
{width="4.513194444444444in" height="2.082638888888889in"}
Figure B.3: Scene from Figure B.2, as perceived on a screen of half size (from
[23])
As seen from Figure 3 reducing the screen size compresses the depth range. The
perceived depths for the original and half screen sizes are listed in Table
B.1.
It should be noted that due to the reduced screen size the viewing distance
**_t~2~_** is significantly smaller than the viewing distance **_t~1~_**.
Table B.1: Variation in perceived depth as screen size scales
* * *
Object Separation Depth  
Original size Half size A -e/2 2t~1~/3 4t~2~/5 B -e/4 4t~1~/5 8t~2~/9 C 0 t~1~
t~2~ D +e/4 4t~1~/3 8t~2~/7 E +e/2 2t~1~ 4t~2~/3 F +2e/3 3t~1~ 3t~2~/2 ∞ e ∞
2t~2~
* * *
# B.4 Discussion
Looking at the results from Figure B.3 and Table B.1 the following effects are
observed when the screen size is reduced:
• All objects seem to move towards the screen.
• Distant objects move closer (e.g. from ∞ to 2t2)
• Depth range is non-linear compressed
• An object travelling with constant speed towards the viewer seems to change
speed (accelerating when approaching screen, slowing down when moving away
from screen)
• Impossible to place objects at infinity distance
• \"Close\" objects move even closer to the viewer (and also to the screen)
• Objects may move out of stereoscopic comfort zone.
Taken these effects into account, corrections of object separations may be
necessary to improve the perceived depth of stereoscopic video content, if
content that is produced for a larger screen is displayed on the 3D display of
a mobile device. Proposals for such depth correction can be found in [23].
###### ### Annex C: Real World Statistics of VoD User Request
This annex describes real world statics of VoD service used in the evaluation
of this TR. The statistics have been measured within the time period of one
month. The provided VoD service offers a wide variety of movies of more than
5000 files among which the users can make their selection from. In these
statistics an average of about 3400 requests per day is reported. Further
statistics on the data are given in Figure C.1, Figure C.2, Figure C.3, and
Table C.1.
Figure C.1 shows the number of requests issued by all users for all files
grouped per hour. A clear diurnal and weekly pattern can be observed. Day 1,
8, 15, 22 and 29 seem to have the largest peaks and these days were identified
as Saturdays.
{width="3.3444444444444446in" height="1.6979166666666667in"}
Figure C.1: Requests statistics
Figure C.2 shows the average over 30 days of the diurnal pattern. That is, the
evolution over each individual day was cut out of the evolution shown in
Figure C.1 and these 30 curves were averaged. It can be seen that the peak
demand occurs at 8pm.
{width="3.1486111111111112in" height="2.107638888888889in"}
Figure C.2: Number of requests per hour averaged over 30 days
Figure C.3 shows the popularity evolution for the 10 most popular multimedia
objects. The number of requests for a particular media object is accumulated
over a day (so that diurnal effects cannot be seen). The weekly patterns can
be observed with peaks on the Saturdays and although not very prominent some
multimedia objects expose an aging effect, i.e., as time goes by the interest
in them decreases.
{width="3.9298611111111112in" height="2.3895833333333334in"}
Figure C.3: Number of requests accumulated over one day for the 10 most
popular files
Table C.1 shows the distribution of the requests for the films.
Table C.1: _Nb_ of requests for the films within the time period of 31 days
* * *
**_Nb_ of requests** **% of nb of films** **Cumulative percentage** 300 - 691
0,312% 0,312% 200 - 299 0,502% 0,814% 100- 199 1,679% 2,493% 30-99 7,201%
9,694% 1-29 76,355% 86,049% 0 13,952% 100%
* * *
#