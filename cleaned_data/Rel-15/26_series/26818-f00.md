# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# Introduction
In the context of the 3GPP activity on the definition of Audio media profiles
for Virtual Reality (VR) streaming services, several candidate solutions have
been considered. The submission process of Audio media profiles included
various tests characterizing the solution performances. The present document
presents the detailed test results provided by the solution proponents and the
crosscheck labs. The results were not compiled to any merit figures of the
candidate solutions hence no such merit figures were used in the selection of
the profile. The test results provided in the present document were not
generated to be used in direct comparison.
# 1 Scope
The present document is a collection of test results on candidate audio media
profiles for VR streaming services over 3GPP. A brief description of the 3
tests characterizing the audio media profile performances is presented under
clause 4. The following clauses provide the test results from the audio media
profile proponent as well as those from the crosscheck labs. The four
documented solutions are (in alphabetical order):
\- DTS-UHD
\- Metadata Assisted EVS Codec (MAEC)
\- OMAF 3D Audio Baseline Profile
\- Spatial AAC extension (spAACe)
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TS 26.259: \"Subjective test methodologies for the evaluation of
immersive audio systems\".
[3] ITU-R Recommendation BS.1534-3: \"Method for the subjective assessment of
intermediate quality level of audio systems\".
[4] ETSI TS 103 491 (V1.1.1): \"DTS-UHD Audio Format; Delivery of Channels,
Objects and Ambisonic Sound Fields\".
[5] ETSI TS 103 584 (V1.1.1): \"DTS-UHD Point Source Renderer\".
[6] ITU-R Recommendation BS.1116-3: \"Methods for the subjective assessment of
small impairments in audio systems\".
[7] 3GPP S4-180835: \"Dolby VRStream audio profile candidate -- Description of
Bitstream, Decoder, and Renderer plus informative Encoder Description\".
(Document attached to the present document).
[8] ITU-R Recommendation BS.2051-1: \"Advanced sound system for programme
production\".
[9] 3GPP TS 26.118: \"3GPP Virtual reality profiles for streaming
applications\".
[10] \"Google Resonance Monitoring\" plugin (https://github.com/resonance-
audio/resonance-audio-draw-tools).
[11] ISO/IEC 23008-3:2015: \"Information technology -- High efficiency coding
and media delivery in heterogeneous environments -- Part 3: 3D audio\".
[12] ISO/IEC 23008-3:2015/Amd 3:2017; \"MPEG-H 3D Audio Phase 2\".
[13] SADIE KU100 HRTF database (https://www.york.ac.uk/sadie-
project/database.html).
[14] 3GPP S4-180977: \"OMAF 3D Audio Baseline Media Profile for VRStream\".
(Document attached to the present document).
[15] 3GPP TS 26.260 (V0.0.4): \"Objective test methodologies for the
evaluation of immersive audio systems\".
[16] Pulkki, Ville. \"Virtual Sound Source Positioning Using Vector Base
Amplitude Panning.\" Journal of the Audio Engineering Society 45, no. 6 (June
1, 1997): 456--66.
[17] Brinkmann, F. and Weinzierl, S. (2017). AKtools -- An Open Software
Toolbox for Signal Acquisition, Processing, and Inspection in Acoustics,
presented at the 142nd AES Convention. Berlin, Germany.
# 3 Definitions and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
3GPP TR 21.905 [1] and the following apply. A term defined in the present
document takes precedence over the definition of the same term, if any, in
3GPP TR 21.905 [1].
**Group of frames:** an interval between two consecutive sync frames
## 3.2 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
ART Artefacts
BAQ Basic Audio Quality
CCR Comparison Category Rating
Ci Confidence interval
CIBR Common Informative Binaural Renderer
dB Decibel
ESD Equivalent Spatial Domain
EVS Enhanced Voice Services
FOA First Order Ambisonics
GBR Generic Binaural Renderer
GoF Group of Frames
HATS Head and torso simulator
HIQ High Quality
HOA Higher Order Ambisonics
HR Hidden Reference
HRIR Head-Related Impulse Response
HRTF Head-Related Transfer Function
ISO BMFF ISO Based Media File Format
kbps kilobits per second
LEV Loudness level
LFE Low Frequency Effects
LP Low pass
MUSHRA MUltiple Stimuli with Hidden Reference and Anchor
OMAF Omnidirectional Media Application Format
OSC Open Sound Control
PCM Pulse Code Modulation
SPA Spatial quality
SuT System under Test
TIM Timbre
VBAP Vector base amplitude panning
VBR Variable Bit-Rate
VR Virtual Reality
VST Virtual Studio Technology
# 4 VR streaming tests description
## 4.1 Test 1
The Test 1 assesses the Codec Quality Characterization for the audio profiles
submitted in the context of VR streaming services. The Test 1 Codec Quality
Characterization test methodology is defined in 3GPP TS 26.259 [2] clause 5.
This test assesses the _Basic Audio Quality_ attribute at different bit-rates
for a given audio profile.
The audio profile is tested:
\- according to 3GPP TS 26.259 [2] clause 5,
\- using its own _Reference Renderer_ for Reference and Degraded conditions,
\- over loudspeakers,
\- based on ITU-R BS.1534-3 [3] (MUSHRA),
\- evaluating the _Basic Audio Quality_.
With 20 test items as input, Test 1 is split into two tests, Test 1a and Test
1b with 10 test items each.
If not included in the original Test 1a and Test 1b, a third test focused on
First Order Ambisonics (FOA) called Test 1c was provided. This FOA test only
considered the pure HOA source materials that were converted into FOA by
truncation to the 1st order.
## 4.2 Test 2
The Test 2 also assesses the Codec Quality Characterization for the audio
profiles submitted in the context of VR streaming services but, unlike Test 1,
in the binaural environment. The Test 2 Codec Quality Characterization test
methodology is defined in 3GPP TS 26.259 [2] clause 7. This test also assesses
the _Basic Audio Quality_ attribute at different bit-rates for a given audio
profile.
The audio profile is tested:
\- according to 3GPP TS 26.259 [2] clause 7,
\- using a _Common Informative Binaural Renderer_ (CIBR) for reference and
degraded conditions,
\- over headphones,
\- based on ITU-R BS.1534-3 [3] (MUSHRA),
\- evaluating the _Basic Audio Quality_.
With the same 20 input test items as for Test 1, Test 2 is split into two
tests, Test 2a and Test 2b with the same test items as Test 1a and Test 1b
respectively.
## 4.3 Test 3
The Test 3 assesses the Reference Binaural Renderer Quality Characterization
for the audio profiles submitted in the context of VR streaming services. The
Test 3 Reference Binaural Renderer Quality Characterization test methodology
is defined in 3GPP TS 26.259 [2] clause 6. This test characterizes the audio
profile performance with _Reference Renderer_ and, optionally but strongly
recommended, the audio profile performance with _Common Informative Binaural
Renderer_.
The audio profile is tested:
\- according to 3GPP TS 26.259 [2] clause 6,
\- over headphones with head tracking,
\- evaluating the following attributes:
\- _Spatial Quality_
\- _Artefacts_
\- _Timbre Quality_
\- _Overall Quality_
Test 3 contains 12 test items. Test 3 is split into two sessions: One
comparing the candidate audio profile with CIBR 1st order, and the other
comparing the candidate audio profile with CIBR 3rd order.
# 5 DTS-UHD tests results
## 5.1 Xperi test results on Test 1
### 5.1.1 Test design
Test 1 has been conducted according to the 3GPP TS 26.259 [2] clause 5 using
the MUSHRA test methodology defined in ITU-R BS.1534-3 [3].
Two tests were performed: Test 1a and Test 1b. Both tests consisted of ten
tracks and five systems under test (plus the hidden reference and two low-pass
anchors). The same ten post-screened listeners were used, so that the results
from Tests 1a and 1b may be combined for statistical analysis.
The following eight test signals were included in each of the MUSHRA trials:
\- Reference (uncompressed)
\- Content coded at 512 kbps
\- Content coded at 384 kbps
\- Content coded at 256 kbps
\- FOA anchor
\- FOA coded at 128 kbps
\- 7 kHz low-pass anchor (low-passed reference)
\- 3.5 kHz low-pass anchor (low-passed reference)
The FOA conditions have been included in all of the MUSHRA trials since,
including the FOA signals in some of the trials and not others would make the
statistical analysis of the results challenging. It has been suggested to make
the FOA conditions optional for Test 1, but that would amount to not
characterizing the FOA profile performance. There have also been suggestions
to test the FOA conditions separately, but that requires adding one more
separate test. Given the above, it was decided to include the FOA conditions
for all the test materials. This has the added value of assessing how an FOA
profile may perform, should one decide to convert various content types to an
FOA representation.
Since testing 128 kbps FOA without the corresponding equitable uncompressed
FOA signal would not allow assessing the impact of the compression itself, the
uncompressed FOA anchor is included throughout.
For the HOA-only content, the FOA anchor was created by truncating HOA to FOA.
For all the other contents, the FOA anchor was created by rendering the source
material to FOA with the Audio Profile renderer. The compressed FOA bit-
streams have been generated by encoding the FOA anchor with the same Audio
Profile encoder configuration as all the other contents.
### 5.1.2 Test processing
The source material and the corresponding metadata have been encoded with the
Xperi DTS-UHD VRStream Audio Profile encoder/decoder at the target bit-rates
of 256, 384, and 512 kbps, with the FOA content encoded at 128 kbps. The DTS-
UHD codec defined in ETSI TS 103 491 [4] uses a Variable Bit-Rate (VBR) model
that guarantees the target bit-rate when measured over a Group of Frames (GoF,
an interval between two consecutive sync frames). The GoF duration has been
set in these tests to 2 sec; i.e., the codec achieves Constant Bit-Rate for
each consecutive 2 sec audio segments. All the results correspond to the
instantaneous VBR peak rate not exceeding 2.5 times the target bit-rate.
The Xperi VRStream rendering process is based on the CIBR configuration (see
3GPP TS 26.259 [2] clause 6) illustrated on Figure 5.1.1:
{width="3.959722222222222in" height="2.7743055555555554in"}
Figure 5.1.1: VRStream rendering process based on the CIBR configuration
with the following:
\- \"Documented Loudspeaker Renderer\" as described in the DTS VBAP renderer
specification in ETSI TS 103 584 [5].
\- The same ETSI TS 103 584 [5] VBAP renderer used for the ESD domain signal
conversion to the 7.4.1 loudspeaker configuration per Test 1 specification.
The following acronyms are defined to describe the processing of the test
material:
\- SM: source material
\- SM-FOA: source material rendered to the FOA domain
\- BS: compressed bit-stream
\- HOA-ESD: conversions between Ambisonics and ESD
\- ESD16-HOA: conversion from ESD-16 to HOA as described in Annex A
\- HOA-ESD16: inverse of ESD16-HOA
\- ESD4-FOA: conversion from ESD-4 to FOA as described in Annex A
\- FOA-ESD4: inverse of ESD4-FOA
\- R-ESD: rendering to the ESD
\- R-ESD16: rendering to ESD-16
\- For Channels/Objects: ETSI 103 584 specification
\- For HOA: the HOA-ESD16 conversion
\- R-ESD4: rendering to ESD-4
\- For Channels/Objects: ETSI 103 584 specification
\- For FOA: the FOA-ESD4 conversion
\- RX-7.1.4: rendering from ESD to the 7.1.4 loudspeaker output
\- Per ETSI 103 584 specification
With the above, the test material has been generated as follows:
\- Reference (uncompressed): SM → R-ESD16 → RX-7.1.4
\- FOA anchor (SM-FOA, uncompressed): SM → R-ESD4 → ESD4-FOA
\- Non-FOA Test Signals (compressed): BS → Decoder → R-ESD16 → RX-7.1.4
\- FOA Test Signals (compressed): BS → Decoder → R-ESD4 → RX-7.1.4
### 5.1.3 Test material
Test materials were provided by 3GPP and included tracks from the four audio
profile proponents as shown in Table 5.1.1.
Table 5.1.1: Test items presented in Tests 1a and 1b
* * *
Test Track Duration Content Type Test 1a 8Obj_Music+Bird 10.560 s Object-based
(8 Objects) Capoeira 11.000 s Scene-based (4th Order HOA) CICP_1A 9.066 s
Channel-based (7.1.4) CosmosTwister 10.000 s Channel-based (7.1.4) Fork 12.021
s Object-based (10 objects) HOA6_Musicopter 12.000 s Scene-based (6th Order
HOA) Indiana 10.072 s Channel-based (7.1.4) leaf_A 12.000 s Mixed (3rd Order
HOA + 4 Objects + LFE) silent_A 11.997 s Mixed (3rd Order HOA + 4 Objects +
LFE) silent_B 12.000 s Channel-based (7.1.4) Test 1b 8Obj_reservoir 10.560 s
Object-based (8 Objects) audiosphere_A 11.998 s Mixed (3rd Order HOA + 4
Objects) audiosphere_B 11.997 s Mixed (3rd Order HOA + 4 Objects)
CICP19_Festival 11.456 s Mixed (Channels-7.1.4 + Objects) CosmosJungle 11.000
s Scene-based (6th Order HOA) DronesAndAnimals 12.000 s Scene-based (6th Order
HOA) JammJam 10.000 s Object-based (12 Objects) LaLechera 11.700 s Channel-
based (7.1.4) PitStop 10.000 s Channel-based (7.1.4) Spoon 12.021 s Object-
based (12 Objects)
* * *
### 5.1.4 Listening environment
The tests were performed in a, ITU-R BS.1116-3 [6] compliant listening lab in
Xperi\'s Calabasas office over a 7.1.4 speaker layout.
### 5.1.5 Grading interface
ARL\'s STEP software was used to conduct the test and to gather listeners\'
data as shown on Figure 5.1.2.
{width="3.332638888888889in" height="4.0in"}
Figure 5.1.2: ARL STEP software MUSHRA test interface
### 5.1.6 Listening panel
The listening panel of this test consisted of eleven Xperi/DTS employees (2
Female, 8 Male) all experienced in taking critical listening tests. Each
listener was trained prior to the test as instructed in ITU-R BS.1534-3 [3]
clause 4.1. One listener was removed from both tests after being post-screened
from Test 1a (to arrive at the same ten listeners for both tests). The Table
5.1.2 illustrates the listener participation and post-screening for Test 1a
and Test 1b.
Table 5.1.2: Listener participation and post-screening
* * *
Test Total participants Participants after post-screening TEST 1a 11 10 TEST
1b 11 10
* * *
### 5.1.7 Results
#### 5.1.7.1 Introduction
All results are presented in graphs including average scores and 95%
confidence intervals (t-distribution).
#### 5.1.7.2 Overall Test 1 scores
As the same listeners participated in Test 1a and Test 1b, the results from
the two tests were combined for statistical analysis. The results are
presented in Figure 5.1.3.
{width="6.2756944444444445in" height="2.775in"}
Figure 5.1.3: Results per system of Test 1a and Test 1b combined
Observations
\- The systems at 256, 384 and 512 kbps perform in the range from 85 to 95
MUSHRA points, i.e. all in the \"Excellent\" range
\- - The FOA signals are in the 50 to 60 range, with the 128 kbps compressed
test signals less than 5 MUSHRA points lower than the uncompressed FOA anchor
#### 5.1.7.3 Test 1a
Results for each system in Test 1a can be found in Figure 5.1.4. Figure 5.1.5
illustrates how each system scores per test item.
{width="6.2756944444444445in" height="2.775in"}
Figure 5.1.4: Results per system of Test 1a data
{width="6.3in" height="2.845138888888889in"}
Figure 5.1.5: Results per system and test Item for Test 1a data
The generally similar observations as for the full Test 1:
\- 256, 384 and 512 kbps in the range of 85-95, i.e. all in the \"Excellent\"
range
\- 128 kbps FOA performing within 5 MUSHRA points of the uncompressed FOA
anchor (both FOA signals considerably lower than the HOA reference)
\- Individual test tracks show a bit larger range of scores, as expected, with
only a couple of cases where 256 kbps falls under 80 (while 384 and 512 kbps
all scoring above 80)
#### 5.1.7.4 Test 1b
Results for each system in Test 1a can be found in Figure 5.1.6. Figure 5.1.7
illustrates how each system scores per test item.
{width="6.3in" height="2.839583333333333in"}
Figure 5.1.6: Results per system for Test 1b data
{width="6.3in" height="2.8048611111111112in"}
Figure 5.1.7: Results per system and test Item for test 1b data
Again, the generally similar observations as for the full Test 1:
\- 256, 384 and 512 kbps in the range of 85-95, i.e. all in the \"Excellent\"
range
\- 128 kbps FOA performing within 5 MUSHRA points of the uncompressed FOA
anchor (both FOA signals considerably lower than the HOA reference)
\- Individual test tracks show a bit larger range of scores, as expected, with
only a couple of cases where 256 kbps falls under 80 (while 384 and 512 kbps
all scoring above 80)
#### 5.1.7.5 Test 1c
An additional test for FOA has been conducted with the following four HOA
content items: Capoeira, CosmosJungle, DronesAndAnimals, and HOA6_Musicopter
(i.e., the four HOA-only test items in Test 1). The tests have been performed
under the same conditions as Tests 1a and 1b, with the same
uncompressed/compressed FOA test samples as processed for Test 1a and 1b.
Twelve experienced listeners participated in the test, with ten passing the
post-screening process as defined in ITU-R BS.1534-3 [3] clause 4.1.
Results for each system in Test 1c can be found in Figure 5.1.8. Figure 5.1.9
illustrates how each system scores per test item.
{width="6.3in" height="2.8472222222222223in"}
Figure 5.1.8: Results per system for Test 1c
{width="6.3in" height="2.8472222222222223in"}
Figure 5.1.9: Results per test item for Test 1c
Observations:
\- FOA at 128 kbps shows performance in the \"Excellent\" range, above 80, for
all test items
## 5.2 Xperi test results on Test 2
Test 2 specified in 3GPP TS 26.259 [2] clause 7 has been marked as Optional.
Due to the time constraints, it was not possible to execute this test before
the specified deadlines.
## 5.3 Xperi test results on Test 3
Test 3 is designed to compare Audio Profile Reference Renderer (Test Signals)
with CIBR (Anchors). The test methodology is specified in 3GPP TS 26.259 [2]
clause 6. The test methodology is based in Comparison Category Rating (CCR).
The Xperi Audio Profile renderer is based on the CIBR configuration (see 3GPP
TS 26.259 [2] clause 6) as shown on Figure 5.3.1:
{width="6.210416666666666in" height="2.6284722222222223in"}
Figure 5.3.1: Xperi audio profile renderer is based on the CIBR configuration
Since the Xperi Audio Profile is configured with CIBR, this test reduces to
comparing two perceptually-equivalent signals. Specifically:
\- 3GPP TS 26.259 [2] clause 6.10 on Test 3, states: \"Proposed Audio Profile
shall be configured for an Operating Point providing transparent quality for
all Test Materials\".
\- Test 3 is split into two sessions: one comparing the candidate with CIBR
1st order and another comparing the candidate with CIBR 3rd order.
In other words:
\- The compressed and uncompressed signals in the tests are, per test
requirements, perceptually equivalent
\- If not, one would have failed the requirement of configuring the Operating
Point to provide transparent quality
\- Test 3 split into 1st order and 3rd order which leads to:
\- Comparing 1st order CIBR to 1st order CIBR, and
\- Comparing 3rd order CIBR to 3rd order CIBR
Conclusions:
\- Xperi VRStream Audio Profile renderer is equivalent to the CIBR reference
(the two using the same renderer configuration)
\- Test 3 results in comparing two perceptually-equivalent Test Signals
## 5.4 Xperi conclusions
The presented Test 1 results show:
\- Xperi VRStream Audio Profile at 256, 384 and 512 kbps performing in the
range from 85 to 95 MUSHRA points, i.e. all within the \"Excellent\" range
\- Xperi VRStream FOA Audio Profile at 128 kbps performing within 5 MUSHRA
points of the uncompressed FOA anchor, i.e. also \"Excellent\" with respect to
its equitable reference
\- An additional test for FOA-only content at 128 kbps also shows performance
above 80, i.e. in the \"Excellent\" quality range
The optional Test 2 was not fully executed before the specified deadline due
to time and resource constraints.
For Test 3, the Xperi VRStream Audio Profile renderer is equivalent to the
CIBR reference, the two using the same renderer configuration.
## 5.5 Fraunhofer IIS crosscheck results
### 5.5.1 Crosscheck package description
The Xperi cross check provided a combined package, including the original test
content processed by the renderer of the profile together with bandlimited
anchor signals and coded conditions under test, as well as a derived First
Order Ambisonics representation of the original test content and additionally
a coded version thereof.
An additional Test 1c for FOA has been conducted with the four HOA-only test
items available for Test 1. The tests have been performed under the same
conditions as Tests 1a and 1b, with the same uncompressed/compressed FOA test
samples as processed for Test 1a and 1b.
### 5.5.2 Test setup
#### 5.5.2.1 Test 1
The subjective listening tests were carried out based on the cross check
package provided by Xperi. The test procedure was a \"MUlti Stimulus test with
Hidden Reference and Anchor (MUSHRA)\" based on ITU-R BS.1534-3 [3] for the
subjective assessment of intermediate quality audio for assessing the _Basic
Audio Quality_ attribute described in ITU-R BS.1534-3 [3].
Loudspeaker tests \"Test 1\" were conducted in the acoustically isolated
listening lab \'Mozart\' at Fraunhofer IIS, which fulfills the room acoustics
requirements described in ITU-R BS.1116-3 [6]. The signals were presented to
the listeners using a high quality speaker setup, consisting of 30 Dynaudio®
BM6A MKII^TM^ speakers (only 12 were active) and one Geithain® TT920
subwoofer.
Test 1 was split into two separate tests. In one sub test, all original
derived content was tested against the provided references. This test was
conducted as two separate sessions, with sessions 1a and 1b using the same
assessors to allow the pooling of all test signals for statistical analysis.
In a second sub test the coded FOA content was tested against the provided
non-coded FOA reference signal. Bandlimited 3.5 and 7 kHz versions of the non-
coded FOA reference signal were added as low and mid-range anchor signals to
the test.
### 5.5.3 Test panel
As these listening tests are aimed to evaluate audio not at intermediate but
very high quality, only participants were chosen that were considered to be
expert listeners, as required in 3GPP TS 26.259 [2] clause 5.3.
Participants at the Fraunhofer IIS test site were chosen from the Audio
Division at Fraunhofer IIS that were considered to be expert listeners,
additionally external expert listeners participated in the test. All external
listeners have undergone a defined training program, participated in prior
Listening Tests, and proven to be critical and reliable listeners.
Of the listeners 3 were female, 15 male. Listener age ranged from 21 to 46
years.
In compliance with ITU-R BS.1534-3 [3] the following rules for post-screening
in Tests 1 were used:
\- none of the hidden references are supposed to be rated below 90 and
\- none of all midrange anchors are to be rated lower than low anchors.
The Table 5.5.1 illustrates the number of listeners per test for Test 1.
Table 5.5.1: Listeners per test
* * *
Test Listeners After post-screening Test 1 10 9 Test 1 FOA 10 10
* * *
### 5.5.4 Codec Quality Characterization Tests
#### 5.5.4.1 Introduction
For the cross check of the Xperi proposal Fraunhofer IIS conducted a series of
loudspeaker listening tests.
#### 5.5.4.2 Listening test over loudspeakers (Test 1)
##### 5.5.4.2.1 Original content Test 1 (Tests 1a and 1b)
Test 1 for the original content was split into two sessions Test 1a and 1b
with 10 items each, as defined in clause 4.1. Listeners randomly started with
one of the Tests 1a or 1b.
{width="6.698611111111111in" height="4.788194444444445in"}
Figure 5.5.1: Mean rating with 95% confidence interval of MUSHRA scores for
original content Test 1 (1a and 1b aggregated)
Figure 5.5.1 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. Detailed numbers are provided in Table
5.5.2.
The Xperi proposal shows \"Good\" quality for the 256 kbps condition with an
overall mean score statistically worse than 80 MUSHRA points. For condition
384 kbps overall quality is statistically not worse than 80 MUSHRA points and
the 512 kbps condition \"Excellent\", i.e. significantly better than 80 MUSHRA
points.
Table 5.5.2: Mean values and confidence intervals for Test 1 (1a and 1b
aggregated)
* * *
Condition Mean Ci_high Ci_low HR 99.8 100.0 99.7 256 kbps 73.4 75.4 71.4 384
kbps 80.4 82.3 78.4 512 kbps 86.9 88.6 85.2 Anchor1 20.3 20.8 19.9 Anchor2
36.8 37.5 36.1
* * *
##### 5.5.4.2.2 FOA content (Test 1c FOA)
All four \"pure\" Higher Order Ambisonics (HOA) test signals available as Test
Material for Test 1 of VRStream testing were converted to FOA by truncating
higher (> 1st) order coefficients to generate the FOA test signals, as
specified in clause 4.1 for a session 1c, consisting of FOA test signals only
(references, anchors, and degraded condition).
{width="6.436111111111111in" height="4.704166666666667in"}
Figure 5.5.2: **Mean rating with 95% confidence interval** of MUSHRA scores
for Test 1 FOA
Figure 5.5.2 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. Xperi proposal shows an \"GOOD\"
overall average performance for the 4 items tested. Detailed numbers are
provided in Table 5.5.3.
Table 5.5.3: Mean values and confidence intervals for FOA Content (Test 1 FOA)
* * *
Condition Mean Ci_high Ci_low HR (FOA) 100.0 100.0 100.0 128 kbps 63.4 66.1
60.7 LP35 21.1 22.2 20.1 LP70 38.8 40.3 37.4
* * *
##### 5.5.4.2.3 Summary
The Xperi proposal achieves \"Good\" quality for the 256 kbps condition with
an overall mean score statistically worse than 80 MUSHRA points in Test1. For
condition 384 kbps overall quality is statistically not worse than 80 MUSHRA
points and the 512 kbps condition is \"Excellent\" or significantly better
than 80 MUSHRA points. The proposal shows \"Good\" performance for the FOA
content tested with 128 kbps.
# 6 Metadata Assisted EVS Codec (MAEC) tests results
## 6.1 Dolby test results on Test 1
### 6.1.1 Test plan
#### 6.1.1.1 Introduction
The test was carried out in accordance with test plan 3GPP TS 26.259 [2].
The Codec Quality Characterization Tests with loudspeaker rendering were
carried out according to MUSHRA test methodology ITU-R BS.1534-3 [3]. System
under test was Dolby\'s VRStream audio profile candidate [7], operated in two
modes, FOA and HIQ. These two modes were tested in two independent tests.
#### 6.1.1.2 Experimental design
The experimental design of the Codec Quality Characterization Tests was such
that all assessors rated all test Conditions. To control for possible
presentation order biases, the presentation order of the test items was fully
randomized during the experiment (double-blind test). The tests were run in
two sessions A and B with 10 test items each. The test material and allocation
to sets for sessions A and B was chosen by ETSI secretary. The test items were
time limited to a duration of 12s. The test of the system in FOA operation
mode tested 2 codec operation points (bit rates). The test of the system in
HIQ operation mode tested 4 codec operation points.
#### 6.1.1.3 Assessors
The selection of assessors followed the guidelines in ITU-R BS.1534-3 [3]
clause 4.1. Only _experienced assessors_ participated in the experiments. Both
Dolby-external and Dolby-internal assessors were used.
**Pre- and post-screening of assessors**
Pre- and post-screening of assessors was done in accordance with ITU-R
BS.1534-3 [3].
The applied post-screening method excludes assessors who assign a very high
grade to a significantly impaired anchor signal, and those who frequently
grade the hidden reference as though it were significantly impaired, as
defined by the following metrics:
\- an assessor should be excluded from the aggregated responses if he or she
rates the hidden reference condition for > 15% of the test items lower than a
score of 90;
\- an assessor should be excluded from the aggregated responses if he or she
rates the mid-range anchor for more than 15% of the test items higher than a
score of 90. If more than 25% of the assessors rate the mid-range anchor
higher than a score of 90, this might indicate that the test item was not
degraded significantly by the anchor processing. In this case assessors should
not be excluded on the basis of scores for that item.
#### 6.1.1.4 Content
Critical audio Material representing typical virtual reality content was used
for this test. The test material as allocated to sessions A and B is shown in
the Table 6.1.1.
Table 6.1.1: Allocation of tests items to test sessions
* * *
Session A Session B silent_B CICP19+2DynObj_Festival CICP19_1A PitStop
CosmosTwister LaLechera Indiana audiosphere_B leaf 8Obj_Reservoir
8Obj_Music+Bird JammJam Fork Spoon silent_A audiosphere_A HOA6_Musicopter
CosmosJungle Capoeira DronesAndAnimals
* * *
#### 6.1.1.5 Content presentation
The content presentation and grading process was done according to ITU-R
BS.1534-3 [3] clauses 5.3 and 5.4.
#### 6.1.1.6 Listening environment
The listening environment (room properties and acoustic properties) were fully
compliant with ITU-R BS.1116-3 [6] clause 8.2 and 8.3.
#### 6.1.1.7 Listening system
The listening system was loudspeaker-based with loudspeaker layout according
to layout J of ITU-R BS.2051-1 [8] Annex 1.
#### 6.1.1.8 Listening level
The listening level was according to ITU-R BS.1534-3 [3] clause 8.
#### 6.1.1.9 Anchor/reference conditions
The tests included one Hidden Reference and two Anchor conditions. The two
Anchors were 3.5 kHz and 7 kHz low-pass filtered versions of the Reference
condition, as described in ITU-R BS.1534-3 [3] clause 5.1.
The Reference and Hidden Reference conditions were the source test material
items directly rendered to the loudspeaker setup through the Reference
Renderer of Dolby\'s Audio Profile proposal. Scene-, channel- and object-based
content were rendered as specified in the renderer description of Dolby\'s
VRStream audio profile candidate [7]. For the listening tests, all items were
rendered for the \"VR Layout\" (assuming L and R channels are at +/-45
degrees).
#### 6.1.1.10 System under test and test conditions
The Test Conditions were generated in accordance with the test plan
requirements.
One particular requirement for the tests are that all content be encoded to
the target bit rate +/- 10%. The Table 6.1.2 lists the encoded bit rates for
all content in the study both for FOA and HIQ tests. All content sits within
the targeted max allowed bit rates. The FOA at 81.2 kbps is not required for
the study but was added to demonstrate operation at lower bit rates.
Table 6.1.2: Coding bit rates (kbps) for FOA and HIQ tests per item
* * *
HIQ HIQ HIQ HIQ FOA FOA Condition label HIQ_r4 HIQ_r3 HIQ_r2 HIQ_r1 FOA_r2
FOA_r1 Target 512.0 384.0 256.0 128.0 128.0 81.2 Max allowed 563.2 422.4 281.6
N/A 140.8 N/A Total Total Total Total Total Total 8Obj_Music+Bird 561.7 401.7
280.6 161.8 131.6 84.0 8Obj_Reservoir 558.8 398.8 279.3 160.5 131.8 84.2
CICP19+2DynObj_Festival 561.0 401.0 280.3 161.5 131.9 84.3 CICP19_1A 557.5
397.5 280.3 161.5 131.5 83.9 Capoeira 556.7 396.7 280.4 161.6 130.9 83.3
CosmosJungle 563.1 403.1 279.8 161.0 132.0 84.4 CosmosTwister 556.2 396.2
279.4 160.6 131.4 84.4 DronesAndAnimals 556.7 396.7 278.7 159.9 131.6 84.0
Fork 562.2 402.2 280.6 161.8 131.8 84.2 HOA6_Musicopter 560.0 400.0 280.1
161.3 131.8 84.2 Indiana 562.3 402.3 280.4 161.6 131.7 84.1 JammJam 562.9
402.9 280.0 161.2 132.2 84.6 LaLechera 558.0 398.0 279.2 160.4 131.4 83.8
PitStop 557.1 397.1 280.3 161.5 131.7 84.1 Spoon 562.7 402.7 280.1 161.3 131.9
84.3 audiosphere_A 555.0 395.0 277.2 158.4 131.2 83.6 audiosphere_B 562.7
402.7 280.6 161.8 131.7 84.1 Leaf 561.2 401.2 280.7 161.9 131.7 84.1 silent_A
561.1 398.1 279.7 160.9 131.4 83.8 silent_B 559.1 399.1 280.1 161.3 131.6 84.0
* * *
#### 6.1.1.11 Attributes
The tests assessed the _Basic Audio Quality_ attribute as described in ITU-R
BS.1534-3 [3] clause 6.4.
### 6.1.2 Test report and presentation of results
#### 6.1.2.1 FOA test results
##### 6.1.2.1.1 Number of assessors
The FOA test results are based on the scores of 10 assessors, after post-
screening as defined above. No assessor was removed after applying the post-
screening procedure.
##### 6.1.2.1.2 Observations/peculiarities
No particular observations were made and no peculiarities were encountered
during test execution.
##### 6.1.2.1.3 Results after statistical analysis
The Figure 6.1.1 displays the mean and the 95% confidence range of the
listener scores per item and as a total across all items (\'mean\').
{width="6.291666666666667in" height="3.1819444444444445in"}
Figure 6.1.1: Mean and 95% confidence range (Min/Max) of listener scores for
FOA test
#### 6.1.2.1 HIQ test results
##### 6.1.2.1.1 Number of assessors
The HIQ test results are based on the scores of 12 assessors, after post-
screening as defined above. No assessor was removed after applying the post-
screening procedure.
##### 6.1.2.1.2 Observations/peculiarities
No particular observations were made and no peculiarities were encountered
during test execution.
##### 6.1.2.1.3 Results after statistical analysis
The Figure 6.1.2 displays the mean and the 95% confidence range of the
listener scores per item and as a total across all items (\'mean\').
{width="6.290972222222222in" height="3.1618055555555555in"}
Figure 6.1.2: Mean and 95% confidence range (Min/Max) of listener scores for
HIQ test
## 6.2 Dolby test results on Test 2
### 6.2.1 Test plan
#### 6.2.1.1 Introduction
The test was carried out in accordance with test plan defined in 3GPP TS
26.259 [2].
The Codec Quality Characterization Tests with _headphone_ rendering were
carried out according to MUSHRA test methodology in ITU-R BS.1534-3 [3].
System under test was Dolby\'s VRStream audio profile candidate [7], operated
in two modes, FOA and HIQ. These two modes were tested in two independent
tests.
#### 6.2.1.2 Experimental design
The experimental design of the Codec Quality Characterization Tests was such
that all assessors rated all test Conditions. To control for possible
presentation order biases, the presentation order of the test items was fully
randomized during the experiment (double-blind test). The tests were run in
two sessions A and B with 10 test items each. The test material and allocation
to sets for sessions A and B was chosen by ETSI secretary. The test items were
time limited to a duration of 12s. The test of the system in FOA operation
mode tested 2 codec operation points (bit rates). The test of the system in
HIQ operation mode tested 4 codec operation points.
#### 6.2.1.3 Assessors
The selection of assessors followed the guidelines in ITU-R BS.1534-3 [3]
clause 4.1. Only _experienced assessors_ participated in the experiments. Both
Dolby-external and Dolby-internal assessors were used.
**Pre- and post-screening of assessors**
Pre- and post-screening of assessors was done in accordance with ITU-R
BS.1534-3 [3].
The applied post-screening method excludes assessors who assign a very high
grade to a significantly impaired anchor signal, and those who frequently
grade the hidden reference as though it were significantly impaired, as
defined by the following metrics:
\- an assessor should be excluded from the aggregated responses if he or she
rates the hidden reference condition for > 15% of the test items lower than a
score of 90;
\- an assessor should be excluded from the aggregated responses if he or she
rates the mid-range anchor for more than 15% of the test items higher than a
score of 90. If more than 25% of the assessors rate the mid-range anchor
higher than a score of 90, this might indicate that the test item was not
degraded significantly by the anchor processing. In this case assessors should
not be excluded on the basis of scores for that item.
#### 6.2.1.4 Content
Critical audio Material representing typical virtual reality content was used
for this test. The test material as allocated to sessions A and B is shown in
the Table 6.2.1.
Table 6.2.1: Allocation of tests items to test sessions
* * *
Session A Session B silent_B CICP19+2DynObj_Festival CICP19_1A PitStop
CosmosTwister LaLechera Indiana audiosphere_B leaf 8Obj_Reservoir
8Obj_Music+Bird JammJam Fork Spoon silent_A audiosphere_A HOA6_Musicopter
CosmosJungle Capoeira DronesAndAnimals
* * *
#### 6.2.1.5 Content presentation
The content presentation and grading process was done according to ITU-R
BS.1534-3 [3] clauses 5.3 and 5.4.
#### 6.2.1.6 Listening environment
The listening environment were fully compliant with the test plan requirements
defined in 3GPP TS 26.259 [2] clause 7.6.
#### 6.2.1.7 Listening system
The listening system was headphone-based using the Common Informative Binaural
Renderer (CIBR) 3GPP TS 26.118 [9] clause 4.5.1.2 for both the Reference and
Degraded conditions.
The binauralisation was done using the HRTFs of the Google Resonance Audio
binauralizer plugin [10] of the CIBR, meaning that the HRTFs were based on a
head and torso simulator (HATS).
The headphones used were Sennheiser® HD 600^TM^. The headphone rendering was
equalized using equalization filters for that type of headphone. The
equalization filters were kindly provided by Qualcomm.
#### 6.2.1.8 Listening level
The listening level was according to ITU-R BS.1534-3 [3] clause 8.
#### 6.2.1.9 Anchor/reference conditions
The tests included one Hidden Reference and two Anchor conditions. The two
Anchors were 3.5kHz and 7kHz low-pass filtered versions of the Reference
condition, as described in ITU-R BS.1534-3 [3] clause 5.1.
The Reference and Hidden Reference conditions were the source test material
items directly rendered to an HOA3 representation, which subsequently was fed
in ESD16 representation into the CIBR. The direct rendering to HOA3
representation is documented in the renderer description of Dolby\'s VRStream
audio profile candidate [7].
#### 6.2.1.10 System under test and test conditions
The Test Conditions were generated in accordance with the test plan
requirements.
One particular requirement for the tests are that all content be encoded to
the target bit rate +/-10%. The Table 6.2.2 lists the encoded bit rates for
all content in the study both for FOA and HIQ tests. All content sits within
the targeted max allowed bit rates. The FOA at 81.2 kbps is not required for
the study but was added to demonstrate operation at lower bit rates.
Table 6.2.2: Coding bit rates (kbps) for FOA and HIQ tests per item
* * *
HIQ HIQ HIQ HIQ FOA FOA Condition label HIQ_r4 HIQ_r3 HIQ_r2 HIQ_r1 FOA_r2
FOA_r1 Target 512.0 384.0 256.0 128.0 128.0 81.2 Max allowed 563.2 422.4 281.6
N/A 140.8 N/A Total Total Total Total Total Total 8Obj_Music+Bird 561.7 401.7
280.6 161.8 131.6 84.0 8Obj_Reservoir 558.8 398.8 279.3 160.5 131.8 84.2
CICP19+2DynObj_Festival 561.0 401.0 280.3 161.5 131.9 84.3 CICP19_1A 557.5
397.5 280.3 161.5 131.5 83.9 Capoeira 556.7 396.7 280.4 161.6 130.9 83.3
CosmosJungle 563.1 403.1 279.8 161.0 132.0 84.4 CosmosTwister 556.2 396.2
279.4 160.6 131.4 84.4 DronesAndAnimals 556.7 396.7 278.7 159.9 131.6 84.0
Fork 562.2 402.2 280.6 161.8 131.8 84.2 HOA6_Musicopter 560.0 400.0 280.1
161.3 131.8 84.2 Indiana 562.3 402.3 280.4 161.6 131.7 84.1 JammJam 562.9
402.9 280.0 161.2 132.2 84.6 LaLechera 558.0 398.0 279.2 160.4 131.4 83.8
PitStop 557.1 397.1 280.3 161.5 131.7 84.1 Spoon 562.7 402.7 280.1 161.3 131.9
84.3 audiosphere_A 555.0 395.0 277.2 158.4 131.2 83.6 audiosphere_B 562.7
402.7 280.6 161.8 131.7 84.1 Leaf 561.2 401.2 280.7 161.9 131.7 84.1 silent_A
561.1 398.1 279.7 160.9 131.4 83.8 silent_B 559.1 399.1 280.1 161.3 131.6 84.0
* * *
#### 6.2.1.11 Attributes
The tests assessed the _Basic Audio Quality_ attribute as described in ITU-R
BS.1534-3 [3] clause 6.4.
### 6.2.2 Test report and presentation of results
#### 6.2.2.1 FOA test results
##### 6.2.2.1.1 Number of assessors
The FOA test results are based on the scores of 10 assessors, after post-
screening as defined above. No assessor was removed after applying the post-
screening procedure.
##### 6.2.2.1.2 Observations/peculiarities
No particular observations were made and no peculiarities were encountered
during test execution.
##### 6.2.2.1.3 Results after statistical analysis
The Figure 6.2.1 displays the mean and the 95% confidence range of the
listener scores per item and as a total across all items (\'mean\').
{width="6.297916666666667in" height="3.1840277777777777in"}
Figure 6.2.1: Mean and 95% confidence range (Min/Max) of listener scores for
FOA test
#### 6.2.2.1 HIQ test results
##### 6.2.2.1.1 Number of assessors
The HIQ test results are based on the scores of 10 assessors, after post-
screening as defined above. No assessor was removed after applying the post-
screening procedure.
##### 6.2.2.1.2 Observations/peculiarities
No particular observations were made and no peculiarities were encountered
during test execution.
##### 6.2.2.1.3 Results after statistical analysis
The Figure 6.2.2 displays the mean and the 95% confidence range of the
listener scores per item and as a total across all items (\'mean\').
{width="6.291666666666667in" height="3.1930555555555555in"}
Figure 6.2.2: Mean and 95% confidence range (Min/Max) of listener scores for
HIQ test
## 6.3 Dolby test results on Test 3
### 6.3.1. Test plan
#### 6.3.1.1 Introduction
The test was carried out in accordance with test plan defined in 3GPP TS
26.259 [2] clause 6.
This test was carried out according to a methodology that was loosely inspired
by the Comparison Category Rating test paradigm.
System under test was Dolby\'s VRStream audio profile candidate [7], operated
in two modes, FOA and HIQ. These two modes were tested in a combined test.
#### 6.3.1.2 Experimental design
In the Renderer Comparison Test, the assessors compared two Test Conditions
(FOA and HIQ) against two Anchor Conditions on four audio quality Attributes.
The presentation of the Test and Anchor Conditions is binaural using head-
tracking. For each trial, one of the Test Condition is compared to one of the
Anchor Conditions as an A v. B comparison. To control for possible
presentation order biases, the Test Conditions were randomized such that
overall the test conditions were in the A samples in exactly half of the
cases. The test were conducted with 2 * 12 Test Materials and two Anchors for
a total of 48 trials (comparisons).
The test was divided in four sessions. The first session compares the FOA Test
Condition against the first Anchor and the second session compares the FOA
Test Condition against the second Anchor. The third session compares the HIQ
Test Condition against the first Anchor and the fourth session compares the
HIQ Test Condition against the second Anchor.
#### 6.3.1.3 Assessors
##### 6.3.1.3.1 Introduction
The selection of assessors followed the guidelines in ITU-R BS.1534-3 [3]
clause 4.1. Only _experienced assessors_ participated in the experiments.
Dolby-internal assessors that were unfamiliar with the test context were used.
##### 6.3.1.3.2 Post-screening of assessors
No post-screening of assessors was done as there was no defined post-screening
procedure.
#### 6.3.1.4 Description of system under test
The test was carried out in accordance with Test Plan 3 defined in 3GPP TS
26.259 [2].
The system under test, defined as utilizing the system providing transparent
audio quality as specified in 3GPP TS 26.259 [2] clause 6, was interpreted by
Dolby as sending content through the Dolby ingestion engine, bypassing the
encoder and decoder, and then rendering using the Dolby Reference renderer.
Dolby selected the default CIBR HOA3 as the Dolby Reference renderer. This
means that the system under test is identical to the HOA3 CIBR anchor.
The system under test for Test 3 implemented the following processing stages:
**System under Test (HiQ) -- \'ESD16HOA\':**
3GPP audio files
↓
Ingestion engine to represent the audio input as scene and objects.
↓
Render the representation to HOA3 audio files
↓
Convert HOA3 signals to ESD16
↓
CIBR binaural renderer ESD16 as input
NOTE: The system under test does not make use of VBAP.
**System under Test (FOA) -- \'ESD4HOA\':**
3GPP audio files
↓
Ingestion engine to represent the audio input as scene and objects.
↓
Render the representation to FOA audio files
↓
Convert FOA signals to ESD4
↓
CIBR binaural renderer ESD4 as input
NOTE: The system under test does not make use of VBAP.
**Anchor 1 (HiQ) -- \'ESD16REF\':**
3GPP audio files
↓
Render HOA elements to HOA3
Render objects and channels (treated as stationary objects) to ESD16 (16
Fliege points) using VBAP
↓
Convert HOA3 signals to ESD16 and sum with ESD16 signals already created from
objects
↓
CIBR binaural renderer with ESD16 as input
**Anchor 2 (FOA) -- \'ESD4REF\':**
3GPP audio files
↓
Render HOA elements to FOA, and
Render objects and channels (treated as stationary objects) to ESD4 (4 Fliege
points) using VBAP
↓
Convert FOA signals to ESD4 and sum with ESD4 signals already created from
objects
↓
CIBR binaural renderer with ESD4 as input
#### 6.3.1.5 Content
The content used for Test 3 consisted of the items listed in Table 6.3.1:
Table 6.3.1: Test 3 test material
* * *
8Obj_Music+Bird audiosphere_B chaFlamenco CICP19+2DynObj_Festival
DronesAndAnimals Farm Fork hoaFlamenco Indiana silent_B Spoon Unfold
* * *
#### 6.3.1.6 Listening environment
The listening environment were fully compliant with the test plan requirements
defined in 3GPP TS 26.259 [2] clause 7.6.
#### 6.3.1.7 Listening system
The listening system was headphone-based using the Common Informative Binaural
Renderer (CIBR) 3GPP TS 26.118 [9] clause 4.5.1.2 for both the Reference and
Degraded conditions.
The binauralisation was done using the HRTFs of the Google Resonance Audio
binauralizer plugin [10] of the CIBR, meaning that the HRTFs were based on a
head and torso simulator (HATS).
The headphones used were Sennheiser® HD 600^TM^. The headphone rendering was
equalized using equalization filters for that type of headphone. The
equalization filters were kindly provided by Qualcomm.
#### 6.3.1.8 Listening level
The listening level was as specified in the test plan defined in 3GPP TS
26.259 [2]. It was the understanding of the source that there was no agreed
way of normalizing the listening level of individual test items (test and
reference condition items). Consequently, the listening level was adjusted on
a global level across all test and reference items.
#### 6.3.1.9 Attributes
The Rendering Comparison Test will assess the four Audio Quality Attributes:
_Timbre_ (TIM), _Spatial_ (SPA), _Artefacts_ (ART) and _Basic Audio Quality_
(BAQ). In addition, the Rendering Comparison Test compares any residual
_Loudness_ (LOUD) difference between A and B samples through an additional
loudness scale.
#### 6.3.1.10 Description of test administration platform
The test system was implemented in Max/MSP. The graphical user interface is
illustrated in Figure 6.3.1.
{width="6.3in" height="3.433333333333333in"}
Figure 6.3.1: GUI for Test 3
The head tracking unit implemented in the test was an InertiaCube4^TM^
supplied by Thales®. The head tracker was mounted on the headphones used for
the test.
### 6.3.2 Test results
#### 6.3.2.1 Number of assessors
The test was carried out with 12 assessors.
#### 6.3.2.2 Observations/peculiarities
No particular observations were made and no peculiarities were encountered
during test execution.
#### 6.3.2.3 Results after statistical analysis
The Figures 6.3.2, 6.3.3, 6.3.4, 6.3.5 and 6.3.6 show the results for each
test item on _Spatial quality_ , _Artefacts_ , _Timbre_ , _Basic Audio
Quality_ and _Level_ respectively.
{width="6.309722222222222in" height="4.195138888888889in"}
Figure 6.3.2: Spatial Quality
{width="6.309722222222222in" height="4.195138888888889in"}
Figure 6.3.3: Artefacts
{width="6.309722222222222in" height="4.195138888888889in"}
Figure 6.3.4: Timbre
{width="6.309722222222222in" height="4.195138888888889in"}
Figure 6.3.5: BAQ
{width="6.309722222222222in" height="4.195138888888889in"}
Figure 6.3.6: Level
The Table 6.3.2 provides a summary of the results for all the items of the
test.
Table 6.3.2: Results summary (all items)
| Spatial Quality | Artefacts | Timbre | BAQ | Level |  |  |  |  |   
---|---|---|---|---|---|---|---|---|---|---  
| mean | 95% CI (+/-) | mean | 95% CI (+/-) | mean | 95% CI (+/-) | mean | 95% CI (+/-) | mean | 95% CI (+/-)  
ESD4REF (+) / ESD4HOA (-) | -0.67 | 0.24 | 0.07 | 0.16 | -0.38 | 0.18 | -0.37 | 0.16 | -0.75 | 0.15  
ESD4REF (+) / ESD16HOA (-) | -1.34 | 0.13 | 0.40 | 0.12 | -0.07 | 0.15 | -0.09 | 0.14 | -0.90 | 0.10  
ESD16REF (+) / ESD4HOA (-) | 0.45 | 0.22 | -0.17 | 0.18 | -0.10 | 0.18 | -0.19 | 0.22 | 0.01 | 0.08  
ESD16REF(+) / ESD16HOA (-) | -0.42 | 0.16 | 0.10 | 0.09 | 0.10 | 0.12 | 0.04 | 0.08 | -0.31 | 0.07  
NOTE: Confidence intervals (CI) assume a normal distribution
The following observations can be made:
\- Comparing ESD4HOA (test condition) with ESD4REF (anchor condition), the
test condition is preferred in terms of _Spatial Quality_ , _Timbre_ and
_Basic Audio Quality_ , while statistically there is no introduction of
_Artefacts_. Perceived _Level_ is increased in the test condition.
\- Comparing ESD16HOA (test condition) with ESD16REF (anchor condition),
spatial quality is preferred in the test condition and there may be a minor
introduction of _Artefacts_. _Timbre_ and _Basic Audio Quality_ are
statistically undistinguishable. Perceived _Level_ is increased in the test
condition.
\- Comparing ESD16HOA (test condition) with ESD4REF (anchor condition),
spatial quality is largely preferred in the test condition and there is an
introduction of _Artefacts_. _Timbre_ and _Basic Audio Quality_ are
statistically undistinguishable. Perceived _Level_ is increased in the test
condition.
\- Comparing ESD4HOA (test condition) with ESD16REF (anchor condition), the
anchor condition is preferred in terms of _Spatial Quality_. _Artefacts_ ,
_Timbre_ , _Basic Audio Quality_ , and _Level_ are statistically
indistinguishable between anchor and test conditions.
## 6.4 Nokia crosscheck results on Test 1
### 6.4.1 Introduction
This clause 6.4 provides a report on the VRStream Audio Cross-Check Lab task
and results for Test 1 performed for the Dolby\'s VRStream audio profile
candidate [7] at Nokia Technologies.
### 6.4.2 Test description and results
The listening tests were carried out for the test items submitted by Dolby
Laboratories for the VRStream Audio Media Profile cross-check task. The test
procedure used for the evaluation was a \"MUlti Stimulus test with Hidden
Reference and Anchor (MUSHRA)\" according to ITU-R BS.1534-3 [3]. The
listening tests took place at Nokia Technologies\' listening room in Tampere,
Finland. The listening room was equipped with a 7.1+4 setup consisting of
Genelec® 8531A SAM^TM^ speakers for the horizontal ring, Genelec® 8330A
SAM^TM^ speakers for the height channels, and a Genelec® 7271A SAM^TM^ Studio
subwoofer. The MUSHRA software used for the test was ARL\'s STEP program. The
channel orders of the test item files were given in the accompanying
README.txt files and verified for correct listening setup.
Test 1 (listening test over loudspeakers) consisted of four sessions of 10
items each. These sessions are called HIQ_A, HIQ_B, FOA_A, and FOA_B. As the
names indicate, there are two types of sessions (HIQ, FOA) that are both
duplicated (A, B) for increased item coverage. The high-quality mode (HIQ)
testing covered four rates (r1, r2, r3, r4) in addition to hidden reference
(HR) and two anchor conditions (ref35, ref70). The First Order Ambisonics mode
(FOA) testing covered two rates (FOA_r1, FOA_r2) in addition to hidden
reference (HR) and two anchor conditions (foa35, foa70). The exact bit rates
were not known during the cross-check.
In total, 9 listeners participated in the listening tests. All the listeners
can be characterized as experienced listeners suitable for the MUSHRA test.
The session and item orders were randomized for each listener.
Figure 6.4.1 presents the high-quality mode (HIQ) aggregated mean ratings with
95% confidence interval for each item. Figure 6.4.2 presents the high-quality
mode (HIQ) aggregated mean ratings with 95% confidence interval averaged over
all items. Table 6.4.1 provides numerical values corresponding to Figure
6.4.2.
Figure 6.4.3 presents the First Order Ambisonics mode (FOA) aggregated mean
ratings with 95% confidence interval for each item. Figure 6.4.4 presents the
First Order Ambisonics mode (FOA) aggregated mean ratings with 95% confidence
interval averaged over all items. Table 6.4.2 provides numerical values
corresponding to Figure 6.4.4.
{width="6.279166666666667in" height="4.231944444444444in"}
Figure 6.4.1: Mean rating with 95% confidence interval per item (Test 1 HIQ_A
and HIQ_B aggregated)
{width="6.084722222222222in" height="3.5729166666666665in"}
Figure 6.4.2: Mean rating with 95% confidence interval (Test 1 HIQ_A and HIQ_B
aggregated)
{width="6.294444444444444in" height="4.845833333333333in"}
Figure 6.4.3: Mean rating with 95% confidence interval per item (Test 1 FOA_A
and FOA_B aggregated)
{width="6.278472222222222in" height="3.651388888888889in"}
Figure 6.4.4: Mean rating with 95% confidence interval (Test 1 FOA_A and FOA_B
aggregated)
Table 6.4.1: Mean values and confidence intervals (Test 1 HIQ_A and HIQ_B
aggregated)
* * *
System Mean 95% Confidence Interval  
Lower Bound Upper Bound HR 99.4 97.9 100.9 r1 84.2 82.7 85.7 r2 90.4 88.9 91.9
r3 91.2 89.7 92.7 r4 91.8 90.3 93.3 ref35 22.1 20.6 23.6 ref70 44.9 43.4 46.4
* * *
Table 6.4.2. Mean values and confidence intervals (Test 1 FOA_A and FOA_B
aggregated)
* * *
System Mean 95% Confidence Interval  
Lower Bound Upper Bound FOA_r1 80.1 78.5 81.8 FOA_r2 90.6 89.0 92.3 foa35 20.5
18.8 22.1 foa70 41.9 40.3 43.5 HR 99.7 98.0 101.3
* * *
## 6.5 Philips crosscheck results for HIQ mode on Test 2
### 6.5.1 Introduction
Philips Research conducted a codec quality characterization test for the HIQ
mode of Dolby\'s VRStream audio profile candidate [7]. Test 2 is an optional
Codec Quality Characterization Test defined to assess the Codec Quality of
proposed Audio Profiles. Its requirements are:
\- According to 3GPP TS 26.259 [2] clause 7
\- Using _Common Informative Binaural Renderer_ for Reference and Degraded
conditions
\- Over headphones
\- Based on ITU-R BS.1534-3 [3] (MUSHRA)
\- Evaluates _Basic Audio Quality_
### 6.5.2 Test setup
The audio material was received from Dolby using the cloud OneDrive ETSI 365\.
The test material was already divided into two sets of ten audio items each,
see Table 6.5.1. These two sets were tested in two separate sessions as
defined in clause 4.2.
Table 6.5.1: Division of the audio items over the two sessions
* * *
Signal number Session 2a Session 2b 1 8Obj_Music+Bird 8Obj_Reservoir 2
Capoeira audiosphere_A 3 CICP19_1A audiosphere_B 4 CosmosTwister
CICP19+2DynObj_Festival 5 Fork CosmosJungle 6 HOA6_Musicopter DronesAndAnimals
7 Indiana JammJam 8 Leaf LaLechera 9 silent_A PitStop 10 silent_B Spoon
* * *
The audio material was provided in two distributions, one without headphone
equalization and one with headphone equalization for Sennheiser® HD 600^TM^.
As the Sennheiser® HD 600^TM^ headphones were not used, the distribution
without headphone equalization was used.
The test was conducted using the MUSHRA methodology with randomized
representation. A quality scale is used where the intervals are labelled
\"bad,\" \"poor,\" \"fair,\" \"good,\" and \"excellent.\" The subjective
responses were recorded on a scale ranging from 0 to 100. The Audio Research
Labs STEP tool (version 2.00) was used for conducting the test. See Figure
6.5.1 for the setup of the STEP tool, and Figure 6.5.2 for an example of the
GUI of the STEP tool at the start of a listening session.
{width="3.4715277777777778in" height="2.652083333333333in"}
Figure 6.5.1: Setup of the STEP tool
{width="3.845833333333333in" height="5.123611111111111in"}
Figure 6.5.2: GUI of the test administration tool
In the test seven conditions were assessed, see the Table 6.5.2.
Table 6.5.2: Conditions that were assessed: the Hidden Reference, four test
conditions and the two Anchors
* * *
Codec number Acronym Description 1 HR Hidden Reference 2 Sys1 HIQ mode at r1
kb/s 3 Sys2 HIQ mode at r2 kb/s 4 Sys3 HIQ mode at r3 kb/s 5 Sys4 HIQ mode at
r4 kb/s 6 LP70 7kHz low-pass filtered version of the Reference 7 LP35 3.5kHz
low-pass filtered version of the Reference
* * *
The listening test was conducted using Beyerdynamic® DT990^TM^ headphones
(with no head-tracking) connected to an ASUS® 15\" Win10 VivoBook S15^TM^
laptop in a quiet listening room with background noise levels not exceeding
the levels in Table 1 of 3GPP TS 26.259 [2] clause 6.6. Each of the 12
experienced assessors listened to both sets of 10 audio items. Half of the
assessors started with session 2a, the other half with session 2b. Before
starting the test itself the assessors started with a training session of two
items. Pre- and Post-screening of assessors was per ITU-R BS.1534-3 [3] clause
4.1.2 and all assessors passed both pre- and post-screening.
### 6.5.3 Test results
In Figure 6.5.3 the test results of the first session are given.
{width="5.238194444444445in" height="4.372916666666667in"}
Figure 6.5.3: Test results of the first session
In Figure 6.5.4 the test results of the second session are given.
{width="5.252083333333333in" height="4.260416666666667in"}
Figure 6.5.4: Test results of the second session
As all assessors participated in both sessions, the averages over all 20 audio
items can be calculated as well and are given in Figure 6.5.5.
{width="5.239583333333333in" height="4.245138888888889in"}
Figure 6.5.5: Mean results of the two sessions combined
In Table 6.5.3 a summary of the test results of Test 2 is given.
Table 6.5.3: Summary of the combined results of the two sessions of Test 2
* * *
Codec number Acronym Mean 95% CI 1 HR 99.2542 0.2961 2 Sys1 87.5333 1.5728 3
Sys2 93.2042 1.0273 4 Sys3 94.8125 0.8123 5 Sys4 95.8292 0.7000 6 LP70 57.6708
2.3344 7 LP35 26.0875 1.3096
* * *
### 6.5.4 Conclusions
A MUSHRA test was conducted at Philips Research using audio items provided by
Dolby. In the test, using headphones, the _Basic Audio Quality_ was assessed
by a panel of experienced listeners. The following conclusions can be drawn:
\- The scores for the Hidden Reference and the Anchor conditions are in line
with ITU-R BS.1534-3 [3] (MUSHRA)
\- All four test conditions, i.e. Sys1, Sys2, Sys3 and Sys4 obtained a mean
score in the range from 87 to 96 points, i.e. all within the \"Excellent\"
range
\- The Sys2, Sys3 and Sys4 test conditions performed significantly better than
the Sys1 test condition
## 6.6 Ericsson crosscheck results for FOA mode
### 6.6.1 Codec Quality Characterization test with binaural rendering (Test 2)
#### 6.6.1.1 Test setup
Two codec quality characterization tests evaluating the _Basic Audio Quality_
on Dolby\'s VRStream audio profile candidate [7] with binaural rendering
according to 3GPP TS 26.259 [2] were conducted at the DRI-Audio section of
Ericsson Research in Sweden.
Both tests were done by 12 listeners that were instructed according to clause
6.6.1.5. By default Sennheiser® HD 600^TM^ head-phones were used, but three
listeners used the Sennheiser® HD 650^TM^ instead because of unavailability of
Sennheiser® HD 600^TM^. Nevertheless, head-phone equalization filters for
Sennheiser® HD 600^TM^ were applied for all listeners, i.e. also for listeners
with Sennheiser® HD 650^TM^ headphones as this was considered better than
utilizing no equalization at all because of their similar frequency responses.
#### 6.6.1.2 Test conditions
The test conditions, according to the labels of the test items, were:
\- foa35 (3.5 kHz low-pass anchor)
\- foa70 (7 kHz low-pass anchor)
\- r1
\- r2
\- ref (Hidden Reference)
#### 6.6.1.3 Test material
The test material of Test 2a and 2b was obtained from the Dolby folder at the
ETSI cloud. Each test included 10 items each according to Table 6.6.1. All
items were pre-equalized by the proponent using equalization filters provided
by Qualcomm for Sennheiser® HD 600^TM^ headphones. The equalization processing
was not cross-checked.
Table 6.6.1: Test material for Test 2
* * *
Test 2a Test 2b 8Obj_Music+Bird 8Obj_Reservoir CICP19_1A
CICP19+2DynObj_Festival Capoeira CosmosJungle CosmosTwister DronesAndAnimals
Fork JammJam HOA6_Musicopter LaLechera Indiana PitStop Leaf Spoon silent_A
audiosphere_A silent_B audiosphere_B
* * *
#### 6.6.1.4 Test results
Pre- and post-screening was applied according to ITU-R BS.1534-3 [3] clause
4.1 resulting in 2 out of the 12 listeners being screened. These listeners
were using the Sennheiser® HD 650^TM^ headphones, meaning that the final
results were obtained by 9 listeners using Sennheiser® HD 600^TM^ and 1
listener using Sennheiser® HD 650^TM^ headphones.
The average scores with 95% confidence intervals, given a two-sided Student\'s
t-distribution, are presented in Figure 6.6.1 and Table 6.6.2. As the same
listeners were taking both sub-tests, i.e. test 2a and 2b, the test results
are combined for average scores. For statistical analysis, difference scores
in comparison to condition \"r2\" are presented in Figure 6.6.2 and Table
6.6.3.
{width="6.311111111111111in" height="4.622222222222222in"}
Figure 6.6.1: Average scores with 95% confidence intervals (t-dist.)
Table 6.6.2: Average scores with 95% confidence intervals over all items
* * *
Condition Mean CI_low CI_high foa35 27.2 25.9 28.4 foa70 57.0 54.9 59.0 r1
81.1 79.0 83.3 r2 92.0 90.6 93.4 ref 99.2 98.6 99.7
* * *
{width="6.311111111111111in" height="4.584722222222222in"}
Figure 6.6.2: Difference scores to condition \"r2\" with 95% confidence
intervals (t-dist.)
Table 6.6.3: Difference scores to condition \"r2\" with 95% confidence
intervals over all items
* * *
Condition Mean CI_low CI_high foa35 -64.9 -66.8 -62.9 foa70 -35.0 -37.4 -32.6
r1 -10.9 -12.9 -8.8 r2 0 0 0 ref 7.2 5.6 8.7
* * *
#### 6.6.1.5 Listener instructions
> _\"In this listening test you will grade the Basic Audio Quality for audio
> signals intended for Virtual Reality streaming applications presented over
> headphones._
>
> _The Basic Audio Quality denotes the single, global attribute used to judge
> any and all detected differences between the reference and a test sample._
>
> _Each trial includes several test samples. You can listen to the samples by
> clicking on the \"play\" buttons above each slider, see GUI in the figure.
> You may listen to the samples in any order, any number of times. You can
> listen to a segment of the sample by marking it in the displayed waveform;
> see the yellow selection in the figure. Left click on the waveform to reset
> the selection. You may adjust the listening level_ {width="0.41875in"
> height="0.1625in"} _by using the volume slider. Please do not change the
> volume during a trial while scoring the samples._
>
> _Use the slider for each sample to indicate your opinion of its quality. You
> can listen to the reference signal by clicking the play button below the
> \"Reference\" label._
>
> _The grading scale is continuous from \"excellent\" to \"bad\". A grade of 0
> corresponds to the bottom of the \"bad\" category, and a grade of 100
> corresponds to the top of the \"excellent\" category. In evaluating the
> samples, please note that you should not necessarily give a grade in the
> \"bad\" category to the sample with the lowest quality in the test. However
> one or more samples must be given a grade of 100 because the unprocessed
> reference signal is also included as one of the samples to be graded._
>
> _When you are satisfied with your grading of all samples in a trial, click
> the \"Next\" button. The test consists of 10 trials._
>
> _Start the test by clicking \ . Write you Ericsson signum when
> UserID is requested._
>
> _Thank you for your participation!\"_
Figure 6.6.3 illustrates the Graphic User Interface used during the test.
{width="3.9291666666666667in" height="5.9430555555555555in"}
Figure 6.6.3: Example of GUI
### 6.6.2 Renderer comparison test (Test 3)
#### 6.6.2.1 Test setup
A renderer comparison test according to 3GPP TS 26.259 [2] clause 6 was
conducted at the DRI-Audio section of Ericsson Research in Sweden. The
attributes evaluated were: _Spatial Quality_ (SPA), _Artefacts_ (ART),
_Timbre_ (TIM), _Basic Audio Quality_ (BAQ) and _Loudness/Level_ (LEV).
Because of limited time, only 7 listeners were able to finalize the test. This
is less than the requirement in 3GPP TS 26.259 [2].
Sennheiser® HD 600^TM^ headphones with the Thales® InertiaCube4^TM^ head-
tracker attached on top were used by all assessors.
No specific instructions were given to the assessors, but as they are
experienced listeners working with audio they had their own understanding of
the attributes.
#### 6.6.2.2 Test conditions
The test conditions were, according to the labels of the test items:
\- ESD16_ref (3rd order CIBR as defined in 3GPP TS 26.259 [2])
\- ESD4_fromHOA
#### 6.6.2.3 Test material
The test material of Test 3 was obtained directly from the proponent. The file
names were identical to the ones obtained from the Dolby folder at the ETSI
cloud except for a suffix EQ. The wave files are different, likely because of
the applied headphone equalization, but this processing has not been verified.
The test software was developed by the proponent and provided together with
randomized input signals for 10 listeners.
The test included 12 test items according to Table 6.6.4 as given by the
obtained material. All items were pre-equalized by the proponent using
equalization filters provided by Qualcomm for Sennheiser® HD 600^TM^
headphones.
Table 6.6.4: Test material for Test 3
* * *
8Obj_Music+Bird audiosphere_B chaFlamenco CICP19+2DynObj_Festival
DronesAndAnimals Farm Fork hoaFlamenco Indiana silent_B Spoon Unfold
* * *
#### 6.6.2.4 Test results
The results have not been post-screened as referred in ITU-R BS.1534-3 [3]
clause 4.1 was not found applicable for the test. Average scores with 95%
confidence intervals, given a two-sided Student\'s t-distribution, are
presented in Figure 6.6.4 and Table 6.6.5.
{width="6.280555555555556in" height="3.8361111111111112in"}
Figure 6.6.4: Average scores with 95% confidence intervals (t-dist.)
Table 6.6.5: Average scores with 95% confidence intervals over all items
* * *
Attribute Mean CI_low CI_high SPA 0.06 -0.18 0.30 ART 0.00 -0.10 0.09 TIM 0.11
0.02 0.21 BAQ 0.06 -0.11 0.23 LEV 0.00 -0.06 0.05
* * *
## 6.7 Fraunhofer IIS crosscheck results
### 6.7.1 Crosscheck package description
This cross check report provides listening test results for the Dolby\'s
VRStream audio profile candidate [7].
Contained are listening test results for Tests 1 (HIQ and FOA) and Test 2
(HIQ) as provided by Dolby.
The Dolby cross check provided two basic configurations, HIQ tests are based
on the original test content processed by the renderer of the profile, whereas
FOA tests used a First Order Ambisonics representation of the original test
content both as a reference signal and to generate the coded conditions under
test.
### 6.7.2 Test setup
#### 6.7.2.1 Test 1
The subjective listening tests were carried out based on the cross check
package provided by Dolby. The test procedure was a \"MUlti Stimulus test with
Hidden Reference and Anchor (MUSHRA)\" based on ITU-R BS.1534-3 [3] for the
subjective assessment of intermediate quality audio for assessing the _Basic
Audio Quality_ attribute described in ITU-R BS.1534-3 [3].
Loudspeaker tests \"Test 1\" were conducted in the acoustically isolated
listening lab \'Mozart\' at Fraunhofer IIS, which fulfills the room acoustics
requirements described in ITU-R BS.1116-3 [6]. The signals were presented to
the listeners using a high quality speaker setup, consisting of 30 Dynaudio®
BM6A MKII^TM^ speakers (only 12 were active) and one Geithain® TT920
subwoofer.
Both Test 1 (HIQ and FOA) tests were conducted as two separate sessions, with
sessions a and b using the same assessors to allow the pooling of all test
signals for statistical analysis.
For the HIQ test the cross check package contained the provided reference
signal, 3.5 and 7 kHz anchors, and 4 test conditions r1, r2, r3 and r4. For
the FOA test the cross check package contained the provided reference signal,
3.5 and 7 kHz anchors, and 2 test conditions r1 and r2.
#### 6.7.2.2 Test 2
For \"Test 2\" the test procedure was a \"MUlti Stimulus test with Hidden
Reference and Anchor (MUSHRA)\" based on ITU-R BS.1534-3 [3] for the
subjective assessment of intermediate quality audio for assessing the _Basic
Audio Quality_ attribute described in ITU-R BS.1534-3 [3].
Test 2 headphone listening tests were conducted in acoustically treated
listening rooms using STAX headphones.
Only the Test 2 HIQ was conducted as separate sessions, with sessions 2a and
2b using the same assessors to allow the pooling of all test signals for
statistical analysis.
### 6.7.3 Test panel
As these listening tests are aimed to evaluate audio not at intermediate but
very high quality, only participants were chosen that were considered to be
expert listeners, as required in 3GPP TS 26.259 [2] clause 5.3.
Participants at the Fraunhofer IIS test site were chosen from the Audio
Division at Fraunhofer IIS that were considered to be expert listeners,
additionally external expert listeners participated in the test. All external
listeners have undergone a defined training program and participated in prior
Listening Tests and proven to be critical and reliable listeners.
Of the listeners 2 were female, 22 male. Listener age ranged from 18 to 46
years.
In compliance with ITU-R BS.1534-3 [3] the following rules for post-screening
in Tests 1 and 2 were used:
\- none of the hidden references are supposed to be rated below 90 and
\- none of all midrange anchors are to be rated lower than low anchors.
The Table 6.7.1 illustrates the number of listeners of Test 1 and 2.
Table 6.7.1: Listeners per Test
* * *
Test Listeners After Post Screening Test 1 11 11 Test 1 FOA 5 4 Test 2 14 11
* * *
### 6.7.4 Codec Quality Characterization Tests
#### 6.7.4.1 Introduction
For the cross check of the Dolby proposal, Fraunhofer IIS conducted a series
of tests. This includes testing over loudspeakers and over headphones.
#### 6.7.4.2 Listening test over loudspeakers (Test 1)
##### 6.7.4.2.1 Original content (HIQ Tests 1a and 1b)
Test 1 for the original content was split into two sessions Test 1a and 1b
with 10 items each, as defined in clause 4.1. Listeners randomly started with
one of the Tests 1a or 1b.
{width="6.280555555555556in" height="3.982638888888889in"}
Figure 6.7.1: Mean rating with 95% confidence interval of MUSHRA scores for
HIQ Test 1 (1a and 1b aggregated)
Figure 6.7.1 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. For all conditions under test the Dolby
VRStream audio profile candidate [7] shows a \"Good\" overall mean score. The
Table 6.7.2 provides the numbered results for Test 1.
Table 6.7.2: Mean values and confidence intervals for Test 1 (1a and 1b
aggregated)
* * *
Condition Mean Ci_high Ci_low HR 100.0 100.0 99.9 LP35 20.8 21.4 20.3 LP70
37.4 38.3 36.4 r1 64.3 65.9 62.7 r2 72.7 74.2 71.2 r3 75.6 77.1 74.2 r4 76.9
78.4 75.5
* * *
##### 6.7.4.2.2 FOA content (Test 1 FOA)
Test 1 for the First Order Ambisonics content was split into two sessions Test
1a and 1b with 10 items each, as defined in clause 4.1. Listeners randomly
started with one of the Tests 1a or 1b.
{width="6.280555555555556in" height="3.982638888888889in"}
Figure 6.7.2: **Mean rating with 95% confidence interval** of MUSHRA scores
for Test 1 FOA
Figure 6.7.2 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. For the conditions under test the Dolby
VRStream audio profile candidate [7] shows a \"Fair\" to \"Good\" overall mean
score. The Table 6.7.3 provides the numbered results for Test 1 FOA.
Table 6.7.3: Mean values and confidence intervals for FOA Content (Test 1a and
b FOA)
* * *
Condition Mean Ci_high Ci_low HR 100.0 100.0 100.0 LP35 20.9 21.5 20.3 LP70
40.0 40.9 39.2 r1 53.9 55.9 52.0 r2 63.5 65.4 61.6
* * *
##### 6.7.4.2.3 Summary
The Dolby proposal achieves a \"Good\" to \"Fair\" overall mean score for the
conditions under test, with \"Good\" quality in Test1 HIQ and \"Fair\" to
\"Good\" quality in Test 1 FOA.
#### 6.7.4.3 Listening test over headphones (Test 2)
##### 6.7.4.3.1 Introduction
Tests over headphones were conducted as defined in clause 4.2 and 3GPP TS
26.259 [2]. The headphone equalization in 3GPP TS 26.259 [2] clause 7.7, has
been omitted due to unavailability of equalization filters for the combination
of STAX® headphones and Neumann KU100 dummy head when the tests were conducted
by Fraunhofer IIS.
In each test presentation of test signals, the presentation order was
randomized for each listener.
##### 6.7.4.3.2 Original content (Tests 2 HIQ)
Test 2 HIQ was split into two sessions Test 2a and 2b with 10 items each as
defined in clause 4.2. Listeners randomly started with one of the tests 2a or
2b.
{width="6.280555555555556in" height="3.982638888888889in"}
Figure 6.7.3: **Mean rating with 95% confidence interval** of MUSHRA scores
for Test 2 HIQ (2a and 2b aggregated)
Figure 6.7.3 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. Conditions r1, r2, and r3 score a
\"Good\" quality rating whereas r4 scores \"Excellent\" i.e. significantly
better than 80 MUSHRA points. The Table 6.7.4 provides the numbered results
for Test 2.
Table 6.7.4: Mean values and confidence intervals for Test 2 (2a and 2b
aggregated)
* * *
Condition Mean Ci_high Ci_low HR 99.9 100.0 99.8 LP35 22.9 23.9 21.9 LP70 40.6
41.7 39.5 r1 62.5 64.0 61.0 r2 73.6 75.1 72.0 r3 78.4 79.8 76.9 r4 81.9 83.3
80.5
* * *
## 6.8 Qualcomm crosscheck results on Test 1
### 6.8.1 Introduction and experimental design
ITU-R recommends that the \"testing, evaluation and reporting procedures given
in ITU-R BS.1534-3 [3] be used for the subjective assessment of intermediate
audio quality\". ITU-R BS.1534-3 [3] has also been previously used in other
standardization activities pertaining to spatial audio coding such as the
MPEG-H standardization. To provide an understanding of what quality levels can
be achieved with the metadata-assisted EVS codec at the nominal bit-rates of
256 kbps, 384 kbps and 512 kbps, the Codec Quality Characterization Test
described in 3GPP TS 26.259 [2] clause 5 was conducted.
In this experiment, 4 different bit-rates (an additional bit-rate of 160 kbps
was also provided by the proponent) were tested with 20 different test
materials covering object-based, scene-based (up to 6th order HOA), channel-
based audio and a combination of these formats.
The experimental design was consistent with 3GPP TS 26.259 [2] clause 5.2. The
experiment was divided in two sessions, each session covering 10 test
materials.
### 6.8.2 Selection of assessors
The selection of Assessors was consistent with 3GPP TS 26.259 [2] clause 5.3.
Participants were all members of Qualcomm Advanced Tech R&D group and familiar
with critical listening and audio quality evaluation. 10 assessors were
selected following pre- and post-screening processes.
### 6.8.3 Test materials
The test materials included twenty different signals covering a range of audio
content typical of Virtual Reality such as vocals, orchestra music, nature
sounds, etc. Each of the three different bit rates was tested with each of the
twenty different signals.
### 6.8.4 Presentation interface
The ARL STEP software v.2.04 was used for presentation of the samples and
collection of results.
### 6.8.5 Listening environment
The listening environment was a critical listening room compliant to 3GPP TS
26.259 [2] clause 5.6.
### 6.8.6 Listening system
The listening system was loudspeaker-based (Genelec® 8240A SAM^TM^
loudspeakers) with a setup according to 3GPP TS 26.259 [2] clause 5.7.
### 6.8.7 Listening level
The listening level was adjusted according to the requirements in 3GPP TS
26.259 [2] clause 5.8.
### 6.8.8 Generation of anchor/reference and test conditions
The signal processing chain for generation of the Test Conditions is according
to the proponent\'s description. According to the proponent\'s report in
clause 6.1.1.10, the actual bit rates were in all Test Materials higher than
the target bit-rate. Table 6.8.1 shows the actual bit-rates for each content.
Table 6.8.1: Actual bit rates for encoded test materials of Test 1 for
Metadata-assisted EVS
|  | R4 | Excess % | R3 | Excess % | R2 | Excess % | R1 | Excess %  
---|---|---|---|---|---|---|---|---|---  
Target bit-rate |  | 512 | - | 384 | - | 256 | - | 128 | -  
8Obj_Music+Bird |  | 561.7 | 9.7 | 401.7 | 4.6 | 280.6 | 9.6 | 161.8 | 26.4  
8Obj_Reservoir |  | 558.8 | 9.1 | 398.8 | 3.9 | 279.3 | 9.1 | 160.5 | 25.4  
CICP19+2DynObj_Festival |  | 561 | 9.6 | 401 | 4.4 | 280.3 | 9.5 | 161.5 | 26.2  
CICP19_1A |  | 557.5 | 8.9 | 397.5 | 3.5 | 280.3 | 9.5 | 161.5 | 26.2  
Capoeira |  | 556.7 | 8.7 | 396.7 | 3.3 | 280.4 | 9.5 | 161.6 | 26.3  
CosmosJungle |  | 563.1 | 10.0 | 403.1 | 5.0 | 279.8 | 9.3 | 161 | 25.8  
CosmosTwister |  | 556.2 | 8.6 | 396.2 | 3.2 | 279.4 | 9.1 | 160.6 | 25.5  
DronesAndAnimals |  | 556.7 | 8.7 | 396.7 | 3.3 | 278.7 | 8.9 | 159.9 | 24.9  
Fork |  | 562.2 | 9.8 | 402.2 | 4.7 | 280.6 | 9.6 | 161.8 | 26.4  
HOA6_Musicopter |  | 560 | 9.4 | 400 | 4.2 | 280.1 | 9.4 | 161.3 | 26.0  
Indiana |  | 562.3 | 9.8 | 402.3 | 4.8 | 280.4 | 9.5 | 161.6 | 26.3  
JammJam |  | 562.9 | 9.9 | 402.9 | 4.9 | 280 | 9.4 | 161.2 | 25.9  
LaLechera |  | 558 | 9.0 | 398 | 3.6 | 279.2 | 9.1 | 160.4 | 25.3  
PitStop |  | 557.1 | 8.8 | 397.1 | 3.4 | 280.3 | 9.5 | 161.5 | 26.2  
Spoon |  | 562.7 | 9.9 | 402.7 | 4.9 | 280.1 | 9.4 | 161.3 | 26.0  
audiosphere_A |  | 555 | 8.4 | 395 | 2.9 | 277.2 | 8.3 | 158.4 | 23.8  
audiosphere_B |  | 562.7 | 9.9 | 402.7 | 4.9 | 280.6 | 9.6 | 161.8 | 26.4  
leaf |  | 561.2 | 9.6 | 401.2 | 4.5 | 280.7 | 9.6 | 161.9 | 26.5  
silent_A |  | 561.1 | 9.6 | 398.1 | 3.7 | 279.7 | 9.3 | 160.9 | 25.7  
silent_B |  | 559.1 | 9.2 | 399.1 | 3.9 | 280.1 | 9.4 | 161.3 | 26.0  
Average bit-rate |  | 559.8 | 9.3 | 399.6 | 4.1 | 279.9 | 9.3 | 161.1 | 25.8  
### 6.8.9 Attributes
Participants were asked to consider all perceptual differences between the
systems under test and the reference signal when scoring the _Basic Audio
Quality_.
### 6.8.10 Presentation of results
Figure 6.8.1 visualizes the absolute scores per test item and bit-rate. Table
6.8.2 further summarizes the results across all test items.
{width="6.308333333333334in" height="4.75in"}
Figure 6.8.1: Absolute score and 95% CI of Codec Quality Characterization test
(Test 1) of Metadata-assisted EVS
Table 6.8.2: Summary of average scores for Test 1 of Metadata-assisted EVS
* * *
System High Low Mean Metadata assisted EVS @ 160 kbps 70.58 68.75 66.91
Metadata assisted EVS @ 280 kbps 78.19 76.49 74.79 Metadata assisted EVS @ 400
kbps 79.03 77.33 75.64 Metadata assisted EVS @ 560 kbps 79.65 78.15 76.65 LP35
18.71 17.54 16.36 LP7 43.11 40.99 38.88 Hidden Reference 100 99.85 99.68
* * *
All bit-rates have scores statistically significantly worse than 80 MUSHRA
points (Excellent).
# 7 OMAF 3D Audio Baseline Media Profile test results
## 7.1 Fraunhofer IIS/Qualcomm test results
### 7.1.1 Test setup
#### 7.1.1.1 Test 1
The system under test, OMAF 3D Audio Baseline Media Profile, relies on MPEG-H
3D Audio [11], [12].
The subjective listening tests were carried out based on the test items
submitted by Dolby, Fraunhofer IIS, Qualcomm, and Xperi for VRStream Audio
Media Profile testing. The test procedure was a \"MUlti Stimulus test with
Hidden Reference and Anchor (MUSHRA)\" based on ITU-R BS.1534-3 [3] for the
subjective assessment of intermediate quality audio for assessing the _Basic
Audio Quality_ attribute described in ITU-R BS.1534-3 [3].
Loudspeaker tests \"Test 1\" were conducted in the acoustically isolated
listening lab \'Mozart\' at Fraunhofer IIS, which fulfills the room acoustics
requirements described in ITU-R BS.1116-3 [6]. The signals were presented to
the listeners using a high quality speaker setup, consisting of 30 Dynaudio®
BM6A MKII^TM^ speakers (only 12 were active) and one Geithain® TT920
subwoofer.
The reference and hidden reference conditions are the source test materials
rendered to the loudspeaker setup through the reference renderer of the OMAF
3D Audio Baseline Profile with the coding bypassed, as required in 3GPP TS
26.259 [2] clause 5.9.
The test conditions were generated with the target operating points of 256,
384, and 512 kbps. For First Order Ambisonics contents only the target bitrate
was set to 128 kbps, as specified in 3GPP TS 26.259 [2] clause 5.10. The
renderer used for the test conditions has been the same renderer as used for
the anchors and reference conditions.
Test 1 was conducted as three separate sessions, with sessions 1a and 1b using
the same assessors to allow the pooling of all test signals for statistical
analysis at the bit rates of 256, 384, and 512 kbps. An additional session 1c
was conducted, which only evaluated the FOA contents at 128 kbps. The test
signals used have been derived from the \'pure\' HOA signals by truncation to
1st order, as specified in clause 4.1.
#### 7.1.1.2 Test 2
The subjective listening tests for Test 2 were carried out based on the test
items submitted by Dolby, Fraunhofer IIS, Qualcomm, and Xperi for VRStream
Audio Media Profile testing. For testing FOA contents, the \'pure\' HOA
signals were truncated to 1st order. The test procedure was a \"MUlti Stimulus
test with Hidden Reference and Anchor (MUSHRA)\" based on ITU-R BS.1534-3 [3]
for the subjective assessment of intermediate quality audio for assessing the
_Basic Audio Quality_ attribute described in ITU-R BS.1534-3 [3].
The test conditions were generated with the target operating points of 256,
384, and 512 kbps. For First Order Ambisonics contents only the target bitrate
was set to 128 kbps, as specified in 3GPP TS 26.259 [2] clause 5.10. The
renderer used for the test conditions has been the same renderer as used for
the anchors and reference conditions.
\"Test 2\" headphone listening tests were conducted in acoustically treated
listening rooms using STAX headphones.
Test 2 was conducted as three separate sessions, with sessions 2a and 2b using
the same assessors to allow the pooling of all test signals for statistical
analysis at the bit rates of 256, 384, and 512 kbps. For First Order
Ambisonics contents only the target bitrate was set to 128 kbps.
#### 7.1.1.3 Test 3
The subjective listening tests for Test 3 were carried out based on the test
items, submitted by Dolby, Fraunhofer IIS, Qualcomm, and Xperi for VRStream
Audio Media Profile testing and selected by the SA4 secretary for Test 3. The
test procedure was according to 3GPP TS 26.259 [2].
\"Test 3\" headphone listening tests were conducted in acoustically treated
listening rooms using Beyerdynamic® DT 990 pro^TM^ headphones with an HTC®
Vive^TM^ tracker mounted on top.
### 7.1.2 Training and introduction phase
As recommended in ITU-R BS.1534-3 [3], the participants were first introduced
to the test environment and given a training session (consisting of the items
following the item submission criteria, but none of the actual test items)
before performing the actual listening test.
#### 7.1.2.1 Test panel
As these listening tests are aimed to evaluate audio not at intermediate but
very high quality, only participants were chosen that were considered to be
expert listeners, as required in 3GPP TS 26.259 [2] clause 5.3.
Participants at the Fraunhofer IIS test site were chosen from the Audio
Division at Fraunhofer IIS that were considered to be expert listeners,
additionally external expert listeners participated in the test. All external
listeners have undergone a defined training program and participated in prior
Listening Tests and proven to be critical and reliable listeners.
Of the listeners 3 were female, 19 male. Listener age ranged from 21 to 33
years.
In compliance with ITU-R BS.1534-3 [3] the following rules for post-screening
in Tests 1 and 2 were used:
\- none of the hidden references are supposed to be rated below 90 and
\- none of all midrange anchors are to be rated lower than low anchors.
For Test 3 no post-screening was applied.
The Table 7.1.1 illustrates the number of listeners per test.
Table 7.1.1: Listeners per test
* * *
Test Listeners After Post Screening Test 1 12 12 Test 1 FOA 18 17 Test 2 16 12
Test 2 FOA 12 11 Test 3 HOA3 12 12 Test 3 FOA 12 12
* * *
### 7.1.3 Generation of bit streams for the test materials
#### 7.1.3.1 Encoding, decoding, and rendering process
The bit streams for Test 1 and Test 2 were generated as outlined on Figure
7.1.1a, 7.1.1b, 7.1.2a and 7.1.2b.
Figure 7.1.1a: Processing workflow for degraded conditions in Tests 1(a,b) and
Test 2(a,b)
Figure 7.1.1b: Processing workflow for reference/anchor conditions in Tests
1(a,b) and Test 2(a,b)
Figure 7.1.2a: Processing workflow for degraded conditions in FOA Tests 1c and
2c
Figure 7.1.2b: Processing workflow for reference/anchor conditions in FOA
Tests 1c and 2c
Figure 7.1.3: MPEG-H processing workflow for Test 3
Whereas the Figure 7.1.3 shows the processing workflow for Test 3, the Figures
7.1.1a, 7.1.1b, 7.1.2a and 7.1.2b show the codec and processing work flow used
to generate the Speaker- and Headphone signals used in the Listening Tests 1
and 2. The depicted Processing Steps are shortly explained here:
**Truncation to 1st Order**
\- \"pure\" HOA Test material is truncated to FOA i.e. keeping only first 4
Ambisonics components (W,X,Y,Z).
\- Is only used for Test 1c and 2c
**3GPP Input Files Conversion (3gpp- >.wav+.xml)**
\- All PCM Wave files of an original test item are multiplexed into one
Interleaved Multichannel PCM wav transparently (reversible).
\- Test Item configuration (speaker signal positions, HOA order, number of
Objects) of each VRStream Test Material is converted to Control Metadata .xml
file for the encoder
\- Object Metadata is repackaged into MPEG-H encoder input format (also stored
in MPEG-H metadata .xml file):
\- Resulting files:
\- Multichannel PCM .wav
\- Metadata .xml
**MPEG-H Encoding:**
\- Input to Encoder:
\- Multichannel PCM .wav
\- Metadata .xml
\- User Parameter: Overall Bitrate (128, 256, 384 or 512 kbps)
\- Encoder Output:
\- MPEG-H Bitstreams encapsulated in ISO BMFF files
\- Same bitstreams used as decoder input for Test 1 and Test 2
**Decoding and \"Rendering\"**
\- Input to Decoder:
\- MPEG-H Bitstreams (256, 384 or 512 kbps; 128 kbps for FOA) encapsulated in
ISO BMFF files
\- Decoder Output:
\- Test 1: Decoded Audio signals rendered to 7.1.4 Loudspeaker Setup
\- Test 2a,b: Decoded Intermediate Audio Signals rendered to ESD configuration
with 16 Fliege points
\- Test 2c: Decoded Intermediate Audio Signals rendered to ESD configuration
with 4 Fliege points
\- Test 3: Decoded Intermediate Audio Signals and metadata according to the
\"External Renderer Interface for MPEG-H 3D Audio\"
**Binaural Rendering with CIBR**
\- Input to Renderer:
\- Test 2a,b Intermediate Audio Signals rendered to ESD configuration with 16
Fliege points
\- Test 2c Intermediate Audio Signals rendered to ESD configuration with 4
Fliege points
\- Renderer Output:
\- Binauralized Stereo Audio Signals for Headphone Representation
**MPEG-H Reference Renderer for loudspeakers**
\- MPEG-H Reference Renderer Inputs:
\- Multichannel PCM .wav
\- Metadata .xml
\- User Parameter: Target Configuration 7.1.4 (CICP 19), ESD configuration
with 4 or 16 Fliege points (for binaural rendering)
\- Transparent rendering of channel content:
\- 7.1.4 Channel Signals will be routed directly to loudspeakers
\- Renderer Output:
\- Test 1: Decoded Audio signals rendered to 7.1.4 Loudspeaker Setup
\- Test 2a,b: Decoded Intermediate Audio Signals rendered to ESD configuration
with 16 Fliege points
\- Test 2c: Decoded Intermediate Audio Signals rendered to ESD configuration
with 4 Fliege points
#### 7.1.3.2 Bitrates
The MPEG-H encoder was configured to use the aforementioned target bit rates
during the encoding. Deviation from the target bitrate for the items in the
test is caused by the bit reservoir used in the MPEG-H encoder. It allows a
varying frame wise bit budget while maintaining a constant overall bitrate.
The size of the bit reservoir is specified by the buffer requirements in
MPEG-H 3D Audio Phase 2 [12], which are met for all test conditions. The
actually used bitrates and the deviations (which is the difference of Bitrate
and Target bitrate over Target bitrate) are detailed in Table 7.1.2 for 128
kbps, in Table 7.1.3 for 256 kbps, in Table 7.1.4 for 384 kbps and Table 7.1.5
for 512 kbps test conditions.
Table 7.1.2: Actual bit rates for the 128 kbps Test Condition (FOA contents)
* * *
Item name Target bitrate (bps) Bitrate (bps) Deviation hoa_Capoeira 128000
129477 0.012 hoa_CosmosJungle 128000 129512 0.012 hoa_DronesAndAnimals 128000
129385 0.011 hoa_Flamenco 128000 128967 0.008 hoa_HOA3_Farm 128000 128458
0.004 hoa_HOA6_Musicopter 128000 129278 0.010
* * *
Table 7.1.3: Actual bit rates for the 256 kbps Test Condition
* * *
Item name Target bitrate (bps) Bitrate (bps) Deviation
cha_CICP19+2DynObj_Festival 256000 256000 0.000 cha_CICP19_1A 256000 257261
0.005 cha_CosmosTwister 256000 259355 0.013 cha_Indiana 256000 256363 0.001
cha_LaLechera 256000 256254 0.001 cha_PitStop 256000 259886 0.015
cha_silent_B_ref 256000 258491 0.010 hoa_audiosphere_A_hiDef_VRStream 256000
257999 0.008 hoa_Capoeira 256000 258458 0.010 hoa_CosmosJungle 256000 258776
0.011 hoa_DronesAndAnimals 256000 258626 0.010 hoa_HOA6_Musicopter 256000
257730 0.007 hoa_silent_A_hiDef_VRStream 256000 257955 0.008
obj_8Obj_Music+Bird 256000 256248 0.001 obj_8Obj_Reservoir 256000 256369 0.001
obj_audiosphere_B_hiDef_VRStream 256000 259387 0.013 obj_Fork 256000 256227
0.001 obj_JammJam 256000 260076 0.016 obj_leaf_A_hiDef_VRStream 256000 258314
0.009 obj_Spoon 256000 257199 0.005
* * *
Table 7.1.4: Actual bit rates for the 384 kbps Test Condition
* * *
Item name Target bitrate (bps) Bitrate (bps) Deviaton
cha_CICP19+2DynObj_Festival 384000 384000 0.000 cha_CICP19_1A 384000 384624
0.002 cha_CosmosTwister 384000 387310 0.009 cha_Indiana 384000 384554 0.001
cha_LaLechera 384000 384381 0.001 cha_PitStop 384000 387396 0.009
cha_silent_B_ref 384000 386635 0.007 hoa_audiosphere_A_hiDef_VRStream 384000
386336 0.006 hoa_Capoeira 384000 385936 0.005 hoa_CosmosJungle 384000 386128
0.006 hoa_DronesAndAnimals 384000 385666 0.004 hoa_HOA6_Musicopter 384000
384980 0.003 hoa_silent_A_hiDef_VRStream 384000 386973 0.008
obj_8Obj_Music+Bird 384000 383902 -0.000 obj_8Obj_Reservoir 384000 384000
0.000 obj_audiosphere_B_hiDef_VRStream 384000 387494 0.009 obj_Fork 384000
384341 0.001 obj_JammJam 384000 386171 0.006 obj_leaf_A_hiDef_VRStream 384000
386520 0.007 obj_Spoon 384000 384341 0.001
* * *
Table 7.1.5: Actual bit rates for the 512 kbps Test Condition
* * *
Item name Target bitrate (bps) Bitrate (bps) Deviation
cha_CICP19+2DynObj_Festival 512000 512000 0.000 cha_CICP19_1A 512000 512001
0.000 cha_CosmosTwister 512000 514303 0.004 cha_Indiana 512000 512812 0.002
cha_LaLechera 512000 512509 0.001 cha_PitStop 512000 513755 0.003
cha_silent_B_ref 512000 514029 0.004 hoa_audiosphere_A_hiDef 512000 513813
0.004 hoa_Capoeira 512000 513677 0.003 hoa_CosmosJungle 512000 513709 0.003
hoa_DronesAndAnimals 512000 512931 0.002 hoa_HOA6_Musicopter 512000 512427
0.001 hoa_silent_A_hiDef_VRStream 512000 514916 0.006 obj_8Obj_Music+Bird
512000 511920 -0.000 obj_8Obj_Reservoir 512000 512000 0.000
obj_audiosphere_B_hiDef_VRStream 512000 515038 0.006 obj_Fork 512000 512454
0.001 obj_JammJam 512000 513944 0.004 obj_leaf_A_hiDef_VRStream 512000 514509
0.005 obj_Spoon 512000 512454 0.001
* * *
### 7.1.4 Codec Quality Characterization tests
#### 7.1.4.1 Introduction
For the OMAF 3D Audio Baseline Profile Fraunhofer IIS conducted a series of
tests, described in clause 4. This includes testing over loudspeakers and over
headphones.
#### 7.1.4.2 Listening test over loudspeakers (Test 1)
##### 7.1.4.2.1 Introduction
Test 1 was conducted in Room Mozart at Fraunhofer IIS. In each test,
presentation of test signals was randomized for each listener.
##### 7.1.4.2.2 Original content (Tests 1a and 1b)
Test 1 for the original (non-FOA) contents was split into two sessions Test 1a
and 1b with 10 items each, as defined in clause 4.1. Listeners randomly
started with one of the Tests 1a or 1b.
{width="5.6097222222222225in" height="3.886111111111111in"}
Figure 7.1.4: **Mean rating with 95% confidence interval** of MUSHRA scores
for Test 1 (1a and 1b aggregated)
Figure 7.1.4 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. For all bit rates under test the MPEG-H
codec shows an \"Excellent\" overall mean score significantly better than 80
MUSHRA points for all test material (HOA, Channels and Objects). Also, for all
of the test items and for each of the bit rates the MPEG-H codec is
statistically not worse than 80 MUSHRA points with all but one item mean
scores rating \"Excellent\". Table 7.1.6 provides the numbered results for
Test 1.
Table 7.1.6: Mean values and confidence intervals for Test 1 (1a and 1b
aggregated)
* * *
Condition Mean Ci_high Ci_low HR 99.2 99.5 99.0 LP35 20.8 21.2 20.5 LP70 40.1
40.3 39.8 256000 86.5 88.0 85.1 384000 91.2 92.4 90.1 512000 93.9 94.8 93.0
* * *
##### 7.1.4.2.3 FOA content (Test 1c)
All \"pure\" Higher Order Ambisonics test signals available as Test Material
for VRStream testing were converted to FOA by truncating higher (> 1st) order
coefficients to generate the FOA test signals, as specified in clause 4.1 for
a session 1c, consisting of FOA test signals only (references, anchors, and
degraded condition).
{width="5.3in" height="3.8645833333333335in"}
Figure 7.1.5: **Mean rating with 95% confidence interval** of MUSHRA scores
for FOA Content (Test 1c)
Figure 7.1.5 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. The MPEG-H codec provides \"Excellent\"
audio quality when encoding FOA signals at 128 kbps i.e. it scores
significantly better than 80 MUSHRA points on average. For each test item
audio quality is rated statistically not worse than \"Excellent\" with all
mean scores rating above 80 MUSHRA points. Table 7.1.7 provides the numbered
results for Test 1c.
Table 7.1.7: Mean values and confidence intervals for FOA Content (Test 1c)
* * *
Condition Mean Ci_high Ci_low HR 99.5 99.9 99.2 128000 85.2 87.7 82.7 LP35
20.0 20.7 19.4 LP70 39.1 40.1 38.1
* * *
##### 7.1.4.2.4 Summary
For all bit rates under test the MPEG-H codec shows an \"Excellent\" overall
mean score significantly better than 80 MUSHRA points for all test material
(HOA, Channels and Objects) if evaluated over loudspeakers. Also, for all of
the test items and for each of the bit rates the MPEG-H codec is statistically
not worse than \"Excellent\", i.e. 80 MUSHRA points.
#### 7.1.4.3 Listening test over headphones (Test 2)
##### 7.1.4.3.1 Introduction
Tests over headphones were conducted as defined in clause 4.2 and 3GPP TS
26.259 [2] All stimuli have been binauraly rendered using the Common
Informative Binaural Renderer (CIBR). A definition of the CIBR can be found in
3GPP TS 26.118 [9] clause 4.6.1.2. The CIBR employs the SADIE KU100 HRTFs [13]
for binaural rendering. The headphone equalization in 3GPP TS 26.259 [2]
clause 7.7, has been omitted due to unavailability of equalization filters for
the combination of STAX® headphones and Neumann KU100 dummy head when the
tests were conducted by Fraunhofer IIS.
The reference and hidden reference conditions are the source test materials
binaurally rendered to headphones through the CIBR. The ESD signals with 16
Fliege points as input to the CIBR were rendered through the reference
renderer of the OMAF 3D Audio Baseline Profile with the coding bypassed, which
is that the rendering of channels and objects content to the virtual
loudspeakers in ESD configuration is performed using the VBAP implementation
specified in MPEG-H 3D Audio Phase 2 [12] clause FC and MPEG-H 3D Audio [11]
clause 8, respectively.
The same encoded bitstreams as for the loudspeaker tests (Test 1) have been
used to generate the ESD signals, correspondingly the bitrates used for Test 2
are identical to Test 1, as reported in clause 7.1.2.2.
In each test presentation of test signals the presentation order was
randomized for each listener.
##### 7.1.4.3.2 Original content (Tests 2a and 2b)
Test 2 was split into two sessions Test 2a and 2b with 10 items each as
defined in clause 4.2. Listeners randomly started with one of the Tests 2a or
2b.
{width="5.518055555555556in" height="3.886111111111111in"}
Figure 7.1.6: **Mean rating with 95% confidence interval** of MUSHRA scores
for Test 2 (2a and 2b aggregated)
Figure 7.1.6 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. For all bit rates under test the MPEG-H
codec shows an \"Excellent\" overall mean score significantly better than 80
MUSHRA points for all test material (HOA, Channels and Objects). Also, for all
of the test items and for each of the bit rates the MPEG-H codec is
statistically not worse than 80 MUSHRA points with all but one item mean
scores rating \"Excellent\". Table 7.1.8 provides the numbered results for
Test 2.
Table 7.1.8: Mean values and confidence intervals for Test 2 (2a and 2b
aggregated)
* * *
Condition Mean Ci_high Ci_low HR 99.1 99.4 98.8 LP35 20.2 20.4 20.0 LP70 40.6
41.0 40.1 256000 86.6 88.0 85.2 384000 91.8 92.8 90.8 512000 94.1 95.0 93.1
* * *
##### 7.1.4.3.3 FOA content (Test 2c)
All \"pure\" Higher Order Ambisonics test signals were converted to FOA by
truncating higher (> 1st) order coefficients to generate the FOA test signals,
as specified in clause 4.2 for a session 2c, consisting of FOA test signals
only (references, anchors, and degraded condition).
{width="5.281944444444444in" height="4.429166666666666in"}
Figure 7.1.7: Plot of MUSHRA scores for FOA content (Test 2c)
Figure 7.1.7 shows mean ratings with 95% confidence interval (computed
assuming normally distributed data and applying a t-distribution) for each
item as well as pooled over all items. In Test 2c the MPEG-H codec scores
statistically not worse than \"Excellent\" for 128 kbps on overall average as
well as for all test item. Table 7.1.9 provides the numbered results for Test
2c.
Table 7.1.9: Mean values and confidence intervals for FOA content (Test 2c)
* * *
Condition Mean Ci_high Ci_low HR (FOA) 100.0 100.0 100.0 LP35 19.4 20.5 18.2
LP70 38.7 40.0 37.4 128000 80.2 83.1 77.3
* * *
##### 7.1.4.3.4 Summary
For the bit rates 256, 384, and 512 kbps under test the MPEG-H codec shows an
\"Excellent\" overall mean score significantly better than 80 MUSHRA points
for all test material (HOA, Channels and Objects) when evaluated over
headphones using the Common Informative Binaural Renderer. For 128 kbps the
MPEG-H codec scores statistically not worse than \"Excellent\", i.e. 80 MUSHRA
points. Also, for all of the test items and for each of the bit rates the
MPEG-H codec is statistically not worse than \"Excellent\", i.e. 80 MUSHRA
points.
### 7.1.4.4 Reference binaural renderer Quality Characterization Tests
#### 7.1.4.4.1 Introduction
##### 7.1.4.4.2 Test system implementation
##### 7.1.4.4.2.1 Overview {#overview .H6}
Max/MSP was used to implement the test framework as required in 3GPP TS 26.259
[2] clause 6. Figure 7.1.8 shows a high-level block diagram for the
implementation.
{width="6.279861111111111in" height="2.5208333333333335in"}
Figure 7.1.8: High-level block diagram of Test 3 implementation on MAX/MSP.
The application takes a folder containing each test item in 2 formats, one
reference in ESD format and one folder of multi mono files with text files
describing the position and type of each source for the System under Test
(SuT).
Anchor/reference conditions were processed according to 3GPP TS 26.259 [2]
clause 6.9.
For the anchor/reference conditions, the rendering of channels and objects
content to the virtual loudspeakers in ESD configuration is performed using
the VBAP implementation specified in MPEG-H 3D Audio Phase 2 [12] clause FC
and MPEG-H 3D Audio [11] clause 8, respectively.
For the test conditions, the mono files for the SuT were created by encoding
and decoding the original Test Materials at a very high bit rate and exported
via the external renderer interface of MPEG-H specified in OMAF 3D Audio
candidate [14] annex X.2. The encoding and decoding steps are performed in the
same way as described in clause 7.1.3.1.The metadata was converted to text
files for easy parsing inside of Max/MSP.
The application can then send the reference audio data in ESD format to the
Common Informative Binaural Renderer (CIBR) and the multi mono files to the
System Under Test. Both renderers are run in parallel when the user presses
play. An A/B switch allows the user to listen to each condition individually
for comparison and switch seamlessly between A and B. A definition of the CIBR
can be found in 3GPP TS 26.118 [9] clause 4.6.1.2.
The Max/MSP application was then running on macOS^TM^ systems, more
specifically on a Mac^TM^ mini (late 2012) with an Intel® Core^TM^ i7 and 16GB
DDR3 RAM. A second test machine was a Mac mini (late 2014) with an Intel®
Core^TM^ i7 and 16GB DDR3 RAM. Both machines were running Mac OS 10.13 High
Sierra^TM^.
##### 7.1.4.4.2.2 Graphical User Interface {#graphical-user-interface .H6}
The Graphical User Interface (GUI) is depicted in Figure 7.1.9. The listener
can switch seamlessly between the two decoding processes through an A/B switch
for the purposes of comparison. By default, a loop section is enabled around
the entire item. The user can control the start and stop points of the looped
region and start/stop the playback.
The listener is presented with 5 sliders, which can be used to rate four
different audio quality attributes (_Timbre_ , _Spatial_ _Quality_ ,
_Artefacts_ and _Basic Audio Quality_), as defined in 3GPP TS 26.259 [2].
These sliders have a discrete scale from -3 to +3. The default rating on
start-up is zero. A separate slider can be used to rate the loudness
difference between the items. This is presented separately to the main four
attributes being tested.
{width="6.277777777777778in" height="5.791666666666667in"}
Figure 7.1.9: Graphical User Interface of Test 3 in Max/MSP
##### 7.1.4.4.2.3 Motion sensing {#motion-sensing .H6}
The motion sensing system used for Test 3 was the _HTC® Vive^TM^ Tracker_ for
head-tracking. The tracker is attached to the top of a _Beyerdynamic® DT 990
Pro^TM^_ headphone via a screw fitting through the headband as shown in Figure
7.1.10, allowing for comfortable listening. The rotation information from the
tracker is received via OSC Messages in the Max Application. This is then
forwarded to both the CIBR path and the System under Test. The zero position
of the tracker is set for each listener at the beginning of the test.
{width="1.9770833333333333in" height="3.0131944444444443in"}
Figure 7.1.10: HTC® Vive^TM^ Tracker mounted to Beyerdynamic® DT 990 Pro^TM^
Headphone
##### 7.1.4.4.2.4 CIBR Implementation {#cibr-implementation .H6}
The CIBR implementation defined in 3GPP TS 26.118 [9] comprises three VST
plugins in series to achieve the desired output. The system is realized as a
Max/MSP object which takes sixteen channels of input audio in the equivalent
spatial domain (ESD) format and outputs a two-channel binauralized signal. For
a definition of the ESD and Fliege point locations as described in 3GPP TS
26.260 [15].
Firstly, the sixteen-channel ESD is converted to 3rd order B-Format Ambisonics
via an inverse HOA matrix. This sixteen-channel HOA signal is then fed into an
Ambisonics rotator and rotated using Euler angles received from the head
tracking device. This rotated HOA Signal is then binauralized in real-time,
resulting in a stereo signal.
The VST plugins used in this implementation are the Ambix_decoder_o3, which is
used in reverse to encode 3rd order B-Format Ambisonics from a sixteen-channel
ESD signal. The ambiX_rotator_o3 is used to rotate this Ambisonics signal in
the Ambisonics domain. Finally, ResonanceAudioMonitorVst from Google is used
to render the Ambisonics to a binauralized stereo signal. A link to these
plugins can be found in 3GPP TS 26.260 [15].
For the second test (Test 3b) a slightly different CIBR Implementation is
used, which differs in that it renders First Order Ambisonics from a four-
channel audio signal in the ESD format. The remaining signal chain is the same
as above, however the sixteen channel signals are replaced with four-channel
signals. The ResonanceAudioMonitorVST was also recompiled to use First Order
Ambisonics as input and rendering.
##### 7.1.4.4.2.5 System under test {#system-under-test .H6}
The system under test is the example external binaural renderer specified in
OMAF 3D Audio candidate [14] annex X. For implementation reasons in the
Max/MSP test framework, VST plugins were used where possible. The SuT accepts
the input from the external renderer interface as channels, objects, and HOA
(as ESD) and associated metadata and renders them as outlined in OMAF 3D Audio
candidate [14] annex X. The \'GBR\' (Generic Binaural Renderer) VST plugin and
the ambiX plugins are used to implement the system described in OMAF 3D Audio
candidate [14] annex X. The input folder includes text files which give
information on the position of each audio channel to be rendered, as well as a
file describing the type of HOA included in the item, if one is included. This
information is parsed and routed so that the positional information is
received by the GBR VST and the HOA information is received by both the GBR
VST and Ambisonics decoders. Information on the order of the HOA in ESD format
is used to determine which ESD-to-HOA matrix should be used for conversion to
a 3rd order Ambisonics. Audio for channels and objects is fed directly to the
GBR VST, whereas the Ambisonics signals are first fed to a the ambiX decoder
using the correct encoder matrix to convert to HOA3. The HOA3 signals are
rotated in the Ambisonics domain using the ambiX rotator VST plugin, before
being converted back to ESD using the ambiX decoder VST plugin for binaural
rendering inside the GBR VST. To avoid a double head-rotation, the head-
rotation in GBR is disabled for channels containing Ambisonics audio.
The HRIR used for both the System under Test and the CIBR is the SADIE KU100
[13]. Due to loudness differences, as outlined in clause 7.1.4.4.2.8, the
level of the HRIRs for the SuT was increased by 1.5 dB.
A diagram of how the system under test was integrated is shown in Figure
7.1.11.
{width="6.288194444444445in" height="1.9444444444444444in"}
Figure 7.1.11: Implementation of the system under test from Fraunhofer IIS
##### 7.1.4.4.2.6 HRIR {#hrir .H6}
The current Google Resonance Plugins do not provide a simple method for
switching the HRIR set. Because the HRIR set will be kept the same between the
two binaural rendering conditions, the binaural renderer under test will be
configured with the Neumann KU100 binaural head HRIR set from the SADIE
database [13].
##### 7.1.4.4.2.7 Equalization {#equalization .H6}
The headphone equalization in 3GPP TS 26.259 [2] clause 6.7, has been omitted
due to unavailability of equalization filters for the combination of the
Beyerdynamic® DT 990 Pro^TM^ headphones and Neumann KU100 dummy head when the
tests were conducted.
##### 7.1.4.4.2.8 Loudness adjustment {#loudness-adjustment .H6}
A preliminary test was conducted with six listeners to investigate the
suitability of the test administration system platform for conducting Test 3.
The preliminary test consisted of 12 items and the system under test is as
described in OMAF 3D Audio candidate [14] annex X. The preliminary test showed
that overall, the CIBR implementation for HOA3 and FOA was louder than the
system under test. To combat this in the final tests, the level of the system
under test was increased by 1.5dB to match the overall level of the CIBR
implementations.
##### 7.1.4.4.3 Test results
In accordance to the Test 3 specification in 3GPP TS 26.259 [2], the System
under Test was compared to the two CIBR variants, against the HOA3 CIBR and
the FOA CIBR.
Figure 7.1.12 shows mean ratings of the comparison of the System under Test
and the HOA3 CIBR with 95% confidence interval (computed assuming normally
distributed data and applying a t-distribution) for each item as well as
pooled over all items. Table 7.1.10 provides the numbered results for Test 3a.
{width="6.279861111111111in" height="4.709722222222222in"}
Figure 7.1.12: Plot of test results for the comparison of SuT vs. CIBR HOA3
(Test 3a)
Table 7.1.10: Test results for the comparison of SuT vs. CIBR HOA3 (Test 3a)
* * *
item_name variable ci_lower mean ci_upper overall TIM -0,67044 -0,46528
-0,26012 SPA -0,72944 -0,53472 -0,34 ART -0,28955 -0,11806 0,053437 BAQ
-0,50866 -0,33333 -0,15801 LOUD -0,34026 -0,21528 -0,09029
* * *
Figure 7.1.13 shows mean ratings of the comparison of the System under Test
and the FOA CIBR with 95% confidence interval (computed assuming normally
distributed data and applying a t-distribution) for each item as well as
pooled over all items. Table 7.1.11 provides the numbered results for Test 3b.
{width="6.279861111111111in" height="4.709722222222222in"}
Figure 7.1.13: Plot of test results for the comparison of SuT vs. CIBR FOA
(Test 3b)
Table 7.1.11: Test results for the comparison of SuT vs. CIBR FOA (Test 3b)
* * *
item_name variable ci_lower mean ci_upper overall TIM -0,70734 -0,49306
-0,27877 SPA -1,34644 -1,09028 -0,83411 ART -0,18997 0,027778 0,24553 BAQ
-0,45754 -0,25 -0,04246 LOUD 0,061412 0,256944 0,452477
* * *
##### 7.1.4.4.4 Summary
The System under Test performs significantly better than the CIBR reference
for both HOA3 and FOA CIBR implementations for the _Timbre_ , _Spatial
Quality_ , and _Basic Audio Quality_ scales. On the _Artefacts_ scale, the SuT
is not worse than the CIBR. The assessors rated the CIBR FOA louder than the
SuT and the SuT louder than the CIBR HOA3.
# 8 spAACe test results
## 8.1 Qualcomm test results on Test 1
### 8.1.1 Introduction and experimental design
ITU-R recommends that the \"testing, evaluation and reporting procedures given
in ITU-R BS.1534-3 [3] be used for the subjective assessment of intermediate
audio quality\". ITU-R BS.1534-3 [3] has also been previously used in other
standardization activities pertaining to spatial audio coding such as the
MPEG-H standardization. To provide an understanding of what quality levels can
be achieved with spAACe at the bit-rates of 256 kbps, 384 kbps and 512 kbps,
the Codec Quality Characterization Test described in 3GPP TS 26.259 [2] clause
5 was conducted.
In this experiment, 3 different bit-rates were tested with 20 different test
materials covering object-based, scene-based (up to 6th order HOA), channel-
based audio and a combination of these formats.
The experimental design was consistent with 3GPP TS 26.259 [2] clause 5.2. The
experiment was divided in two sessions, each session covering 10 test
materials.
### 8.1.2 Selection of assessors
The selection of Assessors was consistent with 3GPP TS 26.259 [2] clause 5.3.
Participants were all members of Qualcomm Advanced Tech R&D group and familiar
with critical listening and audio quality evaluation. 10 assessors were
selected following pre- and post-screening processes.
### 8.1.3 Test materials
The test materials included twenty different signals covering a range of audio
content typical of Virtual Reality such as vocals, orchestra music, nature
sounds, etc. Each of the three different bit rates was tested with each of the
twenty different signals.
### 8.1.4 Presentation interface
The ARL STEP software v.2.04 was used for presentation of the samples and
collection of results.
### 8.1.5 Listening environment
The listening environment was a critical listening room compliant to 3GPP TS
26.259 [2] clause 5.6.
### 8.1.6 Listening system
The listening system was loudspeaker-based (Genelec® 8240A SAM^TM^
loudspeakers) with a setup according to 3GPP TS 26.259 [2] clause 5.7.
### 8.1.7 Listening level
The listening level was adjusted according to the requirements in 3GPP TS
26.259 [2] clause 5.8.
### 8.1.8 Generation of anchor/reference and test conditions
The signal processing chain for generation of the Test Conditions is shown in
Figure 8.1.1. Consistent with the requirements in 3GPP TS 26.259 [2] clause
5.9, the Hidden Reference was generated following a similar chain but with all
encoding/decoding operations bypassed, i.e. only the Reference Rendering
operations were enabled. The Anchors were generated from the Hidden Reference
by low-passing the signals at 3.5 kHz and 7 kHz.
{width="6.291666666666667in" height="3.5118055555555556in"}
Figure 8.1.1: Signal processing chain for generation of the test conditions
The technical details are as follows :
\- The LFE signal given in the hybrid content (LFE combined with objects
and/or HOA) was mapped to CH#4 of the 7.1+4 layout via the LFE Mapper block.
For Test 2, the LFE signal given in the hybrid content was panned to the
nominal angular direction of the LFE loudspeaker in the ESD speaker layout by
means of VBAP [16].
\- HOA (SN3D/ACN) was rendered to 7.1+4 using the HOA rendering matrices for
HOA orders N=3, N=4, N=6 which are shown in Table 8.1.1, Table 8.1.2 and Table
8.1.3, respectively.
\- Audio objects were rendered to 7.0+4 and subsequently mapped to 7.1+4. This
was accomplished by means of the OBJ Mapper block, which takes the output of
the 7.0+4 as an input and it outputs a set of signals for the 7.1+4 where CH#4
(the LFE channel) contains silence.
\- Actual bit-rates for all 20 test items are listed in Table 8.1.4.
Table 8.1.1: HOA N=3 (SN3D/ACN) rendering matrix for 7.1+4 loudspeaker layout
* * *
0.155 0.155 0.126 0 0.197 0.197 0.181 0.181 0.116 0.116 0.137 0.137 0.185
-0.185 0 0 0.23 -0.23 0.377 -0.376 0.14 -0.14 0.161 -0.162 -0.12 -0.12 -0.13 0
-0.165 -0.165 -0.108 -0.107 0.311 0.312 0.317 0.317 0.266 0.266 0.27 0 -0.322
-0.322 0.046 0.046 0.178 0.178 -0.172 -0.173 0.214 -0.214 0 0 -0.225 0.225
0.035 -0.035 0.116 -0.116 -0.108 0.108 -0.075 0.075 0 0 -0.097 0.098 -0.069
0.068 0.19 -0.19 0.219 -0.219 -0.038 -0.038 0.028 0 -0.033 -0.033 -0.018
-0.018 0.039 0.039 0.051 0.051 -0.096 -0.096 -0.069 0 0.111 0.112 -0.002
-0.002 0.21 0.21 -0.195 -0.195 0.1 0.1 0.157 0 0.112 0.112 -0.288 -0.288 0.023
0.023 0.014 0.014 0.05 -0.05 0 0 0.041 -0.041 -0.056 0.056 0.01 -0.01 0.006
-0.006 -0.029 0.029 0 0 0.026 -0.026 -0.002 0.002 0.058 -0.058 -0.05 0.05
-0.008 0.008 0 0 -0.005 0.005 -0.01 0.011 0.02 -0.02 0.023 -0.023 0.013 0.013
-0.014 0 0.007 0.007 -0.007 -0.007 -0.002 -0.002 -0.006 -0.006 -0.009 -0.009
-0.004 0 0.012 0.011 -0.002 -0.002 0.02 0.02 -0.018 -0.018 -0.007 -0.007
-0.006 0 -0.003 -0.003 0.011 0.011 0.004 0.005 -0.004 -0.003 -0.047 -0.048
0.097 0 0 0 0.008 0.008 -0.003 -0.003 0.002 0.002
* * *
Table 8.1.2: HOA N=4 (SN3D/ACN) rendering matrix for 7.1+4 loudspeaker layout
* * *
0.14 0.14 0.116 0 0.179 0.179 0.165 0.165 0.105 0.105 0.125 0.125 0.178 -0.178
0 0 0.221 -0.221 0.362 -0.362 0.135 -0.135 0.156 -0.156 -0.117 -0.117 -0.122 0
-0.158 -0.158 -0.103 -0.103 0.3 0.3 0.304 0.304 0.26 0.26 0.255 0 -0.309
-0.308 0.041 0.041 0.172 0.172 -0.166 -0.167 0.251 -0.251 0 0 -0.264 0.264
0.042 -0.042 0.136 -0.136 -0.128 0.128 -0.081 0.081 0 0 -0.11 0.11 -0.085
0.085 0.218 -0.218 0.258 -0.257 -0.035 -0.035 0.017 0 -0.038 -0.038 -0.027
-0.027 0.047 0.047 0.06 0.06 -0.113 -0.113 -0.083 0 0.13 0.13 0 0 0.246 0.246
-0.229 -0.229 0.078 0.078 0.247 0 0.125 0.124 -0.317 -0.317 0.023 0.023 0.018
0.018 0.113 -0.113 0 0 0.095 -0.095 -0.13 0.13 0.028 -0.028 0.015 -0.015
-0.058 0.058 0 0 0.058 -0.059 -0.006 0.006 0.121 -0.121 -0.107 0.107 -0.018
0.018 0 0 -0.011 0.011 -0.025 0.026 0.047 -0.047 0.055 -0.055 0.02 0.02 -0.015
0 0.015 0.015 -0.011 -0.011 -0.006 -0.006 -0.014 -0.014 -0.021 -0.021 -0.01 0
0.027 0.027 -0.004 -0.004 0.046 0.046 -0.043 -0.043 -0.013 -0.013 -0.021 0
-0.006 -0.006 0.024 0.024 0.011 0.011 -0.009 -0.008 -0.065 -0.066 0.155 0
0.007 0.007 -0.005 -0.005 -0.005 -0.005 0.005 0.005 0.005 -0.005 0 0 -0.003
0.003 -0.002 0.002 0 0 0.002 -0.002 -0.007 0.007 0 0 -0.004 0.004 0.003 -0.003
0.007 -0.007 0.002 -0.002 -0.005 0.005 0 0 0.004 -0.004 0 0 0.011 -0.011 -0.01
0.01 0.002 -0.002 0 0 0.002 -0.002 -0.002 0.002 0 0 0 0 0.001 0.001 -0.001 0
0.001 0.001 0 0 0 0 -0.001 -0.001 0.002 0.002 -0.003 0 -0.001 -0.001 0 0
-0.001 -0.001 0.001 0.001 0 0 -0.004 0 -0.001 -0.001 0.002 0.002 0 0 -0.001 0
0.003 0.003 -0.004 0 -0.002 -0.002 0.001 0.001 -0.003 -0.003 0.003 0.003
-0.018 -0.018 0.027 0 -0.004 -0.005 0.012 0.012 -0.002 -0.002 0.001 0.001
* * *
Table 8.1.3: HOA N=6 (SN3D/ACN) rendering matrix for 7.1+4 loudspeaker layout
* * *
0.126 0.126 0.104 0 0.163 0.163 0.146 0.146 0.088 0.088 0.106 0.106 0.17
-0.169 0 0 0.207 -0.207 0.34 -0.34 0.123 -0.123 0.136 -0.136 -0.108 -0.108
-0.108 0 -0.147 -0.147 -0.086 -0.086 0.287 0.287 0.292 0.292 0.242 0.242 0.239
0 -0.294 -0.294 0.049 0.049 0.15 0.15 -0.148 -0.148 0.277 -0.277 0 0 -0.297
0.297 0.046 -0.046 0.145 -0.145 -0.14 0.14 -0.09 0.09 0 0 -0.123 0.123 -0.089
0.088 0.246 -0.246 0.298 -0.298 -0.032 -0.031 0.023 0 -0.032 -0.032 -0.017
-0.017 0.034 0.034 0.052 0.052 -0.116 -0.117 -0.096 0 0.14 0.141 -0.003 -0.003
0.283 0.283 -0.263 -0.263 0.097 0.097 0.271 0 0.132 0.132 -0.361 -0.361 0.029
0.03 0.021 0.021 0.182 -0.182 0 0 0.151 -0.151 -0.21 0.21 0.047 -0.047 0.024
-0.024 -0.094 0.094 0 0 0.093 -0.093 -0.012 0.012 0.202 -0.201 -0.176 0.177
-0.023 0.023 0 0 -0.013 0.013 -0.035 0.035 0.068 -0.068 0.075 -0.075 0.031
0.031 -0.03 0 0.02 0.02 -0.021 -0.022 -0.003 -0.003 -0.018 -0.018 -0.025
-0.025 -0.014 0 0.035 0.034 -0.007 -0.006 0.062 0.062 -0.059 -0.059 -0.017
-0.017 -0.025 0 -0.006 -0.006 0.032 0.031 0.014 0.015 -0.013 -0.013 -0.094
-0.095 0.218 0 0.005 0.006 -0.002 -0.002 -0.008 -0.008 0.008 0.008 0.021
-0.021 0 0 -0.012 0.012 -0.005 0.005 -0.005 0.005 0.009 -0.009 -0.03 0.03 0 0
-0.017 0.017 0.013 -0.013 0.027 -0.027 0.005 -0.006 -0.022 0.022 0 0 0.014
-0.014 0.001 -0.001 0.049 -0.049 -0.041 0.041 0.01 -0.01 0 0 0.008 -0.008
-0.01 0.01 0 -0.001 0 0 0.005 0.005 -0.006 0 0.003 0.003 -0.003 -0.002 0 0
-0.003 -0.004 0.009 0.009 -0.016 0 -0.003 -0.003 0 0 -0.003 -0.003 0.003 0.003
0.001 0.001 -0.013 0 -0.003 -0.003 0.008 0.008 0.001 0.001 -0.002 -0.001 0.011
0.012 -0.014 0 -0.009 -0.009 0.003 0.003 -0.012 -0.012 0.013 0.012 -0.075
-0.075 0.111 0 -0.016 -0.017 0.046 0.046 -0.008 -0.008 0.004 0.004 -0.003
0.003 0 0 -0.002 0.002 0.004 -0.004 -0.001 0.001 -0.001 0.001 -0.003 0.003 0 0
0 0 0.001 -0.001 0.001 -0.001 0 0 -0.004 0.004 0 0 -0.002 0.002 0.001 -0.001
0.004 -0.004 0.001 -0.001 0.001 -0.001 0 0 0 0 0 0 0.002 -0.002 -0.002 0.002
0.002 -0.002 0 0 0.001 -0.001 -0.001 0.001 -0.001 0.001 0 0 -0.002 -0.002
0.003 0 0 0 0.001 0.001 0 0 0 0 0.001 0.001 -0.001 0 0 0 0 0 0 0 0 0 0.001
0.001 -0.002 0 0 0 0.001 0.001 0 0 0 0 0.004 0.004 -0.006 0 -0.001 -0.001
-0.001 -0.001 -0.002 -0.001 0.002 0.001 0.004 0.004 -0.005 0 0.001 0.001
-0.003 -0.002 0 0 0 0 -0.015 -0.015 0.026 0 0 0 0.003 0.003 0.001 0.001 -0.001
-0.001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 -0.001 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -0.001 -0.001
0.002 0 0 0 0 0 0 0 0 0
* * *
Table 8.1.4: Actual bit rates for encoded test materials of Test 1 and Test 2
* * *
Item # Target Actual Excess Excess % 1 256 253.9 -2.1 -0.82 1 384 385.5 1.5
0.39 1 512 514.8 2.8 0.55 2 256 257.0 1.0 0.39 2 384 387.2 3.2 0.83 2 512
516.0 4.0 0.78 3 256 256.4 0.4 0.16 3 384 384.9 0.9 0.23 3 512 515.5 3.5 0.68
4 256 256.9 0.9 0.35 4 384 386.8 2.8 0.73 4 512 516.0 4.0 0.78 5 256 275.2
19.2 7.50 5 384 406.2 22.2 5.78 5 512 532.1 20.1 3.93 6 256 271.4 15.4 6.02 6
384 403.3 19.3 5.03 6 512 535.2 23.2 4.53 7 256 272.6 16.6 6.48 7 384 404.1
20.1 5.23 7 512 531.4 19.4 3.79 8 256 263.4 7.4 2.89 8 384 393.0 9.0 2.34 8
512 523.8 11.8 2.30 9 256 266.9 10.9 4.26 9 384 395.0 11.0 2.86 9 512 525.8
13.8 2.70 10 256 271.6 15.6 6.09 10 384 401.4 17.4 4.53 10 512 530.0 18.0 3.52
11 256 255.2 -0.8 -0.31 11 384 385.3 1.3 0.34 11 512 514.3 2.3 0.45 12 256
256.4 0.4 0.16 12 384 384.2 0.2 0.05 12 512 514.8 2.8 0.55 13 256 257.2 1.2
0.47 13 384 386.3 2.3 0.60 13 512 517.5 5.5 1.07 14 256 271.1 15.1 5.90 14 384
397.3 13.3 3.46 14 512 528.4 16.4 3.20 15 256 274.4 18.4 7.19 15 384 401.5
17.5 4.56 15 512 531.6 19.6 3.83 16 256 272.6 16.6 6.48 16 384 400.1 16.1 4.19
16 512 532.4 20.4 3.98 17 256 261.1 5.1 1.99 17 384 390.1 6.1 1.59 17 512
520.8 8.8 1.72 18 256 269.8 13.8 5.39 18 384 396.2 12.2 3.18 18 512 531.7 19.7
3.85 19 256 271.3 15.3 5.98 19 384 400.5 16.5 4.30 19 512 530.1 18.1 3.54 20
256 266.5 10.5 4.10 20 384 394.9 10.9 2.84 20 512 525.4 13.4 2.62
* * *
### 8.1.9 Attributes
Participants were asked to consider all perceptual differences between the
systems under test and the reference signal when scoring the _Basic Audio
Quality_.
### 8.1.10 Presentation of results
Figure 8.1.2 visualizes the absolute scores per test item and bit-rate. Table
8.1.5 further summarizes the results across all test items.
{width="6.308333333333334in" height="4.75in"}
Figure 8.1.2: Absolute score and 95% CI of Codec Quality Characterization test
(Test 1)
Table 8.1.5: Summary of average scores for Test 1
* * *
System High Low Mean spAACe @ 256 kbps 83.53 80.19 81.86 spAACe @ 384 kbps
87.56 84.33 85.94 spAACe @ 512 kbps 93.20 90.36 91.78 LP35 16.18 13.54 14.86
LP70 35.80 31.73 33.77 Hidden Reference 99.67 98.94 99.31
* * *
All bit-rates have scores not statistically significantly worse than 80 MUSHRA
points (Excellent).
### 8.1.11 Presentation of results for First Order Ambisonics
A second test was performed with First Order Ambisonics conditions, generated
by truncation of the four Higher Order Ambisonics Test signals. Only the 128
kbps bit-rate was tested. For the FOA test, 12 experienced assessors passed
pre- and post-screening. Results are shown in Figure 8.1.3. Table 8.1.6
further summarizes the results across all test items.
{width="5.891666666666667in" height="4.75in"}
Figure 8.1.3: Absolute scores and 95% CI of Codec Quality Characterization
test for FOA (Test 1c)
Table 8.1.6: Summary of average scores for Test 1c
* * *
System High Low Mean spAACe FOA @ 128 kbps 85.19 79.15 82.17 LP35 14.88 9.33
12.10 LP70 34.60 27.77 31.19 Hidden Reference (FOA) 100.00 100.00 100.00
* * *
## 8.2 Qualcomm test results on Test 2
### 8.2.1 Introduction and experimental design
ITU-R recommends that the \"testing, evaluation and reporting procedures given
in ITU-R BS.1534-3 [3] be used for the subjective assessment of intermediate
audio quality\". ITU-R BS.1534-3 [3] has also been previously used in other
standardization activities pertaining to spatial audio coding such as the
MPEG-H standardization. To provide an understanding of what quality levels can
be achieved with spAACe at the bit-rates of 256 kbps, 384 kbps and 512 kbps,
the Codec Quality Characterization Test described in 3GPP TS 26.259 [2] clause
5 was conducted and described in clause 8.2 (Test 1). However, because in Test
1 the reference condition passes through the rendering stage of the audio
profile (potentially discarding important audio content), a test with a Common
Informative Binaural Renderer is strongly recommended. Results of the Codec
Quality Characterization Test with the Common Informative Binaural Renderer
described in 3GPP TS 26.118 [9] clause 4.5 are reported.
In this experiment, 3 different bit-rates were tested with 20 different test
materials covering object-based, scene-based (up to 6th order HOA), channel-
based audio and a combination of these formats.
The experimental design was consistent with 3GPP TS 26.259 [2] clause 7.2. The
experiment was divided in two sessions, each session covering 10 test
materials.
### 8.2.2 Selection of assessors
The selection of Assessors was consistent with 3GPP TS 26.259 [2] clause 7.3.
Participants were all members of Qualcomm Advanced Tech R&D group and familiar
with critical listening and audio quality evaluation. 11 assessors were
selected following pre- and post-screening processes.
### 8.2.3 Test materials
The test materials included twenty different signals covering a range of audio
content typical of Virtual Reality such as vocals, orchestra music, nature
sounds, etc. Each of the three different bit rates was tested with each of the
twenty different signals.
### 8.2.4 Presentation interface
The ARL STEP software v.2.04 was used for presentation of the samples and
collection of results.
### 8.2.5 Listening environment
The listening environment noise floor was compliant to 3GPP TS 26.259 [2]
clause 7.6.
### 8.2.6 Listening system
Compliant to 3GPP TS 26.259 [2] clause 7.7, the listening system was
headphone-based using a Sennheiser® HD 800^TM^ headphone equalized for the
Neumann KU100 (same head simulator used for the HRTF database).
### 8.2.7 Headphone impulse response measurement
A custom MATLAB script for the acquisition of acoustic impulse responses was
used to measure the two Sennheiser® HD 800^TM^ headphone drivers with the
internal microphones of a Neumann KU100 HATS. A 2.25-second-long logarithmic
sine sweep ranging from 20Hz to 22kHz was used to make the measurements. Each
driver\'s impulse response was measured as the time averaged response over
five repeated measurements. To mitigate intra-subject variability, the
headphones were removed and replaced between repetitions. After averaging, the
impulse response for each driver was truncated to 16,384 samples and windowed
by a Tukey window with a taper ratio of 0.7 (generated with the MATLAB
function tukeywin). Finally, the two-channel impulse response matrix was
normalized to have a maximum absolute sample value of 1 and saved as a WAV
file.
### 8.2.8 Headphone compensation filter generation
Compensation filters for the left and right drivers of the Sennheiser® HD
800^TM^ reference headphones were generated using the impulse responses
described in clause 8.2.7. The filter design procedure was accomplished in
MATLAB, leveraging the AKregulatedInversion method in the AKTools MATLAB
toolbox [17]. Regularized least mean squares inversion was used to generate 16
384 sample FIR filters. 1/6th octave smoothed inverted copies of the original
headphone impulse responses were used as the regularization curves with β=0.2.
The resulting minimum phase inverse filters were fit to a target function
defined by a 2nd order 40 Hz highpass filter cascaded with a 1st order 20 kHz
lowpass filter. Finally, the compensation filters were smoothed by 1/6th
octave band, windowed in the time domain to a length of 256 samples, and saved
to WAV files for future use.
### 8.2.9 Listening level
The listening level was adjusted according to the requirements in 3GPP TS
26.259 [2] clause 7.8.
### 8.2.10 Generation of anchor/reference and test conditions
The signal processing chain for generation of the Test Conditions is shown in
Figure 8.2.1. Consistent with the requirements in 3GPP TS 26.259 [2] clause
7.9, the Hidden Reference was generated following a similar chain but with all
encoding/decoding operations bypassed, i.e. only the Reference Rendering
operations were enabled. The Anchors were generated from the Hidden Reference
by low-passing the signals at 3.5 kHz and 7 kHz.
{width="6.303472222222222in" height="3.2416666666666667in"}
Figure 8.2.1: Signal processing chain for generation of the test conditions
for Test 2
Technical details are as follows:
\- HOA (SN3D/ACN) was rendered to the Equivalent Spatial Domain (ESD) by means
of the inverse of the ESD-to-N3 matrix specified in Annex A. Where applicable,
the HOA content (whose order was larger than N=3) was truncated to N=3 before
rendering it to the ESD16 format. The angular directions of the ESD virtual
loudspeakers are defined in 3GPP TS 26.260 [15].
\- The CIBR binauralisation engine, described in 3GPP TS 26.118 [9] clause 4.5
was implemented.
\- In all Tests, audio objects were rendered to the target playback layouts by
means of the VBAP method described in [16]. The metadata used by the object
renderer implemented for these tests are azimuth, elevation, and gain factor.
\- The headphone compensation filters used (indicated by the blocks HPCompL
and HPCompR in Figure 8.2.1) were obtained by the procedure described in the
Headphone Compensation Filter Generation paragraph above.
\- Bit-rates for all contents are the same as described above.
### 8.2.11 Attributes
Participants were asked to consider all perceptual differences between the
systems under test and the reference signal when scoring the _Basic Audio
Quality_.
### 8.2.12 Presentation of results
Figure 8.2.2 visualizes the absolute scores per test item and bit-rate. Table
8.2.1 further summarizes the results across all test items.
{width="5.891666666666667in" height="4.75in"}
Figure 8.2.2: Absolute score and 95% CI of Codec Quality Characterization test
with binaural rendering (Test 2)
Table 8.2.1: Summary of average scores for Test 2
* * *
System High Low Mean spAACe @ 256 kbps 88.01 85.46 86.74 spAACe @ 384 kbps
90.00 87.38 88.69 spAACe @ 512 kbps 94.10 91.88 92.99 LP35 19.51 15.09 17.30
LP70 40.29 35.57 37.93 Hidden Reference 99.47 98.77 99.12
* * *
All bit-rates have scores not statistically significantly worse than 80 MUSHRA
points (Excellent).
## 8.3 Qualcomm test results on Test 3
### 8.3.1 Introduction and experimental design
Consumption of Virtual Reality content is typically done over headphones with
head tracking. As the binaural renderer plays a large role in the audio
immersive experience, it is desired to have a test that can assess the
performance of the Reference Renderer of a VR audio profile. The test
described in 3GPP TS 26.259 [2] clause 6 fulfils this need. Results of the
Rendering Comparison Test against the Common Informative Binaural Renderer
described in 3GPP TS 26.118 [9] clause 4.5 are reported.
In the Renderer Comparison Test, the assessors compare a Test Condition
against Anchor Conditions on four audio quality Attributes. The presentation
of the Test and Anchor Conditions is binaural using head-tracking. For each
trial, the Test Condition is compared to one of the Anchor Conditions as an A
v. B comparison. To control for possible presentation order biases, the test
Conditions are presented to the assessors as sample A in exactly half of the
trials. The test was conducted with 12 Test Materials and two Anchors (CIBR
1st order and CIBR 3rd order) for a total of 24 trials.
The test was divided in two sessions. The first session compared the Reference
Renderer against the first Anchor and the second session compared the
Reference Renderer against the second Anchor.
Because the Reference Renderer chosen for the spAACe audio profile is the CIBR
3rd order, the result of the comparison to the second Anchor is trivial (see
results clause 8.3.12).
### 8.3.2 Selection of assessors
The selection of Assessors was consistent with 3GPP TS 26.259 [2] clause 6.3.
Participants were all members of Qualcomm Advanced Tech R&D group and familiar
with critical listening and audio quality evaluation. 13 assessors were
selected following pre- and post-screening processes.
### 8.3.3 Test materials
The test materials included twenty different signals covering a range of audio
content typical of Virtual Reality such as vocals, orchestra music, nature
sounds, etc. Each of the three different bit rates was tested with each of the
twenty different signals.
### 8.3.4 Presentation interface
A custom interface in Max/MSP was developed for the purposes of this
experiment as depicted in Figure 8.3.1.
{width="6.291666666666667in" height="5.055555555555555in"}
Figure 8.3.1: GUI for the renderer comparison test
### 8.3.5 Listening environment
The listening environment noise floor was compliant to 3GPP TS 26.259 [2]
clause 6.6.
### 8.3.6 Listening system
Compliant to 3GPP TS 26.259 [2] clause 6.7, the listening system was
headphone-based using a Sennheiser® HD 800^TM^ headphone equalized for the
Neumann KU100 (same head simulator used for the HRTF database).
### 8.3.7 Headphone impulse response measurement
A custom MATLAB script for the acquisition of acoustic impulse responses was
used to measure the two Sennheiser® HD 800^TM^ headphone drivers with the
internal microphones of a Neumann KU100 HATS. A 2.25-second-long logarithmic
sine sweep ranging from 20 Hz to 22 kHz was used to make the measurements.
Each driver\'s impulse response was measured as the time averaged response
over five repeated measurements. To mitigate intra-subject variability, the
headphones were removed and replaced between repetitions. After averaging, the
impulse response for each driver was truncated to 16 384 samples and windowed
by a Tukey window with a taper ratio of 0.7 (generated with the MATLAB
function tukeywin). Finally, the two-channel impulse response matrix was
normalized to have a maximum absolute sample value of 1 and saved as a WAV
file.
### 8.3.8 Headphone compensation filter generation
Compensation filters for the left and right drivers of the Sennheiser® HD
800^TM^ reference headphones were generated using the impulse responses
described in clause 8.3.7. The filter design procedure was accomplished in
MATLAB, leveraging the AKregulatedInversion method in the AKTools MATLAB
toolbox [17]. Regularized least mean squares inversion was used to generate 16
384 sample FIR filters. 1/6th octave smoothed inverted copies of the original
headphone impulse responses were used as the regularization curves with β=0.2.
The resulting minimum phase inverse filters were fit to a target function
defined by a 2nd order 40 Hz high-pass filter cascaded with a 1st order 20 kHz
lowpass filter. Finally, the compensation filters were smoothed by 1/6th
octave band, windowed in the time domain to a length of 256 samples, and saved
to WAV files for future use.
### 8.3.9 Listening level
The listening level was adjusted according to the requirements in 3GPP TS
26.259 [2] clause 6.8. It was observed that the CIBR 1st order had a level on
average 1dB louder than the CIBR 3rd order. Therefore, a 1dB level attenuation
was applied to the CIBR 1st order.
### 8.3.10 Generation of anchor/reference and test conditions
Generation of the test and reference conditions was consistent with 3GPP TS
26.259 [2] clause 6.9.
### 8.3.11 Attributes
Four attributes, _Timbre, Spatial, Artefacts_ and _Basic Audio Quality_ were
evaluated, consistent with 3GPP TS 26.259 [2] clause 6.11. In addition, a
_Loudness_ scale was also provided.
### 8.3.12 Presentation of results
Figure 8.3.2 visualizes the absolute scores per test item for the condition
Reference Renderer vs. CIBR 1st order. Figure 8.3.3 visualizes the absolute
scores per test item for the condition Reference Renderer vs. CIBR 3rd order.
{width="5.8902777777777775in" height="3.198611111111111in"}
Figure 8.3.2: Mean scores and 95% CI of renderer comparison test for Reference
Renderer (SuT A) against CIBR 1st order (SuT B) (Test 3)
{width="5.95in" height="3.198611111111111in"}
Figure 8.3.3: Mean scores and 95% CI of renderer comparison test for Reference
Renderer (SuT A) against CIBR 3rd order (SuT B) (Test 3)
###### ### Annex A: Proposed ESD conversion matrices
# A.1 Summary
As described in 3GPP TS.26.118 [9] clause 4.5.1.2, the Common Informative
Binaural Renderer (CIBR), includes a conversion of a set of audio signals from
the Equivalent Spatial Domain (ESD) to the Higher Order Ambisonics (HOA)
domain. Configuration files have been created for the AmbiX Decoder plugin
with the conversion matrices in ACN/SN3D format and are documented in the
present annex for information.
# A.2 Processing description
The conversion matrices were computed based on the definition of the ESD
described in 3GPP TS 26.260 [15] clause 4.1.1.1.
Two configuration files are documented to facilitate the implementation of the
Common Informative Binaural Renderer for Test 2 and Test 3:
\- ESD-to-N1.config provides to convert the 1st order ESD to 1st Order
Ambisonics.
\- ESD-to-N3.config provides to convert the 3rd order ESD to 3rd Order
Ambisonics.
Source code of the configuration files is listed in the following clauses of
this Annex.
# A.3 ESD to First Order Ambisonics (FOA)
//------- decoder information -------
// decoder file = ./ESD/ESD-to-N1.config
// speaker array name = ESD1
// output horizontal order = 1
// output vertical order = 1
// output coefficient order = acn
// output coefficient scale = sn3d
// input scale = ESD
// output channel order: 00+ 11- 10+ 11+
// input speaker order: S01 S02 S03 S04
//-------
#GLOBAL
/debug_msg ESD-to-N1_1_band
/coeff_scale sn3d
/coeff_seq acn
/flip 0
/dec_mat_gain 1.000000
#END
#SPEAKERS
#spkrNr spkrLabel Radius Azimut Elevation x y z
1 S01 1.000000 0.000000 90.000000 0.000000 0.000000 1.000000
2 S02 1.000000 0.000000 -19.471220 0.942809 0.000000 -0.333333
3 S03 1.000000 120.000002 -19.471220 -0.471405 0.816497 -0.333333
4 S04 1.000000 -120.000000 -19.471224 -0.471405 -0.816497 -0.333333
#END
#HRTF \ \ \
#END
#DECODERMATRIX
1.000000 1.000000 1.000000 1.000000
-0.000000 -0.000000 0.816497 -0.816497
1.000000 -0.333333 -0.333333 -0.333333
-0.000000 0.942809 -0.471405 -0.471405
#END
# A.4 ESD to Third Order Ambisonics (HOA)
//------- decoder information -------
// decoder file = ./ESD/ESD-to-N3.config
// speaker array name = ESD3
// output horizontal order = 3
// output vertical order = 3
// output coefficient order = acn
// output coefficient scale = sn3d
// input scale = ESD
// output channel order: 00+ 11- 10+ 11+ 22- 21- 20+ 21+ 22+ 33- 32- 31- 30+
31+ 32+ 33+
// input speaker order: S01 S02 S03 S04 S05 S06 S07 S08 S09 S10 S11 S12 S13
S14 S15 S16
//-------
#GLOBAL
/debug_msg ESD-to-N3_1_band
/coeff_scale sn3d
/coeff_seq acn
/flip 0
/dec_mat_gain 1.000000
#END
#SPEAKERS
#spkrNr spkrLabel Radius Azimut Elevation x y z
1 S01 1.000000 0.000000 90.000000 0.000000 0.000000 1.000000
2 S02 1.000000 0.000000 41.063779 0.753979 0.000000 0.656899
3 S03 1.000000 64.165957 -26.423222 0.390242 0.806032 -0.444998
4 S04 1.000000 -14.486210 -59.261594 0.494870 -0.127855 -0.859510
5 S05 1.000000 66.210228 28.199531 0.355503 0.806424 0.472544
6 S06 1.000000 116.910929 -9.500334 -0.446397 0.879481 -0.165053
7 S07 1.000000 -79.135829 -26.423174 0.168791 -0.879481 -0.444997
8 S08 1.000000 15.509527 -9.500352 0.950370 0.263731 -0.165054
9 S09 1.000000 -126.289796 0.109778 -0.591869 -0.806032 0.001916
10 S10 1.000000 131.623728 37.454805 -0.527293 0.593409 0.608135
11 S11 1.000000 -160.596133 37.454804 -0.748744 -0.263731 0.608135
12 S12 1.000000 172.515059 -11.039712 -0.973132 0.127855 -0.191489
13 S13 1.000000 123.467745 -61.825361 -0.260381 0.393875 -0.881513
14 S14 1.000000 -36.399341 0.109766 0.804899 -0.593409 0.001916
15 S15 1.000000 -81.344564 35.341976 0.122758 -0.806424 0.578455
16 S16 1.000000 -141.411288 -50.840045 -0.493598 -0.393875 -0.775386
#END
#HRTF \ \ \
#END
#DECODERMATRIX
1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000
1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000
-0.000000 -0.000000 0.806032 -0.127855 0.806424 0.879481 -0.879481 0.263731 -0.806032 0.593409 -0.263731 0.127855 0.393875 -0.593409 -0.806424 -0.393875
1.000000 0.656899 -0.444998 -0.859510 0.472544 -0.165053 -0.444997 -0.165054
0.001916 0.608135 0.608135 -0.191489 -0.881513 0.001916 0.578455 -0.775386
-0.000000 0.753979 0.390242 0.494870 0.355503 -0.446397 0.168791 0.950370 -0.591869 -0.527293 -0.748744 -0.973132 -0.260381 0.804899 0.122758 -0.493598
-0.000000 -0.000000 0.544813 -0.109589 0.496556 -0.679999 -0.257120 0.434125 0.826301 -0.541959 0.342023 -0.215501 -0.177635 -0.827286 -0.171465 0.336738
-0.000000 -0.000000 -0.621257 0.190340 0.660034 -0.251427 0.677867 -0.075396 -0.002675 0.625050 -0.277794 -0.042406 -0.601378 -0.001969 -0.807968 0.528977
1.000000 0.147274 -0.202965 0.608136 -0.165054 -0.459136 -0.202966 -0.459136
-0.499994 0.054743 0.054743 -0.444998 0.665597 -0.499994 0.001916 0.401835
-0.000000 0.857864 -0.300783 -0.736720 0.290969 0.127616 -0.130097 -0.271693 -0.001964 -0.555409 -0.788668 0.322758 0.397556 0.002671 0.122993 0.662906
0.000000 0.492322 -0.430760 0.197929 -0.453743 -0.497286 -0.645186 0.721961
-0.259270 -0.064169 0.425273 0.805956 -0.075638 0.256109 -0.550143 0.076645
-0.000000 -0.000000 -0.122870 -0.072609 -0.172881 -0.122146 0.478371 0.550446 -0.255678 0.226111 -0.336160 0.285506 0.015027 -0.746600 0.385779 -0.179289
-0.000000 -0.000000 -0.542114 0.210622 0.524680 0.250968 0.255846 -0.160223 0.003540 -0.736973 0.465094 0.092274 0.350140 -0.003544 -0.221784 -0.583842
-0.000000 -0.000000 -0.004878 -0.210910 0.057525 -0.465210 0.005325 -0.139503 0.493583 0.308568 -0.137138 -0.063940 0.695934 0.363380 -0.332375 -0.483872
1.000000 -0.276692 0.447197 -0.298158 -0.445021 0.236339 0.447197 0.236339
-0.002874 -0.349938 -0.349938 0.269680 -0.390211 -0.002874 -0.383790 -0.002372
-0.000000 0.534473 -0.002362 0.816337 0.025359 0.236126 -0.001022 -0.502707 0.362437 -0.274188 -0.389341 0.486663 -0.460065 -0.492889 0.050596 -0.606381
0.000000 0.723157 0.428626 -0.380405 -0.479443 0.183534 0.641989 -0.266455
-0.001111 -0.087260 0.578300 -0.345097 0.149091 0.001097 -0.711591 -0.132888
-0.000000 0.338858 -0.554329 0.076624 -0.512798 0.748585 -0.305843 0.521832 0.748079 0.324470 -0.208334 -0.690814 0.081848 -0.259965 -0.187876 0.086541
#END
#