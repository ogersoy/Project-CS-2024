# Foreword
This Technical Report has been produced by the 3^rd^ Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
The present document analyses the aspects with regard to the new interface
between Control Plane and User Plane due to the separation of the following
EPC nodes: S-GW, P-GW and TDF.
Specifically, the following aspects are to be analysed:
\- Restoration procedure enhancements for the separated nodes;
\- Signalling with regards to Load control;
\- Signalling with regards to Overload control;
\- Path management and path failure handling.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TR 23.714: \"Study on control and user plane separation of EPC
nodes\".
[3] 3GPP TS 36.413, \"Evolved Universal Terrestrial Radio Access Network
(E-UTRAN); S1 Application Protocol (S1AP)\".
[4] IETF RFC 4271: \"A Border Gateway Protocol 4\".
[5] IETF RFC 5227: \"IPv4 Address Conflict Detection\".
[6] 3GPP TS 23.007: \"Restoration procedures\".
[7] 3GPP TS 23.214: \"Architecture enhancements for control and user plane
separation of EPC nodes; Stage 2\".
[8] 3GPP TS 29.274: \"Evolved General Packet Radio Service (GPRS) Tunnelling
Protocol for Control plane (GTPv2-C); Stage 3\".
[9] 3GPP TS 29.281: \"General Packet Radio System (GPRS) Tunnelling Protocol
User Plane (GTPv1-U)\".
# 3 Definitions, symbols and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
3GPP TR 21.905 [1] and the following apply. A term defined in the present
document takes precedence over the definition of the same term, if any, in
3GPP TR 21.905 [1].
## 3.2 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply.\ An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
CP Control plane
UP User plane
SGW-C SGW Control plane
SGW-U SGW User plane
PGW-C PGW Control plane
PGW-U PGW User plane
TDF-C TDF Control plane
TDF-U TDF User plane
# 4 Architecture and requirements
The new architecture defined to introduce the control plane and user plane
functional split for the S-GW, P-GW and TDF shall:
\- be able to interwork with networks without the control plane and user plane
split of network functions (i.e. in case of roaming scenarios). In addition,
the split network functions should be able to interwork with the network
functions that are not split within the same network.
\- not impact UE and Radio Access Network.
\- not introduce new reference points other than those between S-GW's, P-GW's,
TDF's corresponding control and user plane functions.
\- use the S-GW/P-GW selection function of the MME/ePDG/TWAN for the selection
of the control plane functional entities.
\- use the existing configuration based mechanism (in P-GW or PCRF) for the
selection of the control plane functional entity of the TDF.
\- support one or more control plane functional entities interfacing with one
or more user plane functional entities (e.g. to enable independent scalability
of control plane functional entity and user plane functional entity).
An excerpt of the 3GPP Architecture to facilitate the related nodes applicable
for separation of control and user plane and their related interfaces are
shown in Figure 4-1,
Figure 4-1: Interface overview for the nodes separated in control and user
plane.
# 5 Restoration
## 5.1 Introduction
The following subclauses analyse the Control plane and User plane node failure
with and without restart for separated SGW, PGW and TDF.
The following subclauses also analyse the Control plane and User plane node
partial failure for separated SGW and PGW.
## 5.2 Solutions for SGW-C failure with and without restart
### 5.2.1 Introduction
This section describes solutions for SGW-C failure with and without restart.
### 5.2.2 SGW-C failure with restart
#### 5.2.2.1 SGW-C failure with restart - Solution #1
##### 5.2.2.1.1 Solution Description
Figure 5.2.1.1-1: clear of sessions after _S_ GW-C Restart
1) When a SGW-C fails, all its session contexts affected by the failure become
invalid and may be deleted. After it restarts, the SGW-C shall delete all
session contexts affected by the restart that it may have stored. The SGW-C
shall also increment a local restart counter and shall place local SGW-C
restart counter value in all Echo requests/responses messages the SGW-C sends.
2) When the SGW-U detects that the SGW-C has restarted, the SGW-U shall delete
all session contexts affected by the SGW-C restart. When the SGW-U receives a
GTP-U PDU from other nodes (such as PGW-U or eNB) with no user plane context
exists, it shall discard the GTP-U PDU.
NOTE: In 3GPP TS 29.281 [9] subclause 7.3.1 it is specified that if a packet
is discarded with TEID different from the value \'all zeros\' the GTP-U node
shall also return a GTP error indication. This needs clarification during
normative work.
When the MME detects the SGW-C has restarted (such as relying on restart
counter as specified in clause 18 \"GTP-C based restart procedures\" in 3GPP
TS 23.007 [6]), it shall delete all PDN connection table data/MM bearer
contexts associated with the SGW-C as well as freeing any internal MME
resources associated with those PDN connections or maintain the bearers and MM
contexts of the PDN connections affected by the SGW-C restart and eligible for
restoration as specified in subclause 27 of 3GPP TS 23.007 [6] see figure
5.2.1.1-2.
When the PGW-C detects the SGW-C has restarted (such as relying on restart
counter as specified in clause 18 \"GTP-C based restart procedures\" in 3GPP
TS 23.007 [6]), it shall trigger the release of Sx session procedure to the
PGW-U.
3) The PGW-C sends the Sx Session Termination Request message to the PGW-U.
The PGW-U shall delete all the Sx session contexts and release the
corresponding user plane resource as requested by the PGW-C and then return
the Sx Session Termination Response message to the PGW-C.
When the PGW-C supports Restoration of PDN connections after an SGW failure as
specified in subclause 27 of 3GPP TS 23.007 [6] and maintain the bearers and
MM contexts of the PDN connections affected by the SGW-C restart and eligible
for restoration it shall initiate a Sx Session Modification Procedure to
modify the FAR when PGW-C receives the Modify bearer request from the
restarted SGW-C see figure 5.2.1.1-2 step 7 and 8. Until the FAR is changed
the PGW-U will forward the packets of the user plane to the SGW-U, the SGW-U
shall discard these packets for which it does not have an active session
(matching PDR).
After an SGW-C restart:
\- if SGW-U and SGW-C supports Sx Association setup procedure initiated by the
UP, the SGW-U may initiate the Sx Setup Procedure to the SGW-C.
\- If the user plane F-TEID is allocated by the SGW-C, the SGW-C should ensure
as far as possible that previously allocated F-TEID values are not immediately
reused after a SGW-C restart, in order to avoid inconsistent F-TEID allocation
throughout the network.
Figure 5.2.1.1-2: MME triggered SGW restoration after SGW-C restart
##### 5.2.2.1.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing S11 / S5 interfaces and GTP-C protocol.
**Cons:**
\- All the affected PDN connections have to be re-established, resulting in
potential signalling storm on S5 and S11. But the PDN connections do only need
to be modified to restore the SGW when the restoration of PDN connections
after an SGW failure as specified in subclause 27 of 3GPP TS 23.007 [6] is
supported. If this is supported - the packets which are received until
sessions in SGW are re-established are discarded and not delivered to the UE.
### 5.2.3 SGW-C failure without restart
#### 5.2.3.1 SGW-C failure without restart - Solution #1, clear resources
##### 5.2.3.1.1 Solution Description
Figure 5.2.3.1-1: SGW-C failure without restart, clear resources
1) When a SGW-C fails and does not restart, all its session contexts affected
by the failure become invalid and may be deleted.
2) When the SGW-U detects that the SGW-C does not reply to any message, after
an operator specific time the SGW-U shall interpret this as path failure and
delete all session contexts affected by the SGW-C failure. When the SGW-U
receives a GTP-U PDU from other nodes (such as eNB, PGW-U) for which no user
plane context exists, it shall discard the GTP-U PDU.
NOTE: In 3GPP TS 29.281 [9] subclause 7.3.1 it is specified that if a packet
is discarded with TEID different from the value \'all zeros\' the GTP-U node
shall also return a GTP error indication. This needs clarification during
normative work.
When the MME detects that a peer SGW-C has failed it shall delete all PDN
connection table data/MM bearer contexts associated with the peer node that
has failed as well as freeing any internal MME resources associated with those
PDN connections. The MME may optionally perform other implementation specific
actions such as to clear external resources (e.g. S1-MME messages to clear eNB
resources) or more advanced forms of restoration;
3) When a PGW-C detects that a peer SGW-C has failed it shall delete all PDN
connection table data/MM bearer contexts associated with the peer node that
fails as well as freeing any internal PGW-C resources associated with those
PDN connections The PGW-C shall initiate Sx session termination request
messages to all PGW-U effected by the SGW-C failure. The PGW-C may perform
other implementation specific actions such as messages to clear other external
resources (e.g. PCC messages);
> Figure 5.2.3.1-2 shows when the PGW-C supports Restoration of PDN
> connections after an SGW failure as specified in subclause 27 of 3GPP TS
> 23.007 [6] and maintain the bearers and MM contexts of the PDN connections
> affected by the SGW-C failure and eligible for restoration it shall initiate
> a Sx Session Modification Procedure to modify the FAR, when the PGW-C
> receives the Modify bearer request from the restarted SGW-C see figure
> 5.2.3.1-2 step 7 and 8. Until the FAR is changed the PGW-U will forward the
> packets of the user plane to the SGW-U, the SGW-U will discard these packets
> for which it does not have an active session (matching PDR).
Figure 5.2.3.1-2: MME triggered SGW restoration after SGW-C Failure
##### 5.2.3.1.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing S11 / S5 /S4 interfaces and GTP-C protocol.
**Cons:**
\- All the affected PDN connections have to be re-established, resulting in
potential signalling storm on Sxa, Sxb, S4, S5 and S11. But the PDN
connections do only need to be modified to restore the SGW when the
restoration of PDN connections after an SGW failure as specified in subclause
27 of 3GPP TS 23.007 [6] is supported. If this is supported \- the packets
which are received until sessions in SGW are re-established are discarded and
not delivered to the UE.
#### 5.2.3.2 SGW-C failure without restart - Solution #2, restore PDN
connection
##### 5.2.3.2.1 Solution Description
Figure 5.2.3.2-1: SGW-C failure without restart,
1) When a SGW-C fails and does not restart, all its session contexts affected
by the failure become invalid and may be deleted.
2) When the SGW-U detects that the SGW-C does not reply to any message, after
an operator specific time the SGW-U shall interpret this as path failure and
delete all session contexts affected by the SGW-C failure. When the SGW-U
receives a GTP-U PDU from other nodes (such as eNB, PGW-U) for which no user
plane context exists, it shall discard the GTP-U PDU and return an error
indication.
When the MME detects that a peer SGW-C has failed it shall follow the
procedures specified in 3GPP TS 23.007 [6] clause 27 to restore the PDN
connections affected by the SGW failure, if the MME and the PGW support these
procedures.
3) When a PGW-C detects that a peer SGW-C has failed it shall follow the
procedures specified in 3GPP TS 23.007 [6] clause 27 to restore the PDN
connections affected by the SGW-C failure, if the MME/S4-SGSN and the PGW-C
support these procedures.
##### 5.2.3.2.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing S11 / S5 /S4 interfaces and GTP-C protocol
but the procedures specified in 3GPP TS 23.007 [6] clause 27 have to be
supported by the MME and the PGW-C.
**Cons:**
\- The procedures specified in 3GPP TS 23.007 [6] clause 27 have to be
supported by the MME and the PGW-C.
## 5.3 Solutions for SGW-U failure with and without restart
### 5.3.1 Introduction
This section describes solutions for SGW-U failure with and without restart.
### 5.3.2 SGW-U Failure with Restart
#### 5.3.2.1 SGW-U Failure With Restart -- Solution #1: SGW-C Recreating the
User Plane Sessions in Restarted SGW-U on Reactive Basis
##### 5.3.2.1.1 Solution Description
When the SGW-C detects the failure of an SGW-U with a restart, the SGW-C or
optionally the SGW-U shall initiate the Sx association establishment when the
SGW-U has restarted.
After establishment of an Sx association between the SGW-C and the SGW-U the
SGW-C provides a wildcarded PDR to the SGW-U to forward packets for which the
SGW-U does not have a session (matching PDR). The SGW-C shall check if it has
an ongoing session for this packet, if so initiate the establishment of the
session in the SGW-U.
Alternatively, the SGW-C may also start restoring prioritary sessions in the
SGW-U after the SGW-U restart, while also restoring other sessions upon
receipt of User Plane packets from the SGW-U.
NOTE: It is CP\'s choice if reactive or proactive solution is performed or
possibly both. E.g. the CP activates reactive approach by activating a
\"wildcarded\" PDR in the UP which forwards packets to CP when there is no
other PDR matching.
The following call flow illustrates the sequence of steps followed to re-
create the sessions at the restarted SGW-U:
Figure 5.3.2.1.1-1: Session Restoration after SGW-U Failure with Restart
1) The restarted SGW-U receives an uplink or downlink GTP-U packet on the S1-U
or the S5-U interface for which the SGW-U does not have a session. It is
expected that a restarted SGW-U takes the same end point addresses on both S5
and S1 interfaces as it had before the failure.
2) If the SGW-U has been instructed by the SGW-C to send packets for which no
active session exist in the SGW-U to the SGW-C, then the SGW-U shall forward
the packet to the SGW-C in an encapsulated tunnel. The outer encapsulation
(F-TEID assigned by the SGW-C) shall identify that the packet is sent to the
SGW-C due to a missing session at the SGW-U. The inner payload shall be
exactly same as the packet received in step 1\. The SGW-C shall use the
identifiers (GTP-U TEID) in the inner payload to identify the bearer context
for which session re-creation at SGW-U is needed. The SGW-U may be configured
to forward all packets or to forward the first packet of the received packets
only, inside the encapsulated tunnel for the SGW-C to use the header
information to identify the session that needs to be restored on the SGW-U.
NOTE 1: If the SGW-U is connected to multiple SGW-C, then the SGW-C
responsible shall be identified by using the GTP-U FTEID pool to which the
destination TEID of the incoming packet belongs.
NOTE 2: It is assumed that when multiple SGW-C interfaces with a SGW-U there
is some logical partitioning of TEID space each SGW-C is responsible for
allocating, if the TEID allocation function is in the SGW-C.
NOTE 3: Whether the SGW-U forwards only the first packet or all the packets
until session restoration to the SGW-C is based on the SGW-U\'s knowledge of
SGW-C\'s buffering capability.
3) If the SGW-C supports buffering, then the SGW-C shall buffer the packet
until the session is re-created at the SGW-U.
NOTE 4: It is an implementation choice if the SGW-C buffers all packets or
uses packets only as trigger to establish the session.
4) The SGW-C shall recreate the Sx session at the SGW-U by using the Sx
Session Establishment Request
If the recreation of the Sx session at the SGW-U fails, the SGW-C may initiate
the release of the session towards the MME/SGSN and PGW.
If the SGW-C does not find any PDR (session) active matching the packets
received, the SGW-C shall discard the received packets.
5) Once the SGW-U accepts the session creation and if the SGW-C has buffered
the packet, then the SGW-C shall forward the buffered packet to the SGW-U. The
forwarded packet will be exactly same as how the packet was received by the
SGW-U in step 1.
6) The SGW-U, having the Sx session re-established, shall forward the received
GTP-U packet to the peer GTP-U entity.
If the SGW-U had failed without a restart and if another SGW-U can be
configured with the same GTP-U end point addresses as the failed SGW-U, then
the above solution can be used for a SGW-U failure without restart as well.
If multiple SGW-C\'s connect to a SGW-U, then this solution requires that the
user plane FTEID pool be partitioned across the multiple SGW-C\'s even when
the FTEID allocation by user plane is used.
If F-TEID allocation is performed in the SGW-U, the SGW-C shall maintain a
list of F-TEIDs allocated by the SGW-U. If the SGW-U restarts, the SGW-C shall
provide the list of F-TEIDs used before the restart during the Sx Association
setup. The SGW-C shall use these F-TEID when recreating the sessions. The
SGW-U shall not use the F-TEIDs provided by the SGW-C when assigning new
F-TEIDs. If the F-TEIDs provided during Sx association setup are not reused
after a predefined time (provided by the CP function together with the F-TEIDs
during the Sx association setup), the SGW-U shall delete the list. As the user
plane F-TEID pool is partitioned in the SGW-U across the multiple SGW-Cs, the
SGW-U does not need to wait for the re-establishment of all the Sx
associations from all SGW-Cs to start assigning new F-TEID for new Sx sessions
for a particular SGW-C.
##### 5.3.2.1.2 Solution Evaluation
**Pros:**
\- This solution has no impacts to peer nodes.
\- No impacts to existing S11 / S5 interfaces and GTP-C protocol.
\- Session recreation is naturally paced as and when uplink or downlink
packets arrive at the SGW-U for missing sessions. There is no mass re-creation
of all sessions. This avoids congestion during restoration.
\- SGW-U needs to support handling error scenarios like missing sessions. This
solution can be adopted for handling GTP-U errors like missing sessions as
well, and avoid SGW-U generating GTP-U error indications.
**Cons:**
\- If the buffering is done at the SGW-C, then there is a short duration
during which SGW-C has to buffer the packet.
\- may cause a lot of user plane packets to be forwarded to the SGW-C if the
SGW-U forwards to the SGW-C all the incoming packets without any existing
session (e.g. for all the on-going VoLTE sessions). SGW-C receives user plane
packets until all sessions are restored.
\- the solution requires F-TEID partitioning (among the SGW-Cs controlling the
SGW-U) when F-TEID is allocated by the SGW-U.
\- the solution requires the F-TEID partitioning (among the SGW-Cs controlling
the SGW-U) to be known by the SGW-U (be the F-TEID allocated by the SGW-C or
SGW-U).
\- may result in delaying the restoration of prioritary Sx sessions (e.g.
emergency PDN connections, eMPS or IMS sessions) until incoming packets are
received for that session (if the solution does not support the option for the
SGW-C to start restoring prioritary sessions after the SGW-U restart).
### 5.3.3 SGW-U Failure Without Restart
#### 5.3.3.1 SGW-U Failure Without Restart -- Solution #1: SGW-C Recreating
the User Plane Sessions in a New SGW-U, without change of GTP-U endpoint
##### 5.3.3.1.1 Solution Description
When the SGW-C detects the failure of an SGW-U without a restart, it may
optionally perform the operations as shown in the call flow below to restore
the user plane sessions:
Figure 5.3.3.1.1-1: Session Restoration after SGW-U Failure without Restart
1) The SGW-C detects that the SGW-U failed without a restart. In order to
restore the user plane sessions hosted in the failed SGW-U, the SGW-C
identifies and select a new SGW-U entity that can take up the user plane
sessions lost from the failed SGW-U. The SGW-C shall follow the procedures
identified in subclause 5.12 of 3GPP TS 23.214 [7] for selection of user plane
entity by the control plane for this purpose. If the failed SGW-U supports
multiple GTP-U end point addresses, then the SGW-C can potentially migrate
each of those GTP-U endpoint address and the list of user plane sessions using
that GTP-U endpoint address to a different SGW-U.
2) The SGW-C instructs the selected SGW-U to take up the given GTP-U end point
address(es) with Sx Association Update Procedure, which is same as the GTP-U
end point address(es) of the failed SGW-U.
In addition if F-TEID allocation is performed by SGW-U, the SGW-C shall
provide the list of F-TEIDs (for the given GTP-U end point address(es)) used
before the failure during the Sx Association Update procedure to the SGW-U.
> Once the selected SGW-U is instructed to take up a GTP-U end point address,
> the SGW-U shall advertise that IP to its MAC address mapping to the peer
> routers, through mechanisms like ARP Announcement (Gratuitous ARP) as
> specified in IETF RFC 5227 [5]. However, the exact mechanisms needed to
> achieve this are out of scope of 3GPP.
3) The SGW-C recreates the user plane sessions that were on the failed SGW-U
on the selected SGW-U by using the Sx session management procedures, according
to the principles specified in subclause 5.3.2.1 for SGW-U Failure With
Restart.
##### 5.3.3.1.2 Solution Evaluation
**Pros:**
\- This solution has no impacts to peer nodes.
\- No impacts to existing S11 / S5 interfaces and GTP-C protocol.
**Cons:**
\- User plane sessions of bearers that share the same S5 GTP-U end-point and
S1 GTP-U addresses can be re-created only in their entirety. This requires a
new SGW-U to be available to take up all the sessions from the failed GTP-U
endpoint of a SGW-U.
\- If existing SGW-U nodes that are healthy have spare capacity to take up
sessions, sessions can\'t be recreated on them directly as they may have
different GTP-U end point addresses. In order to recreate sessions on an
existing healthy SGW-U, a logical partition needs to be created on that SGW-U
and that partition needs to be created with a logical interface having the
specified GTP-U end point address. Even then there may not be enough capacity
on that node to take up all the recreated sessions that share the same S5
GTP-U and the same S1U end-point addresses.
#### 5.3.3.2 SGW-U Failure Without Restart -- Solution #2: SGW-C Recreating
the User Plane Sessions in Other Existing SGW-U, with change of GTP-U endpoint
##### 5.3.3.2.1 Solution Description
When the SGW-C detects the failure of an SGW-U, it may optionally perform the
operations shown below in the call flow to restore the user plane sessions:
Figure _5.3.3.2.1-1_ : Restoration of sessions after SGW-U Failure Without
Restart -- Solution #2
1) During the PDN creation, the MME, SGW-C and PGW advertise their support for
change of SGW-U FTEID during restoration. This is exchanged through indication
flags in the existing Create Session Request procedure.
2) The SGW-C detects that the SGW-U has failed without a restart.
> For each SGW-U session that needs to be restored, identify and select a new
> SGW-U entity. The SGW-C shall follow the procedures identified under sub-
> clause 5.12 of 3GPP TS 23.214 [7] for selection of user plane entity by the
> control plane for this purpose.
Editor\'s Note: The reference to sub-clause x.y needs to be updated once stage
2 normatively specifies the high level principles of user plane selection.
3) Recreate the user plane session on the selected SGW-U by using the Sx
session management procedures. This re-created SGW-U session may have a
different S1U SGW FTEID and S5u SGW FTEID from the F-TEIDs that were used
before the SGW-U failure.
NOTE 1: the restoration of the Sx sessions could also be triggered upon of
receipt of user plane packets, after the step 5, like for the solutions
described in subclauses 5.3.2.1 and 5.3.3.1, to pace the restoration of the
sessions over Sx, when F-TEID is assigned by the CP function.
4) SGW-C subsequently signals the change of S1U SGW FTEID to the MME and the
S5U SGW FTEID to the PGW. The existing Update Bearer Request and the Modify
Bearer Request messages, respectively, can be updated to carry the changed S1U
/ S5U FTEIDs.
NOTE 2: The SGW-C shall apply this solution only if the MME and the PGW
support the signalling procedures for accepting change of S1U SGW FTEID and
S5U SGW FTEID respectively.
5) The MME shall use the existing E-RAB Modification Procedure as specified in
3GPP TS 36.413 [3] sub-clause 8.2.2.
NOTE 2: As per 3GPP TS 36.413 [3] sub-clause 8.2.2.2, if the E-RAB
Modification Procedure is used for modifying the Transport Information IE to
change the SGW S1U FTEID, the QoS and NAS PDU IEs shall be ignored by the eNB.
Consequently, for using this procedure for changing the SGW S1U FTEID at the
eNB, it is enough that the MME just include a dummy NAS message.
##### 5.3.3.2.2 Solution Evaluation
**Pros:**
\- Sessions can be re-created in other available SGW-U in a distributed
fashion.
\- No need to rely on IP / L2 level mechanisms for retaining the same GTP-U
endpoint address and advertising it to peer nodes.
**Cons:**
\- Requires protocol level changes on S11 and S5.
\- There could be potential signalling storm on S5, S11 and the S1 interface.
## 5.4 Solutions for PGW-C failure with and without restart
### 5.4.1 Introduction
This section describes solutions for PGW-C failure with and without restart.
### 5.4.2 PGW-C Failure With Restart
#### 5.4.2.1 PGW-C Failure With Restart Solution #1, Clear resources
##### 5.4.2.1.1 Solution Description
Figure 5.4.2.1-1: clear of sessions after _P_ GW-C Restart
1) When a PGW-C fails, all its session contexts affected by the failure become
invalid and may be deleted. After it restarts, the PGW-C shall delete all
session contexts affected by the restart that it may have stored. The PGW-C
shall also increment a local GTP-C restart counter and shall place this local
GTP-C restart counter value in all Echo requests/responses messages the PGW-C
sends. The PGW-C shall as well increment a local PFCP restart counter and
shall place this local PFCP restart counter in all Heartbeat
requests/responses messages the PGW-C sends.
2) When the PGW-U detects that the PGW-C has restarted, the PGW-U shall delete
all session contexts affected by the PGW-C restart. When the PGW-U receives a
GTP-U PDU from other nodes (such as SGW-U) for which no user plane context
exists, it shall discard the GTP-U PDU and return an error indication.
When an SGW-C detects that a peer PGW-C has restarted (see clause 18 \"GTP-C
based restart procedures\" in 3GPP TS 23.007 [6]) it shall delete all PDN
connection table data/MM bearer contexts associated with the peer node that
fails as well as freeing any internal SGW-C resources associated with those
PDN connections. In addition, if the optional feature PGW Restart Notification
is supported by the SGW-C and MME/S4-SGSN as specified in clause 8.83 in 3GPP
TS 29.274 [8], the SGW-C shall initiate the cleanup of the hanging PDN
connections associated with the SGW-C and the restarted PGW-C at the
corresponding MMEs/S4-SGSNs by sending GTPv2 message(s) PGW-C Restart
Notification, with the control plane IP address of the restarted PGW-C and the
control plane IP address of the SGW on the S11/S4 interface included. The
SGW-C may optionally perform other implementation specific actions such as
messages to clear other external resources (e.g. PCC messages)
3) The SGW-C sends a Sx Session Deletion Request message to the SGW-U for each
Sxa session affected by the PGW-C restart. The SGW-U shall delete all the Sx
session contexts and release the corresponding user plane resource as
requested by the SGW-C and then return the Sx Session Deletion Response
message to the SGW-C.
##### 5.4.2.1.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing S11 / S5 / S4 interfaces and GTP-C protocol.
**Cons:**
\- All the affected PDN connections have to be re-established, resulting in
potential signalling storm on Sxa, Sxb, S4, S5 and S11.
### 5.4.3 PGW-C Failure Without Restart
#### 5.4.3.1 PGW-C Failure Without Restart Solution #1, clear resources
##### 5.4.3.1.1 Solution Description
Figure 5.4.3.1-1: clear of sessions after _P_ GW-C Restart
1) When a PGW-C fails and does not restart, all its session contexts affected
by the failure become invalid and may be deleted.
2) When the PGW-U detects that the PGW-C does not reply to any message, after
an operator specific time the PGW-U shall interpret this as path failure and
delete all session contexts affected by the PGW-C failure. When the PGW-U
receives a GTP-U PDU from other nodes (such as SGW-U) for which no user plane
context exists, it shall discard the GTP-U PDU and return an error indication.
When an SGW-C detects a failure of the path with the PGW-C on S5 interface
(see clause 20.2.2.2 \"S5 path failure\" in 3GPP TS 23.007 [6]) it shall
delete all PDN connection table data/MM bearer contexts associated with the
peer node that does not reply as well as freeing any internal SGW-C resources
associated with those PDN connections.
3) The SGW-C sends the Sx Session Deletion Request message to the SGW-U for
each Sxa session affected by the PGW-C restart. The SGW-U shall delete all the
Sx session contexts and release the corresponding user plane resource as
requested by the SGW-C and then return the Sx Session Deletion Response
message to the SGW-C.
##### 5.4.3.1.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing S11 / S5 /S4 interfaces and GTP-C protocol.
**Cons:**
\- All the affected PDN connections have to be re-established, resulting in
potential signalling storm on Sxa, Sxb, S4, S5 and S11.
## 5.5 Solutions for PGW-U failure with and without restart
### 5.5.1 Introduction
This section describes solutions for PGW-U failure with and without restart
### 5.5.2 PGW-U Failure With Restart
#### 5.5.2.1 PGW-U Failure With Restart -- Solution#1: PGW-C Recreating the
User Plane Sessions in Restarted PGW-U on Reactive Basis
##### 5.5.2.1.1 Solution Description
When the PGW-C detects the failure of a PGW-U with a restart, the PGW-C or
optionally the PGW-U shall initiate the Sx association establishment when the
PGW-U has restarted.
After establishment of an Sx association between the PGW-C and the PGW-U, the
PGW-C provides a wildcarded PDR to the PGW-U to forward packets for which the
PGW-U does not have a session. The PGW-C shall check if it has an ongoing
session for the forwarded packet, if so the PGW-C initiates the establishment
of the session in the PGW-U.
Alternatively, the PGW-C may also start restoring prioritary sessions in the
PGW-U after the PGW-U restart, while also restoring other sessions upon
receipt of User Plane packets from the PGW-U.
NOTE: It is CP\'s choice if reactive or proactive solution is performed or
possibly both. E.g. the CP activates reactive approach by activating a
\"wildcarded\" PDR in the UP which forwards packets to CP when there is no
other PDR matching.
The following call flow illustrates the sequence of steps followed to re-
create the sessions at the restarted PGW-U:
Figure 5.5.2.1.1-1: Session Restoration after PGW-U Failure with Restart
1) The restarted PGW-U receives an uplink GTP-U packet or a downlink IP packet
on the S5-U or the SGi interface respectively for which the PGW-U does not
have a session. It is expected that a restarted PGW-U takes the same end point
addresses on both SGi and S5 interfaces as it had before the failure.
2) If the PGW-U has been instructed to send packets for which no active
session exist in the PGW-U to the PGW-C, then the PGW-U shall forward the full
packet to the PGW-C in an encapsulated tunnel. The outer encapsulation (F-TEID
assigned by the PGW-C) shall identify that the inner packet is sent to the
PGW-C due to a missing session at the PGW-U. For PDNs with overlapping IP
address ranges, the PGW-U shall also indicate the PDN instance for which the
packet was received (alternatively the PGW-C setup a tunnel per PDN instance
with a proper PDR setting). The PGW-C shall use the header of the inner
payload to identify the PDN or bearer session to which it belongs. The PGW-U
may be configured to forward all packets or to forward the firstof the
received packets only, inside the encapsulated tunnel for the PGW-C to use the
header information to identify the session (based on active PDRs) that needs
to be restored on the PGW-U.
NOTE 1: If the PGW-U is connected to multiple PGW-C, then the PGW-C
responsible shall be identified by using the IP pool to which the destination
IP address of the incoming downlink packet belongs or by using the GTP-U FTEID
pool to which the destination TEID of the incoming uplink packet belongs.
NOTE 2: It is assumed that when multiple PGW-C interfaces with a PGW-U there
is some logical partitioning of IP address space and TEID space each PGW-C is
responsible for allocating.
NOTE 3: Whether the PGW-U forwards only the first packet or all the packets
until session restoration to the PGW-C is based on the PGW-U\'s knowledge of
PGW-C\'s buffering capability.
Editor\'s note: it is FFS how the PGW-U signals the PDN instance to the PGW-C.
Editor\'s note: it is FFS how a PGW-U connected to multiple PGW-C identify the
PGW-C responsible for restoring a Sx session in scenarios where the IP address
is assigned by DHCP or an external AAA server in the PDN.
3) If the PGW-C supports buffering, the PGW-C shall buffer the packet until
the session is re-created at the PGW-U.
4) The PGW-C shall recreate the Sx session at the PGW-U by using the Sx
Session Establishment Request
If recreation of the Sx session at the PGW-U fails, the PGW-C may initiate the
release of the session toward the SGW and the MME/SGSN.
If the PGW-C does not find any PDR active matching the packets received the
PGW-C shall discard the received packets.
5) Once the PGW-U accepts the session creation and if the PGW-C has buffered
the packet, then the PGW-C shall forward the buffered packet to the PGW-U. The
forwarded packet will be exactly same as how the packet was received by the
PGW-U in step 1.
6) The PGW-U, having the Sx session re-established, shall forward the received
IP packet to the peer GTP-U entity in the case of downlink data transfer and
shall forward the received inner payload inside the GTP-U packet to the SGi
side after stripping the GTP-U header in the case of uplink data transfer.
If the PGW-U had failed without a restart and if another PGW-U can be
configured with the same IP and GTP-U end point addresses as the failed PGW-U,
then the above solution can be used for a PGW-U failure without restart as
well.
If multiple PGW-C\'s connect to a PGW-U, then this solution requires that the
user plane F-TEID pool be partitioned across the multiple PGW-C\'s even when
the FTEID allocation by user plane is used.
If F-TEID allocation is performed in the PGW-U, the PGW-C shall maintain a
list of F-TEIDs allocated by the PGW-U. If the PGW-U restarts, the PGW-C shall
provide the list of F-TEIDs used before the restart during the Sx Association
setup. The PGW-C shall use these F-TEID\'s when recreating the sessions. The
PGW-U shall not use the F-TEIDs provided by the PGW-C when assigning new
F-TEIDs. If the F-TEIDs provided during Sx association setup are not reused
after a predefined time (provided by the CP function together with the F-TEIDs
during the Sx association setup), the PGW-U shall delete the list. As the user
plane F-TEID pool is partitioned in the PGW-U across the multiple PGW-Cs, the
PGW-U does not need to wait for the re-establishment of all the Sx
associations from all PGW-Cs to start assigning new F-TEID for new Sx sessions
for a particular PGW-C.
##### 5.5.2.1.2 Solution Evaluation
**Pros:**
\- This solution has no impacts to peer nodes.
\- No impacts to existing S5 interface and GTP-C protocol.
\- Session recreation is naturally paced as and when uplink or downlink
packets arrive at the PGW-U for missing sessions. There is no mass re-creation
of all sessions. This avoids congestion during restoration.
\- PGW-U needs to support handling error scenarios like missing sessions. This
solution can be adopted for handling GTP-U errors like missing sessions as
well, and avoid PGW-U generating GTP-U error indications.
**Cons:**
\- If the buffering is done at the PGW-C, then there is a short duration
during which PGW-C has to buffer the packet.
\- may cause a lot of user plane packets to be forwarded to the PGW-C if the
PGW-U forwards to the PGW-C all the incoming packets without any existing
session (e.g. for all the on-going VoLTE sessions). PGW-C receives user plane
packets until all sessions are restored.
\- the solution requires F-TEID partitioning (among the PGW-Cs controlling the
PGW-U) when F-TEID is allocated by the PGW-U.
\- the solution requires the F-TEID partitioning (among the PGW-Cs controlling
the PGW-U) to be known by the PGW-U (be the F-TEID allocated by the PGW-C or
PGW-U).
\- the solution requires the IP address pool partitioning (among the PGW-Cs
controlling the PGW-U) to be known by the PGW-U.
\- may result in delaying the restoration of prioritary Sx sessions (e.g.
emergency PDN connections, eMPS or IMS sessions) until incoming packets are
received for that session (if the solution does not support the option for the
PGW-C to start restoring prioritary sessions after the PGW-U restart).
### 5.5.3 PGW-U Failure Without Restart
#### 5.5.3.1 PGW-U Failure Without Restart -- Solution #1: PGW-C Recreating
the User Plane Sessions in a New PGW-U, without change of GTP-U endpoint
##### 5.5.3.1.1 Solution Description
When the PGW-C detects the failure of an PGW-U without a restart, it may
optionally perform the operations as shown in the call flow below to restore
the user plane sessions:
Figure 5.5.3.1.1-1: Session Restoration after PGW-U Failure without Restart
1) The PGW-C detects that the PGW-U failed without a restart. In order to
restore the user plane sessions hosted in the failed PGW-U, the PGW-C
identifies and select a new PGW-U entity that can take up the user plane
sessions lost from the failed PGW-U. The PGW-C shall follow the procedures
identified in subclause 5.12 of 3GPP TS 23.214 [7] for selection of user plane
entity by the control plane for this purpose. If the failed PGW-U supports
multiple GTP-U end point addresses, then the PGW-C can potentially migrate
each of those GTP-U endpoint address and the list of user plane sessions using
that GTP-U endpoint address to a different PGW-U. In such a case it is assumed
that the user plane sessions that share the same S5 GTP-U endpoint have their
PDN addresses allocated from the same IP sub-pool in the failed PGW-U.
2) The PGW-C instructs the selected PGW-U to take up the given GTP-U end point
address(es) with Sx Association Update Procedure, which is same as the GTP-U
end point address(es) of the failed PGW-U. The PGW-C also instructs the
selected PGW-U to own the IP pool(s) that the PDN addresses of the user plane
sessions to be restored share.
> In addition if F-TEID allocation is performed by PGW-U, the PGW-C shall
> provide the list of F-TEIDs (for the given GTP-U end point address(es)) used
> before the failure during the Sx Association Update procedure to the PGW-U.
Once the selected PGW-U is instructed to take up a GTP-U end point
address(es), the PGW-U shall advertise that IP to its MAC address mapping to
the peer routers, through mechanisms like ARP Announcement (Gratuitous ARP) as
specified in IETF RFC 5227 [5]. However, the exact mechanisms needed to
achieve this are out of scope of 3GPP.
Similarly, the PGW-C shall advertise that the new PGW-U is owning the IP
pool(s) that was owned by the failed PGW-U earlier, to the upstream IP
routers, so that the upstream routers forward the downlink IP packets to the
right PGW-U. The PGW-C may use mechanisms like BGP updates, as specified in
IETF RFC 4271 [4] for this. BGP updates may cause routing convergence delays
in the upstream routers. There could also be other mechanisms that could be
used for updating the upstream routers. However, the exact mechanisms needed
to achieve this are out of scope of 3GPP.
3) The PGW-C recreates the user plane sessions that were on the failed PGW-U
on the selected PGW-U by using the Sx session management procedures, according
to the principles specified in subclause 5.5.2.1 for PGW-U Failure With
Restart.
##### 5.5.3.1.2 Solution Evaluation
**Pros:**
\- This solution has no impacts to peer nodes.
\- No impacts to existing S5 interface and GTP-C protocol.
**Cons:**
\- User plane sessions of bearers that share the same S5 GTP-U end-point
address can be re-created only in their entirety. This requires a new PGW-U to
be available to take up all the sessions from the failed GTP-U endpoint of a
PGW-U.
\- If existing PGW-U nodes that are healthy have spare capacity to take up
sessions, sessions can\'t be recreated on them directly as they may have
different GTP-U end point addresses. In order to recreate sessions on an
existing healthy PGW-U, a logical partition needs to be created on that PGW-U
and that partition needs to be created with a logical interface having the
specified GTP-U end point address(es). Even then there may not be enough
capacity on that node to take up all the recreated sessions that share the
same S5 GTP-U end-point address.
#### 5.5.3.2 PGW-U Failure Without Restart -- Solution #2: PGW-C Recreating
the User Plane Sessions in Other Existing PGW-U, with change of GTP-U endpoint
##### 5.5.3.2.1 Solution Description
When the PGW-C detects the failure of an PGW-U, it may optionally perform the
operations shown below in the call flow to restore the user plane sessions:
Figure _5.5.3.2.1-1_ : Restoration of sessions after _P_ GW-U Failure Without
Restart -- Solution #2
1) During the PDN creation, the MME, SGW and PGW-C advertise their support for
change of PGW-U FTEID during restoration. This is exchanged through indication
flags in the existing Create Session Request procedure.
2) The PGW-C detects that the PGW-U has failed without a restart.
If the SGi side IP pool(s) served by the failed PGW-U can be split into a
number of smaller aggregate IP pools, then for each such smaller aggregate IP
pool (for the user plane sessions of the PDNs that have their PDN address from
that IP pool, that needs to be restored), identify and select a new PGW-U
entity. The PGW-C shall follow the procedures identified in subclause 5.12 of
3GPP TS 23.214 [7] for selection of user plane entity by the control plane for
this purpose.
3) Recreate the block of user plane sessions of the PDNs that share the PDN
addresses from the same aggregate IP pool, on the selected PGW-U by using the
Sx session management procedures. This re-created PGW-U session may have a
different S5U PGW FTEID from the F-TEIDs that were used before the PGW-U
failure.
4) PGW-C subsequently signals the change of S5U PGW FTEID to the SGW. The
existing Update Bearer Request message can be updated to carry the changed S5U
FTEIDs.
NOTE 1: The PGW-C shall apply this solution only if the MME and the SGW
support the signalling procedures for accepting change of S5U PGW FTEID.
The PGW-C shall advertise that a different PGW-U is now owning the IP pool(s)
that was owned by the failed PGW-U earlier, to the upstream IP routers, so
that the upstream routers forward the downlink IP packets to the right PGW-U.
The PGW-C may use mechanisms like BGP updates, as specified in IETF RFC 4271
[4] for this. BGP updates may cause routing convergence delays in the upstream
routers. There could also be other mechanisms that could be used for updating
the upstream routers. However, the exact mechanisms needed to achieve this are
out of scope of 3GPP.
##### 5.5.3.2.2 Solution Evaluation
**Pros:**
\- Sessions can be re-created in other available PGW-U in a distributed
fashion by moving smaller blocks of aggregate IPs (small IP pools) of the PDN
addresses.
\- No need to rely on IP / L2 level mechanisms for retaining the same GTP-U
endpoint address and advertising it to peer nodes.
**Cons:**
\- Requires protocol level changes on S5.
\- There could be potential signalling storm on S5, S11 and S4.
## 5.6 Solutions for TDF-C failure with and without restart
### 5.6.1 Introduction
This section describes solutions for TDF-C failure with and without restart.
### 5.6.2 Solutions for TDF-C failure with restart
#### 5.6.2.1 TDF-C failure with restart Solution #1, clear resources
##### 5.6.2.1.1 Solution Description
Figure 5.6.2.1-1: clear of sessions after _TDF_ -C Restart
1) When a TDF-C fails, all its session contexts affected by the failure become
invalid and may be deleted. After it restarts, the TDF-C shall delete all
session contexts affected by the restart that it may have stored. The TDF-C
shall also increment a local restart counter and shall place local TDF-C
restart counter value in all Heartbeat requests/responses messages the TDF-C
sends.
2) When the TDF-U detects that the TDF-C has restarted, the TDF-U shall delete
all session contexts affected by the TDF-C restart. When the TDF-U receives a
PDU from other nodes (such as PGW-U) for which no user plane context exists,
it shall discard the PDU.
##### 5.6.2.1.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing on GTP-C interfaces and GTP-C protocol.
**Cons:**
\- All the affected TDF sessions have to be re-established, resulting in
potential signalling storm over Sd and Sxc.
### 5.6.3 Solutions for TDF-C failure without restart
#### 5.6.3.1 TDF-C failure without restart Solution #1, clear resources
##### 5.6.3.1.1 Solution Description
Figure 5.6.3.1-1: clear of sessions after _TDF_ -C failure
1) When a TDF-C fails, all its session contexts affected by the failure become
invalid and may be deleted.
2) When the TDF-U detects that the TDF-C does not reply, after an operator
specific time the TDF-U shall treat this in the same way as a path failure
between TDF-C and TDF-U. TDF-U may delete all affected sessions. When the
TDF-U receives a PDU from other nodes (such as PGW-U) for which no user plane
context exists, it shall discard the PDU.
##### 5.6.3.1.2 Evaluation and conclusion
**Pros:**
\- No new impacts on the existing interfaces.
**Cons:**
\- All the affected TDF sessions have to be re-established, resulting in
potential signalling storm over Sd and Sxc.
## 5.7 Solutions for TDF-U failure with and without restart
### 5.7.1 Introduction
This section describes solutions for TDF-U failure with and without restart.
### 5.7.2 TDF-U failure with restart
#### 5.7.2.1 TDF-U failure with restart Solution #1, TDF-C Recreating the User
Plane Sessions in Restarted TDF-U on Reactive Basis
##### 5.7.2.1.1 Solution Description
When the TDF-C detects the failure of a TDF-U with a restart, the TDF-C or
optionally the TDF-U shall initiate the Sx association establishment when the
TDF-U has restarted.
After establishment of an Sx association between the TDF-C and the TDF-U the
TDF-U the TDF-C provides a wildcarded PDR to the TDF-U to forward packets for
which the TDF-U does not have a session. The TDF-C shall check if it has an
ongoing session for this packet, if so initiate the establishment of the
session.
Alternatively, the TDF-C may also start restoring prioritized sessions in the
TDF-U after the TDF-U restart, while also restoring other sessions upon
receipt of User Plane packets from the TDF-U.
NOTE 1: It is CP\'s choice if reactive or proactive solution is performed or
possibly both. E.g. the CP activates reactive approach by activating a
\"wildcarded\" PDR in the UP which forwards packets to CP when there is no
other PDR matching.
The following call flow illustrates the sequence of steps followed to re-
create the sessions at the restarted TDF-U:
Figure 5.7.2.1.1-1: Session Restoration after TDF-U Failure with Restart
1) The restarted TDF-U receives an uplink or a downlink IP packet on the SGi
interface respectively for which the TDF-U does not have a session. It is
expected that a restarted TDF-U takes the same end point addresses on both SGi
interfaces as it had before the failure.
2) If the TDF-U knows that the TDF-C supports buffering, then the TDF-U shall
forward the full packet to the TDF-C in an encapsulated tunnel. The outer
encapsulation shall identify that the inner packet is sent to the TDF-C due to
a missing session at the TDF-U. If the TDF-U knows that the TDF-C does not
support buffering and if the TDF-U supports buffering, then the TDF-U shall
forward only the header of the received packet, inside the encapsulated tunnel
for the TDF-C to use the header information to identify the session that needs
to be restored on the TDF-U.
NOTE 2: Whether the TDF-U forwards only the first packet or all the packets
until session restoration to the TDF-C is based on the TDF-U\'s knowledge of
TDF-C\'s buffering capability.
Editor\'s note: it is FFS how a TDF-U connected to multiple TDF-C identify the
TDF-C responsible for restoring a Sx session in scenarios where the IP address
is assigned by DHCP or an external AAA server in the PDN.
3) If the TDF-C supports buffering, the TDF-C shall buffer the packet until
the session is re-created at the TDF-U.
4) The TDF-C shall recreate the Sx session at the TDF-U by using the Sx
Session Establishment Request
NOTE 3: If the TDF-C receives many triggers to restore sessions, the TDF can
pace session restoration.
If recreation of the Sx session at the TDF-U fails, the TDF-C may initiate the
termination of the session.
If the TDF-C does not find any PDR active matching the packets received the
TDF-C shall discard the received packets.
5) Once the TDF-U accepts the session creation and if the TDF-C has buffered
the packet, then the TDF-C shall forward the buffered packet to the TDF-U. The
forwarded packet will be exactly same as how the packet was received by the
TDF-U in step 1.
6) The TDF-U, having the Sx session re-established, shall forward the received
IP packet to the peer IP session entity.
If the TDF-U had failed without a restart and if another TDF-U can be
configured with the same IP end point addresses as the failed TDF-U, then the
above solution can be used for a TDF-U failure without restart as well.
If multiple TDF-C\'s connect to a TDF-U, then this solution requires that the
user plane IP address pool be partitioned across the multiple TDF-C\'s.
##### 5.7.2.1.2 Solution Evaluation
**Pros:**
\- This solution has no impacts to peer nodes.
\- Session recreation is performed when uplink or downlink packets arrive at
the TDF-U for missing sessions. There is no mass re-creation of all sessions.
This avoids congestion during restoration.
\- TDF-U needs to support handling error scenarios like missing sessions.
**Cons:**
\- If the buffering is done at the TDF-C, then there is a short duration
during which TDF-C has to buffer the packet.
\- may cause a lot of user plane packets to be forwarded to the TDF-C if the
TDF-U forwards to the TDF-C all the incoming packets without any existing
session (e.g. for all the on-going VoLTE sessions). TDF-C receives user plane
packets until all sessions are restored.
\- may result in delaying the restoration of prioritized Sx sessions (e.g.
emergency PDN connections, eMPS or IMS sessions) until incoming packets are
received for that session (if the solution does not support the option for the
TDF-C to start restoring prioritary sessions after the TDF-U restart).
### 5.7.3 TDF-U failure without restart
#### 5.7.3.1 TDF-U failure without restart Solution #1, TDF-C Recreating the
User Plane Sessions in a New TDF-U
##### 5.7.3.1.1 Solution Description
When the TDF-C detects the failure of an TDF-U without a restart, it may
optionally perform the operations as shown in the call flow below to restore
the user plane sessions:
Figure 5.7.3.1.1-1: Session Restoration after TDF-U Failure without Restart
1) The TDF-C detects that the TDF-U failed without a restart. In order to
restore the user plane sessions hosted in the failed TDF-U the redirection of
the traffic originally handled by the failed TDF-U has to be performed.
How traffic redirection is it done is implementation specific.
##### 5.7.3.1.2 Solution Evaluation
**Pros:**
\- This solution has no impacts to peer nodes.
**Cons:**
\- Adds the requirement for traffic redirection to an alternative TDF-U.
## 5.8 Detection of a PFCP entity restart
### 5.8.1 Introduction
This section describes solutions for detecting a peer PFCP entity restart.
### 5.8.2 Solution 1 - Based on the timestamp of the restart
Across PFCP based interfaces a SGW-C, SGW-U, PGW-C, PGW-U, TDF-C, TDF-U,
Combined SGW/PGW-C and Combined SGW/PGW-U, utilize either Sx node related
messages containing the Recovery Information Element to detect and handle a
restart.
A PFCP entity shall maintain the Recovery Information for its own and for each
peer with which the entity is in contact.
After a PFCP entity has restarted, it shall set the Recovery Information for
its own with the current UTC time and shall clear any Recovery Information for
all its remote peers.
A PFCP entity may probe the liveliness of each peer with which it is in
contact by sending an Sx node related message or an Sx session related
message.
Editor\'s Note: It is FFS whether the Recovery Information is associated to
the Source IP address or Node ID.
A PFCP entity that receives a Recovery Information Element in an Sx node
related message or an Sx session related message from a peer, shall compare
the received remote Recovery Information value with the previous Recovery
Information value stored for that peer entity:
\- If no previous value was stored, the Recovery Information value received
shall be stored for the peer.
\- If the value of a Recovery Information previously stored for a peer is
smaller than the Recovery Information value received in the Sx node related
message or Sx session related message, this indicates that the entity that
sent the Sx node related message or Sx session related message has restarted.
The received new Recovery Information value shall be stored by the receiving
entity, replacing the value previously stored for the peer. The Sx node
related message or Sx session related message shall be handled.
\- If the value of a Recovery Information previously stored for a peer is
larger than the Recovery Information value received in the Sx node related
message or Sx session related message, this indicates a possible race
condition (newer message arriving before the older one). The received Sx node
related message or Sx session related messages, and new Recovery Information
value shall be discarded and an error may be logged.
## 5.9 Solutions for SGW-C partial failure
### 5.9.1 Introduction
This section describes solutions for SGW-C partial failure.
### 5.9.2 Solution 1: storing FQ-CSID of control plane nodes in the user plane
function
##### 5.9.2.1 Solution Description
Figure 5.9.2.1-1: Delete affected PDN Connections and their corresponding Sx
session after the SGW-C partial failure
1) When the partial failure feature is deployed in the network, a FQ-CSID,
which is an opaque parameter local to the assigning node, may be assigned for
a unit handling a number of PDN connections and corresponding Sx sessions if
applicable, in a node which may fail and has no possibility to recover and
wish to notify the peers. An FQ-CSID is established in a node and stored in
peer nodes for a PDN connection and its associated Sx Session when applicable,
at the time of PDN connection establishment, or during a node relocation (e.g.
MME change, SGW relocation), and used later during partial failure handling in
messages. Each node that support the feature, including e.g. the MME, the
SGW-C, and the PGW-C, shall maintain the FQ-CSID provided by every other peer
node for a PDN connection and its associated Sx Session when applicable. The
FQ-CSIDs are later used to find the matching PDN connections when a FQ-CSID is
received from a node reporting a partial fault for that FQ-CSID. Steps 1-10
show an example that how FQ-CSIDs are exchanged during a PDN Connection
establishment procedure. To be able to handle the SGW-C partial failure, the
SGW-U shall store the SGW-C FQ-CSID as indicated in the step 2.
NOTE 1: It is useful that PGW-U stores the FQ-CSID allocated by the SGW-C when
the SGW-U does not support the partial failure, in this case, the hanging
SGW-U resource may get released by receiving GTP error indication from the
PGW-U since the corresponding Sx sessions affected by the SGW-C partial
failure are deleted.
2) When an SGW-C detects that it has undergone a partial failure, it shall
verify that one or more corresponding CSID(s) are present for the component
undergoing a partial fault. If there is no such CSID, then the following does
not apply. When one or more CSIDs are currently assigned, the SGW-C shall
perform the following. The SGW-C may perform implementation-specific
operations to clean up any residual state associated with the CSID(s).
3) Step a, the SGW-C sends a Sx message Sx Session Set Deletion Request
including a list of FQ-CSID(s) identifying the failed unit(s) to the affected
SGW-U, the SGW-U shall retrieve all the Sx sessions corresponding to each of
the FQ-CSID(s) present in the message. The SGW-U shall delete all the
retrieved Sx Sessions, free the associated internal resources.
> As a response, the SGW-U shall send an Sx Session Set Deletion Response
> message to the SGW-C.
4) Step b, the SGW-C sends also a GTPv2 message Delete PDN Connection Set
Request including a list of FQ-CSID(s) identifying the failed unit(s) to the
MME.
> When an MME receives a GTPv2 Delete PDN Connection Set Request message from
> an SGW, the MME shall retrieve all the PDN connections corresponding to each
> of the FQ-CSID(s) present in the message. The MME shall delete all the
> retrieved PDN connections and the associated resources. Other
> implementation-specific actions may be performed.
>
> As a response, the MME shall send a GTPv2 Delete PDN Connection Set Response
> message to the SGW-C.
5) Step c and c1, the SGW-C sends also a GTPv2 message Delete PDN Connection
Set Request including a list of FQ-CSID(s) identifying the failed unit(s) to
the PGW-C.
> When a PGW-C receives a GTPv2 Delete PDN Connection Set Request, the PGW-C
> shall retrieve all the PDN connections corresponding to each of the FQ-CSIDs
> present in the message. The PGW-C shall send an Sx Session Set Deletion
> Request message including a list of FQ-CSID(s) identifying the failed
> unit(s) to the affected PGW-U, the PGW-U shall retrieve all the Sx sessions
> corresponding to each of the FQ-CSID(s) present in the message. The PGW-U
> shall delete all the retrieved Sx Sessions, free the associated internal
> resources. As a response, the PGW-U shall send a Sx message Sx Session Set
> Deletion Response message.
>
> After receiving the Sx message Sx Session Set Deletion Response, the PGW-C
> deletes all the retrieved PDN connections and the associated resources.
>
> As a response, the PGW-C shall send a GTPv2 Delete PDN Connection Set
> Response message to the SGW-C.
##### 5.9.2.2 Evaluation and conclusion
**Pros:**
\- Reduce massive signalling to notify a partial failure to the peers for each
of affected PDN Connections and its corresponding Sx sessions if the SGW-C has
stored the PDN connection / Sx session context in a persistent memory which
can survive from the partial failure (i.e. the SGW-C can send Sx session
deletion request per Sx session for all Sx sessions affected by the partial
failure.
\- Can Efficiently delete of the affected user plane resource if there is a
partial failure on the other node, especially for the partial failure on the
its controlling CP function, i.e. on the SGW-C.
**Cons:**
\- The SGW-U is required at least to store the FQ-CSID allocated by the SGW-C
to handle the possible partial failure on the control plane node.
\- If the PGW-U deletes all Sx sessions affected by the SGW-C partial failure
and does not send the usage report for each affected Sx session to the PGW-C,
then the usage report for affected Sx sessions will not be available in the
PGW-C.
## 5.10 Solutions for PGW-C partial failure
### 5.10.1 Introduction
This section describes solutions for PGW-C partial failure.
### 5.10.2 Solution 1: storing FQ-CSID of control plane nodes in the user
plane function
##### 5.10.2.1 Solution Description
Figure 5.10.2.1-1: Delete affected PDN Connections and their corresponding Sx
session after the PGW-C partial failure
1) When the partial failure feature is deployed in the network, a FQ-CSID,
which is an opaque parameter local to the assigning node, may be assigned for
a unit handling a number of PDN connections and corresponding Sx sessions if
applicable, in a node which may fail and has no possibility to recover and
wish to notify the peers. An FQ-CSID is established in a node and stored in
peer nodes for a PDN connection and its associated Sx Session when applicable,
at the time of PDN connection establishment, or during a node relocation (e.g.
MME change, SGW relocation), and used later during partial failure handling in
messages. Each node that support the feature, including e.g. the MME, the
SGW-C and the PGW-C, shall maintain the FQ-CSID provided by every other peer
node for a PDN connection and its associated Sx Session when applicable. The
FQ-CSIDs are later used to find the matching PDN connections when a FQ-CSID is
received from a node reporting a partial fault for that FQ-CSID. Steps 1-10
show an example that how FQ-CSIDs are exchanged during a PDN Connection
establishment procedure. To be able to handle the PGW-C partial failure, the
PGW-U shall store the PGW-C FQ-CSID as indicated in the step 5.
NOTE 1: It is useful that SGW-U stores the FQ-CSID allocated by the PGW-C when
the PGW-U does not support the partial failure. In such case, the hanging
PGW-U resource may get released by receiving GTP error indication from the
SGW-U since the corresponding Sx sessions affected by the PGW-C partial
failure are deleted.
2) When an PGW-C detects that it has undergone a partial failure, it shall
verify that one or more corresponding CSID(s) are present for the component
undergoing a partial fault. If there is no such CSID, then the following does
not apply. When one or more CSIDs are currently assigned, the PGW-C shall
perform the following. The PGW-C may perform implementation-specific
operations to clean up any residual state associated with the CSID(s).
3) Step a, the PGW-C sends a Sx message Sx Session Set Deletion Request
including a list of FQ-CSID(s) identifying the failed unit(s) to the affected
PGW-U, the PGW-U shall retrieve all the Sx sessions corresponding to each of
the FQ-CSID(s) present in the message. The PGW-U shall delete all the
retrieved Sx Sessions, free the associated internal resources.
> As a response, the PGW-U shall send an Sx Session Set Deletion Response
> message to the PGW-C.
4) Step b and b1, the PGW-C sends also a GTPv2 message Delete PDN Connection
Set Request including a list of FQ-CSID(s) identifying the failed unit(s) to
the SGW-C.
> When a SGW-C receives a GTPv2 Delete PDN Connection Set Request, the SGW-C
> shall retrieve all the PDN connections corresponding to each of the FQ-CSIDs
> present in the message. The SGW-C shall send an Sx Session Set Deletion
> Request message including a list of FQ-CSID(s) identifying the failed
> unit(s) to the affected SGW-U, the SGW-U shall retrieve all the Sx sessions
> corresponding to each of the FQ-CSID(s) present in the message. The SGW-U
> shall delete all the retrieved Sx Sessions, free the associated internal
> resources. As a response, the SGW-U shall send a Sx message Sx Session Set
> Deletion Response message.
>
> After receiving the Sx message Sx Session Set Deletion Response, the SGW-C
> deletes all the retrieved PDN connections and the associated resources.
>
> As a response, the SGW-C shall send a GTPv2 Delete PDN Connection Set
> Response message to the PGW-C.
5) Step c, the SGW-C sends also a GTPv2 message Delete PDN Connection Set
Request including a list of FQ-CSID(s) identifying the failed unit(s) to the
MME.
> When an MME receives a GTPv2 Delete PDN Connection Set Request message from
> an SGW, the MME shall retrieve all the PDN connections corresponding to each
> of the FQ-CSID(s) present in the message. The MME shall delete all the
> retrieved PDN connections and the associated resources. Other
> implementation-specific actions may be performed.
>
> As a response, the MME shall send a GTPv2 Delete PDN Connection Set Response
> message to the SGW-C.
##### 5.10.2.2 Evaluation and conclusion
**Pros:**
\- Reduce massive signalling to notify a partial failure to the peers for each
of affected PDN Connections and its corresponding Sx sessions if the PGW-C has
stored the PDN connection / Sx session context in a persistent memory which
can survive from the partial failure (i.e. the PGW-C can send Sx session
deletion request per Sx session for all Sx sessions affected by the partial
failure.
\- Can Efficiently delete of the affected user plane resource if there is a
partial failure on the other node, especially for the partial failure on the
its controlling CP function, i.e. on the PGW-C.
**Cons:**
\- The PGW-U is required at least to store the FQ-CSID allocated by the PGW-C
to handle the possible partial failure on the control plane node. Optionally
The PGW-U may store the FQ-CSID allocated by the MME and SGW-C if the partial
failure is supported in other nodes.
\- If the SGW-U deletes all Sx sessions affected by the PGW-C partial failure
and does not send the usage report for each affected Sx session to the SGW-C,
then the usage report for affected Sx sessions will not be available in the
SGW-C.
## 5.11 Solutions for SGW-U partial failure
### 5.11.1 Introduction
This section describes solutions for SGW-U partial failure.
### 5.11.2 Solution 1: storing FQ-CSID of user plane nodes in the control
plane nodes
#### 5.11.2.1 Solution Description
Figure 5.11.2.1-1: Re-establish affected Sx sessions after the SGW-U partial
failure
1) When the partial failure feature is deployed in the network, a FQ-CSID,
which is an opaque parameter local to the assigning node, may be assigned for
a unit handling a number of PDN connections and corresponding Sx sessions if
applicable, in a node which may fail and has no possibility to recover and
wish to notify the peers. An FQ-CSID is established in a node and stored in
peer nodes for a PDN connection and its associated Sx Session when applicable,
at the time of PDN connection establishment, or during a node relocation (e.g.
MME change, SGW relocation), and used later during partial failure handling in
messages. Each node that support the feature shall maintain the FQ-CSID
provided by every other peer node for a PDN connection and its associated Sx
Session when applicable. The FQ-CSIDs are later used to find the matching PDN
connections when a FQ-CSID is received from a node reporting a partial fault
for that FQ-CSID. Steps 1-10 show an example that how FQ-CSIDs are exchanged
during a PDN Connection establishment procedure. To be able to handle the
SGW-U partial failure, the SGW-C shall store the SGW-U FQ-CSID as indicated in
the step 3.
The FQ-CSID allocated by a SGW-U or a PGW-U is not populated to the nodes
other than its corresponding Control Plane functions i.e. SGW-C and PGW-C.
Since it is deemed not useful if the SGW-C/PGW-C supports to restore the
affected Sx session without notifying other control plane nodes.
2) When an SGW-U detects that it has undergone a partial failure, it shall
verify that one or more corresponding CSID(s) are present for the component
undergoing a partial fault. If there is no such CSID, then the following does
not apply. When one or more CSIDs are currently assigned, the SGW-U shall
perform the following. The SGW-U may perform implementation-specific
operations to clean up any residual state associated with the CSID(s).
3) Step a, the SGW-U sends a Sx message Sx Session Set Deletion Request
including a list of FQ-CSID(s) identifying the failed unit(s) to the affected
SGW-C, the SGW-C shall retrieve all the Sx sessions corresponding to each of
the FQ-CSID(s) present in the message and mark all the retrieved Sx Sessions
to be restored.
As a response, the SGW-C shall send an Sx Session Set Deletion Response
message to the SGW-U.
4) Step b, the SGW-C sends a Sx Session Establishment request message to re-
establish all marked Sx sessions per Sx session.
As a response, the SGW-U shall send a Sx Session Establishment Response
message to the SGW-C for each Sx Session.
Before the affected Sx session is re-established, the received user plane
packets will be dropped unless default PDR(s) for handling of unmatched user
plane packets is assigned. If the affected Sx session cannot be re-established
successfully, the corresponding PDN connection may be re-established.
#### 5.11.2.2 Evaluation and conclusion
**Pros:**
\- Reduce possibility to send massive user plane data to the SGW-C as many Sx
sessions are affected by the partial failure of the SGW-U if default PDRs for
handling of unmatched user plane packets are assigned.
**Cons:**
\- The SGW-C is required to store the FQ-CSID allocated by the SGW-U to handle
the possible partial failure on the user plane node.
## 5.12 Solutions for PGW-U partial failure
### 5.12.1 Introduction
This section describes solutions for PGW-U partial failure.
### 5.12.2 Solution 1: storing FQ-CSID of user plane nodes in the control
plane nodes
#### 5.12.2.1 Solution Description
Figure 5.12.2.1-1: Re-establish affected Sx sessions after the PGW-U partial
failure
1) When the partial failure feature is deployed in the network, a FQ-CSID,
which is an opaque parameter local to the assigning node, may be assigned for
a unit handling a number of PDN connections and corresponding Sx sessions if
applicable, in a node which may fail and has no possibility to recover and
wish to notify the peers. An FQ-CSID is established in a node and stored in
peer nodes for a PDN connection and its associated Sx Session when applicable,
at the time of PDN connection establishment, or during a node relocation (e.g.
MME change, SGW relocation), and used later during partial failure handling in
messages. Each node that support the feature shall maintain the FQ-CSID
provided by every other peer node for a PDN connection and its associated Sx
Session when applicable. The FQ-CSIDs are later used to find the matching PDN
connections when a FQ-CSID is received from a node reporting a partial fault
for that FQ-CSID. Steps 1-10 show an example that how FQ-CSIDs are exchanged
during a PDN Connection establishment procedure. To be able to handle the
PGW-U partial failure, the PGW-C shall store the PGW-U FQ-CSID as indicated in
the step 6.
The FQ-CSID allocated by a SGW-U or a PGW-U is not populated to the nodes
other than its corresponding Control Plane functions i.e. SGW-C and PGW-C.
Since it is deemed not useful if the SGW-C/PGW-C supports to restore the
affected Sx session without notifying other control plane nodes.
2) When a PGW-U detects that it has undergone a partial failure, it shall
verify that one or more corresponding CSID(s) are present for the component
undergoing a partial fault. If there is no such CSID, then the following does
not apply. When one or more CSIDs are currently assigned, the PGW-U shall
perform the following. The PGW-U may perform implementation-specific
operations to clean up any residual state associated with the CSID(s).
3) Step a, the PGW-U sends a Sx message Sx Session Set Deletion Request
including a list of FQ-CSID(s) identifying the failed unit(s) to the affected
PGW-C, the PGW-C shall retrieve all the Sx sessions corresponding to each of
the FQ-CSID(s) present in the message and mark all these Sx sessions to be
restored.
As a response, the PGW-C shall send an Sx Session Set Deletion Response
message to the PGW-U.
4) Step b, the PGW-C sends a Sx Session Establishment request message to re-
establish all marked Sx sessions per Sx session to the PGW-U.
As a response, the PGW-U shall send a Sx Session Establishment Response
message to the PGW-C for each Sx Session.
Before the affected Sx session is re-established, the received user plane
packets will be dropped unless default PDR(s) for handling of unmatched user
plane packets is assigned. If the affected Sx session cannot be re-established
successfully, the corresponding PDN connection may be re-established.
#### 5.12.2.2 Evaluation and conclusion
**Pros:**
\- Reduce possibility to send massive user plane data to the PGW-C as many Sx
sessions are affected by the partial failure of the PGW-U if default PDR(s)
for handling of unmatched user plane packets are assigned.
**Cons:**
\- The PGW-C is required to store the FQ-CSID allocated by the PGW-U to handle
the possible partial failure on the user plane node.
## 5.13 Evaluation and conclusion
### 5.13.1 Evaluation and conclusion on SGW-C and SGW-U failure
SGW-C failure with restart:
\- The solution described in subclause 5.2.2.1 shall be followed.
SGW-C failure without restart:
\- SGW-C failure without restart shall be handled as specified in TS 23.007
for the case SGW without restart also the optional feature described in clause
27 of TS 23.007 apply for MME and PGW-C if they support the feature.\ When the
SGW-U detects that the SGW-C does not reply to any message, after an operator
specific time the SGW-U shall interpret this as path failure and delete all
session contexts affected by the SGW-C failure. When the SGW-U receives a
GTP-U PDU from other nodes (such as eNB, PGW-U) for which no user plane
context exists, it shall discard the GTP-U PDU (see solution described in
5.2.3.1).
SGW-U Failure with Restart:
\- The solution described in clause 5.3.2.1 \"SGW-C Recreating the User Plane
Sessions in Restarted SGW-U on Reactive Basis\" shall be followed.
SGW-U Failure without Restart:
\- The solution described in clause 5.3.3.1 \"SGW-C Recreating the User Plane
Sessions in a New SGW-U, without change of GTP-U endpoint\" shall be realised
as this solution does not require any changes to legacy protocols on S5 and
S11.
### 5.13.2 Evaluation and conclusion on PGW-C and PGW-U failure
PGW-C Failure with Restart:
\- The solution described in clause 5.4.2.1 \"Clear resources\", shall be
realised.
PGW-C Failure without Restart:
\- The solution described in clause 5.4.3.1 \"Clear resources\", shall be
realised.
PGW-U Failure with Restart:
\- The solution described in clause 5.5.2.1 \"PGW-C Recreating the User Plane
Sessions in Restarted PGW-U on Reactive Basis\" limited to the alternative
approach on proactive basis shall be followed i.e. the solution will not
support the sending of packets to the PGW-C to trigger the establishment of
the session.
PGW-U Failure without Restart
\- The solution described in clause 5.5.3.1 \"PGW-C Recreating the User Plane
Sessions in a New PGW-U, without change of GTP-U endpoint\" shall be realised
as this solution does not require any changes to legacy protocols on S5 and
S11.
### 5.13.3 Evaluation and conclusion on TDF-C and TDF-U failure
The clauses 5.6.2.1, 5.6.3.1, 5.7.2.1 and 5.7.3.1 analyses and provide
solution for TDF failure cases. Up to now TDF failure scenarios are not
documented in 3GPP specification. It is concluded not to continue the work and
not to provide a solution.
### 5.13.4 Evaluation and conclusion on detection of a PFCP entity restart
Detection of a PFCP entity restart:
\- The solution described in clause 5.8.2.1 \"Based on the timestamp of the
restart\" is recommended to be realised.
### 5.13.5 Evaluation and conclusion Partial failure
SGW-C partial failure:
\- The solution described in clause 5.9.2.1 \"storing FQ-CSID of control plane
nodes in the user plane function\" is recommended to be realised, if partial
failure is supported.
PGW-C partial failure
\- The solution described in clause 5.10.2.1 \"storing FQ-CSID of control
plane nodes in the user plane function\" is recommended to be realised, if
partial failure is supported.
SGW-U partial failure
\- The solution described in clause 5.11.2.1 \"storing FQ-CSID of control
plane nodes in the user plane function\" is recommended to be realised, if
partial failure is supported.
PGW-U partial failure:
\- The solution described in clause 5.12.2.1 \"storing FQ-CSID of control
plane nodes in the user plane function\" is recommended to be realised, if
partial failure is supported.
# 6 Load control
## 6.1 Introduction
The following subclauses analyse load in the UP and the information needed to
be sent to the CP so that CP nodes can provide load information to the
selecting node on the control plane.
**_Load control enables a UP entity (SGW-U, PGW-U or TDF-U) to send its load
information to its peer CP entities to adaptively balance the Sx session load
across the UP entities. The load information reflects the operating status of
the resources of the UP entity._**
Load control allows for better balancing of the session load, so as to attempt
to prevent overload in the first place (preventive action).
Load control does not trigger overload mitigation actions even if the UP
entity reports a high load.
## 6.2 Solution 1 -- UP function reporting its load to CP function at node
level (as per GTP-C load control principles)
This solution proposes to apply over Sx the same principles as defined for
GTP-C load control at node level:
a) Load Control is an optional feature;
b) a UP entity may signal its Load Control Information to reflect the
operating status of its resources, allowing the receiving CP entity to use
this information to augment the UP selection procedures;
c) the calculation of the Load Control Information is implementation dependent
and its calculation and transfer shall not add significant additional load to
the node itself and to its corresponding peer nodes;
d) the Load Control Information shall be piggybacked in Sx request or response
messages such that the exchange of Load Control Information does not trigger
extra signalling;
NOTE: The inclusion of Load Control Information in existing messages means
that the frequency of transmission of load control information increases as
the session load increases, allowing for faster feedback and thus better
regulation of the load.
e) A Load Control Information (LCI) IE is specified in Sx session related
messages sent by the UP function, with a Load Control Sequence Number and Load
Metric, as defined for GTP-C load control at node level.
## 6.3 Evaluation and conclusion
The solution 1 described in subclause 6.2 allows for better balancing of the
session load across the UP functions, so as to attempt to prevent overload in
the first place (preventive action). **_The solution reuses the same
principles as already adopted for several GTP-C interfaces._**
**_It is agreed to specify this solution over the Sxa, Sxb and Sxc reference
points._**
# 7 Overload control
## 7.1 Introduction
The following subclauses analyse overload in the UP and the information needed
to be sent to the CP so that CP nodes can perform overload status calculation
and signal overload information on the control plane.
A UP entity can be controlled by one or more CP entities. In normal
conditions, requests sent by a CP entity can be processed by the receiving UP
entity which can send back a message indicating the result of the request
(success/failure).
Overload situations in a UP entity occur when the number of incoming requests
exceeds the maximum request throughput supported by the receiving UP entity,
e.g. when the internal available resources of the UP entity, such as
processing power or memory, are not sufficient to serve the number of incoming
requests. As a consequence of the overload situation, the receiving UP entity
cannot successfully process the exceeding proportion of requests. These
requests can be either simply dropped or extremely delayed in the processing.
At best, the UP entity may have enough internal resources to send back to the
request initiator a message indicating that the requests cannot be
successfully processed. Whatever the behaviour of the overloaded UP entities,
the rate of successfully processed requests and consequently the overall
performances of the network decrease.
When a UP entity experiences overload (or severe overload) the number of
unacknowledged Sx messages compounds exponentially and can lead to a node
congestion or even collapse. An overload or failure of a node can lead to an
increase of the load on the other nodes in the network and, in the worst case,
turn into a complete network issue via a snowball effect.Reasons for these
temporary overload cases can be many and various in an operational network,
such as insufficient internal resource capacity of a UP entity faced with a
sudden burst of requests, e.g. after network failure/restart procedures
affecting a large number of users, deficiency of a UP entity component leading
to a drastic reduction of the overall performances of the UP entity.
**_Overload control enables a UP entity becoming or being overloaded to
gracefully reduce its incoming signalling load by instructing its CP peers to
reduce sending traffic according to its available signalling capacity to
successfully process the traffic. A UP entity is in overload when it operates
over its signalling capacity which results in diminished performance
(including impacts to handling of incoming and outgoing traffic)._**
## 7.2 Solution 1 -- UP function reporting its overload to CP function at node
level (as per GTP-C overload control principles)
This solution proposes to apply over Sx the same principles as defined for
GTP-C overload control at node level:
a) Overload control is an optional feature;
b) a UP entity may signal its overload to its controlling CP entities by
including Overload Control Information in Sx signalling which provides
guidance to the receiving CP entity to decide actions which lead to signalling
traffic mitigation towards the sender of the information;
c) the overload control feature should continue to allow for preferential
treatment of priority users (eMPS) and emergency services;
d) the Overload Control Information is piggybacked in Sx request or response
messages such that the exchange of the Overload Control Information does not
trigger extra signalling;
NOTE: The inclusion of Overload Control Information in existing messages means
that the frequency increases as the signalling load increases, thus allowing
faster feedback and better regulation.
e) the computation and transfer of the Overload Control Information shall not
add significant additional load to the UP entity itself and to its
corresponding CP entities. The calculation of Overload Control Information
should not severely impact the resource utilization of the UP entity,
especially considering the overload situation;
f) An Overload Control Information (LCI) IE is specified in Sx session related
messages sent by the UP function, with an Overload Control Sequence Number,
Period of Validity and Overload Metric, as defined for GTP-C overload control
at node level.
## 7.3 Evaluation and conclusion
The solution 1 described in subclause 7.2 enables a **_UP entity becoming or
being overloaded to gracefully reduce its incoming signalling load by
instructing its CP peers to reduce sending traffic according to its available
signalling capacity to successfully process the traffic. The solution reuses
the same principles as already adopted for several GTP-C interfaces._**
**_It is agreed to specify this solution over the Sxa, Sxb and Sxc reference
points._**
# 8 Path management and path failure handling
## 8.1 Introduction
The following subclauses analyse path management and path failure handling for
the Sx interfaces.
## 8.2 Sx interface between SGW-C and SGW-U
### 8.2.1 Solution 1 Echo Request/Echo Response
The path between a SGW-C and SGW-U can be down due to problems with the link
between the two nodes but as well if a peer node is down or restarting. The
case peer node is down or restarting is analysed in clause 5.
The UDP transport does not support a mechanism to check if the peer node is
still reachable. In GTP echo request and echo response is introduced for this
purpose. It is proposed to adopt this mechanism to PFCP.
In 3GPP TS 23.007 [6] clause 20 it is described how Echo Request/Echo Response
is used between EPC nodes, it is proposed to adopt the same mechanism between
SGW-C and SGW-U nodes on Sx interface. Echo Request message should not be sent
before an implementation dependent period of time. A peer\'s IP address
specific counter shall be reset each time an Echo Response message is received
from that peer\'s IP address and incremented when the configured response
timer expires for an Echo Request message sent to that peer\'s IP address. For
the originator of the Echo request message there needs to be an criteria when
the originator should consider the path as down, to stop the continuous trying
to reach the peer by sending echo request and to trigger a proper recovery
procedure. The path shall be considered to be down if the counter exceeds a
configured number of times the response timer expires.
NOTE: In this solution description message names from GTP are reused, it is up
to the normative work to decide on message names to be used for PFCP.
**SGW-C functionality**
If the path to the SGW-U is down, the SGW-C should handle this as SGW-U
Failure without Restart see clause 5.3.3.
**SGW-U functionality**
If the path to the SGW-C is down, the SGW-U should handle this as SGW-C
Failure without Restart see clause 5.2.3.
## 8.3 Sx interface between PGW-C and PGW-U
### 8.3.1 Solution 1 Echo Request/Echo Response
The path between a PGW-C and PGW-U can be down due to problems with the link
between the two nodes but as well if a peer node is down or restarting. The
case peer node is down or restarting is analysed in clause 5.
The UDP transport does not support a mechanism to check if the peer node is
still reachable. In GTP echo request and echo response is introduced for this
purpose. It is proposed to adopt this mechanism to PFCP.
In 3GPP TS 23.007 [6] clause 20 it is described how Echo Request/Echo Response
is used between EPC nodes, it is proposed to adopted the same mechanism
between PGW-C and PGW-U nodes on Sx interface. Echo Request message should not
be send before an implementation dependent period of time. A peer\'s IP
address specific counter shall be reset each time an Echo Response message is
received from that peer\'s IP address and incremented when the configured
response timer expires for an Echo Request message sent to that peer\'s IP
address. For the originator of the Echo request message there needs to be a
criteria when the originator should consider the path as down, to stop the
continuous trying to reach the peer by sending echo request and to trigger a
proper recovery procedure. The path shall be considered to be down if the
counter exceeds a configured number of times the response timer expires.
**PGW-C functionality**
If the path to the PGW-U is down, The PGW-C should handle this as PGW-U
Failure without Restart see clause 5.5.3.
**PGW-U functionality**
If the path to the PGW-C is down, the PGW-U should handle this as PGW-C
Failure without Restart see clause 5.4.3.
## 8.4 Sx interface between TDF-C and TDF-U
### 8.4.1 Solution 1
The path between a TDF-C and TDF-U can be down due to problems with the link
between the two nodes but as well if a peer node is down or restarting. The
case peer node is down or restarting is analyzed in clause 5.
The UDP transport does not support a mechanism to check if the peer node is
still reachable. In GTP echo request and echo response is introduced for this
purpose. It is proposed to adopt this mechanism to PFCP.
In 3GPP TS 23.007 [6] clause 20 it is described how Echo Request/Echo Response
is used between EPC nodes, it is proposed to adopt the same mechanism between
TDF-C and TDF-U nodes on Sx interface. Echo Request message should not be send
before an implementation dependent period of time. A peer\'s IP address
specific counter shall be reset each time an Echo Response message is received
from that peer\'s IP address and incremented when the configured response
timer expires for an Echo Request message sent to that peer\'s IP address. For
the originator of the Echo request message there needs to be a criteria when
the originator should consider the path as down, to stop the continuous trying
to reach the peer by sending echo request and to trigger a proper recovery
procedure. The path shall be considered to be down if the counter exceeds a
configured number of times the response timer expires.
**TDF-C functionality**
If the path to the TDF-U is down, The TDF-C should handle this as TDF-U
Failure without Restart see clause 5.6.3.
**TDF-U functionality**
If the path to the TDF-C is down, the TDF-U should handle this as TDF-C
Failure without Restart see clause 5.7.3.
## 8.5 Evaluation and conclusion
The mechanism introduced for GTP on UDP transport to use echo request/response
message are also applicable solutions for the interface between CP and UP
nodes. Both nodes can check the availability of the peer node by sending a
message equivalent to an Echo request message and can detect by reception of
on equivalent message to an Echo response message that the peer is still
alive.
It is proposed to introduce equivalent Echo request/Echo response for the Sxa
and Sxb interfaces to check the path between a UP and a CP node.
For the Sxc equivalent Echo request/Echo response can be used but no stage 2
restoration procedure will be specified.
# 9 Error handling on the user plane
## 9.1 Introduction
The following sub clauses analyse error handling on the user plane.
## 9.2 Error handling on missing sessions on the user plane
Editor\'s Note: Analysis and provide solutions for Error handling on missing
sessions on the user plane.
### 9.2.1 Solution 1 UP function reports the error to the CP function and
deletes the resources for the impacted rules.
#### 9.2.1.1 SGW-U and SGW-C
If the SGW-U receives a GTP error indication, the SGW-U shall forward the
error indication to the SGW-C. The SGW-C should handle the error indication as
follows:
\- For an \'Active\' mode UE having a user plane connection with an RNC, i.e.
SGW-C has F-TEIDs assigned by RNC for user plane for the UE, when the SGW-C
receives an error indication for a Bearer Context that has the DTI flag set
(i.e. from an RNC), the SGW-C should not delete the associated Bearer Context
but delete all the RNC GTP-U tunnel TEIDs for this MS and sends a Downlink
Data Notification message to the SGSN (the complete behaviour is specified in
clause 22 of 3GPP TS 23.007 [6]). Then the SGW-C notifies the SGW-U to buffer
downlink packets received for this MS. If the buffering function is on the
SGW-C, the SGW-C notifies the SGW-U forward the packets to the SGW-C
\- For an \'Active\' mode UE having a user plane connection with an eNB, i.e.
SGW-C has F-TEIDs assigned by eNB for user plane for the UE, when the SGW-C
receives an error indication for a Bearer Context originated by a eNB, the
SGW-C should not delete the associated Bearer Context but delete all the eNB
GTP-U tunnel TEIDs for this UE and sends a Downlink Data Notification message
to the MME (the complete behaviour is specified in clause 22). Then the SGW-C
notifies the SGW-U to buffer downlink packets received for this UE. If the
buffering function is on the SGW-C, the SGW-C notifies the SGW-U forward the
packets to the SGW-C.
\- For a UE having an S11 user plane connection with an MME, i.e. SGW-U has
S11-U F-TEIDs assigned by MME for user plane for the UE, when the SGW-C
receives an error indication for a Bearer Context originated by an MME, the
SGW-C may:
\- delete all the Bearer contexts associated with the PDN connection
(identified by the default bearer) and notify the Operation and Maintenance
network element, or as an alternative,
\- delete the MME GTP-U tunnel TEID for this UE and send a Downlink Data
Notification message to the MME to re-establish the user plane path without
deleting the PDN connection (the complete behaviour is specified in clause 22
of 3GPP TS 23.007 [6]). Then the SGW-C notifies the SGW-U to buffer downlink
packets received for this UE. If the buffering function is on the SGW-C, the
SGW-C notifies the SGW-U forward the packets to the SGW-C.
\- If the SGW-C receives a GTP error indication originated by S4-SGSN for a
Bearer Context other than the default bearer when S4-U is used, the SGW-C may
delete its Bearer context and may notify the Operation and Maintenance network
element, or as an alternative, the SGW-C may send Downlink Data Notification
message to the S4-SGSN to re-establish the user plane path without deleting
the bearer context.
\- If the SGW-C receives a GTP error indication originated by S4-SGSN for the
default bearer when S4-U is used, the SGW may delete all the Bearer contexts
associated with the PDN connection (identified by the default bearer) and may
notify the Operation and Maintenance network element, or as an alternative,
the SGW-C may send Downlink Data Notification message to the S4-SGSN to re-
establish the user plane path without deleting the PDN connection.
\- If the SGW-C receives a GTP error indication from a SGW-U originated by a
PGW-U for the bearer other than the default bearer, the SGW-C shall delete its
Bearer context and may notify the Operation and Maintenance network element.
\- If the SGW-C receives a GTP error indication from a SGW-U originated by a
PGW-U for the default bearer, the SGW-C shall delete all the Bearer contexts
associated with the PDN connection (identified by the default bearer) and may
notify the Operation and Maintenance network element. The SGW-C may send the
Delete Bearer Request for the default bearer to the MME/S4 SGSN to delete the
associated PDN connection.
#### 9.2.1.2 PGW-U and PGW-C
If the PGW-U receives a GTP error indication from a SGW-U, the PGW-U forward
the error indication to the PGW-C. The PGW-C shall handle the GTP error
indication as follows:
\- If the PGW-C receives a GTP error indication from a SGW-U for the bearer
other than the default bearer, the PGW-C shall delete its Bearer context with
a delete bearer message to SGW-C and may notify the Operation and Maintenance
network element.
\- If the PGW-C receives a GTP error indication from a SGW-U for the default
bearer, the PGW-C shall delete all the Bearer contexts associated with the PDN
connection (identified by the default bearer) with a delete session message to
SGW-C and may notify the Operation and Maintenance network element.
#### 9.2.1.2 Evaluation
## 9.3 User plane path failure detection and handling
### 9.3.1 Introduction
Subclause 20.3 of 3GPP TS 23.007 [6] specifies the procedure for detecting and
handling a user plane path failure between two GTP-U peers, as follows:
\"GTP-U entities shall support detection of path failure by using Echo Request
/ Echo Response messages in the following way. A path counter shall be reset
each time an Echo Response is received on the path and incremented when the
T3-RESPONSE timer expires for any Echo Request message sent on the path. The
path shall be considered to be down if the counter exceeds N3-REQUESTS.
Upon detecting a path failure, the network node should notify the failure via
the Operation and Maintenance system and may either
\- delete the bearer contexts associated with the path in failure; or
\- maintain the bearer contexts associated with the path in failure during an
operator configurable maximum path failure duration. The network node shall
delete the maintained resources if the path is still down when this duration
expires.
NOTE 1: During transient path failures (e.g. path failures not exceeding few
minutes at most), maintaining the bearer contexts associated with the peer\'s
IP address enables the delivery of end user services (when the path is re-
established again) and also avoids unnecessary signalling in the network for
restoring those bearers.
NOTE 2: It is not intended to maintain bearer contexts during long path
failures (e.g. exceeding few minutes at most) as this would imply undesirable
effects like undue charging.\" This subclause analyses how to support these
requirements with Control and User Plane separation of EPC nodes.
Note that with non-split SGW and PGW, path management procedures are typically
run on the GTP-C interfaces, for GTP-U interfaces other than those towards the
RAN. With CUPS, the CP function and the UP function may be located in
completely different locations and networks environments, which can further
justify the need to run user plane path management procedure.
#### 9.3.1.1 Solution 1 -- Reporting the User Plane path failure to the CP
function
##### 9.3.1.1.1 Description
For each GTP-U bearer, the UP function is provisioned with a PDR (with the
Local F-TEIDu) and a FAR (with the remote F-TEIDu).
The UP function may initiate the sending of Echo Request towards GTP-U peers
provisioned in FARs, based on local configuration in the UP function.
The UP function shall respond to incoming Echo Request by returning an Echo
Response message (without the need for specific CP function\'s instructions to
do so).
Upon detecting a GTP-u path failure, the UP function should notify the CP
function of the user plane path failure and provide the CP function with the
remote IP address which is not responding, by:
\- sending an Sx node related message \"Sx Node Report Request\".
Upon being notified of a user plane path failure, the CP function may delete
the affected bearers by modifying or releasing the affected Sx sessions in the
UP function. The CP function needs to take care to smooth the signalling load
towards its peers if a large number of Sx sessions are affected by the user
plane failure.
The CP function or the UP function should report the failure via the Operation
and Maintenance system.
##### 9.3.1.1.2 Evaluation
**Pros:**
\- provides support for the user plane path failure detection and handling
specified in 3GPP TS 23.007 [6];
\- bearer contexts are not maintained during long path failures (e.g.
exceeding few minutes at most), which avoids \"undesirable effects like undue
charging\".
\- the CP function is made aware that packets cannot be delivered to a remote
GTP-U endpoint (as intended by the provisioned FAR).
**Cons:**
\- may cause signalling storms over Sxa or Sxb if the SGW-C or PGW-C modifies
or releases the affected Sx sessions and the user plane path failure affects a
large number of Sx sessions.
## 9.4 Evaluation and conclusion
### 9.4.1 Evaluation and conclusion on Error handling on missing sessions on
the user plane
The solution described in subclause 9.2.1 shall be followed.
### 9.4.2 Evaluation and conclusion on User plane path failure detection and
handling
The solution described in subclause 9.3.1.1 shall be followed.
#