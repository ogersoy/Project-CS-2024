# Foreword
This Technical Report has been produced by the 3^rd^ Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# Introduction
Mobile telephony devices and voice services continue to develop and evolve and
their associated minimum performance requirements and test methodologies also
need to stay relevant and representative of quality demands.
While many advances were made in Rel. 11 to the acoustic requirements and test
specifications in TS 26.131 and TS 26.132 many items therein were left marked
"for further study" and require a final decision by SA4. Additionally, there
are new acoustic requirements and emerging tests we may wish to consider in a
future release, but require further study before incorporation to our
specifications.
This technical report will, first and foremost, address the remaining items
presently designated as "for further study" in TS 26.131 and TS 26.132.
This report will also examine opportunities for new acoustic tests and
requirements that help us to better characterise the UE acoustic experience,
opportunities to replace existing test methods with others that are more
accurate or more efficient and make specific recommendations for their
inclusion in existing or new specifications.
# 1 Scope
The scope of this study is to investigate, first and foremost, the existing
items presently designated as "for further study" in TS 26.131 and TS 26.132.
The investigation will additionally identify, examine and evaluate
opportunities for new acoustic tests and requirements that better help
characterise the UE acoustic experience, opportunities to replace existing
test methods with others that are more accurate or more efficient and to make
specific recommendations for their incorporation inclusion in existing or new
specifications.
While many advances were made in Rel 11 to the acoustic requirements and test
specifications in TS 26.131 and TS 26.132 many items therein were left marked
"for further study" and require a final disposition by SA4 including
  * NB & WB Stability loss, Headset UE (TS 26.131 Sections 5.6 & 6.6)
  * NB & WB Delay, Wireless Headset (TS 26.131 Section 5.12.2.2 & 6.11.2.2)
  * NB & WB Echo control ("double-talk") characteristics (TS 26.131 Sections 5.13 &6.12, TS 26.132 Section 8.11)
    * Handset, Headset, Handheld hands-free, Desktop and vehicle mounted hands-free are all marked FFS
  * NB& WB Free-field measurements for vehicle-mounted hands-free (TS 26.132 Section 7.2.3 & 8.2.3)
  * NB & WB Idle Channel Noise, Sending/Receiving of test signal (TS 26.132 Section 7.3.1, 7.3.2, 8.3.1 & 8.3.2 )
Additionally, there are new acoustic requirements and emerging tests that may
be considered in a future release, but require further study before
incorporation to our specifications. It has been anticipated that topics in
this area would include, but would not be limited to, an evaluation of
  * Time-variant user behaviour
  * Additional UE usage environments
  * New or refined test methods for existing requirements
  * Acceptance of updates (if any) to existing ETSI and ITU-T dependencies
Coordination with other SDOs, such as ITU-T SG 12 and ETSI STQ among others,
is also reported.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TR 41.001: \"GSM Release specifications\".
[3] 3GPP TR 21 912 (V3.1.0): \"Example 2, using fixed text\".
...
[x] \ \[ ([up to and
including]{yyyy[-mm]\|V\}[onwards])]: \"\\".
# 3 Definitions, symbols and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
TR 21.905 [1] and the following apply.\ A term defined in the present document
takes precedence over the definition of the same term, if any, in TR 21.905
[1].
**example:** text used to clarify abstract rules by applying them literally.
## 3.2 Symbols
For the purposes of the present document, the following symbols apply:
\ \
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in TR 21.905
[1] and the following apply.\ An abbreviation defined in the present document
takes precedence over the definition of the same abbreviation, if any, in TR
21.905 [1].
\ \
# 4 Rel.11 "For Further Study" Items
## 4.1 [Stability loss, Headset UE]
[...]
## 4.2 [UE Delay, NB & WB Wireless Headset]
[...]
### 4.3 [NB & WB Echo control ("double-talk") characteristics]
### 4.3.1 Results from a study on NB Echo control ("double-talk")
characteristics using P.835 methodology
#### 4.3.1.1 Background
In Release 11 of TS26.132, new methods for evaluation of echo control
characteristics were introduced, Clauses 7.11 and 8.11. However, corresponding
requirements were not defined in TS26.131.
A subjective listening test based on methods from Recommendation ITU-T P.835
was conducted in order to provide some data for purposes of investigating
possible requirements.
Instead of a conversational test, or talking and listening test, this report
provides results from listening only test, so participants did not experience
echo while talking, only while passively listening. Below are presented
results of the subjective evaluation of real speech double talk test, for 12
devices, in both handset and handheld speakerphone for narrow band.
#### 4.3.1.2 Test Method & Results
##### 4.3.1.2.1 Methods
The categories defined in Clauses 7.11, Figure 17b5, (copied below for
convenience) and Table 2c, and 8.11, Figure 19b5, and Table 2g, are described
in perceptually-relevant terms.
Figure [xxxx]: Classification of echo canceller performance
Table \: Categories for echo canceller performance classification
* * *
Category Level difference (ΔL) Duration (D) Description **A1** -4 dB ≤ ΔL \
for echo canceller performance are compared to the subjective ratings reported
in 4.3.1.2.2. In addition to the categories and levels from TS 26.132, two
additional metrics are considered. The first is found in Recommendation ITU-T
P.502, revised Amendment III [xx], defining a method for computing the
attenuation in the sending direction under double-talk conditions, A~s,DT~.
The second is found in Recommendation ITU-T P.863 [xx]. While the application
to impairments resulting from double-talk is not explicitly within scope of
P.863, it has been used for this purpose in some instances.
#### 4.3.2.1.1 Method for P.863 computations
For P.863 computations, guidance from P.863.1 clause was followed. The four
sentences of segment 2 of the double-talk test signal from TS 26.132 were
grouped sequentially into two sentence-pairs. The reference signal for the
P.863 NB mode was the full-band source, filtered by a NB filter according to
P.863.1 Table 3. The reference signal for the P.863 SWB mode was the full band
source, filtered by a SWB filter according to P.863.1 Table 3. The validation
tests defined in P.863.1 clause 8.8 were passed, with both sentence-pair
references scoring 4.50 for MOS-LQOn and 4.75 for MOS-LQOw. For each test
condition, the P.863 scores MOS-LQOn and MOS-LQOw were computed using the
uplink measurements from that test condition, grouped into two sentence-pairs.
The MOS-LQOn and MOS-LQOw for the test condition are reported as the average
of the scores for each of the two sentence-pairs from the measurements for
that condition.
#### 4.3.2.2 Comparison of metrics to subjective SIG ratings
Table 1 contains summary values for the fit of the above-described metrics to
the SIG DT ratings for both HS and HHHF combined.
Table 1 Summary of model fits for SIG DT
* * *
**SIG** **R^2^** **correl.** **rmse** **ANOVA F**  
**3GPP** **Atten Class** **DT class A1** 0.963 0.981 0.256 _\  2 kHz). Device D at least tries to compensate the absolute
level difference, the lower frequency content almost match in both positions.
* * *
{width="3.1493055555555554in" height="1.9909722222222221in"}
{width="3.1493055555555554in" height="1.9909722222222221in"}
{width="3.1493055555555554in" height="1.9909722222222221in"}
{width="3.1493055555555554in" height="1.9909722222222221in"}
* * *
Figure 8: Frequency Responses for different devices and positionings.
Table 4 shows some more typical metrics for measurements under silence
conditions for each device which can describe these differences by single
values:
  * Sending Loudness Rating (acc. to ITU-T Rec. P. 79)
  * TOSQA 2001 (WB mode, electrical recording)
  * POLQA according to ITU-T P.863, Version 2.4 (fixed active speech level of 73dB SPL)
The absolute values are given in the column "norm", the difference to the
vertical position is given as "vert. - norm.".
* * *
                                      DUT A   DUT B         DUT C   DUT D                                       
                                      norm.   vert.-norm.   norm.   vert.-norm.   norm.   vert.-norm.   norm.   vert.-norm.
Sending Loudness Rating [dB] 10.15 +4.43 7.44 +3.31 7.36 +4.62 8.64 +3.14
TOSQA2001 (WB) [MOS] 3.61 -0.12 3.61 -0.37 3.74 -0.22 3.37 -0.23 P.863 (POLQA)
[MOS] 3.90 -0.23 3.89 -0.07 3.75 -0.24 3.79 +0.06
* * *
Table 4: Metrics for sending direction per device
All loudness ratings increase by at least 3.1 dB (up to 4.6), which is mainly
caused by the modified frequency responses shown in Figure 8. The large
differences in the spectral domain are not leading to huge differences in the
speech quality measures TOSQA and POLQA. In fact, all MOS scores decrease for
POLQA as well as for TOSQA when comparing normal vs. vertical position. The
maximum difference for POLQA is ‑0.24 for Device C, whereas the largest
difference for TOSQA is found for device B (‑0.37). Please note that the
effect of decreased loudness is not captured by TOSQA and POLQA, because a
constant listening level of 73 dB (A) SPL was set.
#### 5.3.3.2 Measurements with Ambient Noise {#measurements-with-ambient-noise
.list-paragraph}
The following tables provide the results according to TS 103 106 [6] for each
device and each positioning. Each MOS value is determined as the average over
16 American English test sentences taken from annex C of [6]. Note that MOS
values as well as the calculated differences are round to one decimal place.
{width="4.945138888888889in" height="2.9277777777777776in"}
Table **5: TS 103 106 S-/N-/G-MOS values for device A**
{width="4.945138888888889in" height="2.9277777777777776in"}
Table **6: TS 103 106 S-/N-/G-MOS values for device B**
{width="4.945138888888889in" height="2.9277777777777776in"}
Table **7: TS 103 106 S-/N-/G-MOS values for device C**
{width="4.945138888888889in" height="2.9277777777777776in"}
Table **8: TS 103 106 S-/N-/G-MOS values for device D**
The decrease of S-/N-/G-MOS for the vertical position is observable for all
devices. The minimum and maximum differences between vertical and normal
position for each category is shown in Table 9. In overall, scores decreases
at least by 0.1 and up to 1.0 MOS for S-, N- and G-MOS.
When using the two different background noise simulation systems very similar
scores are obtained for S-, N- and G-MOS in the normal position with a
tendency to slightly bigger differences in the vertical position. An exception
here is device D. This device shows significant differences between the
playback systems, for both positions. N-MOS scores increase up to 1.0 for the
background noise simulation according to TS 103224. Since the sound field
reproduction system according to TS 103224 provides an accurate sound field
reproduction at the location of the hand-held terminal (in contrast to an
almost diffuse noise field generated when using ES 202 396-1 which does not
reproduce the physical characteristics of the real sound field at the location
of the terminal) it can be assumed that these results might represent more
accurately the "real life" behavior of this device.
* * *
          Min. Diff.   Device   BGN           Max. Diff   Device   BGN
G-MOS -0.3 A Car -0.9 B Road N-MOS -0.2 A Train Stat. -0.9 D Cafeteria S-MOS
-0.1 C Car -1.0 B Train Stat.
* * *
Table **9: Minimum/maximum differences**
# Xx References {#xx-references .H2}
  1. "Determination of sensitivity/frequency characteristics of local telephone systems", ITU-T Rec. P.64, Annex E (11/2007)
  2. 3GPP TS 26.131: "Technical Specification Group Services and System Aspects; Terminal acoustic characteristics for telephony"
  3. 3GPP TS 26.132: "Technical Specification Group Services and System Aspects; Speech and video telephony terminal acoustic test specification"
  4. ETSI TS 103 224 (V1.1.1): "Speech and multimedia Transmission Quality (STQ); A sound field reproduction method for terminal testing including a background noise database".
  5. ETSI ES 202 396-1 (V1.2.2): "Speech Processing, Transmission and Quality Aspects (STQ); Speech quality performance in the presence of background noise; Part 1: Background noise simulation technique and background noise database".
  6. ETSI TS 103 106 (V1.2.1): "Speech quality performance in the presence of background noise: Background noise transmission for mobile terminals-objective test methods"
  7. Recommendation ITU-T P.58: Head and Torso simulator for Telephonometry
### 5.4 Results from a study on objective measures with noise suppression and
background noise {#results-from-a-study-on-objective-measures-with-noise-
suppression-and-background-noise .list-paragraph}
### {#section .list-paragraph}
### 5.4.1 Comparison of P.862 to subjective results for noise suppression
ITU-T Recommendation P.862, _Perceptual Evaluation of Speech Quality_ (PESQ)
[1], was published in 2001 to predict subjective scores as obtained in ITU-T
Recommendation P.800 Absolute Category Rating (ACR) tests of Overall Speech
Quality [2]. P.862 [1] is a very useful tool for assessing the speech quality
of devices in many situations; however it has significant limitations for
assessing speech quality when noise suppression is used, primarily because the
model was developed and trained before modern UE noise suppression evolved.
Since almost all modern UE's contain some form of noise suppression algorithm,
P.862 [1] should not be used for testing UE's in background noise as it
produces misleading results as demonstrated in the following sections.
The inadequacy of P.862 [1] for devices incorporating noise suppression is
well documented. ITU-T Recommendation P.862.3, _Application Guide for
Objective Quality Measurement Based on Recommendations P.862, P.862.1, and
P.862.2_ [3] provides unambiguous guidance regarding usage with noise
suppression as can be seen in the following excerpt [p3-4]:
{width="6.502777777777778in"
height="1.4916666666666667in"}{width="6.504166666666666in"
height="0.5409722222222222in"}
**Figure 1: Excerpt from ITU-T P.862.3** [3]
ITU-T Recommendation P.835 is used for subjective evaluation of systems with
noise suppression [4]. P.835 [4] evaluations use three rating scales: SIG
assessing the amount of speech distortion; BAK assessing the degree of
intrusiveness of any background noise; OVRL providing an overall speech
quality assessment. ETSI TS 103 106 [5] was designed specifically to predict
the three ratings from a P.835 [4] test and was explicitly trained on noise
reduction. In contrast, both P.862 [1] and P.863 [6] were designed to predict
results from P.800[2] listening tests, which only have one rating scale,
overall speech quality, MOS-LQS. In fact, P.835 [4] was developed partly in
reaction to a high degree of uncertainty observed in P.800 [2] tests on
conditions with noise reduction. Studies directly comparing P.800 [2] MOS-LQS
scores to P.835 [4] OVRL scores are predominantly proprietary, but experience
has shown that there is generally good correlation between these two metrics.
An objective quality predictor is normally trained on a wide variety of
conditions, while a single subjective experiment includes a more limited set
of conditions which potentially changes the experimental context. Therefore
results from a specific subjective experiment may deviate from objective
predictions, hence the results below should be considered as case studies, not
as exhaustive and definitive results. However, these case studies can be
considered as indicative of the nature of issues that could arise when
predictors are applied outside their scope.
### 5.4.2 Experiment 1 -- NB P.835 versus P.862.1
{#experiment-1-nb-p.835-versus-p.862.1 .list-paragraph}
#### 5.4.2.1 Setup
In Experiment 1, a recording of American English speech consisting of four
sentences from each of two male and two female native talkers, as used in ETSI
TS 103 106 [5], was reproduced through an equalized HATS artificial at 92.3 dB
SPL active speech level at the MRP of HATS. The background noise generation
method described in ETSI ES 202 396-1 [7] was used to reproduce eight noises
described in Table 2d of Clause 7.12 of 3GPP TS 26.132 [8]. Six handsets were
used, denoted as A, B, C, D, E, and F in the following plots. Each device was
mounted on the HATS in standard position and recordings made of clean speech,
and speech mixed with the eight noises described above, at the output of a
UMTS base-station simulator with AMR speech encoding at 12.2 kbit/s.
ITU-T Recommendation P.835 [4] is the recommended methodology for assessing
the listening quality of systems incorporating noise suppression. A group of
32 naïve listeners, all native speakers of American English, using the P.835
[4] methodology, rated all sentences in all conditions in a partially balanced
randomized blocks design, resulting in 128 votes per condition. Results were
used as training data for ETSI TS 103 106 [5] with further details in Clause
7.2.1 of that document.
For computing metrics, all recordings were taken at 48 kHz sample rate. For
P.862.1 [9], the clean source file was filtered to NB for use as reference and
the scores were computed separately on sentence pairs then averaged to obtain
per-condition values. For TS 103 106 [5], the NB operational mode was selected
and scores were computed on individual sentences and then averaged to obtain
per-condition values.
#### 5.4.2.2 Results
The results of this experiment are shown below, for four noise types:
{width="6.225694444444445in" height="3.71875in"}
Figure 2: Results of Experiment 1: comparing scores from P.835 [4] and P.862.1
[9] in 4 noise types
It can be seen from these graphs that P.862.1 [9] significantly underestimates
the performance of the various handsets when compared to the results obtained
from the P.835 [4] test with human listeners. In addition the crosing of the
lines shows that the results obtained using P.862.1 [9] do not preserve the
rank order that is obtained with human listeners. For example handset D is the
top or almost top performing handset for all noise types when human listeners
are used, with a score of fair to good, however when tested with P.862.1 [9],
it is the 4^th^ or 5^th^ ranking handset in 3 of the noise types with a score
of only poor.
Figure 3 shows a scatter plot of the subjective P.835 [4] OVRL ratings against
objective scores. The red-colored symbols are for P.862.1 [9] while the blue-
colored symbols are for the GMOS output from the P.835 [4] predictor of TS 103
106 [5]. As noted above, the range of the P.862.1 [9] predictions is
compressed relative to the range of subjective ratings. For example,
subjective ratings in the range of 3.5, or mid-way between 3 "Fair" and 4
"Good" are predicted by P.862.1 [9] in the range of 2 "Poor". In contrast, for
GMOS, the predicted scores span the full range of the subjective ratings, and
fall very close to the diagonal line of slope 1.
{width="5.998611111111111in" height="4.7625in"}
Figure 3: Results of Experiment 1 - correlation of P.835 [4] with P.862.1 [9]
and TS 103 106 [5] (NB). Absolute maximum error for P.862.1 [9] is 1.630,
absolute maximum error for TS 103 106 [5] is 0.880. Spearman rank-order
correlation, accounting for 95% confidence interval, for P.862.1 [9] is 0.914
and for TS 103 106[5] is 0.984.
### 5.4.3 Experiment 2 -- Problems with tuning for P.862.1
{#experiment-2-problems-with-tuning-for-p.862.1 .list-paragraph}
#### 5.4.3.1 Setup
In Experiment 2, a recording of American English speech consisting of four
sentences from each of two male and two female native talkers, as used in ETSI
TS 103 106 [5], was reproduced through an equalized artificial mouth. The
active speech level was -1.7 dBPa at the MRP of HATS. The background noise
generation method described in ETSI ES 202 396-1 [7] was used to reproduce
eight noises described in Table 2d of Clause 7.12 of 3GPP TS 26.132 [8]. In
this case, a single handset was used, but with noise suppression parameters
adjusted in two ways. The tuning labeled "Tuned for P.862.1" was defined so as
to provide high values of ITU-T Recommendation P.862.1 [9]. The tuning labeled
"Alternative Tuning" was defined in general accordance with the requirements
of the marketplace, based on network operator requirements. The device was
mounted on the HATS in standard position, and recordings made of clean speech,
and speech mixed with the eight noises described above, at the output of a
UMTS base-station simulator with AMR speech encoding at 12.2 kbit/s.
A group of 32 naïve listeners, all native speakers of American English, using
the ITU-T Recommendation P.835 [4] methodology, rated all sentences in all
conditions in a partially balanced randomized blocks design, resulting in 128
votes per condition.
#### 5.4.3.2 Results
{width="3.884027777777778in" height="2.5215277777777776in"}
Figure 4: Results of Experiment 2 -- P.835 [4] Overall Score
{width="3.9159722222222224in" height="2.7895833333333333in"}
Figure 5: Results of Experiment 2 -- P.835 [4] Signal Score
{width="3.9583333333333335in" height="2.5215277777777776in"}
Figure 6: Results of Experiment 2 -- P.835 [4] Background Score
The results for the overall performance in the P.835 [4] listening test of
figure 4 show that tuning an algorithm to get the best P.862.1 [9] score does
not produce an optimum result. The version of the algorithm tuned for P.862.1
[9] significantly underperforms in 6 of the 9 noise types. The graphs in
figures 5 and 6 break down the performance in terms of the signal and
background noise scores. These show that while tuning an algorithm to maximize
the P.862.1 [9] score slightly improves the perceived quality of the speech
signal, figure 5, it significantly degrades the perception of the background
noise signal, figure 6, leading to the degraded overall score as shown figure
4.
### 5.4.4 Experiment 3: WB P.835 v P.862.2, P.863 and TS 103 106
#### 5.4.4.1 Setup
The method used was very similar to the one described for narrow-band in
5.4.2.1. However, the UMTS base-station simulator was set to use speech
encoding with AMR-WB at 12.65 kbit/s.
For computing metrics, all recordings were taken at 48 kHz sample rate. For
P.862.2 [10] the clean source file was filtered to WB for use as reference and
the scores were computed separately on sentence pairs then averaged to obtain
per-condition values. For P.863 [6], version 2.4 was used; the clean source
was filtered to SWB for use as reference and the scores were computed using
the SWB mode, separately on sentence pairs then averaged to obtain per-
condition values. For TS 103 106 [5], scores were computed on individual
sentences and then averaged to obtain per-condition values.
#### 5.4.4.2 WB Correlation Results
Figure 7 shows a scatter plot of the subjective P.835 OVRL [4] ratings against
objective scores. The red-colored (+) symbols are for P.862.2 (MOS-LQOw) [10],
while the blue-colored (x) symbols are for the GMOS output from the P.835 [4]
predictor of [5] and the green-colored (o) symbols are for P.863 Version 2.4
[6].
As for narrowband, the range of the P.862.2 [10] predictions is compressed
relative to the range of the subjective ratings. Subjective ratings of about
3.5, or midway between "Fair" and "Good" are scored by P.862.2 [10] at about
1.7, or below "Poor", and the RMSE is 1.659.
For P.863 [6] (MOS-LQOs), there is some compression and offset of the
predictions relative to the subjective ratings, but the compression is not as
severe as for P.862.2 [10]. Subjective ratings of about 3.5 are predicted as
about 2.0 by P.863, and the RMSE is 1.108.
The TS 103 106-WB [5]scores generally span the same range as the subjective
ratings, and fall close to the reference line, without the compression
observed in the P.862.2 [10] predictions. The RMSE is 0.196; however for some
cases, particularly at lower scores, the error can again be large. These
larger errors are not unexpected, since during the training phase of TS 103
106 [5] there was relatively little data available with low scores.
{width="6.406944444444444in" height="5.075in"}
Figure 7: Correlation of P.835 Overall with P.862.2 [10] (MOS-LQOw), TS 103
106 [5] (WB) GMOSw and P.863 [6] (MOS-LQOs). Maximum error of P.862.2 [10] is
2.192, of P.863 [6] is 1.459, and of TS 103 106 [5] is 0.424. Spearman rank-
order correlation, accounting for 95% confidence interval, for P.862.2 [10] is
0.890, for P.863 [6] is 0.897, and for TS 103 106 [5] is 0.975.
#### 5.4.4.3 WB Rank Order Results
The graphs in figure 8 compare the scores of the various measures for each of
the six phones (A-F), in each noise type. Figure 9 then shows the number of
absolute rank order errors for each metric in each noise type when compared to
the results from the listening test. These results do not take account of
overlapping confidence intervals; hence the errors may be exaggerated,
especially for the clean condition where the listening tests results were very
similar.
For P.862.2 [10] the rank order is not preserved, again there are frequent
shifts of one and two positions, as well as shifts of three positions in
cafeteria and car noise. For P.863 [6] rank order errors are observed, but not
as many as for P.862.2 [10]. There are still frequent single rank switches,
but fewer two-rank switches, although there are larger errors observed in the
clean condition where the confidence intervals overlap. TS 103 106 [5] has the
best performance; however single rank switches are still common and occasional
two and three-rank switches also occur in clean, cafeteria and pub noise.
{width="6.504166666666666in" height="7.711805555555555in"}
Figure 8: Scores per device and noise type for P.835 Overall [4], P.862. 2[10]
(MOS-LQOw), TS 103 106 [5] (WB) GMOSw and P.863 [6] (WB) (MOS-LQOw)
{width="6.905555555555556in" height="5.019444444444445in"}
Figure 9: Rank Order Errors for each Objective Measure in WB
### 5.4.5 Experiment 4 SWB P.835 v P.862.2, P.863 and TS 103 106
#### 5.4.5.1 Setup
The method used was similar to the one described in 5.4.2.1. However, the
following differences should be noted. As commercial super-wideband terminals
are not generally available, a mock- up of a handset was used. The mock-up was
the size and shape of a typical mobile handset, and was equipped with several
microphones, as in some current commercially available wideband terminals. The
same speech and background noise generation as for NB and WB was used, but
recordings were made from the microphones on the mock-up. The signals were
processed with offline processing to produce the noise-reduced signals. No
speech encoding was used.
For computing metrics, all recordings were taken at 48 kHz sample rate. For
P.862.2 [10], the source file was filtered to WB and the scores were computed
separately on sentence pairs then averaged to obtain per-condition values. For
P.863 [6] version 2.4 was used; the source was filtered to SWB and the scores
were computed separately on sentence pairs then averaged to obtain per-
condition values. For TS 103 106[5], the source file was used as SWB and
scores were computed on individual sentences using the WB mode of the tool,
and then averaged to obtain per-condition values.
#### 5.4.5.2 SWB Correlation Results
Figure 10 shows a scatter plot of the subjective P.835 [4] OVRL ratings
against objective scores. The red-colored (+) symbols are for P.862.2 (MOS-
LQOw) [10], while the blue-colored (x) symbols are for the GMOS output from
the P.835 predictor of [5] and the green-colored (o) symbols are for P.863
(ITU-T P.863) V2.4 [6].
As expected the P.862.2 [10] results show a poor correlation with the SWB
listening scores with an RMSE of 1.458. SWB P.863 [6] scores are more
consistent and have an RMSE of 0.815, however they show a similar compression
of the range of scores as was observed for NB and WB. Also as expected, the TS
103 106-WB [5] scores are less well correlated in SWB than in WB with an RMSE
of 0.345.
{width="5.073611111111111in" height="3.7270833333333333in"}
Figure 10: Correlation of P.835 Overall with P.862.2 [10](MOS-LQOw), TS 103
106 [5](WB) GMOSw and P.863 [6] (SWB) (MOS-LQOs). Maximum absolute error for
P.862.2 [10] is 2.463, for P.863 [6] is 1.326, and for TS 103 106 [5] is
0.842. Spearman rank-order correlation, accounting for 95% confidence
interval, for P.862.2 [10] is 0.755, for P.863 [6] is 0.855, and for TS 103
106 [5] is 0.956.
#### 5.4.5.3 SWB Rank Order Results
The graphs in figure 11 compare the scores of the various measures for the
mock-up phones with various levels of noise suppression (0-15), in each noise
type. Figure 12 then shows the number of absolute rank order errors for each
metric in each noise type when compared to the results from the listening
test.
None of the objective measures preserve the rank order of the listening tests
for SWB. All three measures have frequent shifts of up to three ranks and
occasional larger shifts. P.863 [6] also commonly shifts by four positions.
It can also be seen from the graphs in figure 11 that if these scores were
used to try and tune the noise suppression parameter in this algorithm,
different results would be obtained depending on which objective measure was
used, and in addition none of the measures would reliably select the same
optimization as that determined by the human listeners.
{width="6.670138888888889in" height="7.992361111111111in"}
Figure 11: Scores per device and noise type for P.835 [4] Overall, P.862.2
[10] (MOS-LQOw), TS 103 106 [5] (WB) GMOSw and P.863 [6] (SWB) (MOS-LQOs)
{width="6.677083333333333in" height="3.595138888888889in"}
Figure 12: Rank Order Errors for each Objective Measure in SWB
### 5.4.6 Conclusions {#conclusions .list-paragraph}
The use of P.862.1 [9] and P.862.2 [10] for assessing the performance of
handsets in noise should be avoided. Almost all modern UEs now provide noise
suppression as part of their default operation and it is shown that P.862.1
[9] and P.862.2 [10] produces misleading results when used in conjunction with
noise suppression algorithms. Using P.862.1 [9] and P.862.2 [10] to compare
UE's is unreliable since a comparison of the results with actual listening
tests shows a different rank order between the two tests, i.e. the best
P.862.1 [9] and P.862.2 [10] score does not always produce the best overall
score from a listening test. The P.862.1 [9] and P.862.2 [10] scores (MOS_LQO)
also substantially under predict the P.835 [4] OVRL scores obtained from the
listening test. In addition, in Annex B of ETSI EG 202 396-3 [11], results for
P.835 [4] listening tests are compared to predictions from P.862.1 [9] and
P.862.2 [10] and are shown to not correlate well with the subjective results.
Finally, the use of P.862.1 [9] and P.862.2 [10] for comparing handsets may
steer manufacturers to tune their algorithms to maximize the P.862.1 [9] and
P.862.2 [10] score. For the reasons exposed, such tuning may actually degrade
the speech quality as perceived by human listeners.
For WB it is not too surprising that the objective tools that are intended to
predict the perceived quality of telephone speech with noise reduction (e.g.
TS 103 106 [5]) perform that task better than tools which were not initially
designed to do so. However there is still room for improvement, as even TS 103
106 [5] does not consistently preserve the rank order, which can make
comparative evaluations unreliable.
For SWB none of the three predictors performed particularly well. Again this
is to be expected since P.862.2 [10] and TS 103 106 [5] were not designed to
be used on SWB speech, and P.863 [6] was not designed for use with modern
terminal noise suppression algorithms.
Further work is needed to develop more effective objective measures especially
for wider bandwidths. It is particularly important to ensure that maximum
error and rank order are taken into account as well as just RMSE, which would
enable more reliable comparative evaluations of solutions across a range of
operation scenarios including different background noises and noise
suppression technologies.
\-------------------------------------------------------------------------------------------------------------------------
# **References** **for section 5.4 of** **TR 26.931**
> [1] Recommendation ITU-T P.862, Perceptual evaluation of speech quality
> (PESQ): An objective method for end-to-end speech quality assessment of
> narrow-band telephone networks and speech codecs, 02/2001.
>
> [2] Recommendation ITU-T P.800, Methods for subjective determination of
> transmission quality, 08/1996.
[3] Recommendation ITU-T P.862.3, Application guide for objective quality
measurement based on Recommendations P.862, P.862.1 and P.862.2, 11/2007.
[4] Recommendation ITU-T P.835, Subjective test methodology for evaluating
speech communication systems that include noise suppression algorithm,
11/2003.
> [5] ETSI TS 103 106 v1.3.1 (2014-04), Speech quality performance in the
> presence of background noise: Background noise transmission for mobile
> terminals -- objective test methods.
[6] Recommendation ITU-T P.863 (2014 -09), Perceptual objective listening
quality assessment.
> [7] ETSI ES 202 396-1 v1.4.1 (2014-01), Speech quality performance in the
> presence of background noise; Part 1: Background noise simulation technique
> and background noise database.
>
> [8] 3GPP TS 26.132, V12.5.0 (2015-03), Speech and video telephony terminal
> acoustic test specification.
>
> [9] Recommendation ITU-T P.862.1, Mapping function for transforming P.862
> raw result scores to MOS-LQO, 11/2003.
[10] Recommendation ITU-T P.862.2, Wideband extensions to Recommendation P.862
for the assessment of wideband telephone networks and speech codecs, 11/2007.
> [11] ETSI EG 202 396-3 v1.5.1 (2015-05), Speech quality performance in the
> presence of background noise; Part 3: Background noise transmission --
> Objective test methods.
#