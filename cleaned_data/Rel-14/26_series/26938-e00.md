# Foreword
This Technical Report has been produced by the 3^rd^ Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# Introduction
3GPP\'s Dynamic Adaptive Streaming over HTTP (DASH) specifications were
developed in Rel-9 and Rel-10 and are available in TS 26.247 [2]. Despite
being integrated into the PSS architecture, the specifications have
significant flexibility for deployments also outside the 3GPP services. This
has been recognized by other organizations such as MPEG and Open IPTV Forum.
In continuous alignment efforts, 3GPP and MPEG have developed a generic format
for Dynamic Adaptive Streaming over HTTP (DASH).
These specifications serve an urgent need: With the evolution of radio access
technologies towards HSPA & LTE higher data rates are provided allowing more
feature rich services with higher quality and access to multimedia services
has grown significantly. And the most popular multimedia services today are
services delivered over HTTP. Serving content from standard HTTP-servers has
many advantages in terms of deployment costs and convergences with regular web
services.
With the completion of the specifications, first deployments of services based
on DASH and similar technologies are happening. The experiences from initial
deployments of massively scalable video streaming delivery over HTTP and
advanced radio access technologies result in new use cases, demands and
requirements. Improvements for the support of DASH when delivered over 3GPP
networks and architectures are expected to be necessary and deployments
guidelines are important. Considered improvements are in the area of improved
user experience, improved bandwidth efficiency or more efficient delivery over
HTTP-caching infrastructures. Furthermore, the combination of DASH with other
services and technologies is an ongoing challenge and effort. Not limited to
this, but some examples are the delivery of DASH over different 3GPP radio
access networks, the combination with presentation technologies such as
HTML-5, the support of advanced content protection schemes, or the support for
QoS in 3GPP networks.
Service improvements might not require additional TS 26.247 [2] specification
work, but do require a detailed analysis of the envisaged use cases, the
resulting requirements, the ability to solve these use cases with the existing
3GPP and/or other existing specifications and provide guidelines and
deployment examples. The analysis of the use cases may lead to additional
specification work, but this should first be identified and justified from the
above analysis.
# 1 Scope
The present document covers
\- deployment guidelines for DASH in 3GPP networks and architectures,
\- use cases for the improved support of DASH in 3GPP networks and
architectures as well as requirements to support those use cases,
\- recommendations for potentially necessary normative specification work in
3GPP,
\- recommendations for the documentation of potentially informative guide
lining work.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] 3GPP TS 26.247: \"Transparent end-to-end Packet-switched Streaming Service
(PSS); Progressive Download and Dynamic Adaptive Streaming over HTTP (3GP-
DASH)\".
[3] 3GPP TS 26.234: \"Transparent end-to-end packet switched streaming service
(PSS); Protocols and codecs\".
[4] 3GPP TS 26.346: \"Multimedia Broadcast/Multicast Service (MBMS); Protocols
and codecs\".
[5] 3GPP TS 26.244: \"Transparent end-to-end packet switched streaming service
(PSS); 3GPP file format (3GP)\".
[6] IETF RFC 2616: \"Hypertext Transfer Protocol -- HTTP/1.1\", Fielding R. et
al., June 1999.
[7] ISO/IEC 14496-12 \| 15444-12:2012 \"Information technology -- Coding of
audio-visual objects -- Part 12: ISO base media file format\" \| \"Information
technology -- JPEG 2000 image coding system -- Part 12: ISO base media file
format\".
[8] IETF RFC 6726 (November 2012): \"FLUTE - File Delivery over Unidirectional
Transport\",\ T. Paila, M. Luby, R. Lehtonen, V. Roca, R. Walsh.
[9] ISO/IEC 23009-1:2012/Cor1:2013 \" Information technology -- Dynamic
adaptive streaming over HTTP (DASH) -- Part 1: Media presentation description
and segment formats\".
[10] ISO/IEC 23009-3:2013 \"Information technology -- Dynamic adaptive
streaming over HTTP (DASH) -- Part 3: Implementation and Deployment
Guidelines\".
[11] ISO/IEC 23009-2:2013 \" Information technology -- Dynamic adaptive
streaming over HTTP (DASH) -- Part 2: Conformance and Reference Software\".
[12] W3C Working Draft, \"XMLHttpRequest\", January 30, 2014.
[13] (void)
[14] ITU-R Recommendation BT.500-11: \"_Methodology for the Subjective
Assessment of the Quality of Television Pictures\",_ 2002.
[15] 3GPP TS 23.203: \"Policy and Charging Control Architecture\".
[16] 3GPP TS 23.207: \"End-to-End Quality of Service (QoS) Concept and
Architecture\".
[17] 3GPP TS 29.213: \"Policy and charging control signalling flows and
Quality of Service (QoS) parameter mapping\"
[18] 3GPP TS 29.214: \"Policy and charging control over Rx reference point\"
[19] 3GPP TS 23.401: \"**General Packet Radio Service (GPRS) enhancements for
Evolved Universal Terrestrial Radio Access Network (E-UTRAN) access\"**
[20] 3GPP TS 33.220: \"Generic Authentication Architecture (GAA); Generic
Bootstrapping Architecture (GBA)\"
[21] 3GPP TR 36.814: \"Further advancements for E-UTRA physical layer
aspects\".
[22] ISO/IEC 23009-1:2014: \"Information technology -- Dynamic adaptive
streaming over HTTP (DASH) -- Part 1: Media presentation description and
segment formats\".
[23] **3GPP TR 23.705** : \"**System Enhancements for User Plane Congestion
Management\".**
[24] **3GPP TS 23.228** : \"I**P Multimedia Subsystem (IMS); Stage 2\".**
[25] IAB VMAP: \"Digital Video Multiple Ad Playlist (VMAP) 1.0\", July 2012,
www.IAB.net[.]{.underline}
[26] SCTE 35: \"Digital Program Insertion Cueing Message for Cable\", 2013,
http://www.scte.org
[27] IAB VAST: \"Digital Video Ad Serving Template (VAST) 3.0\", July,2012,
www.IAB.net[.]{.underline}
[28] ISO/IEC 23001-10:2014 \"Information technology -- MPEG systems
technologies -- Part 10: Carriage of Timed Metadata Metrics of Media in ISO
Base Media File Format\".
[29] IETF RFC 4337: \"MIME Type Registration for MPEG-4,\" March 2006.
[30] IETF RFC 6381: \"The \'Codecs\' and \'Profiles\' Parameters for
\"Bucket\" Media Types,\" August 2011.
[31] IETF RFC 6265: \"HTTP State Management Mechanism\".
[32] IETF RFC 2109: \"HTTP State Management Mechanism\".
[33] Recommendation ITU-T P.1202.1: \"Parametric non-intrusive bitstream
assessment of video media streaming quality - Lower resolution application
area\".
[34] ISO/IEC 23001-9: \" Information technology -- MPEG systems technologies
-- Part 9: Common encryption of MPEG-2 transport streams\".
[35] IETF RFC 5681: \"TCP Congestion Control\".
[36] Recommendation ITU-T J.181: \"Digital program insertion cueing message
for cable television systems\".
# 3 Definitions and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
TR 21.905 [x] and the following apply. A term defined in the present document
takes precedence over the definition of the same term, if any, in TR 21.905
[1].
**altitude:** number indicating the altitude in meters. The reference
altitude, indicated by zero, is set to the sea level.
**digital zoom:** number indicating the enlargement scale factor of the image
due to cropping and interpolating the pixel dimensions back to the original
size.
**latitude:** number indicating the latitude in degrees. Negative values
represent southern latitude.
**longitude:** number indicating the longitude in degrees. Negative values
represent western longitude.
**optical zoom:** number indicating the optical magnification scale factor.
**pan:** number measured in degrees and corresponding to the compass direction
of the component in the plane parallel to the earth\'s surface of any vector
which points in the same direction that the camera is facing. For example,
North corresponds to 0 degrees, East corresponds to 90 degrees, etc. If the
camera is pointing in a direction perpendicular to the earth\'s surface
(either straight up at the sky or straight down at the ground), then the value
of Pan is undefined. For the direction corresponding to Pan, it is useful to
have an indication of whether the direction is \"true\" or \"magnetic\".
**rotation:** number measured in degrees corresponding to the rotational
position about the axis in the direction that the camera is facing. Since Tilt
and Rotation are independent parameters, Rotation is defined for a Tilt value
of 0, i.e. the camera is first tilted to be pointing parallel to the earth\'s
surface in the direction that would correspond to Pan. Rotation is then the
amount of counter-clockwise rotation about the axis that the camera is facing
needed to bring a vector initially pointing straight up towards the sky into
alignment with the camera \"up\" direction. In the event that Pan is undefined
as the camera is either pointing straight up or straight down, Rotation can be
defined as the amount of rotation needed to bring a vector initially pointing
North into alignment with the camera \"up\" direction.
**tilt:** number measured in degrees corresponding to the rotational position
about the axis in the plane of constant amplitude through the camera centre
that is perpendicular to the Pan direction. For example, if the camera is
pointing parallel to the earth\'s surface, Tilt is 0. If the camera is
pointing straight up towards the sky, the Tilt is 90 degrees and if the camera
is pointing straight down towards the earth Tilt is -90 degrees.
## 3.2 Abbreviations
For the purposes of the present document, the abbreviations given in TR 21.905
[1] and the following apply. An abbreviation defined in the present document
takes precedence over the definition of the same abbreviation, if any, in TR
21.905 [1].
3GP 3GPP file format
3GP-DASH 3GPP Dynamic Adaptive Streaming over HTTP
ACDC Application specific Congestion control for Data Communication
AHS Adaptive HTTP Streaming
AJAX **Asynchronous JavaScript and XML**
AVC Advanced Video Coding
AVP Attribute-Value Pairs
BMW Bayerische Motoren Werke
CAS Conditional Access System
CBP Constrained Baseline Profile
CDN Content Delivery Network
CoD Content-on-Demand
DASH Dynamic Adaptive Streaming over HTTP (DASH)
DRM Digital Rights Management
DVD Digital Versatile Disc
FLUTE File Delivery over Unidirectional Transport
GPS Global Positioning System
HD High Definition
HTML Hypertext Markup Language
HTTP Hypertext Transfer Protocol
HTTPS Hypertext Transfer Protocol Secure
MPD Media Presentation Description
MOS Mean Opinion Score
MSS Maximum Segment Size
MS-SSIM Multi-Scale Structural SIMilarity
P-GW PDN Gateway
PDN Packet Data Network
PSNR Peak-Signal-to-Noise-Ratio
PSS Packet-switched Streaming Service
QoE Quality-of-Experience
QoS Quality-of-Service
RAT Radio Access Technology
RTT Round-Trip Time
SAP Stream Access Point
SSIM Structural SIMilarity
TCP/IP Transmission Control Protocol / Internet Protocol
TV TeleVision
UE User Equipment
UPCON User Plan Congestion control
URI Uniform Resource Identifier
URL Uniform Resource Locator
URN Uniform Resource Name
UTC Coordinated Universal Time
VBR Variable Bit Rate
VGA Video Graphics Array
VoD Video-on-Demand
WLAN Wireless Local Access Network
WQVGA Wide Quarter Video Graphics Array
WVGA Wide Video Graphics Array
XML EXtended Markup Language
# 4 Relevant Specifications
## 4.1 Overview
MPEG had initiated a standardization process to provide specifications to
enable scalable and flexible video distribution that addresses fixed and
mobile networks. The work had been in close coordination with a parallel
effort in 3GPP such that the two standards are aligned for broad industry
support across different access networks. 3GPP\'s Release-9 specification on
Adaptive HTTP Streaming (AHS) [3], section 12 completed in 2010 served as a
baseline for MPEG\'s DASH [9] (MPEG-DASH) as well as for 3GPP\'s Release 10\'s
DASH specification [2] (3GP-DASH).
In addition to the format specification, MPEG provides additional
specifications as part of MPEG-DASH, namely:
\- ISO/IEC 23009-2: Conformance and Reference software [11]
\- ISO/IEC 23009-3: Implementation and Deployment Guidelines [10]
Due to the close coordination in the development of 3GP-DASH it is achieved
that 3GPP Release 10 DASH can be viewed as a profile of MPEG-DASH with minor
extensions. Clause 5.2 provides a description on how 3GP-DASH may be
represented as a profile of MPEG-DASH. Beyond the formats defined in both
specifications, 3GP-DASH also defines the transport protocol when deployed
within PSS as being HTTP [6]. Furthermore, 3GPP also supports the delivery of
DASH formats within MBMS [4] using FLUTE [8] as the delivery protocol.
Both specifications rely for the segment formats on the ISO base media file
format [7]. In 3GPP, compatibility is achieved with the 3GPP file format [5].
In addition, during 2012 and 2013 MPEG has conducted work on a second edition
of DASH [22] that includes additional technologies. These technologies are
currently not part of 3GP-DASH, but some the technologies are discussed in the
present document as they may serve as a candidate technology to fulfil
advanced use cases.
## 4.2 3GP-DASH as a profile of MPEG-DASH
### 4.2.1 General
The 3GP-DASH Release-10 profile as defined in TS 26.247 [2], section 7.3.3 and
identified by the URN \"urn:3GPP:PSS:profile:DASH10\" may be described as an
MPEG-DASH profile as follows:
The 3GP-DASH Release-10 profile is identified by the URN
\"urn:3GPP:PSS:profile:DASH10\".
The \@mimeType attribute of each Representation is expected to be provided
according to RFC 4337 [29]. Additional parameters may be added according to
RFC 6381 [30].
### 4.2.2 Media Codecs
For the 3GP-DASH Release-10 profile clients supporting a particular continuous
media type, the corresponding media decoders are specified in TS 26.234 [3],
clause 7.2 for speech, clause 7.3 for audio, clause 7.4 for video, clause 7.9
for timed text and clause 11 for timed graphics.
### 4.2.3 Media Presentation Description constraints
The Media Presentation Description are expected to conform to the following
constraints:
\- The rules for the MPD and the segments as defined in ISO/IEC 23001-9 [34],
section 7.3, apply.
\- Representations with value of the \@mimeType attribute other than
video/mp4, video/3gp, audio/3gp or audio/mp4 may be ignored. Additional
profile or codec specific parameters may be added to the value of the MIME
type attribute. For details refer to specific parameters below.
\- The **Subset** element may be ignored.
\- Any **SegmentBase** , **SegmentTemplate** or **SegmentList** element that
contain a **SegmentTimeline** element may be ignored.
\- Any Representation that contains a **FramePacking** element may be ignored.
\- Any Representation that contains an \@scanType attribute with value other
than \"progressive\" may be ignored.
### 4.2.4 Segment format constraints
Representations and Segments referred to by the Representations in the
profile-specific MPD for this profile, the following constraints are expected
to be met:
> \- Representations are expected to comply with the formats defined in clause
> 7.3 in ISO/IEC 23009-1.
\- Representations are expected to comply with a 3GP file format profile in a
sense that the profile parameter of the \@mimeType attribute will contain the
\'3gh9\' brand.
### 4.2.5 Extensions
#### 4.2.5.1 Media Presentation Description Delta
If the **x3gpp:DeltaSupport** element is present in the **MPD** element, the
content provider indicates that MPD delta files, as defined in this clause,
are supported on the server. The URI of the MPD delta is provided in
**x3gpp:DeltaSupport** \@sourceURL. The **x3gpp:DeltaSupport**
\@availabilityDuration element, if present, indicates that the MPD delta file
referenced by the URI is available for at least the value of the
\@availabilityDuration attribute (after this time, the server may redirect the
client to the full MPD). If **x3gpp:DeltaSupport** \@availabilityDuration is
not present, then no information is conveyed about the availability of the MPD
delta. If a client request for an MPD delta file results in an error, the
client should request a full MPD.
The semantics of the attributes within the **x3gpp:DeltaSupport** element are
provided in Table 4.1. The XML-syntax of **x3gpp:DeltaSupport** element is
provided in Table 4.2.
Table 4.1: Semantics of x3gpp:DeltaSupport element
+-------------+-------------+-------------+-------------+-------------+ | Element or | Use | Description | | | | Attribute | | | | | | Name | | | | | +-------------+-------------+-------------+-------------+-------------+ | | **x3gpp:Del | | If present, | | | | taSupport** | | this | | | | | | element | | | | | | indicates | | | | | | that MPD | | | | | | delta files | | | | | | are | | | | | | supported | | | | | | by the | | | | | | server. | | +-------------+-------------+-------------+-------------+-------------+ | | | \@sourceURL | M | The source | | | | | | string | | | | | | providing | | | | | | the URL of | | | | | | the MPD | | | | | | delta. The | | | | | | URL may be | | | | | | relative to | | | | | | any | | | | | | **BaseURL** | | | | | | on MPD | | | | | | level and | | | | | | reference | | | | | | resolution | | | | | | according | | | | | | to clause | | | | | | 8.2.3 of | | | | | | TS26.247 | | | | | | [2] will | | | | | | be applied. | +-------------+-------------+-------------+-------------+-------------+ | | | \@availabil | O | When | | | | ityDuration | | provided, | | | | | | indicates | | | | | | the | | | | | | duration | | | | | | that the | | | | | | server | | | | | | guarantees | | | | | | the | | | | | | a | | | | | | vailability | | | | | | of the MPD | | | | | | delta file | | | | | | referenced | | | | | | in | | | | | | \@sourceURL | | | | | | after the | | | | | | MPD has | | | | | | been | | | | | | updated. | | | | | | After that | | | | | | the client | | | | | | may be | | | | | | redirected | | | | | | to the full | | | | | | MPD. | +-------------+-------------+-------------+-------------+-------------+ | Legend: | | | | | | | | | | | | > For | | | | | | > | | | | | | attributes: | | | | | | > M | | | | | | =Mandatory, | | | | | | > | | | | | | O=Optional, | | | | | | > | | | | | | OD=Optional | | | | | | > with | | | | | | > Default | | | | | | > Value, | | | | | | > CM=Co | | | | | | nditionally | | | | | | > | | | | | | Mandatory. | | | | | | > | | | | | | > For | | | | | | > elements: | | | | | | > \...\ | | | | | | > (N | | | | | | =unbounded) | | | | | | | | | | | | Elements | | | | | | are bold; | | | | | | attributes | | | | | | are | | | | | | non-bold | | | | | | and | | | | | | preceded | | | | | | with an @. | | | | | +-------------+-------------+-------------+-------------+-------------+
Table 4.2: XML-Syntax of x3gpp:DeltaSupport element
* * *
\\ \\ \\ \\
\\ \\ \\ \\ \
* * *
An MPD delta is a text file that includes the delta between the MPD that
references it and the latest provided MPD. Note that the value of \@sourceURL
in successive MPDs is necessarily different because it is impossible for the
delta between two different MPDs and the most recent MPD to be the same.
The output format consists of one or more structures, each corresponding to a
change. The changes are in decreasing line number order. The structure format
looks like:
change-command\ to-file-line\ to-file-line...\ .
There are three types of change commands change-command. Each consists of a
line number or comma-separated range of lines in the first file and a single
character indicating the kind of change to make. All line numbers are the
original line numbers in the file. The types of change commands and the
instructions are provided in Table 4.3.
Table 4.3: Change commands and the instructions for delta MPD files
* * *
Change command Instruction Example _l_ a Add text from the second file after
line _l_ in the first file. \'8a\' means to add the following lines after line
8 of file 1 _r_ c Replace the lines in range _r_ in the first file with the
following lines. Like a combined add and delete, but more compact. \'5,7c\'
means change lines 5--7 of file 1 to read as the text file 2. _r_ d Delete the
lines in range _r_ from the first file. \'5,7d\' means delete lines 5--7 of
file 1. NOTE: This is the format supported by the GNU diff utilities, see
http://www.gnu.org/software/diffutils/manual/#Detailed-ed
* * *
Regardless of the presence of a **x3gpp:DeltaSupport** element, the full MPD
will always be available to clients for regular MPD updates. MPD Delta related
procedures are optional at the client.
# 5 Deployment Guidelines
## 5.1 Introduction
Deployment guidelines include:
\- instructions on how content may be offered using the DASH formants,
\- instructions on relevant client implementation and operation aspects,
\- operational guidelines on how operate a DASH-based service.
## 5.2 Content Authoring Guidelines
For generic content authoring guidelines please refer to ISO/IEC 23009-3 [10].
In order to address 3GPP-specific aspects the capabilities of 3GPP PSS codecs
as well as bitrates mapped to typical 3GPP networks should be considered.
## 5.3 Client implementation and client operation guidelines
### 5.3.1 Guidelines for rate adaptation
#### 5.3.1.1 Introduction
DASH merely specifies the formats for Media Presentation Description (MPD) and
media segments, while client operations, such as rate adaptation algorithms,
are not specified. The operation of the rate adaptation algorithm might affect
the perceived presentation quality as media segments from different
representations within one Adaptation Set could be selected to present the
same media content component. The perceived quality might be affected by the
bitrate of the selected media rate as well as potentially experienced
interruptions from buffer underruns due to non-timely arrival of the media
segments.
#### 5.3.1.2 Rate adaptation in DASH
When designing rate adaptation algorithm for DASH, one should consider among
others:
\- that the rate adaptation algorithm is efficiently utilizing the sharable
network capacities, which affects playback media quality,
\- that the rate adaptation algorithm is capable of detecting network
congestion and is able to react promptly to prevent playback interruption,
\- that the rate adaptation algorithm can provide stable playback quality even
if the network delivery capacities fluctuate widely and frequently,
\- that the rate adaptation algorithm is able to tradeoff maximum
instantaneous quality and smooth continuous quality, for example by smoothing
short-term fluctuation in the network delivery capacities by using buffering,
but still switch to better presentation quality/higher bitrates if more long-
term bandwidth increase is observed,
\- that the rate adaptation algorithm is able to avoid excessive bandwidth
consumption due to over-buffering media data.
When implementing rate adaptation in DASH, one could balance between different
criteria listed above to improve the overall Quality of Experience (QoE)
perceived by the user. The guideline of rate adaptation in DASH is summarized
based on the QoE metrics specified in 3GPP TS 26.247 [2].
In absence of other information, e.g. from the radio network status, the
measurement for certain QoE metrics may be used in rate adaptation in DASH,
e.g.:
\- average throughput: average throughput measured by a client in a certain
measurement interval;
\- Segment Fetch Time (SFT) ratio: the ratio of Media Segment Duration (MSD)
divided by SFT. MSD and SFT denote the media playback time contained the media
segment and the period of time from the time instant of sending a HTTP GET
request for the media segment to the instant of receiving the last bit of the
requested media segment, respectively;
\- buffer level: buffered media time at a client.
In conjunction with rate adaptation, client implementations can include a
request cancellation functionality in order to address stalled or expiring
HTTP requests, i.e. if the client identifies that the requested
segment/subsegment cannot be received in time., or the case that the data is
no longer needed due to user interaction. This is relevant to avoid buffer
under-runs and to be reactive to user interactions. However, cancelling an
HTTP request does have a disadvantage, as this typically requires tearing down
and re-establishing a TCP connection. This should be taken into account before
cancelling a TCP connection. Any improvements to support HTTP request
cancellation may be suitable.
For improving throughput especially during media startup, HTTP pipelining as
defined in RFC 2616 [6] may be used by the client. HTTP servers used for DASH
distribution preferably support HTTP pipelining.
Further rate adaptation enhancements based on the availability of quality and
QoS information are discussed in clauses 6.8 and 6.17.
## 5.4 Operational and deployment guidelines
### 5.4.1 General
For general operational and deployment guidelines see ISO/IEC 23009-3 [10].
As access bandwidth on 3GPP networks is typically shared among many users and
is precious, DASH clients are recommended avoiding excessive download of non-
consumed data as well as downloading data that is unsuitable for the
consumption. DASH clients are recommended avoiding building large download
buffers, for example in the range of several minutes, as user may decide to
terminate the viewing or apply fast forwards and so on. In addition a DASH
client is recommended avoiding downloading Representations that it is not
expected to consume, for example alternate languages etc. Furthermore, DASH
clients are recommended not downloading Representations for which no quality
gains are obvious under the current consumption model. For example, DASH
clients are recommended avoiding downloading full resolution video if video is
only played as a thumbnail in an application.
Content authoring is recommended to be such that downloading of unnecessary
data can be avoided, for example by not multiplexing multiple languages into a
single Representation.
### 5.4.2 Proxy/cache switch for DASH service
#### 5.4.2.1 Assumptions
It is assumed that many HTTP proxy/cache that also support DASH are physically
located at or close to different P-GWs or for different RATs, can be deployed
within the operator domain.
#### 5.4.2.2 Description
Operator A owns both LTE and WLAN networks and proxy caches are provided for
both LTE and WLAN network. Robert accesses a DASH service over an LTE network
of operator A. A proxy cache is placed inside the LTE network to reduce
latency and scalability in order to optimize HTTP delivery over TCP/IP. Robert
enters the office covered by the WLAN network also owned by operator A. The
operator A knows LTE traffic surging in the office area and the WLAN network
is available for traffic offloading. Robert\'s UE switches to WLAN for the
DASH service. The content is served from another proxy cache within the WLAN
network as the proxy cache physically close to the UE and therefore provides
higher TCP/IP throughput due to reduced latency.
NOTE: It is assumed that mobility events may cause a change in proxy cache.
#### 5.4.2.3 Working assumption
DASH client may be served by another proxy cache after a mobility event occurs
#### 5.4.2.4 Recommended Requirements
A change in proxy cache should have minimum impact on the user experience of
the DASH service.
# 6 General Use Cases
## 6.1 Introduction
This clause introduces use cases that are either supported by 3GP-DASH [2],
possibly in combination with other 3GPP technologies, or the use cases are in
the context of DASH, but may require extensions in 3GP-DASH or other
technologies. Therefore, the use cases are analysed, potential solutions
reusing existing technologies are provided and potential gaps are identified.
## 6.2 Advanced Support for Live Services
### 6.2.1 Description
#### 6.2.1.1 Setup
A service provider wants to provide a live soccer event using DASH that can
potentially be accessed by millions of users. The service provider provides
redundant infrastructure in terms of encoders and servers to enable a seamless
switch-over in case any of the components fail during the live event or get
overloaded.
#### 6.2.1.2 Use Case A: Start-up latency
Anna accesses the service in the bus with her mobile DASH-enabled device, and
the service is available immediately.
#### 6.2.1.3 Use Case B: Aligned Presentation
Continuing Use Case A, across from her sits Paul, who watches the event on his
DASH-enabled laptop. A goal is scored and both, despite watching on different
screens, celebrate this event at the same time.
#### 6.2.1.4 Use Case C: End-to-end latency
Continuing Use Case B, other people that follow the game on a 3GPP Rel-6 PSS
terminal observe the goal within a similar time.
#### 6.2.1.5 Use Case D: Time-Shift Buffer
Continuing Use Case C, Another goal is scored. Paul tells Anna that the first
goal in the game was even more exciting and Anna uses the offering that she
can view the event 30 minutes back in time on her DASH-enabled device. After
having seen the goal she goes back to the live event.
#### 6.2.1.6 Use Case E: Infrastructure Upgrade
Continuing Use Case D, the football match gets into overtime, the star player
of CF Anolacrab, Lenoil Issem, is brought into the game by the coach of the
year, Aloidraug, hits twice the post, but cannot score. Due to the
extraordinary tension in the match, more and more users join such that the
service provider requires migrating the service to the redundant
infrastructure without interrupting the service to the users.
#### 6.2.1.7 Use Case F: Ad Insertion
Continuing Use Case E, finally penalty shooting is necessary. The live event
is interrupted by a short break during which advertisement is added. The exact
timing of the ad breaks is unknown due to the extra time of the extension and
the start of the penalty shooting is delayed.
### 6.2.2 Operation with MPD dynamic Mode
#### 6.2.2.1 Introduction
This section provides an overview on using the MPD dynamic mode and how a
client can make use of MPD offerings. The focus is on the client operation
here. Details on a possible service offering to fulfil the use cases in clause
6.2.1 is provided in clause 6.2.3.
#### 6.2.2.2 Problem Statement
Generally, an HTTP streaming client accesses and downloads a manifest, based
on which it would like to initiate the live session. Based on this manifest,
and for each selected Representation, the client needs to take several
decisions:
1) Determine what is the latest segment that is available on server.
2) Determine the segment availability start time of the next segment and
possibly future segments.
3) Determine when to start playout the segment and from which presentation
timeline in the segment in order to be as close as possible to the live edge.
4) Determine when to check for an updated manifest.
#### 6.2.2.3 Existing Technologies
In existing non-DASH streaming technologies these issues are solved as
follows:
\- for each segment that is made available, the server publishes a new
manifest;
\- the client, once joining the service, gets the latest manifest, looks at
the playlist and then can access the latest segment;
\- the client starts playing out the segment and expects, when playing the
segment from the beginning, that it can continue accessing the next segment in
time;
\- before fetching a new segment (or requiring to fetch one), the client
fetches a new manifest providing the location where to get the latest segment.
#### 6.2.2.4 Consequences with Existing Technologies
The following consequences result from this basic live operation as documented
in clause 6.2.2.3:
\- The manifest is updated on the server with each newly available segment:
\- This requires the client to fetch the manifest and use the information in
the manifest whenever they join, i.e. joining means manifest fetching and the
manifest needs to be the latest.
\- This requires that the server needs to update the manifest to accommodate
the change whenever a new Segment if produced. The manifest renewal is
especially critical in cases where the manifest is distributed through FLUTE
[8] or needs to be pushed into caches. In this case along with each new
segment, a new manifest needs to be pushed.
\- The client does not have any insight at what time the next segment is
available/published on the server:
\- It will expect that the next segment is published, at the latest, after
segment duration time. This can be verified by updating the manifest prior to
fetching a new segment.
\- The client does not have any insight if any presentation time later than
the earliest presentation time of the latest available segment can be played
out in order to get closer to the live edge without a risk of rebuffering
later:
\- As a fact of the loose timing model, and the client not knowing when the
next segment becomes available, it can only assume that the earliest
presentation time can played.
\- The client does not have any insight if playout of other clients that
download the same segment is synchronized.
\- The client needs to fetch a new manifest when joining the service to obtain
the latest information. This \"fetching\" requires at least one manifest fetch
round-trip time and may increase start-up.
In summary, the main reason for all these issues is that existing solutions do
not provide a good idea on the exact time schedule of the manifest and media
segment creation. As an example, if one operates on 10-second segments, the
client has little insight whether the manifest had just been published, or
whether it will be published shortly after. So the DASH client may still be
off by 10 seconds. In addition, it requires updating the manifest frequently
with every segment. No reference clock is available to the client that enables
a playout that is closer to the live edge or enables playout synchronized with
other clients. At the same time, hiding the publish time from the clients
typically provides ensures that the requests for segments from different
clients are spread.
#### 6.2.2.5 How does DASH solve this?
##### 6.2.2.5.1 Overview
DASH attempts to address the above-mentioned weaknesses, namely:
\- to operate closer to the live edge,
\- to synchronize playout of clients that are consuming the same media
presentation,
\- to avoid regular updates of the MPD on the server and fetches by the
client, and
\- to avoid fetching the MPD in real-time when joining the service.
DASH uses a wall-clock time documented in the MPD, which sets up the live
Media Presentation. DASH assumes that the MPD is generated such that the MPD
generation process does have access to an accurate clock. This enables that
clients that are synchronized to the wall-clock time by any means can operate
closer to the live edge.
##### 6.2.2.5.2 Benefits of this approach
In case the template construction with \@duration is used, the above approach
provides several advantages compared to existing solutions:
1) The MPD does not have to be updated on the server as long as the segment
construction can be continued. As long as the client records the fetch time of
the MPD, it can download the MPD ahead of time (or keep it in the buffer) for
several different services that are anticipated to be accessed, for example
different channels.
2) Also, in a multicast environment, the MPD can be distributed only once or
at least with a much smaller frequency than for every new segment.
3) The client knows exactly the time when the next segment is
available/published on the server. This permits operation closer to the live
edge as the client can request the segment as soon as it gets available.
4) In order to accurately tune to the live edge, the client may start
presentation of the first segment not from the start, but even somewhere in
the middle. The exact timing is obtained by mapping the presentation time to
the live edge time.
5) The client can synchronize its playout with other clients.
6) Server operation is simple, i.e. no special server beyond HTTP is required.
DASH uses a wall-clock time documented in the MPD, which sets up the live
Media Presentation. DASH assumes that the MPD is generated such that the MPD
generation process does have access to an accurate clock. This enables that
clients that are synchronized to the wall-clock time by any means can operate
closer to the live edge.
Specifically, the following information is available in the MPD when using a
number-template-based Representations and using the using the \@duration
attribute:
\- **MPD** \@availabilityStartTime: the start time is the anchor for the MPD
in wall-clock time. The value is denoted as _AST_.
\- **MPD** \@minimumUpdatePeriod: the minimum update period of the MPD. The
value is denoted as _MUP_.
\- **MPD** \@suggestedPresentationDelay: suggested presentation delay as delta
to segment availability start time. The value is denoted as _SPD_.
\- **MPD** \@minBufferTime: minimum buffer time, used in conjunction with the
\@bandwidth attribute of each Representation. The value is denoted as _MBT_.
\- **MPD** \@timeShiftBufferDepth: time shift buffer depth of the media
presentation. The value is denoted as _TSB_.
\- **Period** \@start: the start time of the Period relative to the MPD
availability start time. The value is denoted as _PS_.
\- **SegmentTemplate** \@startNumber: number of the first segment in the
Period. The value is denoted as _SSN_.
\- **SegmentTemplate** \@duration: the duration of a segment in units of a
time. The value divided by the value of \@timescale is denoted as _d._
Also assume that the client did fetch the MPD at fetch time _FT_. Note that a
reasonable estimate on the lower value of _FT_ is the time when the request
for then new MPD is issued and for the higher value _FT_ when the MPD is
received.
#### 6.2.2.6 MPD Times
For using the same concept with different addressing schemes, the following
two values are introduced according to ISO/IEC 23009-1:
> \- the position of the segment in the Period denoted as _k_ with _k_
> =1,2,...
>
> \- The MPD start time of the segment at position _k_ , referred to as
> _MST_(_k_).
>
> \- The MPD duration of a segment at position _k_ , referred to as _MD_(_k_).
Assuming now that the wall-clock time at the client is denoted at _WT_ , and
then the client can derive the following information:
1\. the latest available Period on the server, denoted by its period start
time _PS*_
2\. The segment availability start time of any segment at position k within
the Period, denoted as _SAST(k)_.
3\. The position of the latest segment that is available on server in the
Period, referred to as _k*_
4\. The address of the latest segment that is available on server
5\. The time when to fetch a new MPD based on the current presentation time,
or more specifically, the greatest segment position _k\'_ within this Period
that can be constructed by this MPD.
6\. The media presentation time within the Representation that synchronizes
closest to the live edge, _MPTL_.
7\. The media presentation time within the Representation that synchronizes to
other clients, _MPTS_.
#### 6.2.2.7 General Derivation
Using these times, the values from above can be derived as:
> 1\. The latest Period is obtained as the Period for which _AST_ +_PS+MD(1)_
> \
> 2\. The segment availability start time is obtained as:
_SAST_(_k_) = _AST_ \+ _PS_ \+ _MST_(_k_) + _MD_(_k_)
> Specifically, For the number-based template with _d_ the value for the
> \@duration attribute and _SSN_ the value of the \@startNumber attribute this
> results in:
_SAST_(_k_) = _AST_ \+ _PS_ \+ ( _k_ \- _SSN_ \+ 1 ) * _d_
1\. Within this Period the latest segment available on the client is the
segment at the position _k*_ which results in the greatest value for
_SAST(k*)_ and at the same time is smaller than NTP. For the number based
template with d the value for the \@duration attribute and _SSN_ the value of
the \@startNumber attribute this results in:
_k*_ = floor ( (_NTP_ \- ( _AST_ \+ _PS_ ) _\- d_ )/ _d_ ) + _SSN_
2\. The address of the latest segment is obtained by using the position
information _k*_ and then the segment address can be derived. The segment
address depends on the addressing method.
3\. Within this Period the greatest segment position k\' that can be
constructed by this MPD is the one that results in the greatest value for
_SAST(k\')_ and at the same time is smaller than _FT_ \+ _MUP_.
_k\'_ = ceil ( _FT + MUP_ \- ( _AST_ \+ _PS_ ) - _d_ )/ _d_ ) + _SSN_
#### 6.2.2.8 Derivation of MPD Times
If the \@duration attribute is present and the value divided by the value of
\@timescale is denoted as _d_ then the MPD times are derived as:
> _\- MD_(_k_) = _d_
>
> _\- MST_(_k_) = (_k_ -1)_*d_
#### 6.2.2.9 Addressing Methods
##### 6.2.2.9.1 Introduction
The addressing method is independent of the usage of the timeline generation.
The interpretation of the \@startNumber depends on the addressing method.
##### 6.2.2.9.2 Playlist-Method
If the Representation contains or inherits one or more **SegmentList**
elements, providing a set of explicit URL(s) for Media Segments, then the
position of the first segment in the segment list is determined by
\@startNumber. The segment list then provides the explicit URLs.
##### 6.2.2.9.3 Number-Based Template
If the Representation contains or inherits a **SegmentTemplate** element with
_\$Number\$_ then the URL of the media segment at position _k_ is obtained by
replacing the \$_Number_ \$ identifier by (_k_ -1) + \@startNumber in the
**SegmentTemplate** \@media string.
#### 6.2.2.10 Scheduling Playout
The client schedules the playout based on the available information in the
MPD.
The media presentation time in a Period is determined for each Representation
as presentation time value in the media segments minus the value of the
\@presentationTimeOffset, if present, for each Representation.
Each segment at position _k_ has assigned an earliest media presentation time
_EPT_(_k_).
By offering an MPD it is guaranteed that:
> 1\. each segment in this Period is available prior to its earliest
> presentation time and its duration, i.e. for all _k_ ,
>
> 2\. _SAST_(_k_) \ 5\. Each segment in this Period is available at least until _SAST_(_k_) +
> _TSB_ \+ _MD_(_k_).
Using this information, the client can now start scheduling playout taking
into account the information in the MPD as well the download speed.
A suitable playout time is _POT_(_PT_) = _MPTS_(_PT_), if the attribute
\@suggestedPresentationDelay is present. If not, then a suitable playout time
takes into account the first, second and fourth constraints, i.e. the segment
availability times at the server as well as the bitrate variation of the media
stream.
#### 6.2.2.11 Validity of MPD
The MPD can be used to construct and request segments until media time _FT_ \+
_MUP._ The greatest segment position _k\'_ that can be constructed by this MPD
is the one that results in the greatest value for _SAST_(_k\'_) and at the
same time is smaller than _FT_ \+ _MUP_. Note that the latest segment may be
shorter in duration than the other ones.
### 6.2.3 Mapping Use Cases to Live Operation
#### 6.2.3.1 Use Case A
##### 6.2.3.1.1 Description
Anna accesses the service in the bus with her mobile DASH-enabled device, and
the service is available immediately.
##### 6.2.3.1.2 MPD example
Below is a snippet of an MPD example. This MPD may have been distributed out-
of-band and ahead of time. The DASH client when accessing the service can
generally use the MPD to immediately determine the segment information.
\
\http://www.example.com/\
\
...
\
\
...
> \ presentationTimeOffset=\"2016000\" duration=\"96000\"
> initialization=\"audio/fr/init.mp4a\" media=\"audio/fr/\$Number\$\"/>
...
\
##### 6.2.3.1.3 Client Procedure
Assume further that the client has fetched the MPD at fetch time _FT_
=\"2011-12-25T12:30:17\" and the wall-clock time is _NTP_
=\"2011-12-25T12:30:27\" the DASH service to be accessed. The latest segment
number is:
_k*_ = floor ( (_NTP_ \- ( _AST_ \+ _PS_ ) _\- d_ )/ _d_ ) + _SSN_ = floor
(15/2) + 22 = 29
The URL for the latest segment is http://www.example.com/audio/fr/29.mp4. The
client access the segment and may start playout with the media time _PT_ =
(29-22+1)*96000/48000 = 16 at time _MPTS_(_PT_) = (_AST_ \+ _PS_) + _PT_ \+
_MBT_ = \"2011-12-25T12:30:31\", i.e. in 5 seconds. The client may also
download earlier segments and may start earlier with the playout process, for
example with segment 27.
#### 6.2.3.2 Use Case B
##### 6.2.3.2.1 Description
Continuing Use Case A, across from her sits Paul, who watches the event on his
DASH-enabled laptop. A goal is scored and both, despite watching on different
screens, celebrate this event at the same time.
##### 6.2.3.2.2 MPD example
Below is a snippet of an MPD example with the suggested presentation delay
added.
\
\http://www.example.com/\
\
...
\
\
...
> \ presentationTimeOffset=\"2016000\" duration=\"96000\"
> initialization=\"audio/fr/init.mp4a\" media=\"audio/fr/\$Number\$\"/>
...
\
##### 6.2.3.2.3 Client Procedure
The same procedure as in 2.3.1.3 to extract the MPD information is carried
out. For synchronized playout, the client accesses the segment and may start
playout with the media time _PT_ = (29-22+1)*96000/48000 = 16 at time
_MPTS_(_PT_) = (_AST_ \+ _PS_) + _PT_ \+ _SPD_ = \"2011-12-25T12:30:36\", i.e.
in 10 seconds. If both clients adhere to the SPD value, synchronized playout
can be achieved.
#### 6.2.3.3 Use Case C
##### 6.2.3.3.1 Description
Continuing Use Case B, Other people that follow the game on a 3GPP Rel-6 PSS
terminal observe the goal within a similar time.
##### 6.2.3.3.2 MPD example
The same as in clause 6.3.2.2 applies,
##### 6.2.3.3.3 Client Procedure
The same procedure as in 6.2.1.3 and 6.2.2.3 to extract the MPD information is
carried out. However, instead of downloading and playing only segment 29, the
client may already download segment 24 or 25 and start playout earlier. While
starting playout, the client may gradually fill the buffer with segments up to
the segment availability start time.
#### 6.2.3.4 Use Case D
##### 6.2.3.4.1 Description
Continuing Use Case C, Another goal is scored. Paul tells Anna that the first
goal in the game was even more exciting and Anna uses the offering that she
can view the event 30 minutes back in time on her DASH-enabled device. After
having seen the goal she goes back to the live event.
##### 6.2.3.4.2 MPD example
Below is a snippet of an MPD example with the minimum time shift buffer depth
of 1 hour is added.
\
\http://www.example.com/\
\
...
\
\
...
> \ presentationTimeOffset=\"2016000\" duration=\"96000\"
> initialization=\"audio/fr/init.mp4a\" media=\"audio/fr/\$Number\$\"/>
...
\
##### 6.2.3.4.3 Client Procedure
The time has moved forward to at _NTP_ =\"2011-12-25T13:32:57\". The operation
is based on an MPD that was fetched at time FT=\"2011-12-25T13:32:32\". The
client is downloading segment with segment number 1959. The event of the goal
happened 30 minutes ago. With the above MPD, the segments are available far
into the time-shift buffer of one hour. The client computes the segment with
has presentation time roughly 30 minutes back and understands that this 1 059
and starts fetching this to playout the presentation time 30 minutes ago.
After watching this for 2 minutes, the user wants to move forward into the
future again. Based on an updated MPD (necessary as the live edge is no longer
presented in the MPD above, the client can then compute the latest segment at
the live edge and perform the same operations as in cases documented in
clauses 6.2.1.3, 6.2.2.3 and 6.2.3.3.
#### 6.2.3.5 Use Case E
##### 6.2.3.5.1 Description
Continuing Use Case D, the football match gets into overtime, the star player
of CF Anolacrab, Lenoil Issem, is brought into the game by the coach of the
year, Aloidraug, hits twice the post, but cannot score. Due to the
extraordinary tension in the match, more and more users join such that the
service provider requires migrating the service to the redundant
infrastructure without interrupting the service to the users.
##### 6.2.3.5.2 MPD example
Below is a snippet of an MPD example with a new server location added.
\
\http://www.example.com/\
**\ http://www.example-massive-scalable.com/\**
\
...
\
\
...
> \ presentationTimeOffset=\"2016000\" duration=\"96000\"
> initialization=\"audio/fr/init.mp4a\" media=\"audio/fr/\$Number\$\"/>
...
\
##### 6.2.3.5.3 Client Procedure
Clients updating the MPD may observe that a new server location is available.
Based on poorer download experience with the original server location, the
clients are expected to probe the new server location and when observing
better download experience, they are expected to use this new server location
and move away from the old one.
#### 6.2.3.6 Use Case F
##### 6.2.3.6.1 Description
Continuing Use Case E, finally penalty shooting is necessary. The live event
is interrupted by a short break during which advertisement is added. The exact
timing of the ad breaks is unknown due to the extra time of the extension and
the start of the penalty shooting is delayed.
##### 6.2.3.6.2 MPD example
Below is a snippet of an MPD example with a new Period added for ad insertion
and then the live program is continued.
\
\http://www.example.com/\
\http://www.example-massive-scalable.com/\
\
...
\
\
...
> \ presentationTimeOffset=\"2016000\" duration=\"96000\"
> initialization=\"audio/fr/init.mp4a\" media=\"audio/fr/\$Number\$\"/>
...
\
\
...
> \ initialization=\"http://adserver.com/audio/fr/init.mp4a\"
> media=\"http://adserver.com/audio/fr/audio/fr/\$Number\$\"/>
...
\
\
...
> \ presentationTimeOffset=\"18146784000\" duration=\"96000\"
> initialization=\"audio/fr/init.mp4a\" media=\"audio/fr/\$Number\$\"/>
...
\
##### 6.2.3.6.3 Client Procedure
With another update the client obtains an MPD with a new Period that points to
an ad server. The advertisement is scheduled for 60 seconds and after this it
returns to the main program.
### 6.2.4 Gap Analysis
Despite the improved timing control and the advantages of the DASH solution,
the following aspects are crucial and may need more considerations, especially
when operating on a low-latency live service:
1) The server and the client need to have accurate UTC timing. There is no
requirement how to implement this, but it still requires implementation of a
globally accurate timing standard on both ends. NTP is considered as one
option, but the NTP protocol may not be accessible to clients that rely on the
HTTP protocol only. Simpler methods for client-server synchronization may be
desired.
2) Server overload as all clients may access the segment at the same time as
the segment availability time is exposed explicitly. This problem needs
further investigation.
3) A more accurate resolution of time is necessary (seconds may be to coarse
to operate on at the live edge).
4) Drift of the video source compared to UTC.
5) Leap seconds.
### 6.2.5 Working Assumptions
As MPEG has ongoing work and core experiments on improved live services, it is
proposed to complete the work in MPEG, but potentially send 3GPP specific
requirements to MPEG in order to ensure that these aspects are taken into
account.
## 6.3 Use Cases for Content Protection
### 6.3.1 Use Case A -- Efficient Caching for Multiple DRM Systems
#### 6.3.1.1 Description
Service provider \"WebMedia\" acquires various video contents from movie
studios and TV broadcasters for delivery over DASH to its registered
subscribers. Some of these programs, such as newly-released movies and hit-
series TV episodes, are premium content for which the content providers assign
usage rights or licenses through WebMedia for access by its subscribers.
WebMedia employs three popular DRM systems, Playball, Fairgame and Grapewine
to provide the requisite content protection. Furthermore, a common encryption
mechanism \"FooCrypt\", featuring the use of a single encryption algorithm
(but changeable across programs) and common encryption parameter values for
any given content item, is implemented by all three of these DRM systems. This
enables distribution and caching of the same segments despite different DRM
systems are used. WebMedia specifies the use of FooCrypt for content
encryption, and ensures that all WebMedia-capable end user devices support
FooCrypt in conjunction with one of Playball, Fairgame or Grapewine DRM
Agents. Upon DASH-based consumption of such encrypted content, the DRM Agent
grants the security key for content decryption and rendering in accordance to
the DRM rights or license associated with that content item. WebMedia passes
content usage information and any payments to its content providers as
dictated by business agreements.
#### 6.3.1.2 Actors\' issues
\- Content Provider -- Wants to ensure controlled (and possibly paid) access
premium content delivered by its designated service provider, in accordance
with assigned usage rights.
\- Service Provider -- Wants the ability to honour business contract with
content provider for rights-based content access. Desires the simplicity and
cost effectiveness of providing a single encrypted version of protected
content that is compatible with multiple DRM systems to be supported.
\- User device vendors -- want to implement content protection which meet
service provider requirements with minimum complexity.
\- End user -- wants seamless user experience in viewing HTTP streamed
content, and be fully agnostic of any underlying DRM and decryption
mechanisms.
#### 6.3.1.3 Analysis in the Context of Rel-10 TS 26.247
TS 26.247 [2] is agnostic to the DRM that is used. However, neither in TS
26.247 nor in 3GPP file format TS 26.244 [5] is there explicit support for
common encryption.
### 6.3.2 Use Case B -- Signalling of Rights/License Acquisition Information
in MPD
#### 6.3.2.1 Description
The MLF (Major League Football) via its designated DASH service provider,
wishes to make available live transmission of the 2012 SuperBall game to its
subscribers. The game event is targeted to Snoozzz.com enabled clients, all of
which support the OpraDRM content protection standard, on devices equipped
with the OpraDRM Agent. The OpraDRM related protection information, i.e. the
URL to the rights issue operated by Snoozzz.com for acquiring the associated
rights and keys, is nominally contained in the DASH initialization segment.
The service provider expects a large audience turnout for reception of the
game transmission, but unfortunately, its rights issuer servers have limited
TPS (Transactions Per Second) capability to handle the expected high traffic
load. Snoozzz.com is concerned of potentially inferior user experience in
excessive start-up delay of playout. Therefore, it desires an alternative
means for delivering rights/licenses acquisition information, or the
rights/license itself, to user devices prior to the game. This would allow for
the rights/licenses and corresponding key material to be already fetched,
cached and made ready for use by the device when the SuperBall game begins.
#### 6.3.2.2 Actors\' issues:
\- Content Provider -- Wants to ensure its designated service provider can
deliver protected live events with low start-up delay.
\- Service Provider -- Wants to minimize or better control start-up delay
given limited processing capability of its servers to handle rights/licenses
acquisition traffic.
\- User device vendors -- Want to implement content protection which meet
service provider requirements with minimum complexity and high performance.
\- End user -- Wants seamless user experience in viewing live HTTP streamed
content, and be fully agnostic of any underlying DRM and decryption
mechanisms.
#### 6.3.2.3 Analysis in the Context of Rel-10 TS 26.247
TS 26.247 is agnostic to the DRM that is used. However, neither in TS 26.247
nor in 3GPP file format TS 26.244 [5] is there explicit support for common
encryption.
In addition TS 26.247 allows the use of Early Available Periods as defined in
clause 8.4.2 of TS 26.247. An MPD may contain a Period that can be provided
without a start time of the period. This means that the Period is expected to
occur and any resources indicated in the Period structure are available, but
the actual start time of the Period is only determined with updates of the
Period. In this case, Content Protection relevant scheme specific information,
such as DRM server URL etc., may be added to the content protection element.
In this case the structure of the Period is announced without a start time
(see example below in bold).
\
> .....
\
**\ 
...
> \
>
> \
>
> ...
>
> \
>
> **\ **
\
\
At the time when it is know that the first Media Segment is available, the
start time may be added.
**\ **
> .....
\
....
**\ 
...
> \
>
> \
>
> ...
>
> \
>
> **\ **
\
\
### 6.3.3 Use Case C -- Time-Varying Decryption Keys
#### 6.3.3.1 Description
A service provider employs broadcast delivery of live TV services to its
users. For protected content, it needs the ability to dynamically change
encryption keys, as well as introduce new keys, over the duration of a program
transmission. One reason is to ensure greater security for premium content
delivery. The service provider also requires the ability to provide overlaid
rendering onto the main program, a prerecorded program segment that is
protected with a different key; it wants to be able to make such combined
presentation decision just before content delivery time.
#### 6.3.3.2 Actors\' issues:
\- Service Provider -- for protected live programs, it wants:
a) The capability to dynamically vary encryption keys and the associated
rights/licenses for greater security.
b) The ability to carry time-varying encryption keys inband with the live
program delivery.
c) The usability of key rotation with inband key delivery mechanism by both
content protection (DRM) and service protection (CAS) technologies.
d) The capability for key rotation with inband key delivery mechanisms to be
useable by multiple concurrent schemes within a given protection technology
type (DRM or CAS) in the course of common encryption of the content (see Use
Case 3.5.1).
e) The capability for key rotation with inband key delivery mechanisms to be
useable by multiple concurrent schemes within multiple protection technology
type (DRM and CAS) in the course of common encryption of the content (see Use
Case 3.5.1).
f) Ability for \"just in time\" decision on combining the presentation of
prerecorded content, protected by different keys, with the main program.
\- User device vendors -- Wants to be able to acquire any changed or new
licenses/keys in a timely manner to avoid potential presentation problems.
\- End user -- Wants seamless user experience in viewing live HTTP streamed
content, and be fully agnostic of any underlying DRM and decryption
mechanisms.
#### 6.3.3.3 Analysis in the Context of Rel-10 TS 26.247 [2]
There is no explicit support for key rotation in TS 26.247 [2] and TS 26.244
[5].
## 6.4 Fast Media Start-up
### 6.4.1 Description
Alice clicks through in a browser session to start consuming DASH. She is
delivered an initial download of data and this allows her user agent to begin
fetching media segments. In due time, Alice\'s user agent downloads all of the
MPD data and Alice is enabled to use all features enabled by the MPD.
### 6.4.2 Analysis in the Context of Rel-10 TS 26.247
Media startup is influenced among others by:
\- the size of the initial MPD
\- the amount of requests before the first media is downloaded
Different means exist in TS 26.247 [2] to keep the initial MPD of a service
compact and minimize the amount of requests necessary to start playout. Among
others, the following tools may be used:
\- For On-Demand cases, Self-Initializing Media Segments may be used. In this
case the MPD is compact and the download of the Segment Index allows for
proper scheduling of subsegment requests. The segment index itself may be
hierarchically, so downloading of the initial portion is sufficient to start
media download. Typically two or at most three requests are necessary to
obtain the first media.
\- Segment templates: By using segment templates, the MPD size is small and
independent of the segment size. The usage of segments to generate the
appropriate HTTP-URLs is discussed in detail in TS 26.247 as well as in clause
6.2 of the present document. Only the MPD request and the request for the
Initialization Segment and the first media segment is necessary.
\- Xlink: In order to keep the initial MPD small, Segments or Periods with a
later media presentation time may be added to remote elements by using xlink.
Xlink may be used in combination with Periods, Adaptation Sets and Segment
Lists. It also allows that in case of dynamic live services, \"older\" content
is moved to remote elements.
Generally, TS 26.247 provides sufficient means to support fast media start-up.
## 6.5 Advanced Trick Modes
### 6.5.1 Description
Lisa consumes the latest series of the show \"X\" in SD coded at a bitrate of
2 MBit/s that is distributed to an DASH-ready Client set. Her client is
equipped with a H.264/AVC video decoder that is capable to handle H.264/AVC
High Profile level 3.0. All of a sudden the phone rings and she pauses the
service.
After the phone call, she resumes the service, but realizes that she wants to
go backward in time, as she cannot remember the start of the scene. She seeks
backward to the last scene changes and resumes the service from there.
After a while she needs to leave for her Football practice and she decides to
continue to watch the movie from her smart phone with H.264/AVC CBP level 1.3.
She enters the service and does a fast-forward 64-times of the original speed
to the position where he stopped on the TV set. Once she is close, she reduces
the search speed gradually down until she recognizes the position. Once the
position found, she resumes the service at normal playback speed.
She meets her friend Max and pauses the service. She remembers the great scene
in the show wants to share the scene with her friend. She seeks backward in-
time and finally gets to the scene and shares it with her friend.
### 6.5.2 Analysis in the Context of MPEG-DASH and Rel-10 TS 26.247
#### 6.5.2.1 Overview
TS 26.247 and MPEG-DASH provide different means to support trick modes. The
most relevant ones are:
\- dedicated trick mode Representations with frequent IDR frames or IDR-frame
only. The latter can be provided by using the \@codingDependency flag may be
set to false for video representations to indicate that a Representation is
IDR-frames only.
\- Sub-Representations may be used to signal temporal subsequences in
Representations. This is discussed in more detail in the following aligned
with ISO/IEC 23009-3 [10].
#### 6.5.2.2 Sub-Representations
#### 6.5.2.3 MPD authoring
The MPD file for this use case should be prepared in accordance to general
constraints for ISO Base media file format On Demand profile, specified in
clauses 8.1, 8.3.1, and 8.3.2 of ISO/IEC 23009-1.
In addition, the following conditions should be satisfied:
\- The **SubRepresentation** element should be contained at the
Representation.
\- The **SubRepresentation** \@level should be present.
\- The **SubRepresentation** \@dependencyLevel should be provided to indicate
the dependencies among SubRepresentations.
#### 6.5.2.4 Segment generation
Media segments for this use case should be prepared in accordance to general
constraints for ISO Base media file format On Demand profile, specified in
clauses 8.1, 8.3.1, and 8.3.3 of ISO/IEC 23009-1.
In addition the following conditions as taken from ISO/IEC 23009-3 [10] should
be satisfied:
1) The Initialization Segment should contain the Level Assignment (\'leva\')
box with the same levels as provided in **SubRepresentation** \@level.
2) All Media Segments should conform to Sub-Indexed Media Segments as defined
in ISO/IEC 23009-1, clause 6.3.4.4 and therefore should include \'sims\' as
compatible brand in the \'styp\' box.
3) If the **SubRepresentations** defined by the levels in the \'leva\' box
have assignment type equal to 0 or 1 for a track, the Media Segments should
contain the \'sbgp\' (sample to group) box in the corresponding \'traf\' and
the \'sgpd\', in case the corresponding \'sgpd\' is not included in the
\'stbl\' in the Initialization Segment.
4) If the **SubRepresentations** defined by the levels in the \'leva\' box
have assignment type equal to 2, a single movie fragment is contained in the
Subsegment and each of the level contains data of a single track of the tracks
indicated in the \'trak\' boxes in the \'moov\' box.
5) If the **SubRepresentations** defined by the levels in the \'leva\' box
have assignment type equal to 3, more than one movie fragment is contained in
the Subsegment and each of the level contains data of a movie fragment.
6) If the **SubRepresentations** defined by the levels in the \'leva\' box
have assignment type equal to 4 for a track, the Media Segments will contain
the \'sbgp\' (sample to group) box in the corresponding \'traf\' and the
\'sgpd\', in case the corresponding \'sgpd\' is not included in the \'stbl\'
in the Initialization Segment. Furthermore, the Media Segment will contain a
\'udta\' box with a \'strk\' box. The \'stsg\' box in the \'strd\' of the
\'strk\' contains information to identify the sample grouping information in
the \'sbgp\' box.
7) Data from lower levels should not depend on data in higher levels.
There are four possibilities of generating the segments in order to allow for
trick modes, i.e. 3), 4), 5) and 6).
When (3) is considered and assuming the trick mode is performed only for the
video media component, there is a single track with sample groups for
describing the different level (e.g. the \'tele\' sample group). In this case,
as well as if level definition is based on subtracks (6), it is necessary to
arrange all the samples belonging to each of the leves at the beginning of the
Subsegment. As an example Figure 6.1 shows how this can be done for fast
forwarding using the sample grouping \'tele\' for a video stream encoded with
AVC with GOP size 4 using bi-predictive hierarchical pictures, i.e. with
Structure IB~1~B~0~B~1~P... in presentation order.
{width="5.01875in" height="2.036111111111111in"}
Figure 6.1: Movie fragment format for arranged samples for easing fast forward
with \'ssix\' box
Since it is necessary to group the samples in temporal order it is necessary
to split the \'trun\' in multiple \'trun\'-s. For such an arrangement of the
samples in an order different from the decoding order, it is necessary to add
multiple \'trun\' boxes in order to still provide the correct decoding time.
Whenever two contiguous samples in the \'mdat\' do not have decoding time
following each other, a new \'trun\' is needed. Then the different levels
could be described e.g. as level 0 containing I and P frames, level 1
containing B~0~ frames, level 2 B~1~ frames and so forth.
If (4) of (5) are considered, i.e. \'leva\' box with assignment type 2 or 3,
the usage of extractors would be needed for preparing the content for allowing
fast forward trick mode.
In Figure 6.2 an example of the format segment for supporting
**SubRepresentations** for an assignment type other than 3 is shown. In this
case the \'moof\' box contains all the tracks and a Subsegment should consist
of a single movie fragment. The yellow arrows and the dashed lines correspond
to the position until which the data belonging to the first level is present,
which is indicated in the \'ssix\'. In this example only two levels are
considered and the second expands until the end of the Subsegment (in this
case movie fragment).
{width="5.372916666666667in" height="1.479861111111111in"}
Figure 6.2: Example of usage of \'ssix\' box for Sub-Representations for self-
initializing segment with assignment type in \'leva\' box other than 3
In Figure 6.3, an example of a Segment format for assignment type equal to
three is shown. As it can be seen in this figure, each of the movie fragments
contained within a Subsegment contains data from different tracks. In this
case the byte ranges provided by the \'ssix\' box should contain whole numbers
of movie fragments.
{width="6.564583333333333in" height="1.3069444444444445in"}
Figure 6.3: Example of usage of \'ssix\' box for Sub-Representations for self-
initializing segment with assignments type in \'leva\' box equal to 3
In general, when the tracks are used to perform sub-representation extraction
(e.g. for trick modes), if several tracks describe one media component,
extractors are used and only one track of those is played accessing to the
samples in other tracks by reference by the extractors. The usage of
extractors should be done very carefully if combined with sub-representations.
If extractors are used in higher levels pointing to lower levels there would
not be any problem at the client side but if extractors are used in the
segments, and these are stored in the lower level pointing to data in higher
levels, DASH Clients may try to access non existing data. Therefore, special
care should be taken to use extractors in lower levels if assignment type
other than 3 is used and the padding_flag in the \'leva\' box is set.
#### 6.5.2.5 Summary
Trick modes are well supported in TS 26.247.
## 6.6 Content and Device Interoperability
### 6.6.1 Use Case Description
Streaming service provider WebMedia has decided to deploy streaming services
based on 3GP-DASH to 3GPP UEs. WebMedia does not have any requirements on the
codecs, but due to its large library encoding and transcoding of content is
expensive. WebMedia wants to distribute the content efficiently through a CDN
and also efficiently over 3GPP access networks. At the same time WebMedia
wants to avoid to provide specific Representations for 3GPP devices, but wants
to distribute the same content to TV sets, Set-Top boxes and other fixed net
devices. To fulfil regulatory requirements and other user demands, WebMedia
also needs support for subtitles and closed captioning.
For cost and scalability reasons, WebMedia wants to use exactly one
Representation to provide a certain quality for audio and video. WebMedia
wants to deliver content to three different terminal classes:
\- Devices supporting WQVGA video rendering and stereo sound, i.e.
400x240\@24fps
\- Devices supporting WVGA video rendering and stereo sound, i.e.
800x480\@25fps
\- Devices supporting HD video rendering and multichannel sound with display
capabilities to be defined. For HD video, WebMedia also has requirements on
content protection, namely that at least one of the three DRMs are supported:
ReadyPlay, WineWide and PlayFair.
WebMedia is also very cautious to provide best user experience when switching
Representations within one Adaptation Set are switched for rate adaptation
purposes. Therefore, the MPEG DASH functionalities:
\- segment indexing for On-demand services
\- number-based segment templating for their newly introduced live service
\- segment alignment and subsegment alignment
\- starts with SAP is set to 2
is integrated in the content preparation.
### 6.6.2 Working Assumption
Specific profile restrictions are aligned with common industry practice.
### 6.6.3 Gap Analysis
3GP-DASH as defined TS 26.247 lacks a profile that is aligned with existing
industry practices.
## 6.7 Advanced Support for Live Services
### 6.7.1 Description
The use extends the live service use cases in clauses 6.2, 6.3 and 6.4.
In certain deployment scenarios, low latency for a live distribution service
is essential. One example is the in-venue distribution of an event, such as
sports event or a concert. In this case, the delay between the actual live
action and the presentation on a mobile device is most appropriate as low as
possible in the range of a few seconds at most. Other low latency use cases
include betting applications or events with user interaction, etc.
In a deployment scenario, the distribution may happen completely or partially
not over unicast, but supported by multicast or broadcast as for example
defined in TS 26.346 [3].
### 6.7.2 Working Assumption
Tools defined for advanced live services are preferably aligned with
technologies defined in other organizations, such as in HTTP/1.1 or MPEG-DASH
second edition [22].
### 6.7.3 Gap Analysis
3GP-DASH as defined TS 26.247 lacks tools and guidelines for low-latency live
services.
6.7.4 Potential Solutions
MPEG-DASH second edition [22] defines certain tools for this purpose that may
be considered to improve latency.
For Live services, chunked delivery per RFC 2616 [6] in TS 26.247 may be
explicitly enabled so as to support partial delivery of Segments prior to
their availability.
## 6.8 Consistent QoE/QoS for DASH users
### 6.8.1 Description
A network operator deploying DASH services or a network operator supporting
the delivery of DASH services of a service provider has the ambition to
provide consistent quality for users in its network. For this purpose, the
content provider wants to provide sufficient QoE to all users that have been
granted acquisition to the network and the service. It may also have the
ambition to provide certain premium users to maintain a certain service
quality when the user plane is congested.
The operator may want to influence its QoS control and radio resource
management to actively support such use cases.
The following three cases can happen:
\- The operator is able to read the MPD and knows how client will use the MPD
in terms of issuing requests for specific Adaptation Sets, Representations,
and so on.
\- The operator is able to read the MPD but does not know how client will use
the MPD.
\- The operator does not have access to the MPD.
### 6.8.2 Proposed Work
To identify the relevant aspects in this area it is proposed to work on the
following aspects:
\- Define an end-to-end reference architecture to understand the different
components in the application and network and to what extent they influence
the rate control. This includes servers, QoS architecture, RRM and schedulers
as well as the clients implementation for among others, TCP congestion
control, HTTP usage, selection of Adaptation Sets, buffer sizes and rate
adaptation.
\- Define a simple reference client architecture that decomposes the different
components in the client that influence performance of the work.
\- Define some indicative performance metrics for streaming experience to
discuss different options and solutions.
\- Identify the performance of a DASH client when operating with and without
specific treatment in the network, possibly with client support.
\- Communicate with SA1 on the specific DASH-specific aspects for UPCON and
the progress on UPCON.
\- Considering potential optimization on the various components.
The benefit of signalling events of MPD updates will be investigated in the
context of this use case.
### 6.8.3 Utilization of QoS Information in DASH
The topic of QoS support for DASH services has been an active area of
discussion in 3GPP SA4 since Release 10 and has resulted in specification work
on the derivation of QoS mapping guidelines from the DASH MPD in 3GPP TS
26.247 (informative Annex I) [2] to be used by the application function (AF)
of 3GPP Policy Charging and Control (PCC) architecture [15], [16], [17], and
[18].
A DASH client may take into consideration available QoS information when
requesting representations such that the consumed content bandwidth remains
within the limits established by the signalled QoS information. Detailed LTE-
based evaluation results on the performance benefits of utilizing QoS
information in DASH client adaptation logic are provided in Annex B.
It should be noted that in the 3GPP system, PCC-level signalling can already
accomplish the communication of network QoS information to the client device
(user equipment or UE) and therefore the DASH client can locally (within the
UE) obtain the QoS information via internal APIs.
The PCC architecture is defined in TS 23.203 [15] and provides the Rx
reference point, which enables the application layer to authorize a specific
usage. In this architecture the DASH HTTP streaming server or any other
function in the HTTP streaming path (e.g. an HTTP proxy) can act as
Application Function and interact with the PCRF via the Rx reference point for
QoS control. It is assumed here that the AF has knowledge of the application
type and of the MPD. The relevant AVPs are the ones enabling the PCRF to
establish bearers with correct characteristics for DASH users. The AVPs are
defined in TS 29.214 [18]. The further PCRF mapping from AVP to IP QoS
parameter mapping is defined in TS 29.213 [17].
Figure 6.4 depicts an example PCC architecture delivering end-to-end QoS
support for DASH services with the capability to interpret the media
presentation description (MPD) in order to gain information on the
application-layer parameters for DASH content. In the current PCC
architecture, the application function (AF) interacts with the applications
requiring dynamic policy and charging control. Hence, in order to provide QoS
for DASH services, the AF can extract DASH content information from the MPD,
map it into the appropriate attribute-value pairs (AVPs), and provide the AVPs
to the policy and charging rules function (PCRF) over the Rx reference point.
The PCRF combines the DASH-related AVPs received over the Rx reference point
and the input received from the Gx and Gxa/Gxc reference points with user-
specific policies data from the subscriber profile repository (SPR) to form
session-level policy decisions and provides those to the PCEF and BBERF. In
other words, the PCRF takes the subscriber information into account when
setting QoS. Access-specific QoS parameters are then communicated to the UE
from PCEF/BBERF. In particular, [19] describes how the UE acquires QoS
information during dedicated bearer activation and bearer modification with
bearer QoS update. It is also noted in [19] that \"application usage of the
EPS bearer QoS information is implementation dependent\".
Figure 6.4: An example policy and charging control (PCC) architecture to
deliver QoS for DASH services
## 6.9 DASH as download format
### 6.9.1 Description
A content provider wants to offer content with multiple languages as well as
with possible different video bitrates such that clients can access according
to their capabilities and user preferences. The content provider is looking
for a format that is supported in 3GPP and also considers distribution over
HTTP/TCP/IP and multicast MBMS.
The content provider is quite disappointed to not find any such format until
he reads TS 26.247 [2] and MPEG DASH. Looking at the example for the basic-on-
demand profile copied below, the DASH Media Presentation perfectly describes a
format the can also be used for download services. The MPD permits to offer
DVD-like content as download content. The content provider decides to use the
MPEG DASH formats for download delivery over unicast and multicast, but it is
required to provide all the necessary signalling to completely support this.
* * *
\\ \\ \
\http://cdn1.example.com/\\
\http://cdn2.example.com/\\ \ \\ \\ \\ \\
\\
\7657412348.mp4\\ \\ \\ \3463646346.mp4\\
\\ \\ \\ \\ \\ \\ \\ \3463275477.mp4\\ \\
\\
\5685763463.mp4\\ \\ \\
\\ \\ \\ \\ \796735657.mp4\\
\\ \\ \\ \\
\\
\\
\8563456473.mp4\\ \\ \\
\56363634.mp4\\ \\ \\
\562465736.mp4\\ \\ \\
\41325645.mp4\\ \\ \\
\89045625.mp4\\ \\ \\
\23536745734.mp4\\ \\ \\
\\ \
* * *
6.9.2 Analysis against TS26.247
3GP-DASH formats are defined to support download services, especially for
advanced use cases for which access to individual components of the media is
relevant. However, TS26.247 in section 6.3 only permits two types of file
format for progressive download. In order to support this feature, a dedicated
profile may be defined:
\- single period
\- single segment per Representation
\- presence of segment index for download scheduling
\- no requirements on segment alignment and IDR frames
This profile may then be added to section 6 of TS 26.247 [2] as a supported
profile for progressive download over HTTP. Implementation guidelines may be
added to provide details on how to use the format as download and progressive
download format.
## 6.10 Use Case: Use case description for Efficiency of HTTP-caching
infrastructure on DASH
### 6.10.1 Description
As illustrated in Figure 6.5, heterogeneous UEs with varying capabilities in
terms of processing power, rendering and display techniques are connected to a
3GPP network. A DASH-based service that offers stored (VoD) and live video
content needs to address this device heterogeneity by offering representations
that match the capabilities of the UEs, e.g. 2D or 3D video at various
resolutions, e.g. as low as VGA up to 1080p. The nature of wireless
connectivity leads to varying channel conditions for UEs that affect available
bandwidth and adds further need for adaptivity in terms of multiple
representations per content with different bitrates.
{width="6.692361111111111in" height="2.875in"}
Figure 6.5: Multi-representation content and UE heterogeneity ((c) copyright
2008, Blender Foundation / www.bigbuckbunny.org)
A DASH-based service is used to deliver multi-representation video content
over a 3GPP network to heterogeneous UEs as illustrated in Figure 6.6. HTTP
caching infrastructure is available to be used in the core network. The
request characteristics cover different scenarios, e.g. network congestion on
the access link or congestion free transmission.
{width="6.125in" height="2.307638888888889in"}
Figure 6.6: Illustration of the infrastructure for a DASH-based service
6.10.2 Analysis against TS 26.247
The use is fully supported since Rel-11 of TS 26.247. The example below shows
a service offering that enables the use cases as documented in Figure 6.6.
+----------------------------------------------------------------------+ | \\ | | \\ | | \ | | \http://www.example.com/\\ | | \ | | \\ | | \\ | | \\ | | \\ | | \\ | | \ | | | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \ | | | | \ | | | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \ | | | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \ | | | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \\ | | \ | +----------------------------------------------------------------------+
## 6.11 Use Case: Multiple Spectator Views offered with DASH
### 6.11.1 Description
Much of the discussion on 3GP-DASH has focused on use cases in which a
professional content provider has prepared content such as a movie at
different bitrates, resolutions, etc. Another interesting use case is that
media is recorded by multiple spectators of an event in different locations
and/or recording orientations on handheld devices and uploaded to a server.
Location could be determined via GPS for outdoor events or via numerous other
means for indoor events (such as WLAN RF fingerprint, WLAN and cellular
fingerprint, Bluetooth beams, etc.) The determination of location and
recording orientation is obviously outside the scope of 3GP-DASH and is not
proposed to be studied as part of the study item. Users at the same event can
record video with cell phones or tablets and upload or stream the content to a
server. The transfer of the media content from the recording device to the
server is outside the scope of 3GP-DASH and is not proposed to be studied as
part of the study item.
When this content is downloaded via a DASH server, information about the
location and orientation of the recording device at the event might be
relevant in choosing which Adaptation Set or media presentation time to
consume. For example, if users record content at an event such as a hockey
game, the DASH client might switch to an Adaptation Set showing a view closer
to the net at the time of a goal. On the other hand, if a fight breaks out at
centre ice, the client might switch to an Adaptation Set that corresponds to
video that was recorded closer to centre ice or had zoomed in on the players.
Note that there may be other ways of tagging the content besides location and
orientation (for example a particular hockey player that is wearing a helmet
cam may be tagged, etc.). Users could go to a website and select relevant
times of interest at a particular event and the corresponding times and
locations for these instances could be downloaded to the user\'s client
device. For example, a user might select instances of dunks or blocks in a
basketball game or instances where a particular player scored, etc. The user
might be provided a checklist where they could check multiple types of
instances that they are interested in. By downloading the time and position of
these relevant instances, the client or user might determine which Segments or
Representations to download based on the corresponding view of the event (the
position, orientation, amount of zoom, etc. of the camera). The server might
also customize the MPD or content for the user based on their selections.
Downloading of the relevant times and positions is just an example application
and does not need to be included in 3GP-DASH.
### 6.11.2 Gap Analysis
#### 6.11.2.1 File support for timed position/location
The device should be able to record location and orientation information
dynamically as media content is recorded. The device location could be
described in terms of latitude, longitude, and altitude as is done in the
location information box in 3GPP TS 26.244 [5].
The \'Location Information box\'\' [7] (a static box) is as specified in Table
6.2 below:
Table 6.2: The Location Information box
* * *
Field Type Details Value **BoxHeader**.Size Unsigned int(32)  
**BoxHeader**.Type Unsigned int(32) \'loci\' **BoxHeader**.Version Unsigned
int(8) 0 **BoxHeader**.Flags Bit(24) 0 Pad Bit(1) 0 Language Unsigned
int(5)[3] Packed ISO-639-2/T language code  
Name String Text of place name  
Role Unsigned int(8) Non-negative value indicating role of location  
Longitude Unsigned int(32) Fixed-point value of the longitude  
Latitude Unsigned int(32) Fixed-point value of the latitude  
Altitude Unsigned int(32) Fixed-point value of the Altitude  
Astronomical_body String Text of astronomical body  
Additional_notes String Text of additional location-related information
* * *
where Longitude, Latitude, and Altitude have the following semantics:
> **Longitude** : fixed-point 16.14 number indicating the longitude in
> degrees. Negative values represent western longitude.
>
> **Latitude** : fixed-point 16.14 number indicating the latitude in degrees.
> Negative values represent southern latitude.
>
> **Altitude** : fixed-point 16.14 number indicating the altitude in meters.
> The reference altitude, indicated by zero, is set to the sea level.
In addition to location, the device orientation can be described according to
the direction the camera is facing and how it is tilted and rotated. This is
illustrated in Figure 6.7 below:
{width="3.0006944444444446in" height="2.704861111111111in"}
Figure 6.7: Device orientation
The parameters Pan, Rotation, and Tilt should be defined to describe device
orientation just as Longitude, Latitude, and Altitude describe the device\'s
position. In addition to the above parameters, a parameter defining the amount
of optical or digital zoom could also be useful as a person farther away with
more zoom might have a preferable view to another person who is closer to the
event with less zoom.
There is support in the ISO Base Media File Format [7] for a timed metadata
track. The SDL code for the sample description box is given as follows:
aligned(8) class SampleDescriptionBox (unsigned int(32) handler_type)
extends FullBox(\'stsd\', 0, 0){
int i ;
unsigned int(32) entry_count;
for (i = 1 ; i \ **4.6.5 Infrastructure for the send() method** | | > | | > The **same-origin request event rules** are as follows: | | > | | > **If the response has an HTTP status code of 301, 302, 303, 307, | | > or 308** | | > | | > If the redirect violates infinite loop precautions this is | | > a [network | | > erro | | r]{.underline}. | | > | | > Otherwise, run these steps: | | > | | > Set the [request | | > UR | | L]{.underline} to | | > the [UR | | L]{.underline} conveyed | | > by the Location header. | | > | | > If the [source | | > origin]{ | | .underline} and | | > the [origin]{.underli | | ne} of [request | | > URL]{.unde | | rline} are [same | | > origin]{.underline} **transparently | | > follow the redirect** while observing the [same-origin request | | > event | | > rules]{.underline}. | | > | | > Otherwise, follow the [cross-origin request | | > steps]{.underline} and | | > terminate the steps for this algorithm. | +----------------------------------------------------------------------+
So assuming that only transparent redirects are supported, the only possible
redirects would be to media segments of a different representations. In other
words, the client would request a segment from one representation but the
response is a redirection to a media segment from another representation. This
trick might work only if the used media codecs and configuration information
are identical, the request does not contain a byte range, and the segments are
time aligned.
Even under those very strong restrictions, the DASH client may still get
confused because of the different bandwidth of the segments. The client will
be downloading the media segments at a faster pace, if it gets segments from a
lower bandwidth representation. This might trigger the client to try to switch
to an even higher representation, which will cause even more problems.
Now assuming that redirects do not get followed automatically, in which case,
the client will receive a redirection message and the entity body, which might
be a textual or HTML fragment. Without knowing the content and format of that
response, the DASH client will not be able to interpret the contents of the
body and might simply send a GET request to the new resource location.
In other words, the redirection approaches with existing status codes and
semantics may not work, unless the client understands the semantics of the
redirections and knows how to interpret the body of the redirection message
and then extracts the information about the Representations it should consume,
this approach will not work.
Additional redirection methods may be considered that take into account:
\- redirecting not to a specific object, but to a sequence of object or a new
BaseURL
\- consistent implementation of such redirection methods in order to ensure
that the redirection information is passed to the DASH client.
#### 6.13.3.3 Bandwidth Throttling
The two key issues in video delivery are user experience and delivery
efficiency/costs. One of the key performance indicators for video streaming is
continuous loss-free playout. Rebuffering and packet losses are considered as
the most severe degradation in video delivery. DASH addresses these issues by:
\- relying on a reliable transport protocol, namely HTTP/TCP, and
\- by providing multiple switchable versions of the same content at different
bitrates (aka representations). This enables the client to control its buffer
states and choose the requested representations appropriate to the available
access bandwidth in order to maintain continuous playout.
Adaptation to changing network conditions such as congestions are naturally
handled by TCP congestion control and the end-to-end rate adaptation, driven
by the DASH client.
When running TCP in a congested network the TCP throughput is reduced due to
increased packet delays and losses. The bandwidth reduction is a reaction to
reduced TCP throughput reacting to the above effects packet delay and packet
loss. The DASH client will observe the reduced TCP throughout and will
therefore use its rate adaptation to adjust the requested bandwidth in order
to maintain proper throughout.
The well-known TCP throughput upper bound can be used:
rate \ MPEG-DASH provides this by offering a single MPD which may contain different
> content. The content is \"concatenated/spliced\" into a single time line
> which provides exact timing of the contained media. The exact details on
> what \"concatened/spliced\" means is discussed in the following.
>
> No gaps are identified.
_2) The functionality that is provided is not an ad insertion system, but
functional tools for the DASH client that may be used for other purposes._
> The solution looks into methods on how to properly \"splice\" content.
> Splicing may be done for other purposes as well and may be used by the
> service provider without an ad insertion system on the backend.
>
> No gaps are identified.
_3) Some main content is augmented with ads._
> To support simple splicing/concatenation, DASH supports the following
> functions:
\- Periods: This allows interrupting main content with content that is
completely differently encoded, has different DRM, is accessible at different
resources etc.
\- Presentation Time Offset: specifies the presentation time offset of the
Representation relative to the start of the Period. This allows that main
content can be interrupted quite arbitrarily and can be continued at a new
Period where the internal presentation time of the media that corresponds to
the start of the Period is signalled in the value of the
\@presentationTimeOffset attribute. However, the addition of a Period may not
necessarily result in a seamless playout.
> The following gaps and optimization opportunities are identified:
\- The continuation of content over Period boundaries and the association to
main content and ad content is not possible. A solution consideration is the
Asset Identifier in the second edition of MPEG-DASH [22]. The identifier is
added on Period level that allows signalling that content in two different
Periods belong to the same asset.
\- Seamless playout across period boundary and efficient multi period content
offering is not yet supported, but is under discussion in further amendments
in MPEG.
\- The content ought be DASH formatted in order to be presented in a DASH
Media Presentation.
_4) Ads may be targeted/personalized/individual_
> To support personalized and individual content, a request for a specific
> resource may result in different responses for different users. In an DASH
> context this is supported by the following functions:
\- When making the HTTP GET call the client may associate a previously
delivered Cookie with the request, based on the URL path as defined in RFC
2109 [32].
\- This Cookie for example may provide a client identifier.
> Cookie support is apparently now a required capability, to be an HTTP user
> agent. This comes from the relatively recently published RFC 6265 [31]. An
> excerpt is as follows:
>
> \"Origin servers MAY send a Set-Cookie response header with any
>
> response. User agents MAY ignore Set-Cookie headers contained in
>
> responses with 100-level status codes but MUST process Set-Cookie
>
> headers contained in other responses (including responses with 400-
>
> and 500-level status codes). An origin server can include multiple
>
> Set-Cookie header fields in a single response. The presence of a
>
> Cookie or a Set-Cookie header field does not preclude HTTP caches
>
> from storing and reusing a response.\"
>
> Cookies may be used in the MPD requests and then an individual MPD is
> maintained for each different request. Therefore, personalized content
> offering can be provided, but the individual MPDs may still have common
> parts, namely the main content.
>
> The following gaps and optimization opportunities are identified:
\- It may be necessary that a system requires the support of RFC 6265 [31]. It
needs to analysed if anything needs to be added in TS 26.247. Other aspects
that enable personalization/targeting may be considered.
\- While cookie processing ability is a requirement, the time the cookie is
stored is not normatively defined and is allowed to be shorter than the
intended time. Alternative means for client / session identification may need
to be investigated.
_5) The main content may be live. For live services,_
_\- the cues as well as the ad insertion decision is generally done in real-
time_
_\- ads breaks are of the same duration for same content viewed by all
viewers, however different viewers may see different ads and have different ad
durations within this break._
> The first bullet point requires that new Periods can be added to the live
> content at arbitrary times during the content distribution. DASH supports
> this by:
\- MPD updates: The MPD author promises to the client that an instance of the
MPD can only be used up to a certain Media Presentation timeline. Before
moving forward it requires to fetch a new MPD. The server may have added a new
Period to a new instance of the MPD. By keeping the \@minimumUpdatePeriod
small, the MPD can be changed quite frequently. The updated MPD should be
fetched by the client early enough to allow for ad decision and buffering, in
order to prevent rebuffering and service disruption at the transition from
main to inserted content. Frequent poll-based MPD updates may be costly for
some environments.
\- If MPDs would be used that are of personalized, then the inserted ad breaks
need to of the same or at least very similar duration in order to maintain
that all clients playout and request the data at the same time. This is
essential to ensure that the segments of the produced live content are
available at the announced times in the MPD. If the same **Period** \@start
value is used each MPD, then for Periods of slightly different durations the
note in TS 26.247 applies:
\- At the start of a new Period, the playout procedure of the media content
components may need to be adjusted at the end of the preceding Period to match
the _PeriodStart_ time of the new Period as there may be small overlaps or
gaps with a Representation at the end of the preceding Period. Overlaps
(respectively gaps) may result from Media Segments with actual presentation
duration of the media stream longer (respectively shorter) than indicated by
the Period duration. Also in the beginning of a Period if the earliest
presentation time _T_ ~P~ of any access unit of a Representation is not equal
to _T_ ~O~ then the playout procedures need to be adjusted accordingly.
The following gaps and optimization opportunities are identified:
\- An efficient method for MPD updates. A possible solution are inband event
messages with MPD validation expiry events signaled in the event message box
as available in second edition of MPEG-DASH [22].
\- An efficient and continuous playout mechanism across Period boundaries.
_6) The main content may be On-Demand. For On-Demand services, inserted ads
may be of the same or different duration._
> TS 26.247 supports this by:
\- the features documented above for inserting main content
\- the ability to use **Period** \@duration for Periods not being the first
one. This enables that a concatenation of On-Demand content can done by just
concatenating Periods in one MPD with different duration.
> The following gaps and optimization opportunities are identified:
\- the **MPD** \@mediaPresentationDuration or the **MPD**
\@minimumUpdatePeriod should be present which does not take into account that
the duration of the Media Presentation can be deduced from the last Period
duration, if present. This has been addressed in the second edition of MPEG-
DASH [22].
_7) The main content may be On-Demand that is converted from live content
without changing the segments and segment URLs._
> MPEG-DASH supports this by one of the following features:
\- by designing a new MPD of type static, using the same Segment URLs as in
the live distribution and by using the technologies above.
\- by changing the live MPD to type static, but then the same advertisement is
available that was also available in the live content.
> No gaps are identified.
_8) The distribution supports scalability. In addition, the ad insertion
opportunities are part of the content as sent to the client. Whether an ad is
added and the duration of the ad is decided case-by-case._
> Due to the fact that the Ads are personalized for each session, this means
> that the Headend should maintain unique MPDs for each client session, which
> is unsalable and inefficient.
>
> DASH support efficient handling of this issue by the support of xlink. This
> means that certain part of the content may be offered in one MPD is common
> and provided directly, whereas content that is specific to a subset of users
> may be provided only after requesting the content. xlink is supported to
> resolve content contained in the following elements:
\- Period
\- AdaptationSet
\- SegmentList
> Xlink supports two different processing models: onLoad and onRequest. For
> onLoad, the following is defined in TS 26.247.
\- onLoad: an application should dereference the remote element immediately on
loading the MPD.
> Specifically, the aspect of personalized ads can be fulfilled by using
> Periods with xlink and the resolution of the xlink is done using the
> technologies mentioned above, for example cookies.
>
> When using xlink and personalized ads, the following aspects of the previous
> cases are also fulfilled:
\- for live service the content provider adds a Period with xlink at the time
when an ad is due and uses as processing model onLoad, i.e. the DASH client
immediately requests the xlinked resource.
\- for On-Demand service the content provider adds a Period with xlink at each
position at which possibly an ad may be inserted and uses processing model
onLoad. In addition it only uses **Period** \@duration for all Periods that
are present in the MPD. When the DASH client loads the MPD, it also resolves
all xlinks and may get returned a Period with zero duration (empty), one
Period or multiple Periods. These Periods also only include **Period**
\@duration attributes.
\- for Live to On-Demand converted data, the same applies as for the previous
two cases.
> There are cases when http resources are not accessible. Error codes and
> error cases are defined in section A.7 of TS26.247, but not for xlink.
>
> Based on this, the following gaps and optimization opportunities are
> identified:
\- define the reaction to status codes when an xlink fails, especially fixing
the status that an invalid xlink necessarily invalidates the MPD.
\- clarify the exact resolution strategies when using xlink
Both aspects are addressed in the second edition of MPEG-DASH [22].
_9) Ad decision close to the time when the content is consumed_.
> In this case, the ad decision server wants to provide an ad close to the
> time when the content is consumed. This may be done in a personalized or
> non-personalized fashion, e.g. taking into account the time when the
> resolution is requested.
>
> TS 26.247 provides the following features for this:
\- Using a dynamic service, possibly even for VoD content in a personalized
manner. Then ads can be inserted close to the time when the content is
consumed. However, such an approach is not scalable for VoD and requires heavy
involvement of the server.
\- For live services with a small time-shift buffer depth the xlink+onLoad
based solution mentioned above may be used.
> The main issue is that the xlink for onLoad is expected to be resolved at
> the time when the MPD is loaded. However, using the onRequest method seems
> more suitable. For onRequest, the following is defined in TS 26.247.
\- onRequest (default): formally, an application should dereference the remote
element only on a post-loading event triggered for the purpose of
dereferencing. In the context of this Part of ISO/IEC 23009, the application
dereferences the link only for those resources it needs (or anticipates it
probably will need). Examples include dereferencing a link in a **Period**
element when the play-time is expected to enter that Period, dereferencing an
Adaptation Set link when it appears to contain Representations that will be
needed, and so on.
> This means that when an xlink is added, be it in On-Demand or Live services,
> the xlink is only executed when the play-time is expected. The use case is
> fulfilled in principle, but the following clarification aspects are
> identified.
1) how can this behaviour be ensured. This is discussed in more details below
and is independent of the signal
2) what happens when the client visits the same content again?
Both aspects are addressed in the second edition of MPEG-DASH [22].
_10) Live content may be mixed with On-Demand Advertisement._
> Despite the content may be live and segments are offered in a dynamic
> fashion, interleaved ad Periods may be On-Demand. Despite Segments are
> available earlier than their regularly computed availability start time,
> there is no problem to offer the On-Demand ads as dynamic content. However,
> clients will only access the content at the time earliest at the computed
> availability start time.
>
> As a gap analysis,
\- the availability of On-demand ads cannot be signalled in TS 26.247. A
possible solution is provided in the second edition of MPEG-DASH [22] using
the availabilityTimeOffset.
_11) The ad provider may apply logic on whether the ad can be skipped, or when
it is skipped based on information from the DASH client._
> The logic available in TS 26.247 is that ads are treated as regular content
> and can be skipped. In addition, it is assumed that the same content is
> played in the time shift, as the URLs are the same. However, there may be
> cases where the content provider offers content only if the DASH clients
> playout is obeying certain rules based on signals in the MPD.
TS26.247 does not currently define mechanisms like this, but may be improved
by two orthogonal concepts:
\- signaling of simple playout instructions in the MPD for certain content
(e.g. do not skip, do not rewind, etc.)
\- client authentication, the client authenticates that it will for example
obey the playout instructions
_12) Some tracking of the ad consumption may provided._
> DASH inherently supports tracking by server-side tracking of the HTTP
> requests. However, this will allow you to only know if a segment has been
> retrieved but it does not allow you to determine if the segment was viewed.
> It also does not allow you to track if the segment was viewed in realtime
> etc. Hence, this is rather \"poor mans reporting\" and optimizations may be
> considered.
_13) Different ads may be displayed at the same break for the same user when
the same point in an On-Demand content is reached again. In some cases ad
break may be skipped altogether._
> This feature is not supported in TS 26.247. A possible solution is provided
> by MPEG-DASH second edition [22] allowing \@xlink:href attribute to be
> returned when a remote Period is dereferenced.
### 7.4.2 Presentation Layer controlled Ad Insertion Analysis
_1) DASH will be used as means of triggering ad decision (and consequent
context switch)._
> While it is possible to preload a complete out-of-band schedule of ad breaks
> at the beginning of VOD playback (this is how IAB VMAP [25] operates),
> however this is impractical in a continuous live service due to
> unpredictability of ad break start. In existing adaptive streaming systems
> trigger information is passed by embedding SCTE 35 [26] cue messages, either
> as XML in an ISO-BMFF box in a media segment, or in as a tag in the
> manifest. In both cases this is a proprietary extension defined by content
> producers and operators, rather than enshrined in the specifications
> themselves.
>
> In DASH case, trigger information can be passed using user-defined DASH
> events, which are defined in ISO/IEC 23009-1 [22]. In a media-centric
> approach, all information needed to trigger ad decision is expressed in the
> media segments themselves. This way, inband `emsg` boxes will carry trigger
> information. The `emsg` event timing would indicate the intended splice time
> in media time. In an MPD-centric workflow MPD Validity Expiration event is
> inserted into a media segment. This event triggers an MPD update, and rather
> than an ad decision, hence the Validity Expiration event should appear early
> enough to allow for both MPD update and ad decision.
>
> No gap is identified in MPEG DASH, however use of events needs to be added
> to 3GPP-DASH.
>
> In interests of interoperability it may be worth to specify transport of
> SCTE 35 -- while its up to the presentation layer to interpret it,
> specifying the format may help content producers when ad breaks are marked
> up at the content generation time.
_2) Some tracking of the ad consumption may be provided._
> An MPD (or media segments) for a single MPD is augmented with additional
> information using non-DASH format. The standard DASH client is still able to
> play the presentation, however extended functionality will be available to
> clients that have modules handling these non-DASH XML-based formats.
>
> The reason for use of non-DASH formats is avoiding reinventing the wheel and
> making integration with existing ecosystem easier -- e.g. there is a widely
> deployed VAST [27] standard that provides sufficiently rich information. The
> VAST (not DASH!) client will issue HTTP GET requests that will be understood
> by existing tracking servers.
>
> There are no gaps in MPEG DASH -- support for DASH events is the enabler for
> this architecture -- the most reasonable way of conveying e.g. VAST
> information is DASH events.
This section mentions several external standards, such as SCTE 35 and VAST.
SCTE 35 is a standard that provides inband information on the upcoming ad
breaks. Some of the information provided is timing (start / duration) and
break identification. The parameters extracted from the SCTE 35 message are
passed to the ad server and are used in process of ad decision by the ad
decision servers. SCTE 35 is a binary format defined for MPEG-2 TS and its use
is ubiquitous in the N. American market. An older version of SCTE 35 is also
known as ITU-T J.181 [36]. An XML representation of SCTE 35 will be available
in SCTE 35 2013.
The Interactive Advertising Bureau (IAB) provides standards for online
advertisement. IAB\'s Video Ad Serving Template (VAST) specification specifies
ad server response instructing the client on ad content it is expected to
play. IAB Video Multiple Ad Playlist (VMAP) provides out-of-band information
on ad breaks, with functionality similar to SCTE 35\. The major difference
between the two is the fact that SCTE 35 is tightly synchronized with media
and appears inband, while VMAP is loaded at the beginning of a presentation.
A reference Ad insertion system architecture is shown below:
Figure 7.2: Example system Architecture for Ad insertion for DASH
The content publisher controls when and where to add ad in the content stream.
The content publisher delivers the content with in-band signalling to the
packager for content distribution,
The presentation layer interacts with DASH clients to play DASH content. The
Presentation layer also interacts with Ad server for Ad MPD URLs access, other
non-DASH Ad content access and tracking report.
The in-band signalling conveyed as event in main content will trigger DASH
client to send the trigger information to the presentation layer to initiate
the interaction between the presentation layer and Ad server. The Ad MPD URL
and other non-DASH Ad content will be retrieved by the presentation layer from
the Ad server. The Ad MPD URL will be passed to DASH client by the
presentation layer. The Ad DASH client will play the Ad accordingly.
## 7.4 Examples
### 7.4.1 Fixed Duration in On-Demand
The following is an example MPD containing fixed advertisement in the middle
of an on demand movie.
\
\
\http://cdn1.example.com/\
\http://cdn2.example.com/\
\
\
\video_1/\
\
\
\
\
\
\
\
\
\
\
\ad/\
\
\
\
\
\
\
\
\video_2/\
\
\
\
\
\
\
\
### 7.4.2 Targeted Advertisements
The following is an example MPD containing a remote period which is actually
the advertisement in the middle of an on demand movie. When resolving the
xlink, the advertisement server selects advertisement according to the request
URL and feed back the XML element with URLs for the advertisement segment:
\
\
\http://cdn1.example.com/\
\http://cdn2.example.com/\
\
\
\video_1/\
\
\
\
\
\
\
\
\
\
\
\video_2/\
\
\
\
\
\
\
\
The xlink:href=\"http://adserver.com/movie_11/ad_1.period document may be the
below.
\
\
\
\
\ad/\
\
\
\
\
\
Once the resolution is applied it results in the following MPD.
\
\
\http://cdn1.example.com/\
\http://cdn2.example.com/\
\
\
\video_1/\
\
\
\
\
\
\
\
\
\
\
\ad/\
\
\
\
\
\
\
\
\video_2/\
\
\
\
\
\
\
\
### 7.4.3 Example call for Ad insertion for DASH
The example call flow for Ad insertion according to clause 7.3.2 for DASH is
illustrated in Figure 7.3.
Figure 7.3: Example call flow of target Ad insertion for DASH
In-stream Ad normally is classified as liner Ad type, non-liner Ad type and
companion Ad type. The liner Ad is DASH format compliant for DASH support. The
non-linear Ad and companion Ad include text, graphic, rich media, etc. those
content format is non-DASH compliant. The application interacts with Ad server
by VAST protocol support. The whole solution relies on the support which is
outside of scope of 3GPP.
## 7.6 Advanced Advertisement insertion in the operator network
### 7.6.1 Description
#### 7.6.1.1 Advertisement insertion based on user subscription
A subscriber has a \"low cost\" subscription, allowing a limited bandwidth,
restricting his access to high quality multimedia content. As part of his
mobile subscription, he has informed his network operator that he is willing
to watch some advertisements in exchange of being able to upgrade his
multimedia experience (e.g. higher maximum bitrate, or lower degradation of
bitrate during congestion situations).
The network operator inserts an advertisement before the DASH videos that this
subscriber is playing.
The network operator could also insert an ad break in the middle of the DASH
video (especially for longer content) before the user can resume watching the
video.
Another subscriber with the same \"low cost\" subscription has elected not to
have advertisements displayed before watching movies. The network operator in
this case will not play an advertisement ahead of (or during) the DASH videos
(and will not upgrade the subscriber\'s experience either).
#### 7.6.1.2 Targeted advertisement insertion
The mobile subscription information of a subscriber indicates that an
advertisement will be inserted before (or during) DASH video content is played
to the UE.
Based on the location of the UE, a specific advertisement can be played (e.g.
related to sales of a nearby store).
Based on the subscriber information, a different advertisement can be played
(e.g. based on gender, age, etc.), taking privacy in account.
Based on the known available bandwidth, a different advertisement can be
played (e.g. simple content authoring (e.g. timed graphics) or high quality
video depending on the available bandwidth).
#### 7.6.1.3 Bandwidth-related advertisement/message
A subscriber watches a DASH video over a 3GPP radio network. The subscriber
enters an area where the bandwidth capacity is too low for the video content
to be played satisfactorily, possibly leading to an empty buffer for an
unknown duration.
The network operator inserts a low-bandwidth DASH content (not necessarily an
advertisement) until the radio network conditions are sufficient for the
original video to resume.
### 7.6.2 Working assumptions
\- The operator\'s network is deployed in a way that allows the operator to
insert DASH content (advertisement or other) before or during a service using
DASH.
\- The decision for the network operator to insert additional content and the
selection of the content to insert can be based on subscription information,
bandwidth information, UE location, and video information.
### 7.6.3 Solution based on TS 26.247 and Gap Analysis
On use cases in clauses 7.6.1.1 and 7.6.1.2: Based on information exchange
with 3GPP SA2, the use of Sh from a PSS server is not restricted in TS 23.228
[24] and therefore the use cases in clauses 7.6.1.1 and 7.6.1.2 can be
fulfilled by using the Sh interface. This is a deployment choice.
On use case in clause 7.6.1.3:
\- According to clause 6.12.3 and based on feedback from SA2 on their
discussions during the work on UPCON in Rel-12 and feedback they received from
RAN groups, the access to accurate information about the frequently changing
radio conditions at the RAN node in a timely manner is seen as almost
impossible. Information about user plane congestion at a RAN node should be
expected to represent a mean value over a period of time (e.g. a congestion
level for a couple of minutes).
\- However, a DASH content provider can add low-bitrate content in an
Adaptation Set to be played in case the client observes issues on the
available access bandwidth. If the client observes low bitrate, it
automatically switches to the low bitrate content.
Other options are to provide a GBR bearer to provide a minimum bitrate even in
case of congestion.
Generally, no gaps are identified, but proper documentation is encouraged of
how the use cases can be fulfilled with today\'s architectures.
# 8 Conclusions and Recommendations
3GPP\'s Dynamic Adaptive Streaming over HTTP (DASH) specification was
developed in and Rel-10 and is available in TS 26.247 [2] in alignment with
MPEG\'s ISO/IEC 23009-1 [9]. During 2012 and 2013 MPEG has conducted work on a
second edition of DASH [22] that includes additional technologies. These
technologies are currently not part of 3GP-DASH, but at least some of them may
be considered useful also for 3GPP-based DASH distribution as identified in
this TR.
Clause 5 of the present document provides deployment guidelines for content
authoring, client operation as well as operational guidelines. These
guidelines provide an initial overview, but may be expanded further in order
to support implementers in choosing appropriate parameters.
In terms of use cases and technologies, the following conclusions can be
drawn:
\- For Live Services (see clause 6.2), TS 26.247 supports all basic aspects to
offer a live service. Additional tools may be considered to optimize
efficiency and robustness.
\- For Content Protection (see clause 6.3), TS 26.247 is agnostic to the DRM
that is used. However, neither in TS 26.247 nor in 3GPP file format TS 26.244
[5] there is explicit support for common encryption nor key rotation.
\- For Fast Media Startup (see clause 6.4), no gaps are identified and the
tools included in TS 26.247 and described in clause 6.6 are considered
sufficient.
\- For Advanced Trick Modes (see clause 6.5), no gaps are identified and the
tools included in TS 26.247 and described in clause 6.7 are considered
sufficient.
\- For Content and Device Interoperability (see clause 6.6), it was identified
that 3GP-DASH as defined TS26.247 lacks a profile that is aligned with
existing industry practices.
\- For Advanced Support for Live Services 3GP-DASH (see clause 6.7), TS 26.247
lacks tools and guidelines for low-latency live services. MPEG-DASH second
edition [22] defines certain tools for this purpose that may be considered to
improve latency. In addition, the use of certain HTTP delivery modes may be
considered.
\- For Consistent QoE/QoS for DASH users (see clause 6.8), the use of the
existing 3GPP PCC architecture as defined in TS 23.203 [15] and providing the
Rx reference point provides sufficient means to fulfil the use case.
\- For DASH as download format (see clause 6.9), the DASH formats may also be
used in the progressive download context using a restricted subset of DASH. No
specific gaps are identified, but the usage may be documented.
\- For Efficiency of HTTP-caching infrastructure (see clause 6.10) on DASH the
use case is fully supported since Rel-11 of TS26.247 and no gaps are
identified.
\- For Multiple Spectator Views offered with DASH (see clause 6.11), TS26.247
provides certain tools to support the use case, but gaps are identified to
provide location/orientation information in the MPD and in timed metadata
tracks in the 3GPP File Format as well as providing MPD indication of
highlights and capturing parameters.
\- For Operator control of video streaming services (see clause 6.12) at least
a certain amount of use cases may be solved by solutions introduced in 6.15.3.
Additional optimizations may be considered, but may require consultation with
other 3GPP groups.
\- For DASH Operation with Network Proxy Caches (see clause 6.13), certain
gaps have been identified including the inability to provide proactive or
reactive information to the DASH client about the location of
Representations/Segments or information from the PSS server to the network
proxy cache.
\- For Services with caching of DASH content at UE functions (see clause
6.14), a need to provide information from the DASH-aware HTTP proxy cache in
the operator\'s network to the DASH client on which representation(s) is or
are preferred.
\- For handling special content (see clause 6.15), TS 26.247 provides basic
tools using dynamic services. However, the approach has limitations in terms
providing a consistent operation. Identified gaps include the playout requires
customized MPDs, no explicit signalling is available on special content,
consistent and trusted client behaviour including authentication,
authorization and session control is missing and tracking of all client
requests and verification of the client behaviour may need to be implemented.
\- For DASH Authentication the Generic Bootstrapping Architecture (GBA) [20]
(see clause 6.16) can be used to authenticate the end-user(s) and bootstrap a
secure end-to-end connection between the Streaming Server and the end-user(s).
The Generic Bootstrapping Architecture currently does not contain any content
access authorization methods for DASH. However, authorization of content
access and streaming quality can be additionally implemented in the Streaming
Server that takes on the role of NAF. The Generic Bootstrapping Architecture
can also be used to derive the necessary shared secret(s) required to
integrity protect the application level content/metadata between the UE and
server serving this DASH content. No further gaps are identified.
\- For Consistent Quality for DASH users QoE of DASH service (see clause 6.17)
can be maintained if DASH service is carried over GBR bearer. Existing QoS
mechanism can be used to support consistent QoE of DASH service. Considering
the current EPC architecture supports QoS feature, consistent QoE of DASH
service is supported already from 3GPP architecture point of view. In the mean
time, signalling of quality-related information about the content (via the
DASH MPD or other means) to the DASH client can be desirable as demonstrated
by performance evaluation results documented in Annex A.
\- For Ad Insertion (see clause 7), TS 26.247 supports a significant amount of
tools, but certain optimizations are provided in ISO/IEC 23009-1 second
edition [22] to enable more comprehensive and more feature rich ad insertion
use cases. It was also highlighted that ad insertion in operator\'s network is
enabled by existing architectures.
For all potential solution and optimizations, it is recommended to investigate
whether existing technologies defined by MPEG in ISO/IEC 23009-1 second
edition [22], other MPEG technologies as well as other organization such as
the IETF fulfil the use cases.
###### ### Annex A: Detailed Performance Evaluation Results on Quality-Driven
Rate Adaptation Algorithms
# A.1 Introduction
This annex provides detailed performance evaluation results on quality-driven
rate adaptation algorithms. It supports the use case in clause 6.17.
# A.2 Simulation Setup
Figure A.1 describes our simulation setup. In our simulation, the following
tools were used
A) DASH Content Generation
\- Encoder: x264
\- Quality generation: MSU tool
(http://compression.ru/video/quality_measure/video_measurement_tool_en.html)
to calculate MS-SSIM, and a MOS Estimator to map MS-SSIM to MOS on different
devices (further details on the latter provided below)
\- DASH encoder (from ITEC web site): [http://www-itec.uni-
klu.ac.at/dash/?page_id=282]{.underline}: This encoder produces the required
MPD files according to DASH specifications. Additional codes are written to
add quality information in the MPD file.
B) DASH Server
\- Microsoft IIS HTTP streaming server in Windows platform. The IIS streaming
server supports HTTP streaming which is compatible with VLC DASH plugin.
C) Network Emulator
\- Apposite Netropy N60 is a hardware emulation engine that enables high-
precision emulation of up to 15 separate WAN links to model complex network
topologies or run multiple concurrent tests.
D) DASH Client
\- VLC-2.1.x Player with DASH plug-in (from VideoLan
[http://nightlies.videolan.org/]{.underline} ). VLC player includes a DASH
plugin implementation. This implementation was modified to support adding
quality and segment size information to the MPD file. In addition, rate
adaptation cases were implemented to evaluate the use of quality in rate
adaptation.
\- Summary of details include:
1\. Parsing quality and size information from the modified MPD file.
2\. Adding a sliding window to measure download rates at the client over a
defined time interval. This sliding window contains the download rate of
previous duration and will be used to estimate the available download rate for
next segment.
3\. Implementing advanced rate-adaptation algorithms for non-quality and
quality-based MPD. More details will be discussed in clause A.4.
{width="6.200694444444444in" height="2.5708333333333333in"}
Figure A.1: Simulation Setup
# A.3 Content Preparation
The test clip used in the simulation is a 5-min video
\"A_Glimpse_of_China_short\" provided by Huawei. The clip shows live footage
of Shanghai, and offer variety of content: architecture, people, trees, cars,
etc. The original clip comes in 720p, 25fps format, encoded at very high rate
(81.5Mbps) using H.264 high profile. The content is encoded with x264 with
unconstrained VBR and capped VBR and parameters described in Table A.1. The
content is encoded into eight representations and the segment length is fixed
to 2 seconds.
NOTE 1: Used --ratetol inf and --tune ssim for the unconstrained VBR setting
since VLC DASH has problems supporting --crf encoding videos.
The quality generation process is shown in Figure A.2. The per-segment MS-SSIM
scores of encoded content are calculated using the MSU tool and then mapped to
MOS scores on different devices based on an estimation method empirically
validated based on comprehensive subjective testing. The 5-point MOS scale was
used as shown in Table t2 for the subjective quality evaluation.
{width="6.670833333333333in" height="2.832638888888889in"}
Figure A.2: Quality generation process
Table A.1: Definition of 5-point MOS for Subjective Video Quality Evaluation
* * *
Scale Description 5 Excellent: there are no artifacts 4 Good: artifacts are
slightly noticeable, but they do not bother me 3 Fair: artifacts are
noticeable, and they bother me a little 2 Poor: artifacts are very noticeable,
and they bother me a lot 1 Bad: artifacts are severely noticeable, and I would
not continue to watch
* * *
For the calculation of MOS scores, the subjective quality was modeled as a
linear function of an objective quality metric, i.e. MS-SSIM in this case, as
shown in Equation 1, where the prediction coefficients $\alpha$ and $\beta$
are functions of video content characteristics (videos classified based on
spatial details, motion levels, bitrate, resolution) and device
characteristics (display size and resolution).
{width="1.5833333333333333in" height="0.19791666666666666in"} (1)
As such, this subjective quality estimator uses MS-SSIM, video content
characteristics, and device characteristics to determine subjective video
quality. The device knows about the device characteristics and can analyze the
compressed video to get the content characteristics. However, MS-SSIM is a
reference-based objective quality metric and cannot be known by the device
unless this information is explicitly signaled to the client. So in order to
determine the subjective quality at the client, signaling the quality
information is necessary.
Comprehensive subjective testing experiments were conducted based on the
standardized procedures established in [14] toward validating the above MOS
estimation method for calculating MOS scores from MS-SSIM. All evaluations
took place in a usability lab located at the Intel facilities in Hillsboro,
Oregon, USA. Five different devices were considered in the experiment - HDTV,
Androidï›š Tablet, Androidï›š Phone, iPadï›š and iPhoneï›š. For each device, about 30
participants are asked to rate the video quality on a 5-point MOS scale as
shown in Table A.1 and the subjective results are collected for evaluation.
NOTE 2: Androidï›š is the trade name of a product supplied by Google Inc. iPadï›š
is the trade name of a product supplied by Apple Computer Inc. iPhoneï›š is the
trade name of a product supplied by Apple Computer Inc. This information is
given for the convenience of users of the present document and does not
constitute an endorsement by 3GPP of the product named. Equivalent products
may be used if they can be shown to lead to the same results.
In Figure A.3, the subjective quality MOS values estimated based on MS-SSIM is
plotted against the empirically obtained subjective quality scores from
experimentation. The results show that subjective video quality can be well
estimated if the objective quality score (i.e. MS-SSIM), video content
information, and client device characteristics are known.
{width="6.502083333333333in" height="4.409027777777778in"}
Figure A.3: MOS Estimation based on MS-SSIM, Video Content and Device
Information
# A.4 DASH Rate Adaptation Algorithms
## A.4.1 Adaptation based on per-segment bitrate information (Non-Quality):
The basic idea of the non-quality algorithm is to adapt the segment bitrate to
the available network bandwidth with different rate factors, which are
determined by the buffer level. When the buffer level is high, the client
could perform more aggressively by selecting a representation bitrate bounded
by available BW*rate_factor. The flowchart of the algorithm is shown in Figure
A.4.. The following parameters are defined in the algorithm:
\- Buffer percentage parameters: buf_low, buf_med, buf_high
\- Bitrate threshold factor: rate_factor1, rate_factor2
{width="5.843055555555556in" height="2.5631944444444446in"}
Figure A.4: Flowchart of Non-quality-based Rate Adaptation Strategy
Algorithm Details:
**Condition 0** : buf \ buf_high
Select highest bitrate representation lower than the available BW*rate_factor2
## A.4.2 Adaptation based on per-segment bitrate and quality information
(Quality-based)
The main idea of the quality-based algorithm is to maintain a balance among
buffer level, selected bitrate and quality based on the available bandwidth
and per-segment bitrate/quality information. The flowchart of the quality-
based algorithm is shown in Figure A.5 and the following parameters are
defined:
\- Buffer percentage parameters: buf_low, buf_med, buf_high
\- Quality threshold: quality_min, quality_max-
\- Bitrate threshold factor: rate_factor1, rate_factor2
{width="6.128472222222222in" height="2.563888888888889in"}
Figure A.5: Flowchart of Quality-based Rate Adaptation Strategy
Algorithm Details:
**\- Condition 0: buf \  quality_max, select the lowest bitrate representation
**\- Condition 3: buf > buf_high**
\- Select representations lower than the available BW*rate_factor2
\- If quality is higher than quality_max, choose the lowest bitrate
representation that satisfies quality_max
\- Else: choose highest quality representation
## A.4.3 Bandwidth Model
Apposite Netropy N60 Network Emulator was used to emulate various channel
conditions. Figure A.6 shows the bandwidth models evaluated in the simulation.
In model A, the available bandwidth stays constant at a level for 10s and then
switches to a different level following the pattern shown in the figure. In
model B, the available bandwidth alternatively switches between 2 Mbps and 200
kbps every 5 s.
{width="6.6875in" height="2.713888888888889in"}
Figure A.6: Bandwidth Models A and B
## A.4.4 Experimental Results
In this section, evaluation results are presented on the performance of non-
quality and quality-based DASH rate adaptation algorithms with unconstrained
VBR and constrained VBR DASH content in different network scenarios. The VLC
buffer size is fixed at 30 s. For both algorithms, the pre-defined parameters
in Table A.2 are used unless otherwise noted.
Table A.2: Pre-defined Parameters for Rate Adaptation
* * *
                  buf\_low   buf\_med   buf\_high   rate\_factor1   rate\_factor2   Q~min~   Q~max~
Non-quality 30 % 50 % 70 % 1.0 1.0 -- -- Quality-based 30 % 40 % 70 % 3.0 3.0
3.0 4.5
* * *
Table A.3 compares the statistics of non-quality and quality-based rate
adaptation algorithms under network model A. It is seen that for the
constrained VBR case, the quality-based algorithm achieves the same average
quality as the non-quality algorithms with less percentage of low-quality
periods. At the same time, the quality-based algorithm consumes 27 % less
bandwidth and maintains a higher buffer level while the non-quality algorithms
suffer from one rebuffering event. For the unconstrained VBR case, similar
observations can be made that the quality-based algorithm achieves the same
average quality with shorter bad-quality periods and consumes 34 % less
bandwidth with a higher average buffer level. The results show that with the
quality information, the DASH client can maintain a better balance among
bitrate, quality and buffer level. The results also show that the constrained
VBR has worse average quality and larger quality fluctuations under the same
network assumption, which indicates that when stricter bitrate variation is
applied to the compressed content, it is very important to signal quality
information to the DASH client in order to efficiently stream the videos with
good user experience.
Table A.3: Statistics of Non-quality and Quality-based Rate Adaptation
Algorithms (Bandwidth Model A)
+---------+---------+---------+--------+---------+---------+---------+ | Cons | | | | | | | | trained | | | | | | | | VBR | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Metric | Avg. | Avg. | MOS\<3 | Avg. | Rebu | No. | | | Bitrate | MOS | | Buffer | ffering | R | | Al | (Mbps) | | | % | Time | ebuffer | | gorithm | | | | | (s) | | +---------+---------+---------+--------+---------+---------+---------+ | Non- | 2.02 | 3.98 | 24.3 % | 56.0 % | 4.9 | 1 | | Quality | | | | | | | | (rf1=r | | | | | | | | f2=1.0) | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Non- | 2.03 | 3.92 | 26.2 % | 45.5 % | 14.3 | 1 | | Quality | | | | | | | | (r | | | | | | | | f1=1.5, | | | | | | | | r | | | | | | | | f2=2.0) | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Qualit | 1.47 | 3.99 | 15.7 % | 64.7 % | 0 | 0 | | y-based | (27%) | | | | | | | (Q~mi | | | | | | | | n~=3.0, | | | | | | | | Q~ma | | | | | | | | x~=4.5) | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Uncons | | | | | | | | trained | | | | | | | | VBR | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Non- | 2.04 | 4.21 | 5.0 % | 45.0 % | 0 | 0 | | Quality | | | | | | | | (rf1=r | | | | | | | | f2=1.0) | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Non- | 2.05 | 4.21 | 5.0 % | 43.6 % | 0 | 0 | | Quality | | | | | | | | (r | | | | | | | | f1=1.5, | | | | | | | | r | | | | | | | | f2=2.0) | | | | | | | +---------+---------+---------+--------+---------+---------+---------+ | Qualit | 1.34 | 4.22 | 3.6 % | 70.5 % | 0 | 0 | | y-based | (34 %) | | | | | | | (Q~mi | | | | | | | | n~=3.0, | | | | | | | | Q~ma | | | | | | | | x~=4.5) | | | | | | | +---------+---------+---------+--------+---------+---------+---------+
Figures A.7-A.9 present the corresponding streamed segment bitrate, quality
and the buffer status. These findings show that the quality-based algorithm
can make smarter adaptation decision based on current buffer level, segment
bitrates and quality information. In some situations, the algorithm chooses to
stream at a lower bitrate when the quality requirement is met, which helps to
save bandwidth consumption and fill up the buffer faster. In other situations,
the algorithm may request a higher bitrate than the available bandwidth to
trade off the quality gains if the buffer level allows. On the contrary, for
the non-quality case, requesting a bitrate higher than the available bandwidth
without knowing the quality tradeoff could unnecessarily drain the buffer and
worsen the overall performance.
Furthermore, another case can be considered where the representations provided
to the devices are limited based on the quality (i.e. do not offer
representations higher than a MOS=4.5) and the performance can be evaluated
under bandwidth model B. The statistics are shown in Table A.4. It is seen
that capping the representation bitrate based on the quality information helps
to improve the efficiency of the non-quality based algorithm. It limits the
unnecessary bandwidth consumption when max quality requirement is met.
Compared to the non-quality algorithm without representation capping, it
achieves better quality performance and higher buffer level with the same
amount of bandwidth consumption. However, quality-based algorithms still
yields a better overall performance since capping high bitrate representation
would not help the case where the client needs to adapt to several moderate
bitrate representations based on the quality information. The results also
show that choosing the proper quality parameters for different network
conditions helps to improve the performance. This indicates that the quality-
based algorithm can be further improved by designing a cost function that
takes into account buffer level, segment bitrate, segment quality, and
available bandwidth (short-term and long-term) to find the optimal
representation.
{width="6.694444444444445in" height="2.8444444444444446in"}
Figure A.7:Segment Index vs. Segment Bitrate (Bandwidth Model A)
{width="6.164583333333334in" height="2.8680555555555554in"}
Figure A.8: Segment Index vs. Segment Quality (Bandwidth Model A)
Table A.4: Statistics of Non-quality and Quality-based Rate\ Adaptation
Algorithms (Bandwidth Model B)
+---------------+---------------+----------+--------+---------------+ | Constrained | | | | | | VBR* | | | | | +---------------+---------------+----------+--------+---------------+ | Metric | Avg. Bitrate | Avg. MOS | MOS\<3 | Avg. Buffer % | | | (Mbps) | | | | | Algorithm | | | | | +---------------+---------------+----------+--------+---------------+ | Non-Quality | 1.36 | 3.62 | 32.9 % | 39.2 % | | (rf1=rf2=1.0) | | | | | +---------------+---------------+----------+--------+---------------+ | Non-Quality | 1.33 | 3.55 | 35.7 % | 35.2 % | | (rf1=1.5, | | | | | | rf2=2.0) | | | | | +---------------+---------------+----------+--------+---------------+ | Non-Quality | 1.27 | 3.80 | 25.0 % | 55.9 % | | ( | | | | | | rf1=rf2=1.0), | | | | | | Capped | | | | | | MOS=4.5 | | | | | +---------------+---------------+----------+--------+---------------+ | Non-Quality | 1.34 | 3.83 | 21.4 % | 51.8 % | | (rf1=1.5, | | | | | | rf2=2.0), | | | | | | Capped | | | | | | MOS=4.5 | | | | | +---------------+---------------+----------+--------+---------------+ | Quality-based | 1.14 | 3.74 | 16.2 % | 51.7 % | | (Q~min~=3.0, | | | | | | Q~max~=4.5) | | | | | +---------------+---------------+----------+--------+---------------+ | Quality-based | 1.01 | 3.75 | 12.1 % | 58.0 % | | (Q~min~=3.0, | | | | | | Q~max~=4.0) | | | | | +---------------+---------------+----------+--------+---------------+
{width="5.995833333333334in" height="2.5395833333333333in"}
Figure A.9: Buffer Percentage (Bandwidth Model A)
###### ### Annex B: Evaluation of QoS-Driven DASH Client Adaptation
This annex describes simulation methodology and results on the evaluation of
end-to-end capacity and QoE over an LTE-based system-level simulation platform
in the presence of enforcement of dedicated QoS bearer policies for each DASH
client. In particular, an analysis is presented quantifying the performance
benefits of QoS-driven DASH adaptation techniques based on operator\'s
selection of the maximum bitrate (MBR) and consequent adaptation at the DASH
client. Furthermore, additional simulation results are provided demonstrating
the quality improvement from the availability guaranteed bitrate (GBR)
information at the DASH client during start-up.
Re-buffering has been identified as one of the most critical QoE metrics for
streaming video. In a 3GPP DASH-based implementation of QoE metrics in the
client device, this metric can be computed via monitoring the buffer status
and/or play list metrics. Given the key importance of re-buffering in
dictating the QoE delivered to the user, the service capacity of an LTE system
is defined based on an outage criterion that is centered around the re-
buffering percentage, i.e. the percentage of the total presentation time in
which the user experiences re-buffering due to buffer starvation. In
particular, a user is designated to be satisfactorily supported if its re-
buffering percentage is smaller than a re-buffering outage threshold A^out^.
The service capacity is then defined as the maximum number of users that can
be supported in the network such that the percentage of satisfied users is
greater than the network coverage threshold A^cov^. i.e.
where **E[.]** is denotes the expectation over multiple user geometry
realizations and **1(.)** denotes the indicator function.
**Five VBR-encoded video clips (Sony, Citizen Kane, Die Hard, NBC News, Matrix
Part1) are considered with different bitrate requirements hosted at the HTTP
server with multiple versions of each video clip available at different
quality levels in the PSNR range of 26-39 dB, as shown in Figure B.1 and Table
B.1.** Two video traces for each video representation level contain content
information with regards to -- i) size and quality information for each video
frame and ii) offset traces which give information of the video quality
obtained by concealing lost video frames with previous frames. PSNR was used
to model video quality as a representative although other advanced metrics
could also be used.
**A cellular deployment is assumed based on** an IMT-Advanced urban macro-cell
(UMa) test environment with an inter-site distance (ISD) of 500 m**, where
each user in the LTE network randomly requests one of the five available video
clips.** A 19-cell scenario is considered, where the center cell generating
video traffic is surrounded by two layers of interfering cells generating full
buffer traffic. Users are randomly dropped in the center cell. **The
simulation parameter settings and assumptions on the LTE air interface are
provided in Table B.2 below. The additional assumptions include the following:
1) For the link to system mapping, Mutual Information Effective SINR Metric
(MIESM) is used, 2) AWGN PER versus SINR curve corresponding to that
modulation, code rate are used to determine the probability of error, 3)
Channel Quality Indicator (CQI) are delayed by 5ms, 4) HARQ retransmissions
are delayed by 8 ms with a maximum of 4 retransmissions. 5) The base stations
in all other cells generate interference patterns corresponding to a full
buffer mode of operation. 6) 100,000 sub-frames were simulated to generate LTE
link statistics, 7) Users were picked randomly from a user population of 684
dropped uniformly in the sector. 8) For each configuration, statistics were
collected from thirty different random drops of users in the network. 9)
Packet fragmentation based on the maximum MTU size of 1500 bytes is
considered, and HTTP/TCP/IP layer protocol behaviour and overheads are also
incorporated in the analysis -** 40 bytes of header was included in each TCP
segment (10 bytes for NALU prefix + 12 bytes for HTTP header + 8 bytes for TCP
header)**. 10)** All the main features of TCP Reno flavour were implemented in
the simulator including flow control, slow start, congestion avoidance, RTT
estimation, timeout, re-transmission, fast re-transmit and fast-recovery to
account for the presence of TCP. **11)** The Backhaul Network (BN) between the
eNodeB (eNB) and S-GW is modelled with a fixed bandwidth of 1 Gbps. 12) Core
Network (CN) from video servers to the S-GW was modelled using a fixed delay
of 50 ms. 13) Core and back-haul networks are assumed to lossless and radio
access network is considered as the main bottleneck. 14) Uplink transmissions
are assumed to be errorless. 15) The delay involved in establishment of the
dedicated bearer (e.g. GBR bearers) was not included in the assumed system
model.
Multiuser resource allocation over the OFDMA-based downlink LTE air interface
is performed based on the well-known proportional fair scheduling principles.
Only half of the available bandwidth of the 10 MHz LTE system is assumed to be
reserved for the DASH-based video streaming service while the remaining half
is assumed to be dedicated for other services, e.g. voice and data services.
{width="5.080555555555556in" height="4.113888888888889in"}
Figure B.1: Rate-PSNR Curves of Sample Videos
Table B.1: Details on the video content used in the evaluation
{width="6.4875in" height="2.0590277777777777in"}
Table B.2: LTE Air Interface configuration
{width="4.429861111111111in" height="4.178472222222222in"}
According to the DASH-based adaptive streaming framework, users may consume
varying qualities of video based on the working of the assumed adaptation
algorithm, which selects the optimal quality/bitrate representation among the
available video clips based on monitoring of user experience via 3GPP-based
QoE metrics, i.e. particularly the playback buffer level. The different
representations of the video requested by a representative client are indexed
using letter k. In particular, k=1 represents the lowest bitrate
representation level and k = N represents the highest representation level and
b~k~ represents the bitrate of encoded video of representation level k, b~1~ â‰¤
b~2~ â‰¤ b~3~ â‰¤ ... â‰¤ b~N~. Rate adaptation is client-driven and is done at
segment level where each video segment might contain one or more GOPs (Group
of Pictures).
The DASH-based adaptive streaming framework monitors the LTE link throughput
and client buffer state and requests the video representations accordingly to
realize the highest possible quality but also making sure to avoid playback
buffer starvation. The DASH client starts playback with initial start-up delay
of one second. It requests the video at a higher fetch rate during the
buffering mode (playback buffer under a specified threshold) while the fetch
rate is lower during the streaming mode (playback buffer above the specified
threshold). Encountering playback buffer starvation, the client enters re-
buffering mode while stalling the playback. The playback resumes after a
certain targeted amount of media (i.e. 1 second) is aggregated in the media
buffer.
A typical DASH-level throughput estimate is the average segment Throughput
which is defined as the average ratio of segment size to the download time of
the segment.
where S~seg~(s), ,are the size, fetch time, and download time of the j^th^
video segment, S~i~ the number of segments downloaded until frameslot i, and F
is the number of video segments over which the average is computed.
The best video representation level possible in frameslot i, , is determined
based on the current average segment throughput estimate as well as the GBR
and MBR signaled by the network as follows:
Therefore, if the client is in steady state, then the best representation
level is chosen as determined by the minimum of the DASH-level throughput
estimate and MBR. Furthermore, in the start-up phase, the best representation
level is chosen as determined by the maximum of the DASH-level throughput
estimate and GBR.
Based on these simulation conditions, an evaluation of the cumulative
distribution function (CDF) of re-buffering percentage was conducted for
different system loading conditions in terms of the number of users the re-
buffering outage threshold A^out^ is set to 2 % and the network coverage
threshold A^cov^ is set to 95 %.
Figure B.2 shows the CDFs of re-buffering percent for various loads (number of
users in the system) when the MBR is set to 2000 Kbps (GBR=0). Only the curve
with Nue = 35 has 95 % of users with re-buffering less than 2 %. Figure B.3
and Figure B.4 plot the CDFs of re-buffering percent for various number of
users when the MBR is set to 500 Kbps and 250 Kbps. As the MBR is reduced, the
curves of more number of users have 95 % users with re-buffering less than 2
%.
Figure B.5 plots the percentage of users with re-buffering less than 2 % as
the load is varied for different settings of MBR (GBR=0). For a given MBR, as
loading is increased, the percentage of users that experience re-buffering
less than 2% decreases. For the same loading, as the MBR is decreased the
number of users with re-buffering less than 2 % is higher.
Figure B.6 plots the mean video quality obtained in terms of PSNR as the load
is varied for different settings of MBR (GBR=0). For a given MBR, as loading
is increased, mean video quality decreases. Also setting an MBR sets an upper
limit on the video quality that could be obtained. Also note that the curves
for different MBR values converge after the loading is increased beyond a
certain point.
Figure B.7 plots the service capacity as the MBR is varied (GBR=0). As the MBR
is increased, the service capacity decreases drastically initially and then
gradually after a certain limit.
Figure B.8 plots the mean quality obtained when operating at the system
capacity for a given MBR versus MBR. As the MBR is increased the improvement
in quality initially increases drastically but then increases very gradually
at higher MBRs.
The evaluations indicate that the there exists a tradeoff between service
capacity and achievable video quality that could be obtained by varying the
MBR, and that the service capacity could be enhanced by properly setting MBR
limits in the system while offering a reasonable maximum video quality.
Therefore the network MBR limit has to be properly set depending on the
capacity for which the system has to be designed and the target video quality
desired. In that sense, the operator can effectively accommodate various
levels of user loading and still deliver satisfactory QoE to the end users by
controlling the MBR provided that the DASH clients can receive and use the MBR
information in their adaptations.
The evaluation on the impact of GBR deals with a 100-user loading scenario
with 25 % of the users each on a dedicated bearer with a certain GBR (premium
users) and the rest of the users served by a default bearer (MBR is infinity
for all bearers). A delay-bounded quality optimization in the start-up phase
is considered with a target delay value of 2 seconds. For the premium users
with a certain GBR, a scheduler that ensures the enforced GBR is used. There
are two schemes of interest, (i) GBR is enforced by the network but not known
to the DASH clients of the premium users (referred to as \'QASch only\') and
(ii) GBR is enforced by the network and is known by the DASH clients of the
premium users (referred to as \'QASch + QASig\'). Figures B.9 and B.10 plot
the average user throughputs of premium and default users after scheduler\'s
enforcement of GBR=250 kps and 500 kbps, respectively.
Figure B.11 plots the start-up quality CDFs of the premium users for the
comparison of \'QASch only\', and \'QASch + QASig\' schemes at various GBR
values. It is seen that the startup quality improves significantly when the
GBR information is available at the DASH client. The intuition for this result
is clear; in the buffering mode, the DASH client without GBR knowledge will
start with the lowest quality and try to fill up its buffer as fast as
possible, while the DASH client with GBR knowledge can start from a higher
quality level as long as its target start-up delay requirement is satisfied.
For verification purposes, Figure B.12 plots the corresponding start-up delay
CDFs of the premium users; clearly showing that all schemes do meet the
imposed delay requirement.
Figure B.13 plots the overall quality CDFs of the premium users for the
comparison of \'QASch only\', and \'QASch + QASig\' schemes at various GBR
values. As expected, it is seen that the knowledge of the GBR at the DASH
client provides little improvement to the overall quality, since client is
able to rely on its average segment throughput estimates to optimally utilize
the available bandwidth after the start-up phase is over.
{width="5.027777777777778in" height="4.061805555555556in"}
Figure B.2: CDF of Re-buffering percentage with MBR = 2000 Kbps
{width="4.952083333333333in" height="4.01875in"}
Figure B.3: CDF of Re-buffering percentage with MBR = 500 Kbps
{width="5.1097222222222225in" height="4.113888888888889in"}
Figure B.4: CDF of Re-buffering percentage with MBR = 250 Kbps
{width="5.302083333333333in" height="3.9902777777777776in"}
Figure B.5: Percentage of users with Rebuf \< 2 % vs. load
{width="5.220833333333333in" height="4.260416666666667in"}
FigureB.6: Mean Video Quality (PSNR) vs. Load
{width="5.372222222222222in" height="4.217361111111111in"}
Figure B.7: Service Capacity vs. MBR
{width="5.75in" height="4.197916666666667in"}
Figure B.8: Mean Quality at Capacity vs. MBR
{width="5.314583333333333in" height="3.8722222222222222in"}
Figure B.9: CDFs of average user scheduler throughput for GBR=250 kbps
{width="5.135416666666667in" height="3.783333333333333in"}
Figure B.10: CDFs of average user scheduler throughput for GBR=500 kbps
{width="5.949305555555555in" height="4.124305555555556in"}
Figure B.11: Mean Start-up Quality CDF comparison at various GBRs
{width="5.983333333333333in" height="4.418055555555555in"}
Figure B.12: Mean Start-up Delay CDF comparison at various GBRs
{width="5.983333333333333in" height="4.354861111111111in"}
Figure B.13: Mean Overall Quality CDF comparison at various GBRs
#