# Foreword
This Technical Report has been produced by the 3rd Generation Partnership
Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# 1 Scope
This present document provides stage 1 use cases and potential 5G requirements
on supporting tactile and multi-modal communication services. In the context
of the present document, the aspects addressed include:
1) Study new scenarios and identify use cases and potential > requirements for
immersive real time experience involving tactile > and multi-modal
interactions, including:
```{=html}
``` a) Network assistance for coordinated transmission of multiple modal
representations associated with the same session,
b) aspects of charging, security and privacy, and
c) KPIs (including network reliability and availability).
```{=html}
``` 2) Gap analysis with existing requirements and functionalities on >
supporting tactile and multi-modal communication services.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or nonâ€‘specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] ITU-T, \"Technology Watch Report: The Tactile Internet\", August 2014.
[3] O. Holland et al., \"The IEEE 1918.1 \"Tactile Internet\" Standards
Working Group and its Standards,\" Proceedings of the IEEE, vol. 107, no. 2,
Feb. 2019.
[4] 3GPP TS 22.263: \"Service requirements for Video, Imaging and Audio for
Professional Applications\".
[5] S. K. Sharma, I. Woungang, A. Anpalagan and S. Chatzinotas, \"Toward
Tactile Internet in Beyond 5G Era: Recent Advances, Current Issues, and Future
Directions,\" in IEEE Access, vol. 8, pp. 56948-56991, 2020
[6] 3GPP TS 22.261: \"Service requirements for the 5G system\".
[7] Kwang Soon Kim, et al., \"Ultrareliable and Low-Latency Communication
Techniques for Tactile Internet Services\", PROCEEDINGS OF THE IEEE, Vol. 107,
No. 2, February 2019
[8] SAE Manoeuver Sharing and Coordinating Service Task Force,
https://www.sae.org/servlets/works/committeeHome.do?comtID=TEVCSC3A.
[9] SAE Sensor-Sharing Task Force,
https://www.sae.org/servlets/works/committeeHome.do?comtID=TEVCSC3B.
[10] M. During and K. Lemmer, \"Cooperative manoeuver planning for cooperative
driving,\" IEEE Intell. Transp. Syst. Mag., vol. 8, no. 3, pp. 8--22, Jul.
2016.
[11] D. Soldani, Y. Guo, B. Barani, P. Mogensen, I. Chih-Lin, S. Das, \"5G for
ultra-reliable low-latency communications\". IEEE Network. 2018 Apr 2;
32(2):6-7.
[12] Void.
[13] IEEE SA, \"P1918.1 - Tactile Internet: Application Scenarios, Definitions
and Terminology, Architecture, Functions, and Technical Assumptions\",
https://standards.ieee.org/project/1918_1.html
[14] M. Eid, J. Cha, and A. El Saddik, \"Admux: An adaptive multiplexer for
haptic-audio-visual data communication\", IEEE Tran. Instrument. and
Measurement, vol. 60, pp. 21--31, Jan 2011.
[15] K. Iwata, Y. Ishibashi, N. Fukushima, and S. Sugawara, \"QoE assessment
in haptic media, sound, and video transmission: Effect of playout buffering
control\", Comput. Entertain., vol. 8, pp. 12:1--12:14, Dec 2010.
[16] N. Suzuki and S. Katsura, \"Evaluation of QoS in haptic communication
based on bilateral control\", in IEEE Int. Conf. on Mechatronics (ICM), Feb
2013, pp. 886--891.
[17] E. Isomura, S. Tasaka, and T. Nunome, \"A multidimensional QoE monitoring
system for audiovisual and haptic interactive IP communications\", in IEEE
Consumer Communications and Networking Conference (CCNC), Jan 2013, pp. 196--
202.
[18] A. Hamam and A. El Saddik, \"Toward a mathematical model for quality of
experience evaluation of haptic applications\", IEEE Tran. Instrument. and
Measurement, vol. 62, pp. 3315--3322, Dec 2013.
[19] M. Back et al., \"The virtual factory: Exploring 3D worlds as industrial
collaboration and control environments,\" 2010 IEEE Virtual Reality Conference
(VR), 2010, pp. 257-258
[20] S. Schulte, D. Schuller, R. Steinmetz and S. Abels, \"Plug-and-Play
Virtual Factories,\" in IEEE Internet Computing, vol. 16, no. 5, pp. 78-82,
Sept.-Oct. 2012
[21] 3GPP TS 22.104: \"Service requirements for cyber-physical control
applications in vertical domains\"
[22] Altinsoy, M. E., Blauert, J., & Treier, C., \"Inter-Modal Effects of Non-
Simultaneous Stimulus Presentation,\" A. Alippi (Ed.), Proceedings of the 7th
International Congress on Acoustics, Rome, Italy, 2001.
[23] Hirsh I.J., and Sherrrick C.E, 1961. J. Exp. Psychol 62, 423-432
[24] Altinsoy, M.E. (2012). \"The Quality of Auditory-Tactile Virtual
Environments,\" Journal of the Audio Engineering Society, Vol. 60, No. 1/2,
pp. 38-46, Jan.-Feb. 2012.
[25] M. Di Luca and A. Mahnan, \"Perceptual Limits of Visual-Haptic
Simultaneity in Virtual Reality Interactions,\" 2019 IEEE World Haptics
Conference (WHC), 2019, pp. 67-72, doi: 10.1109/WHC.2019.8816173.
[26] Arnon, Shlomi, et al. \"A comparative study of wireless communication
network configurations for medical applications.\" IEEE Wireless
Communications 10.1 (2003): page 56-61.
[27] K. Antonakoglou et al., \"Toward Haptic Communications Over the 5G
Tactile Internet\", IEEE Communications Surveys & Tutorials, 20 (4), 2018.
# 3 Definitions, symbols and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
3GPP TR 21.905 [1] and the following apply. A term defined in the present
document takes precedence over the definition of the same term, if any, in
3GPP TR 21.905 [1].
**end-to-end latency:** the time that takes to transfer a given piece of
information from a source to a destination, measured at the communication
interface, from the moment it is transmitted by the source to the moment it is
successfully received at the destination.
NOTE 1: This definition was taken from TS 22.261 [6].
**Multi-modal Data:** Multi-modal Data is defined to describe the input data
from different kinds of devices/sensors or the output data to different kinds
of destinations (e.g. one or more UEs) required for the same task or
application. Multi-modal Data consists of more than one Single-modal Data, and
there is strong dependency among each Single-modal Data. Single-modal Data can
be seen as one type of data.
**reliability** : in the context of network layer packet transmissions,
percentage value of the amount of sent network layer packets successfully
delivered to a given system entity within the time constraint required by the
targeted service, divided by the total number of sent network layer packets.
NOTE 2: This definition was taken from TS 22.261 [6].
**service area:** geographic region where a 3GPP communication service is
accessible.
NOTE 3: The service area can be indoors.
NOTE 4: For some deployments, e.g., in process industry, the vertical
dimension of the service area can be considerable.
NOTE 5: This definition was taken from TS 22.261 [6].
**synchronisation threshold:** A multi-modal synchronisation threshold can be
defined as the maximum tolerable temporal separation of the onset of two
stimuli, one of which is presented to one sense and the other to another
sense, such that the accompanying sensory objects are perceived as being
synchronous.
NOTE 6: This definition is based on [22].
**Tactile Internet** : A network (or network of networks) for remotely
accessing, perceiving, manipulating, or controlling real or virtual objects or
processes in perceived real time by humans or machines.
NOTE 7: This definition is based on IEEE P1918.1 [3].
**user experienced data rate:** the minimum data rate required to achieve a
sufficient quality experience, with the exception of scenario for broadcast
like services where the given value is the maximum that is needed.
NOTE 8: This definition was taken from TS 22.261 [6].
## 3.2 Symbols
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
DoF Degrees of Freedom
# 4 Overview
## 4.1 Multi-modal service
Tactile and multi-modal communication services enable multiof -modal
interactions, combining ultra-low latency with extremely high availability,
reliability and security. Tactile Internet can be applied in multiple fields,
including: industry, r.obotics and telepresence, virtual reality, augmented
reality, healthcare, road traffic, serious gaming, education and culture,
smart grid, etc. [2]. Multiple modalities can be used in combination in a
service to provide complementary methods that may convey redundant information
but can convey information more effectively. With the benefit of combining
input from more than one source and/or output to more than one destination,
interpretation in communication services will be more accurate and faster,
response can also be quicker, and the communication service will be smoother
and more natural.
For a typical tactile and multi-modal communication service/application, there
can be different modalities affecting the user experience, e.g.:
  * Video/Audio media;
  * Information perceived by sensors about the environment, e.g. > brightness, temperature, humidity, etc.;
  * Haptic data: can be feelings when touching a surface (e.g., > pressure, texture, vibration, temperature), or kinaesthetic senses > (e.g. gravity, pull forces, sense of position awareness).
The ambient information may be further processed to generate IoT control
instructions as the feedback. The haptic data, according to the physiological
perception, has specific characteristics, e.g. frequency and latency, and may
require adequate periodic, deterministic and reliable communication path. For
example, the sampling rate of the haptic device for teleoperation systems may
reach 1000 times per second and samples are typically transmitted individually
hence 1000 packets per second, while the video is 60/90 frames per second. The
high frequency transmission of small packets over a long distance would be a
great challenge for 5G system.
Multiple modalities can be transmitted at the same time to multiple
application servers for further processing in a coordinated manner, in terms
of QoS coordination, traffic synchronization, power saving, etc.
  * Multiple outcomes may be generated as the feedback. In the scenario > of real time remote virtual reality service, a VR user may use a > plurality of independent devices to separately collect video, > audio, ambient and haptic data from the person and to receive > video, audio, ambient and haptic feedback from one or multiple > application servers for a same VR application. In this case, an > end user could wear VR glasses to receive images and sounds, and a > touch glove to receive a touch sensation, a camera to collect > video inputs, a microphone to collect audio inputs, multiple > wearable sensors to provide haptic information and environmental > information associated to the user. The real time remote virtual > reality service can also be conducted between two users.
  * Multiple outcomes may need to reach the distributed UEs at the very > same time. In the scenario of sound field reappearing, different > channels of sounds are sent to the distributed sound boxes to > simulate the sound from a particular direction. A small time > difference may cause big direction error to impact user > experience. In some cases, time difference of 1ms may cause more > than 30Â° angle error.
  * Multi-modal applications may involve a big number of UEs at a long > distance. In the scenario of multi-modal telepresence, tens of UEs > may need synchronization for time, control signal and visual > signal.
In another scenario, the devices associated to the same tactile and multi-
modal communication service may be triggered to wake up by the discovery of a
tactile and multi-modality capable user/UE in proximity. And a different group
of tactile and multi-modality capable devices can serve the user as he moves.
Other scenarios that can be investigated are industrial manufacturing and
drones real-time applications, which require synchronous control of visual-
haptic feedback.
## 4.2 Multi-modal interactive system
{width="6.6930555555555555in" height="2.939583333333333in"}
Figure 4.2-1. Multi-modal interactive system
As shown in figure 4.2-1, multi-modal outputs are generated based on the
inputs from multiple sources. In the multi-modal interactive system, modality
is a type or representation of information in a specific interactive system.
Multi-modal interaction is the process during which information of multiple
modalities are exchanged. Modal types consists of motion, sentiment, gesture,
etc. Modal representations consists of video, audio, tactition (vibrations or
other movements which provide haptic or tactile feelings to a person), etc.
# 5 Use case
## 5.1 Immersive multi-modal Virtual Reality (VR) application
### 5.1.1 Description
Immersive multi-modal VR application describes the case of a human interacting
with virtual entities in a remote environment such that the perception of
interaction with a real physical world is achieved. Users are supposed to
perceive multiple senses (vision, sound, touch) for full immersion in the
virtual environment. The degree of immersion achieved indicates how real the
created virtual environment is. Even a tiny error in the preparation of the
remote environment might be noticed, as humans are quite sensitive when using
immersive multi-modal VR applications. Therefore, a high-field virtual
environment (high-resolution images and 3-D stereo audio) is essential to
achieve an ultimately immersive experience.
One of the major objectives of VR designers and researchers is to obtain more
realistic and compelling virtual environments. As the asynchrony between
different modalities increases, users' sense of presence and realism will
decrease. There have been efforts (since 1960s or even earlier) in multi-
modal-interaction research regarding the detection of synchronisation
thresholds. The obtained results vary, depending on the kind of stimuli and
the psychometric methods employed. Hirsh and Sherrick measured the
synchronisation thresholds regarding visual, auditory and tactile modalities
[23].
{width="5.117361111111111in" height="1.4847222222222223in"}
Figure 5.1.1-1 The synchronisation thresholds regarding visual, auditory and
tactile modalities measured by Hirsh and Sherrick
M.E. Altinsoy and co. believe the audio-tactile synchronization has to be at
least within an accuracy of Â±40 ms [22]. More results have been reported based
on extensive theoretical and experimental efforts. [24] further indicated the
perceptual threshold values were 50 ms for the audio lag and the 25 ms for
audio lead.
As to the visual-tactile synchronisation threshold, Massimiliano Di Luca and
Arash Mahnan provided test results in [25] that indicate that none of the
participants could reliably detect the asynchrony if haptic feedback was
presented less than 50ms after the view of the contact with an object. The
asynchrony tolerated for haptic before visual feedback was instead only 15ms.
### 5.1.2 Pre-conditions
The devices for immersive multi-modal VR application may include multiple
types of devices such as VR glass type device, the gloves and other potential
devices that support haptic and/or kinaesthetic modal. These devices which are
5G UEs are connected to the immersive multi-modal VR application server via
the 5G network without any UE relays, see Figure 5.1.2-1.
NOTE: The devices that are connected to VR application via the 5G network are
assumed to be 3GPP UEs.
Based on the service agreement between MNO and immersive multi-modal VR
application operator, the application operator may in advance provide the 5G
network with the application information including the application traffic
characteristics and the service requirement for network connection. For
example, the packet size for haptic data is related to the Degrees Of Freedom
(DoF) that the haptic devices supports, and packet size for one DoF is 2-8
Bytes [3] and the haptic device generates and sends 500 haptic packets within
one second.
{width="6.761805555555555in" height="1.7027777777777777in"}
Figure 5.1.2-1. Immersive multi-modal VR application with multiple 5G UEs
directly connected to 5G network
### 5.1.3 Service Flows
1\. The application user utilizes the devices to experience immersive multi-
modal VR application. The user powers on the devices to connect to the
application server, then the user starts the gaming application.
2\. During the gaming running period, the devices periodically send the
sensing information to the application server, including: haptic and/or
kinesthetic feedback signal information which is generated by haptic device,
and the sensing information such as positioning and view information which is
generated by the VR glasses.
NOTE 1: The devices may send the haptic data and the sensing data with
different periodic time. As an example, the device may send one packet
containing haptic information to the application server every 2ms, and send
the packets related to sensing information to application server every 4ms.
Thus the haptic data and sensing data may be transferred in 5G network via two
separate flows. The amount of haptic packets that are generated and
transferred within one second may be 1K - 4K packets (without haptic
compression encoding), or 100-500 packets (with haptic compression encoding).
As indicated in IEEE 1918.1 [3], the size of each haptic packet is related to
the DoF capacity that haptic device supports, the data size for one DoF is 2-8
Byte.
3\. According to the uplink data from the devices, the application server
performs necessary process operations on immersive game reality including
rendering and coding the video, the audio and haptic model data, then
application server periodically sends the downlink data to the devices, with
different time periods respectively, via 5G network.
NOTE 2: The application server may also send the haptic data and the
video/audio data with different periodic time. For example, the application
server sends one packet containing haptic information to the device every 2ms,
and it sends the packets related to one video/audio frame to the device every
16.7ms in case 60 Frame Per Second which forms one burst traffic that goes on
3ms. Thus the haptic data and audio/video data may be transferred via two
separate service data flows of a single session.
4\. The devices, respectively, receive the data from the application server
and present the related sensing including video, audio and haptic to the user.
NOTE 3: To obtain more realistic and compelling virtual environments, network
assistance may be needed to ensure synchronisation thresholds between
different modal data thus improve the end users' sense of presence and
realism.
### 5.1.4 Post-conditions
The user experiences the immersive game reality application enabled by 5G
network, and the 5G system address the service requirements of the
application.
### 5.1.5 Existing features partly or fully covering the use case
functionality
3GPP TS 22.261 [6] specifies KPIs for high data rate and low latency
interactive services including Cloud/Edge/Split Rendering, Gaming or
Interactive Data Exchanging, Consumption of VR content via tethered VR
headset, and audio-video synchronization thresholds.
Support of audio-video synchronisation thresholds has been captured in TS
22.261:
> _Due to the separate handling of the audio and video component, the 5G
> system will have to cater for the VR audio-video synchronisation in order to
> avoid having a negative impact on the user experience (i.e. viewers
> detecting lack of synchronization). To support VR environments, the 5G
> system shall support audio-video synchronisation thresholds:_
>
> _\- in the range of [125 ms to 5 ms] for audio delayed and_
>
> _\- in the range of [45 ms to 5 ms] for audio advanced._
### 5.1.6 Potential New Requirements needed to support the use case
[PR 5.1.6-1] The 5G System shall provide the network connection to address the
KPIs for immersive multi-modal VR applications, see table 5.1.6-1.
Table 5.1.6-1 -- Potential key performance requirements for immersive multi-
modal VR applications
+-------+-------+-------+-------+-------+-------+-------+-------+-------+ | **Use | * | * | * | | | | | | | Ca |_Char |_ Infl | *Rema | | | | | | | ses** | acter | uence | rks**| | | | | | | | istic | quant | | | | | | | | | para | ity** | | | | | | | | | meter | | | | | | | | | | (K | | | | | | | | | | PI)**| | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | |** Max | **Se |** Rel | **Me |** # | **UE |** Se | | | | al | rvice | iabil | ssage | of | Sp | rvice | | | | lowed | bit | ity**| size | UEs** | eed**| A | | | | end-t | rate: | | (by | | | rea** | | | | o-end | u | | te)**| | | | | | | late | ser-e | | | | | | | | | ncy** | xperi | | | | | | | | | | enced | | | | | | | | | | data | | | | | | | | | | r | | | | | | | | | | ate** | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | Imme | 5 ms | 16 | [99 | 1 | - | Stati | typi | H | | rsive | | k | .9%] | DoF: | | onary | cally | aptic | | m | (note | bit/s | (wi | 2-8 | | or | | fee | | ulti- | 2) | -2 | thout | | | Pedes | \ integrated camera and sensor to send back video, audio and haptic > information.
  2. Alice hold the control stick and can receive the haptic information, > and receive the video, audio information synchronous on the screen > and from the sound.
  3. After analysing these information, Alice perform the next move on > the operator sticker.
  4. The haptic information including force and DoF transfer to remote > robot, and the robot performs the same action.
### 5.2.4 Post-conditions
Alice can remotely control the robot to finish the maintaining work.
### 5.2.5 Existing features partly or fully covering the use case
functionality
In 3GPP TS 22.263 [4], there are requirements for supporting video, imaging
and audio for professional applications.
### 5.2.6 Potential New Requirements needed to support the use case
[PR 5.2.6-1] The 5G system shall be able to support tactile and multi-modal
communication service with following KPIs.
Table 5.2.6-2: Potential Key performance requirements for remote control robot
[3]
+-------+-------+-------+-------+-------+-------+-------+-------+-------+ | **Use | * | * | * | | | | | | | Ca |_Char |_ Infl | *Rema | | | | | | | ses** | acter | uence | rks**| | | | | | | | istic | quant | | | | | | | | | para | ity** | | | | | | | | | meter | | | | | | | | | | (K | | | | | | | | | | PI)**| | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | |** Max | **Se |** Rel | **Me |** # | **UE |** Se | | | | al | rvice | iabil | ssage | of | Sp | rvice | | | | lowed | bit | ity**| size | UEs** | eed**| Ar | | | | end-t | rate: | | (by | | | ea[2 | | | | o-end | u | | te)** | | | 1]**| | | | late | ser-e | | | | | | | | | ncy** | xperi | | | | | | | | | | enced | | | | | | | | | | data | | | | | | | | | | r | | | | | | | | | | ate** | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | R | 1 | 16 | 9 | 2- | - | hi | â‰¤ 1 | H | | emote | -20ms | k | 9.99% | 8/DoF | | gh-dy | km^2^ | aptic | | co | | bit/s | | | | namic | | fee | | ntrol | | -2 | | | | | | dback | | robot | | M | | | | (â‰¤ 50 | | | | | | bit/s | | | | km/h) | | | | | | | | | | | | | | | | (wi | | | | | | | | | | thout | | | | | | | | | | h | | | | | | | | | | aptic | | | | | | | | | | c | | | | | | | | | | ompre | | | | | | | | | | ssion | | | | | | | | | | encod | | | | | | | | | | ing); | | | | | | | | | | | | | | | | | | | | 0.8 - | | | | | | | | | | 200 | | | | | | | | | | k | | | | | | | | | | bit/s | | | | | | | | | | | | | | | | | | | | (with | | | | | | | | | | h | | | | | | | | | | aptic | | | | | | | | | | c | | | | | | | | | | ompre | | | | | | | | | | ssion | | | | | | | | | | enco | | | | | | | | | | ding) | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | 20- | 16 | 9 | 2- | - | Stati | â‰¤ 1 | H | | | 100ms | k | 9.99% | 8/DoF | | onary | km^2^ | aptic | | | | bit/s | | | | or | | fee | | | | -2 | | | | Pedes | | dback | | | | M | | | | trian | | | | | | bit/s | | | | | | | | | | | | | | | | | | | | (wi | | | | | | | | | | thout | | | | | | | | | | h | | | | | | | | | | aptic | | | | | | | | | | c | | | | | | | | | | ompre | | | | | | | | | | ssion | | | | | | | | | | encod | | | | | | | | | | ing); | | | | | | | | | | | | | | | | | | | | 0.8 - | | | | | | | | | | 200 | | | | | | | | | | k | | | | | | | | | | bit/s | | | | | | | | | | | | | | | | | | | | (with | | | | | | | | | | h | | | | | | | | | | aptic | | | | | | | | | | c | | | | | | | | | | ompre | | | | | | | | | | ssion | | | | | | | | | | enco | | | | | | | | | | ding) | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | 1-100 | 99.9% | 1500 | - | Stati | â‰¤ 1 | Video | | | | M | | | | onary | km^2^ | | | | | bit/s | | | | or | | | | | | | | | | Pedes | | | | | | | | | | trian | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | 5-512 | 99.9% | 5 | - | Stati | â‰¤ 1 | Audio | | | | k | | 0-100 | | onary | km^2^ | | | | | bit/s | | | | or | | | | | | | | | | Pedes | | | | | | | | | | trian | | | +-------+-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | \ Clause 6.3 Multiple Access Technologies
>
> "The 5G system shall support a set of identities for a single user in order
> to provide a consistent set of policies and a single set of services across
> 3GPP and non-3GPP access type"
>
> Clause 6.26.2.5 Traffic Types
>
> "The 5G system shall support traffic scenarios typically found in a home
> setting (from sensors to video streaming, relatively low amount of UEs per
> group, many devices are used only occasionally) for 5G LAN-type service"
### 5.5.6 Potential New Requirements needed to support the use case
[PR. 5.5.6-1] The 5G network shall support a mechanism to allow an authorized
3rd party to provide QoS policy for flows of multiple UEs associated with an
application. The policy may contain e.g. the expected 5GS handling and the
associated triggering event.
[PR. 5.5.6-2] The 5G system shall support a mechanism to apply QoS policy for
flows of multiple UEs associated with an application received from an
authorized 3rd party.
[PR 5.5.6-3] The 5G system shall provide a network connection to address the
KPIs for immersive multi-modal navigation applications, see Table 5.5.6-1.
Table 5.5.6-1: Potential Key performance requirements for a personal exclusion
zone in dangerous remote environments.
| **Use Cases** | **Characteristic parameter (KPI)** | **Influence quantity** | **Remarks** |  |  |  |  |  |   
---|---|---|---|---|---|---|---|---|---|---  
|  | **Max allowed end-to-end latency** | **Service bit rate: user-experienced data rate** | **Reliability** | **Message size (byte)** | **# of UEs** | **UE Speed** | **Service Area** |  |   
| Immersive multi-modal navigation applications Remote Site ïƒ  Local Site (DL) | 50 ms [11] | 16 kbit/s -2 Mbit/s (without haptic compression encoding) 0.8 - 200 kbit/s (with haptic compression encoding) | [99.999 %] | 1 DoF:  
2 to 8 10 DoF:  
20 to 80 100 DoF:  
200 to 800 | - | Stationary or Pedestrian | â‰¤ 100 km2 NOTE 2 | Haptic feedback |   
|  |  generation, the primary camera placed in a location owning the > best view
  * Camera#2: data collection for motion prediction, placed in the best > location for capturing the motion
  * Camera#3: data collection for motion prediction and footage > generation
  * Camera#4: data collection for footage generation
  * Camera#5: data collection for motion prediction
### 5.6.3 Service Flows
  1. The football game starts. Camera#1, Camera#2, Camera#3, Camera#4 > and Camera#5, as the UEs, are switched on and registered to the > 5GS network to collect video and audio data to conduct Live Event > Selective Immersion service.
  2. The Application Server informs 5GS that UEs corresponding to > Camera#1, Camera#2, Camera#3, Camera#4 and Camera#5 are > subject to the service application, and provides QoS requirements > of these UEs and the coordination policies for this multi-modal > service for assistance from 5GS.
  3. The QoS requirements and the coordination policy are applied at 5GS. > Camera#1, Camera#2, Camera#3, Camera#4 and Camera#5 transmit > the collected data over 5GS to the Application Server at the > target QoS.
  4. The Application Server makes motion prediction based on data > received from Camera#1, Camera#2, Camera#3 and Camera#5, and > generates footages based on data received from Camera#1, > Camera#3 and Camera#4.
  5. The Application Server transmits motion prediction of the object(s) > over 5GS to Camera#1, Camera#2, Camera#3 and Camera#5 and > transmits footages over 5GS to Alice's UE.
  6. Some people are gathering at the gate of the stadium for the > celebration of winning scores, then network congestion happens > from time to time. Based on the coordination policy of the > multi-modal service, when the target QoS of Camera#1 can't be > guaranteed, 5GS reduces QoS of Camera#4 to make sure QoS of > Camera#1 is guaranteed; when the congestion is relieved, 5GS > increases QoS of Camera#4 while target QoS of Camera#1 is still > guaranteed.
  7. The network congestion gets more serious, and target QoS of > Camera#2 can't be guaranteed. Since the motion data collected by > Camera#2 is mandatory for motion prediction without which the > motion prediction can't be made, 5GS releases resources of > Camera#2 and Camera#5 based on the coordination policy of the > multi-modal service.
NOTE: When motion prediction doesn't work, the Application Server may request
the 5GS network to only guarantee QoS of Camera#1 or to release resources of
all the cameras. This is beyond what 5GS can coordinate.
### 5.6.4 Post-conditions
Alice receives multiple footages and selects one of them to enjoy the
immersive experience.
### 5.6.5 Existing features partly or fully covering the use case
functionality
TS 22.261 clause 6.7.2 and clause 6.8 defined the following policy control
requirements that can be reused to this use case:
  * The 5G system shall be able to provide the required QoS (e.g. > reliability, end-to-end latency, and bandwidth) for a service and > support prioritization of resources when necessary for that > service.
  * The 5G system shall be able to support QoS for applications in a > Service Hosting Environment.
  * The 5G system shall support the creation and enforcement of > prioritisation policy for users and traffic, during connection > setup and when connected.
  * Based on operator policy, the 5G system shall support a real-time, > dynamic, secure and efficient means for authorized entities (e.g. > users, context aware network functionality) to modify the QoS and > policy framework. Such modifications may have a variable duration.
3GPP TS 22.261 [6] clause 6.23.2 defines the following requirements enabling
5GS to notify an authorized entity of the communication events:
  * The 5G system shall be able to provide notification of communication > events to authorized entities per pre-defined patterns (e.g. every > time the bandwidth drops below a pre-defined threshold for QoS > parameters the authorized entity is notified, and the event is > logged).
### 5.6.6 Potential New Requirements needed to support the use case
[PR 5.6.6-1] The 5G system shall support a mechanism to allow an authorized
3rd party to provide QoS policy for flows of multiple UEs associated with an
application. The policy may contain e.g. the expected 5GS handling and the
associated triggering event.
[PR 5.6.6-2] The 5G system shall support a mechanism to apply QoS policy for
flows of multiple UEs associated with an application received from an
authorized 3rd party.
## 5.7 Support for IEEE P1918.1 architecture
5.7.1 Description
The on-going IEEE project P1918.1 "Tactile Internet: Application Scenarios,
Definitions and Terminology, Architecture, Functions, and Technical
Assumptions" [13] facilitates the rapid realization of the Tactile Internet as
a 5G and beyond application, across a range of different user groups. The
standard defines a framework for the Tactile Internet, including descriptions
of various application scenarios, definitions and terminology, functions, and
technical assumptions. This framework prominently also includes a reference
model and architecture, which defines common architectural entities,
interfaces between those entities, and the mapping of functions to those
entities. The Tactile Internet encompasses low latency high reliability
applications (e.g., manufacturing, transportation, healthcare and mobility),
as well as non-critical applications (e.g., edutainment and events).
Tactile Internet provides a medium for remote physical interaction, including
the exchange of haptic information. This interaction are among humans and / or
machines (e.g., robots, networked functions, software, or any other connected
entity). There are two broad categories of haptic information, namely, tactile
or kinaesthetic. Tactile information refers to the perception of information
by the various mechanoreceptors of the human skin, such as surface texture,
friction, and temperature. Kinaesthetic information refers to the information
perceived by the skeleton, muscles, and tendons of the human body, such as
force, torque, position, and velocity. The goal of Tactile Internet in human-
in-the-loop scenarios is that humans should not be able to distinguish between
locally executing a manipulative task compared to remotely performing the same
task across the Tactile Internet.
Figure 5.8.1-1 illustrates the functional architecture for the Tactile
Internet proposed by IEEE P1918.1 [3]. Each tactile edge consists of one or
multiple tactile devices (TD), where TDs in tactile edge A communicate tactile
/ haptic information with TDs in tactile edge B through a network domain, to
meet the requirements of a given Tactile Internet use case. The gateway node
(GN) is an entity with enhanced networking capabilities that resides at the
interface between the tactile edge and the network domain and is mainly
responsible for user plane data forwarding. The GN is accompanied by a network
controller (NC) that is responsible for control plane processing including
intelligence for admission and congestion control, service provisioning,
resource management and optimization, and connection management in order to
achieve the required QoS for the Tactile Internet session. The network domain
is shown to be composed of a radio access point or base station connected
logically to control plane entities (CPEs) and user plane entities in the
network core. 5G radio access and core network can be a network domain to meet
the quality requirements of tactile use cases.
{width="6.354861111111111in" height="3.7715277777777776in"}
* * *
**AG:** Actuator Gateway **AN:** Actuator Node **CN:** Controller Node
**CPE:** Control Plane Entity **GN:** Gateway Node **GNC:** GN & CN **HN:**
human-system interface node **NC:** Network Controller **S/A:**
Sensor/Actuator **SE:** computing and storage Entity **SG:** Sensor Gateway
**SN:** Sensor Node **TD:** Tactile Device **TSM:** Tactile Service Manager
**UPE:** User Plane Entity
* * *
**Figure 5.7.1-1. IEEE** **P1918.1** **[3] architecture with the GN and the NC
residing as part of the network domain**
The tactile service manager (TSM) plays a critical role in defining the
characteristics and requirements of the service between the two tactile edges
and in disseminating this information to key nodes in the tactile edge and
network domain. The control information between the TSM and the GNC is carried
over Service (S) Interface. SE, a computing and storage entity, provides both
computing and storage resources for improving the performance of the tactile
edges and meeting the delay and reliability requirements of the E2E
communications. Open (O) Interface is used to carry information exchange
between any architectural entity and the SE.
We demonstrate how 5G network is used as the "network domain" in the IEEE
P1918.1 [3] architecture to support a typical multi-modal use case --
teleoperation.
### 5.7.2 Pre-conditions
Teleoperation allows human users to immerse into an inaccessible environment
to perform complex tasks. A typical teleoperation system includes a controller
(i.e., the user) and a device (i.e., the tele-manipulator), which exchange
haptic signals (forces, torques, position, velocity, vibration, etc.), video
signals, and audio signals over a communication network. In particular, the
communication of haptic information imposes strong demands on the
communication network as it closes a global control loop between the user and
the tele-operator. Four communication streams are involved in a typical multi-
modal use case -- teleoperation:
  * Haptic Control stream. It carries command queries from the user to > the remote haptic equipment.
  * Haptic Feedback stream. It carries sensor data and response queries > from the remote haptic equipment back to the user.
  * Video stream. It carries an encoded video stream from the remote > environment back to the user. Depending on the resolution of the > video, this stream usually occupies the highest percentage of the > bandwidth of the communicational channel.
  * Audio stream. It carries audio data from the remote environment back > to the user.
Note that multiple devices may be involved at both or either side of the
multi-modal communication, and a single multi-modal communication session may
comprise multiple streams between multiple devices. It is assumed that all the
above streams are carried over the 5G network as the "network domain" as
defined in IEEE P1918.1 functional architecture.
### 5.7.3 Service Flows
1\. Both the controller ("Tactile Edge A") and the tele-manipulator ("Tactile
Edge B") are equipped with multiple devices to capture, transmit and receive
audio, video and haptic information.
2\. When a session starts, multiple streams are established over the 5G
network ("Network Domain" in the IEEE P1918.1 architecture) between the
corresponding devices at the controller and the tele-manipulator that carry
multiple modalities data. Table 5.7.3-1 depicts the typical QoS requirements
that have to be fulfilled in order for the users' QoE to be satisfactory.
Table 5.7.3-1 Typical QoS requirements for multi-modal streams [14] [15] [16]
[17] [18]
* * *
                        **Haptics**   **Video**      **Audio**
Jitter (ms) â‰¤ 2 â‰¤ 30 â‰¤ 30 Delay (ms) â‰¤ 50 â‰¤ 400 â‰¤ 150 Packet loss (%) â‰¤ 10 â‰¤ 1
â‰¤ 1 Update rate (Hz) â‰¥ 1000 â‰¥ 30 â‰¥ 50 Packet size (bytes) 64-128 â‰¤ MTU 160-320
Throughput (kbit/s) 512-1024 2500 - 40000 64-128
* * *
3\. The controller starts to capture the first Media Units (MUs) of haptic
information, video and voice at the same time. In this case, the three MUs
have the same timestamp, which represents the generation time. Assuming that
the sampling interval for haptics, video and audio are 1 ms, 30 ms and 20 ms.
The source transmits the first haptic MU about 20-30 ms earlier than the MUs
of audio and video, which may result in more 20 ms difference between the
arrival time of the MUs of different modalities. If the destination outputs
the MUs at the same time, it has to delay the output of the haptic MU until
the voice and video MUs arrive at the destination.
4\. A Synchronization Unit is assumed to preserve the time relation of the
original signal as steady as possible and synchronize the three media streams
with each other. This unit can be part of TSM or can be located in the Tactile
Edge. Synchronization becomes increasingly challenging with the increasing
demand from the application itself, for example immersive XR experience, as
well as the inevitable jitter/delay issues (especially due to the nature of
the wireless communication) in the network domain. Necessary information is
exchanged between the TSM (including the synchronization unit) and the 5G
network for the assistance of the synchronization between different streams of
a multi-modal communication session. Audio, video and haptic MUs arrive at the
Synchronization Unit and are re-synchronized before getting to the
destination.
### 5.7.4 Post-conditions
The user enjoys the good experiences in teleoperation enabled by 5G network
and Tactile Internet, where human users are not being able to distinguish
between locally executing a manipulative task compared to remotely performing
the same task across the Tactile Internet.
### 5.7.5 Existing features partly or fully covering the use case
functionality
TS 22.261 [6], TS 22.263 [4] and TS 22.104 [21] have captured the KPIs for
high data rate and low latency interactive services including Cloud/Edge/Split
Rendering, Gaming or Interactive Data Exchanging, Consumption of VR content
via tethered VR headset, and audio-video synchronization thresholds.
### 5.7.6 Potential New Requirements needed to support the use case
[PR 5.7.6-1] The 5G system shall support a mechanism to ensure users' QoE of
the multi-modal communication service involving one or multiple devices at
either end of the communication. QoE refers to the difference of the physical
interaction across the 5G network and the same manipulation carried out
locally.
[PR 5.7.6-2] The 5G system shall support a mechanism for a 3^rd^ party
application server to provide real-time feedback on the traffic
characteristics and service requirements of the multiple streams of a multi-
modal communication session.
[PR 5.7.6-3] The 5G system shall support a mechanism to assist the
synchronisation between the multiple streams (e.g., haptic, audio and video)
of a multi-modal communication session in order to avoid the negative impact
on the user experience.
## 5.8 Virtual factory
### 5.8.1 Description
Virtual factory is an important feature in industry 4.0, which provides people
on remote site easy access to factory. Virtual factory could support immersive
monitor of real scene, simulation and analysis on production line planning and
practical production adjustment.
{width="3.4930555555555554in" height="4.25in"}
Figure 5.8.1-1. Virtual Factory and a photo of the real factory floor under
construction [19].
Also it can provide an approach in managing distributed realistic factory when
considering establishing a complex production line which need to combine the
capability of several factories.
{width="3.4625in" height="2.532638888888889in"}
Figure 5.8.1-2. A service-oriented virtual factory [20]
### 5.8.2 Pre-conditions
  1. Factory is covered by 5G signals. An industrial robot and a > monitoring camera are connected to 5G network.
  2. The remote site where the virtual factory will be displayed is also > covered by 5G signals.
### 5.8.3 Service Flows
  1. The factory first tells 5G network that the data flows of motion information collector of robot and monitor video need coordination.
  2. The motion information of the robot is collected and transferred through dataflow 1. A monitor camera captures the real movement of the industrial robot and transmit video signal through dataflow 2. Network will mark these two data flows according to the information factory provided.
  3. Data flow1 which carries the motion information signal will be transferred to the VR server and produce VR video according to the motion information. Dataflow 2 will be transferred directly to a screen in the remote site.
  4. On the remote site, there's a VR glasses which will receive the video data from the VR server. Alongside the VR glasses there's the monitor screen of the real robot motion.
  5. As the processing from motion information to VR video need time, dataflow 2 should be hold by network for a certain period. The dataflow of VR and monitor video will arrive at the remote site within a certain time window, so that users will not feel the delay between these two flows.
{width="3.571527777777778in" height="2.4125in"}
Figure 5.8.3-1. Figure of service flow on virtual factory
### 5.8.4 Post-conditions
Due to the coordination processing network has done, users can see the virtual
factory through VR glasses and the real scene in factory on screen without
feeling any delay.
### 5.8.5 Existing features partly or fully covering the use case
functionality
none
### 5.8.6 Potential New Requirements needed to support the use case
[PR 5.8.6-1] 5G system shall be able to support the interaction with
applications on UEs or data flows grouping information within one tactile and
multi-modal communication service.
[PR 5.8.6-2] The 5G system shall support a means to apply 3rd party provided
policy(ies) for flows associated with an application. The policy may contain
e.g. the set of UEs and data flows, the expected QoS handling and associated
triggering events, other coordination information.
NOTE: The policy can be used by a 3rd party application for coordination of
the transmission of multiple UEs' flows (e.g., haptic, audio and video) of a
multi-modal communication session.
# 6 Consolidated requirements
## 6.1 Consolidated potential requirements
**Table 6.1-1: Consolidated Requirements**
+------------+-------------------+-------------------+-------------+ | **CPR #** | **Original PR |** Consolidated | **Comment** | | | #**| Potential | | | | | Requirement** | | +------------+-------------------+-------------------+-------------+ | CPR 6.1-1 | [PR 5.2.6-2], | The 5G system | | | | [PR 5.3.6-2], | shall enable an | | | | [PR 5.5.6-1], | authorized 3rd | | | | [PR 5.6.6-1], | party to provide | | | | [PR 5.7.6-2], | policy(ies) for | | | | [PR 5.8.6-1], | flows associated | | | | | with an | | | | | application. The | | | | | policy may | | | | | contain e.g. the | | | | | set of UEs and | | | | | data flows, the | | | | | expected QoS | | | | | handling and | | | | | associated | | | | | triggering | | | | | events, other | | | | | coordination | | | | | information. | | | | | | | | | | NOTE: The policy | | | | | can be used by a | | | | | 3rd party | | | | | application for | | | | | coordination of | | | | | the transmission | | | | | of multiple UEs' | | | | | flows (e.g., | | | | | haptic, audio and | | | | | video) of a | | | | | multi-modal | | | | | communication | | | | | session. | | +------------+-------------------+-------------------+-------------+ | CPR 6.1-2 | [PR 5.5.6-2], | The 5G system | | | | | shall support a | | | | [PR 5.6.6-2], | means to apply | | | | | 3rd party | | | | [PR 5.7.6-3], | provided | | | | [PR 5.8.6-2] | policy(ies) for | | | | | flows associated | | | | | with an | | | | | application. The | | | | | policy may | | | | | contain e.g. the | | | | | set of UEs and | | | | | data flows, the | | | | | expected QoS | | | | | handling and | | | | | associated | | | | | triggering | | | | | events, other | | | | | coordination | | | | | information. | | | | | | | | | | NOTE: The policy | | | | | can be used by a | | | | | 3rd party | | | | | application for | | | | | coordination of | | | | | the transmission | | | | | of multiple UEs' | | | | | flows (e.g., | | | | | haptic, audio and | | | | | video) of a | | | | | multi-modal | | | | | communication | | | | | session. | | +------------+-------------------+-------------------+-------------+
## 6.2 Consolidated potential KPIs
The 5G system shall support tactile and multi-modal communication services
with the following KPIs.
Table 6.2-1: Multi-modal communication service performance requirements
+-------+-------+-------+-------+-------+-------+-------+-------+ | **Use | * | * | * | | | | | | Ca |_Char |_ Infl | *Rema | | | | | | ses** | acter | uence | rks**| | | | | | | istic | quant | | | | | | | | para | ity** | | | | | | | | meter | | | | | | | | | (K | | | | | | | | | PI)**| | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | |** Max | **Se |** Rel | **Me |** UE | **Se | | | | al | rvice | iabil | ssage | Sp | rvice | | | | lowed | bit | ity** | size | eed**| A | | | | end-t | rate: | | (by | | rea** | | | | o-end | u | | te)**| | | | | | late | ser-e | | | | | | | | ncy** | xperi | | | | | | | | | enced | | | | | | | | | data | | | | | | | | | r | | | | | | | | | ate** | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Imme | 5 ms | 16 | 99.9% | 1 | Stati | typi | H | | rsive | | k | (wi | DoF: | onary | cally | aptic | | m | (note | bit/s | thout | 2-8 | or | | fee | | ulti- | 2) | -2 | h | | Pedes | \< | dback | | modal | | M | aptic | 3 | trian | 100 | | | VR | | bit/s | c | DoFs: | | km^2^ | | | (UL: | | | ompre | 6-24 | | | | | d | | (wi | ssion | | | (note | | | evice | | thout | enco | 6 | | 5) | | | ïƒ  | | h | ding) | DoFs: | | | | | a | | aptic | | 12-48 | | | | | pplic | | c | 99 | | | | | | ation | | ompre | .999% | More | | | | | s | | ssion | (with | DoFs | | | | | ever) | | encod | h | can | | | | | | | ing); | aptic | be | | | | | | | | c | supp | | | | | | | 0.8 - | ompre | orted | | | | | | | 200 | ssion | by | | | | | | | k | enco | the | | | | | | | bit/s | ding) | h | | | | | | | | | aptic | | | | | | | (with | [3] | d | | | | | | | h | | evice | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | enco | | | | | | | | | ding) | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | \< | 9 | 1500 | Stati | typi | Se | | | | 1M | 9.99% | | onary | cally | nsing | | | | bit/s | | | or | | i | | | | | [3] | | Pedes | \< | nform | | | | | | | trian | 100 | ation | | | | | | | | km^2^ | e.g. | | | | | | | | | pos | | | | | | | | (note | ition | | | | | | | | 5) | and | | | | | | | | | view | | | | | | | | | i | | | | | | | | | nform | | | | | | | | | ation | | | | | | | | | gene | | | | | | | | | rated | | | | | | | | | by | | | | | | | | | the | | | | | | | | | VR | | | | | | | | | gl | | | | | | | | | asses | +-------+-------+-------+-------+-------+-------+-------+-------+ | Imme | 10 ms | 1-100 | 99.9% | 1500 | Stati | typi | Video | | rsive | | M | | | onary | cally | | | m | (n | bit/s | [3] | | or | | | | ulti- | ote1) | | | | Pedes | \< | | | modal | | | | | trian | 100 | | | VR | | | | | | km^2^ | | | (DL: | | | | | | | | | a | | | | | | (note | | | pplic | | | | | | 5) | | | ation | | | | | | | | | sever | | | | | | | | | ïƒ  | | | | | | | | | de | | | | | | | | | vice) | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 10 ms | 5-512 | 99.9% | 50 | Stati | typi | Audio | | | | k | | | onary | cally | | | | | bit/s | [3] | | or | | | | | | | | | Pedes | \< | | | | | | | | trian | 100 | | | | | | | | | km^2^ | | | | | | | | | | | | | | | | | | (note | | | | | | | | | 5) | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | 16 | 99.9% | 1 | Stati | typi | H | | | | k | (wi | DoF: | onary | cally | aptic | | | (note | bit/s | thout | 2-8 | or | | fee | | | 2) | -2 | h | | Pedes | \< | dback | | | | M | aptic | 3 | trian | 100 | | | | | bit/s | c | DoFs: | | km^2^ | | | | | | ompre | 6-24 | | | | | | | (wi | ssion | | | (note | | | | | thout | enco | 6 | | 5) | | | | | h | ding) | DoFs: | | | | | | | aptic | | 12-48 | | | | | | | c | 99 | | | | | | | | ompre | .999% | | | | | | | | ssion | (with | | | | | | | | encod | h | | | | | | | | ing); | aptic | | | | | | | | | c | | | | | | | | 0.8 - | ompre | | | | | | | | 200 | ssion | | | | | | | | k | enco | | | | | | | | bit/s | ding) | | | | | | | | | | | | | | | | | (with | [3] | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | enco | | | | | | | | | ding) | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | R | 1 | 16 | 99 | 2-8 | hi | â‰¤ 1 | H | | emote | -20ms | k | .999% | (1 | gh-dy | km^2^ | aptic | | co | | bit/s | | DoF) | namic | | fee | | ntrol | | -2 | [3] | | (â‰¤ 50 | | dback | | robot | | M | | | km/h) | | | | | | bit/s | | | | | | | | | | | | | | | | | | (wi | | | | | | | | | thout | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | encod | | | | | | | | | ing); | | | | | | | | | | | | | | | | | | 0.8 - | | | | | | | | | 200 | | | | | | | | | k | | | | | | | | | bit/s | | | | | | | | | | | | | | | | | | (with | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | enco | | | | | | | | | ding) | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 20- | 16 | 99 | 2-8 | Stati | â‰¤ 1 | H | | | 100ms | k | .999% | (1 | onary | km^2^ | aptic | | | | bit/s | | DoF) | or | | fee | | | | -2 | [3] | | Pedes | | dback | | | | M | | | trian | | | | | | bit/s | | | | | | | | | | | | | | | | | | (wi | | | | | | | | | thout | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | encod | | | | | | | | | ing); | | | | | | | | | | | | | | | | | | 0.8 - | | | | | | | | | 200 | | | | | | | | | k | | | | | | | | | bit/s | | | | | | | | | | | | | | | | | | (with | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | enco | | | | | | | | | ding) | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | 1-100 | 99 | 1500 | Stati | â‰¤ 1 | Video | | | | M | .999% | | onary | km^2^ | | | | | bit/s | | | or | | | | | | | [3] | | Pedes | | | | | | | | | trian | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | 5-512 | 99.9% | 5 | Stati | â‰¤ 1 | Audio | | | | k | | 0-100 | onary | km^2^ | | | | | bit/s | [3] | | or | | | | | | | | | Pedes | | | | | | | | | trian | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 5 ms | \< | 99 | - | Stati | â‰¤ 1 | S | | | | 1M | .999% | | onary | km^2^ | ensor | | | | bit/s | | | or | | i | | | | | [3] | | Pedes | | nform | | | | | | | trian | | ation | +-------+-------+-------+-------+-------+-------+-------+-------+
+-------+-------+-------+-------+-------+-------+-------+-------+ | Ski | 5 | 0.8 - | 99 | 1 | Stati | **100 | H | | llset | -10ms | 200 | ,999% | DoF: | onary | km | aptic | | sh | | k | | 2-8 | or | ^2^** | | | aring | | bit/s | \ | | Pedes | | (posi | | low- | | (with | [3]\ | 3 | trian | | tion, | | dy | | co | [27] | DoFs: | | | velo | | namic | | mpres | | 6-24 | | | city) | | rob | | sion) | | | | | | | otics | | | | 6 | | | | | | | | | DoFs: | | | | | (incl | | | | 12-48 | | | | | uding | | | | | | | | | tele | | | | | | | | | opera | | | | | | | | | tion) | | | | | | | | | Contr | | | | | | | | | oller | | | | | | | | | to | | | | | | | | | cont | | | | | | | | | rolee | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Ski | 5 | 0.8 - | 99 | 1 | Stati | **100 | H | | llset | -10ms | 200 | ,999% | DoF: | onary | km | aptic | | sh | | k | | 2-8 | or | ^2^** | fee | | aring | | bit/s | \ | | Pedes | | dback | | low- | | (with | [3]\ | 10 | trian | | | | dy | | co | [27] | DoFs: | | | | | namic | | mpres | | 20-80 | | | | | rob | | sion) | | | | | | | otics | | | | 100 | | | | | | | | | DoFs: | | | | | (incl | | | | 20 | | | | | uding | | | | 0-800 | | | | | tele | | | | | | | | | opera | | | | | | | | | tion) | | | | | | | | | | | | | | | | | | Cont | | | | | | | | | rolee | | | | | | | | | to | | | | | | | | | contr | | | | | | | | | oller | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 10ms | 1-100 | 99 | 1500 | Stati | **100 | Video | | | | M | ,999% | | onary | km | | | | | bit/s | | | or | ^2^** | | | | | | [3] | | Pedes | | | | | | | \ | | trian | | | | | | | [27] | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 10ms | 5-512 | 99,9% | 50 | Stati | **100 | Audio | | | | k | | | onary | km | | | | | bit/s | [3] | | or | ^2^** | | | | | | \ | | Pedes | | | | | | | [27] | | trian | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Ski | 1-5ms | 16 | 99 | 1 | hi | 4 | H | | llset | | k | ,999% | DoF: | gh-dy | **km | aptic | | sh | | bit/s | (with | 2-8 | namic | ^2^** | | | aring | | -2 | co | | | | (posi | | H | | M | mpres | 3 | | | tion, | | ighly | | bit/s | sion) | DoFs: | | | velo | | dyn | | | | 6-24 | | | city) | | amic/ | | (wi | 99,9% | | | | | | m | | thout | (w/o | 6 | | | | | obile | | h | co | DoFs: | | | | | rob | | aptic | mpres | 12-48 | | | | | otics | | c | sion) | | | | | | | | ompre | | | | | | | Contr | | ssion | [3] | | | | | | oller | | encod | \ | | | | | | to | | ing); | [27] | | | | | | cont | | | | | | | | | rolee | | 0.8 - | | | | | | | | | 200 | | | | | | | | | k | | | | | | | | | bit/s | | | | | | | | | | | | | | | | | | (with | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | enco | | | | | | | | | ding) | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Ski | 1-5ms | 0.8 - | 99 | 1 | hi | 4 | H | | llset | | 200 | ,999% | DoF: | gh-dy | **km | aptic | | sh | | k | (with | 2-8 | namic | ^2^** | fee | | aring | | bit/s | co | | | | dback | | H | | | mpres | 10 | | | | | ighly | | | sion) | DoFs: | | | | | dyn | | | | 20-80 | | | | | amic/ | | | 99,9% | | | | | | m | | | (w/o | 100 | | | | | obile | | | co | DoFs: | | | | | rob | | | mpres | 20 | | | | | otics | | | sion) | 0-800 | | | | | | | | | | | | | | Cont | | | [3] | | | | | | rolee | | | \ | | | | | | to | | | [27] | | | | | | contr | | | | | | | | | oller | | | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 1 | 1-10 | 99 | 2000 | hi | 4 | Video | | | -10ms | M | ,999% | -4000 | gh-dy | **km | | | | | bit/s | | | namic | ^2^** | | | | | | [3] | | | | | | | | | \ | | | | | | | | | [27] | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | 1 | 10 | 99,9% | 100 | hi | 4 | Audio | | | -10ms | 0-500 | | | gh-dy | **km | | | | | k | [3] | | namic | ^2^** | | | | | bit/s | \ | | | | | | | | | [27] | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | Imme | 50 ms | 16 k | 99. | 1 | Stati | â‰¤ 100 | H | | rsive | \ | bit/s | 999 % | DoF: | onary | km^2^ | aptic | | m | [39] | -2 | | 2 to | or | | fee | | ulti- | | M | [3] | 8 | Pedes | ( | dback | | modal | | bit/s | | | trian | no | | | navig | | (wi | | 10 | | te 5) | | | ation | | thout | | DoF: | | | | | ap | | h | | 20 to | | | | | plica | | aptic | | 80 | | | | | tions | | c | | | | | | | | | ompre | | 100 | | | | | R | | ssion | | DoF: | | | | | emote | | encod | | 200 | | | | | Site | | ing); | | to | | | | | ïƒ  | | | | 800 | | | | | Local | | 0.8 - | | | | | | | Site | | 200 | | | | | | | (DL) | | k | | | | | | | | | bit/s | | | | | | | | | (with | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | c | | | | | | | | | ompre | | | | | | | | | ssion | | | | | | | | | enco | | | | | | | | | ding) | | | | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | \<4 | 1- | 99. | 1500 | S | â‰¤ 100 | Video | | | 00 ms | 100 M | 999 % | | tatio | km^2^ | | | | \ | bit/s | | | nary/ | | | | | [39] | | [3] | | or | (no | | | | | | | | P | te 5) | | | | | | | | edest | | | | | | | | | rian, | | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | \<1 | 5- | 9 | 50 | Stati | â‰¤ 100 | Audio | | | 50 ms | 512 k | 9.9 % | | onary | km^2^ | | | | \ | bit/s | | | or | | | | | [39] | | [3] | | Pedes | (no | | | | | | | | trian | te 5) | | +-------+-------+-------+-------+-------+-------+-------+-------+ | | \<3 | 600 M | 9 | 1500 | Stati | â‰¤ 100 | VR | | | 00 ms | bit/s | 9.9 % | | onary | km^2^ | | | | | | | | or | | | | | | | [3] | | Pedes | (no | | | | | | | | trian | te 5) | | +-------+-------+-------+-------+-------+-------+-------+-------+
+-------+-------+-------+-------+------+-------+-------+-------+ | Imme | \<3 | 12 | 99. | 1500 | Stati | â‰¤ 100 | Biom | | rsive | 00 ms | kbi | 999 % | | onary | km^2^ | etric | | m | | t/s \ | | | or | | / | | ulti- | | [26] | [3] | | Pedes | (no | Affe | | modal | | | | | trian | te 5) | ctive | | navig | | | | | | | | | ation | | | | | | | | | ap | | | | | | | | | plica | | | | | | | | | tions | | | | | | | | | Local | | | | | | | | | Site | | | | | | | | | ïƒ  | | | | | | | | | R | | | | | | | | | emote | | | | | | | | | Site | | | | | | | | | (UL) | | | | | | | | +-------+-------+-------+-------+------+-------+-------+-------+ | | \<4 | 1- | 99. | 1500 | Wor | â‰¤ 100 | Video | | | 00 ms | 100 M | 999 % | | kers: | km^2^ | | | | \ | bit/s | | | S | | | | | [39] | | [3] | | tatio | (no | | | | | | | | nary/ | te 5) | | | | | | | | or | | | | | | | | | P | | | | | | | | | edest | | | | | | | | | rian, | | | | | | | | | UAV: | | | | | | | | | [3 | | | | | | | | | 0-300 | | | | | | | | | mph] | | | +-------+-------+-------+-------+------+-------+-------+-------+ | | \<1 | 5- | 9 | 50 | Stati | â‰¤ 100 | Audio | | | 50 ms | 512 k | 9.9 % | | onary | km^2^ | | | | \ | bit/s | | | or | | | | | [39] | | [3] | | Pedes | (no | | | | | | | | trian | te 5) | | +-------+-------+-------+-------+------+-------+-------+-------+ | | \<3 | 600 M | 9 | 1500 | Stati | â‰¤ 100 | VR | | | 00 ms | bit/s | 9.9 % | | onary | km^2^ | | | | | | | | or | | | | | | | [3] | | Pedes | (no | | | | | | | | trian | te 5) | | +-------+-------+-------+-------+------+-------+-------+-------+ | NOTE | | | | | | | | | 1: | | | | | | | | | M | | | | | | | | | otion | | | | | | | | | -to-p | | | | | | | | | hoton | | | | | | | | | delay | | | | | | | | | (the | | | | | | | | | time | | | | | | | | | diffe | | | | | | | | | rence | | | | | | | | | be | | | | | | | | | tween | | | | | | | | | the | | | | | | | | | u | | | | | | | | | ser's | | | | | | | | | m | | | | | | | | | otion | | | | | | | | | and | | | | | | | | | cor | | | | | | | | | respo | | | | | | | | | nding | | | | | | | | | c | | | | | | | | | hange | | | | | | | | | of | | | | | | | | | the | | | | | | | | | video | | | | | | | | | image | | | | | | | | | on | | | | | | | | | dis | | | | | | | | | play) | | | | | | | | | is | | | | | | | | | less | | | | | | | | | than | | | | | | | | | 20 | | | | | | | | | ms, | | | | | | | | | and | | | | | | | | | the | | | | | | | | | com | | | | | | | | | munic | | | | | | | | | ation | | | | | | | | | la | | | | | | | | | tency | | | | | | | | | for | | | | | | | | | tr | | | | | | | | | ansfe | | | | | | | | | rring | | | | | | | | | the | | | | | | | | | pa | | | | | | | | | ckets | | | | | | | | | of | | | | | | | | | one | | | | | | | | | au | | | | | | | | | dio-v | | | | | | | | | isual | | | | | | | | | media | | | | | | | | | is | | | | | | | | | less | | | | | | | | | than | | | | | | | | | 10 | | | | | | | | | ms, | | | | | | | | | e.g. | | | | | | | | | the | | | | | | | | | pa | | | | | | | | | ckets | | | | | | | | | cor | | | | | | | | | respo | | | | | | | | | nding | | | | | | | | | to | | | | | | | | | one | | | | | | | | | v | | | | | | | | | ideo/ | | | | | | | | | audio | | | | | | | | | frame | | | | | | | | | are | | | | | | | | | t | | | | | | | | | ransf | | | | | | | | | erred | | | | | | | | | to | | | | | | | | | the | | | | | | | | | de | | | | | | | | | vices | | | | | | | | | w | | | | | | | | | ithin | | | | | | | | | 10 | | | | | | | | | ms. | | | | | | | | | | | | | | | | | | NOTE | | | | | | | | | 2: | | | | | | | | | Acco | | | | | | | | | rding | | | | | | | | | to | | | | | | | | | IEEE | | | | | | | | | 1 | | | | | | | | | 918.1 | | | | | | | | | [3] | | | | | | | | | as | | | | | | | | | for | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | feed | | | | | | | | | back, | | | | | | | | | the | | | | | | | | | la | | | | | | | | | tency | | | | | | | | | is | | | | | | | | | less | | | | | | | | | than | | | | | | | | | 25 ms | | | | | | | | | for | | | | | | | | | accur | | | | | | | | | ately | | | | | | | | | compl | | | | | | | | | eting | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | o | | | | | | | | | perat | | | | | | | | | ions. | | | | | | | | | As | | | | | | | | | rend | | | | | | | | | ering | | | | | | | | | and | | | | | | | | | har | | | | | | | | | dware | | | | | | | | | intr | | | | | | | | | oduce | | | | | | | | | some | | | | | | | | | d | | | | | | | | | elay, | | | | | | | | | the | | | | | | | | | com | | | | | | | | | munic | | | | | | | | | ation | | | | | | | | | delay | | | | | | | | | for | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | mod | | | | | | | | | ality | | | | | | | | | can | | | | | | | | | be | | | | | | | | | reaso | | | | | | | | | nably | | | | | | | | | less | | | | | | | | | than | | | | | | | | | 5 ms, | | | | | | | | | i.e. | | | | | | | | | the | | | | | | | | | pa | | | | | | | | | ckets | | | | | | | | | re | | | | | | | | | lated | | | | | | | | | to | | | | | | | | | one | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | fee | | | | | | | | | dback | | | | | | | | | are | | | | | | | | | t | | | | | | | | | ransf | | | | | | | | | erred | | | | | | | | | to | | | | | | | | | the | | | | | | | | | de | | | | | | | | | vices | | | | | | | | | w | | | | | | | | | ithin | | | | | | | | | 10 | | | | | | | | | ms. | | | | | | | | | | | | | | | | | | NOTE | | | | | | | | | 3: | | | | | | | | | H | | | | | | | | | aptic | | | | | | | | | fee | | | | | | | | | dback | | | | | | | | | is | | | | | | | | | typi | | | | | | | | | cally | | | | | | | | | h | | | | | | | | | aptic | | | | | | | | | si | | | | | | | | | gnal, | | | | | | | | | such | | | | | | | | | as | | | | | | | | | force | | | | | | | | | l | | | | | | | | | evel, | | | | | | | | | t | | | | | | | | | orque | | | | | | | | | l | | | | | | | | | evel, | | | | | | | | | vibr | | | | | | | | | ation | | | | | | | | | and | | | | | | | | | tex | | | | | | | | | ture. | | | | | | | | | | | | | | | | | | NOTE | | | | | | | | | 4: | | | | | | | | | The | | | | | | | | | la | | | | | | | | | tency | | | | | | | | | re | | | | | | | | | quire | | | | | | | | | ments | | | | | | | | | are | | | | | | | | | exp | | | | | | | | | ected | | | | | | | | | to be | | | | | | | | | sati | | | | | | | | | sfied | | | | | | | | | even | | | | | | | | | when | | | | | | | | | multi | | | | | | | | | modal | | | | | | | | | com | | | | | | | | | munic | | | | | | | | | ation | | | | | | | | | for | | | | | | | | | ski | | | | | | | | | llset | | | | | | | | | sh | | | | | | | | | aring | | | | | | | | | is | | | | | | | | | via | | | | | | | | | ind | | | | | | | | | irect | | | | | | | | | ne | | | | | | | | | twork | | | | | | | | | conne | | | | | | | | | ction | | | | | | | | | ( | | | | | | | | | i.e., | | | | | | | | | re | | | | | | | | | layed | | | | | | | | | by | | | | | | | | | one | | | | | | | | | UE to | | | | | | | | | ne | | | | | | | | | twork | | | | | | | | | re | | | | | | | | | lay). | | | | | | | | | | | | | | | | | | NOTE | | | | | | | | | 5: In | | | | | | | | | prac | | | | | | | | | tice, | | | | | | | | | the | | | | | | | | | se | | | | | | | | | rvice | | | | | | | | | area | | | | | | | | | de | | | | | | | | | pends | | | | | | | | | on | | | | | | | | | the | | | | | | | | | a | | | | | | | | | ctual | | | | | | | | | d | | | | | | | | | eploy | | | | | | | | | ment. | | | | | | | | | In | | | | | | | | | some | | | | | | | | | cases | | | | | | | | | a | | | | | | | | | local | | | | | | | | | app | | | | | | | | | roach | | | | | | | | | (e.g. | | | | | | | | | the | | | | | | | | | a | | | | | | | | | pplic | | | | | | | | | ation | | | | | | | | | se | | | | | | | | | rvers | | | | | | | | | are | | | | | | | | | h | | | | | | | | | osted | | | | | | | | | at | | | | | | | | | the | | | | | | | | | ne | | | | | | | | | twork | | | | | | | | | edge) | | | | | | | | | is | | | | | | | | | pref | | | | | | | | | erred | | | | | | | | | in | | | | | | | | | order | | | | | | | | | to | | | | | | | | | sa | | | | | | | | | tisfy | | | | | | | | | the | | | | | | | | | re | | | | | | | | | quire | | | | | | | | | ments | | | | | | | | | of | | | | | | | | | low | | | | | | | | | la | | | | | | | | | tency | | | | | | | | | and | | | | | | | | | high | | | | | | | | | re | | | | | | | | | liabi | | | | | | | | | lity. | | | | | | | | +-------+-------+-------+-------+------+-------+-------+-------+
# 7 Conclusions and recommendations
This TR provides a number of use cases for tactile and multi-modality
communication services such as immersive multi-modal virtual reality (VR)
application, remote controlled robots, support of skillset sharing for robots,
haptic feedback for dangerous environments, live event selective immersion,
virtual factory, and others.
The potential new requirements for each use cases are compiled into a set of
potential consolidated requirements, including functional requirements and
performance requirements, wherein a set of KPIs are defined, such as max
allowed end-to-end latency, service bit rate, user-experienced data rate,
reliability, message size, service area.
The resulting consolidated potential requirements and KPIs identified in this
TR can be considered for the development of normative requirements.
#