# Foreword
This Technical Specification has been produced by the 3rd Generation
Partnership Project (3GPP).
The contents of the present document are subject to continuing work within the
TSG and may change following formal TSG approval. Should the TSG modify the
contents of the present document, it will be re-released by the TSG with an
identifying change of release date and an increase in version number as
follows:
Version x.y.z
where:
x the first digit:
1 presented to TSG for information;
2 presented to TSG for approval;
3 or greater indicates TSG approved document under change control.
y the second digit is incremented for all changes of substance, i.e. technical
enhancements, corrections, updates, etc.
z the third digit is incremented when editorial only changes have been
incorporated in the document.
# Introduction
Audio is a key component of an immersive multimedia experience and 3GPP
systems are expected to deliver immersive audio with a high Quality of
Experience. However, industry agreed methods to assess the Quality of
Experience for immersive audio are relatively few and the present document
seeks to address this gap by providing objective test methods for the
assessment of immersive audio.
# 1 Scope
The present document specifies objective test methodologies for 3GPP immersive
audio systems including channel based, object based, scene-based and hybrids
of these formats. The subjective evaluation methods described in the present
document are applicable to audio capture, coding, transmission and rendering
as indicated in their corresponding clauses.
# 2 References
The following documents contain provisions which, through reference in this
text, constitute provisions of the present document.
\- References are either specific (identified by date of publication, edition
number, version number, etc.) or non‑specific.
\- For a specific reference, subsequent revisions do not apply.
\- For a non-specific reference, the latest version applies. In the case of a
reference to a 3GPP document (including a GSM document), a non-specific
reference implicitly refers to the latest version of that document _in the
same Release as the present document_.
[1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".
[2] J. Fliege und U. Maier: \"A two-stage approach for computing cubature
formulae for the sphere,\" Dortmund University, 1999.
[3] ISO 3745 - Annex A: \"Acoustics - Determination of sound power levels and
sound energy levels of noise sources using sound pressure -- Precision methods
for anechoic rooms and hemi-anechoic rooms - Annex A: General procedures for
qualification of anechoic and hemi-anechoic rooms\".
[4] ISO 1996 Acoustics: \"Description, measurement and assessment of
environmental noise\".
[5] ANSI S1.4: \"Specifications for Sound Level Meters\".
[6] ISO 3: \"Preferred numbers -- Series of preferred numbers\".
[7] B. Rafaely, "Analysis and design of spherical microphone arrays," IEEE
Transactions on Speech and Audio Processing, no. 13, 2005, pp. 135 \-- 143
[8] M. Poletti, "Unified Description of Ambisonics Using Real and Complex
Spherical Harmonics," Ambisonics Symposium 2009, June 25-27, 2009, Graz,
Austria.
# 3 Definitions, symbols and abbreviations
## 3.1 Definitions
For the purposes of the present document, the terms and definitions given in
3GPP TR 21.905 [1] and the following apply. A term defined in the present
document takes precedence over the definition of the same term, if any, in
3GPP TR 21.905 [1].
**spherical coordinates:** The coordinate system used in this document is
defined such that the x-axis points to the front, the y-axis to the left and
the z-axis to the top (see Figure 0). Spherical coordinates are the distance
from the origin, the azimuth in mathematical positive orientation (counter-
clockwise) and the elevation angle relative to the z-axis (with 0 degrees
pointing to the equator and +90 degrees pointing to the North pole).
Figure 0: Spherical coordinate system
**dBFS:** dB full-scale, where 0 dBFS refers to the RMS level of a DC-free
sinusoidal signal exercising the full scale of the digital interface/file.
## 3.2 Symbols
For the purposes of the present document, the following symbols apply:
**LA~eq~** the sound level in decibels equivalent to the total A-weighted
sound energy measured over a stated period of time.
azimuth
elevation
## 3.3 Abbreviations
For the purposes of the present document, the abbreviations given in 3GPP TR
21.905 [1] and the following apply. An abbreviation defined in the present
document takes precedence over the definition of the same abbreviation, if
any, in 3GPP TR 21.905 [1].
# 4 Objective Test Methodologies for Immersive Audio Systems
## 4.1 Objective Test Methodologies for Assessment of Immersive Audio Systems
in the Sending Direction
### 4.1.1 Diffuse-field Send Frequency Response for Scene-based Audio
#### 4.1.1.1 Introduction
This test is applicable to UEs capturing scene-based audio (e.g. First and
Higher Order Ambisonics).
NOTE: Currently, the test method uses a periphonic loudspeaker array for
generation of a diffuse-field. Additional loudspeaker setups for the
derivation of the diffuse sound field are under consideration.
**General test conditions**
**Free-field propagation conditions**
\- The test environment shall contain a free-field volume, wherein free-field
sound propagation conditions shall be observed.
\- The free-field sound propagation conditions shall be observed down to a
frequency of 200 Hz or less.
\- Qualification of the free-field volume shall be performed using the method
and limits for deviation from ideal free-field conditions described in [3].
**Test environment noise floor**
Within the _free-field volume_ , the equivalent continuous sound level of the
test environment in each 1/3^rd^ octave band, _L~eq~(f),_ shall be less than
the limits of the NR10 curve, following the noise rating determination
procedures in [4].
#### 4.1.1.2 Definition
The Diffuse-field Send Frequency Response for Scene-based Audio is defined as
the transfer function, , between:
, the estimated sound pressure magnitude spectrum obtained from a diffuse-
field scene-based audio capture and reference synthesis at the geometric
center of a _free-field volume_ ; and
, the sound pressure magnitude spectrum obtained from a diffuse-field
microphone recording the same diffuse field at the origin of a spherical
coordinate system.
Figure 1 describes a typical block diagram for the scene-based audio sending
direction with measurement points when using a periphonic loudspeaker array.
Figure 1: Scene-based audio capture block diagram for sending direction
measurements
**Definition of Equivalent Spatial Domain**
The equivalent spatial domain representation, **w**(t)**,** of a _N^th^_ order
Ambisonics soundfield representation **c**(t) is obtained by rendering **c(**
t) to _K_ virtual loudspeaker signals _w~j~_ (_t_), 1 ≤ _j_ ≤ _K_ , with _K =_
(_N+1_)^2^. The respective virtual loudspeaker positions are expressed by
means of a spherical coordinate system, where each position lies on the unit
sphere, i.e., a radius of 1. Hence, the positions can be equivalently
expressed by order-dependent directions **_Ω_** ~j~^(_N_)^=(_θ~j~_ ^(_N_)^, _φ
~j~_ ^(_N_)^), 1 ≤ _j_ ≤ _K,_ where _θ~j~_ ^(_N_)^ and _φ ~j~_ ^(_N_)^ denote
the inclinations and azimuths, respectively. These directions are defined
according to [2] and reproduced in Annex A for convenience.
The rendering of into the equivalent spatial domain can be formulated as a
matrix multiplication:
**w(_t_) = (Ψ _^(N,N)^_)^-1^ ⋅c(t),**
where (⋅)^-1^ denotes the inversion.
The matrix **Ψ** ^(_N,N_)^ of order _N_ with respect to the order-dependent
directions **_Ω_** ~j~^(_N_)^ is defined by:
**Ψ^(_N,N_)^ := [S~1~^(_N_)^ S~2~^(_N_)^ _..._ S _~K~_ ^(N)^],**
with:
**~j~^(_N _)^ :=__[_ S*~0~^0^(_**Ω** _~j~^(_ N _)^)_ S*~-1~^-1^(**_Ω_**~j~^(_N
_)^)_ S*~-1~^0^(_**Ω** _~j~^(_ N _)^)_ S*~-1~^1^(**_Ω_**~j~^(_N _)^)_
S*~-1~^1^(_**Ω** _~j~^(_ N _)^) ... S_ ~N~^N^*(**_Ω_ __~j~^(_ N_)^)]^_T_ ^ ,
where S~n~^m^(⋅) represents the real valued spherical harmonics of the order n
and degree m as defined in [8].
The matrix **Ψ** _^(N,N)^_ is invertible so that the HOA representation
**_c_**(_t_) can be converted back from the equivalent spatial domain by:
**c**(t) = **Ψ** _^(N,N)^_ ·**w**(t)
#### 4.1.1.3 Test method with periphonic array
##### 4.1.1.3.1 Test Conditions
**Periphonic loudspeaker array**
a) A _periphonic loudspeaker array_ shall be placed within the free-field
volume with the geometric center of the _periphonic loudspeaker array_
coinciding with the geometric center of the free-field volume.
b) The _periphonic loudspeaker array_ shall have a radius greater or equal
than 1 meter.
c) The _periphonic loudspeaker array_ shall be composed of (_N_ +1)^2^ coaxial
loudspeaker elements. Each of the (_N_ +1)^2^ coaxial loudspeaker elements
shall be equalized (if necessary) and level compensated to conform with the
operational room response curve limits given in [5] Section 8.3.4.1. _N_
should be equal or greater than the maximum ambisonics order supported by the
device under test (DUT), e.g. _N >=_4 for a DUT supporting 4^th^ order
Ambisonics capture.
d) The (_N_ +1)^2^ coaxial loudspeaker elements shall be positioned according
to the azimuth and elevation coordinates given in Annex B.
e) All coaxial loudspeaker elements shall be oriented such that their acoustic
axis intersects at the geometric center of the _free field volume_.
f) The radius of each coaxial loudspeaker element shall be such that, at the
geometric center of the _free-field volume_ , the far field approximation for
the coaxial loudspeaker axial pressure amplitude decay holds true.
##### 4.1.1.3.2 Measurement
**Reference Spectrum measurement for periphonic loudspeaker array method**
a) A diffuse-field / random incidence, or multi-field microphone is mounted in
the _free-field volume_ such that the tip of the microphone corresponds to the
geometric center of the _free-field volume_ and the geometric center of the
_periphonic loudspeaker array_.
NOTE 1: Diffuse-field / random incidence microphones, are described in [5].
b) (_N_ +1)^2^ decorrelated pink noise signals are played simultaneously over
each of the (_N_ +1)^2^ coaxial loudspeakers of the _periphonic loudspeaker
array_.
c) The playback level is adjusted such that the _LAeq_ , measured over a 30s
time window at the geometric center of the _periphonic loudspeaker array,_ is
equal to 78dBSPL(A) ± 0.5dB.
d) The reference sound pressure at the geometric center of the _fr_ e _e-field
volume_ , _p(t)_ , is captured with the diffuse-field or multi-field
microphone.
e) The magnitude spectrum of the reference sound pressure, _P(f)_ , is
calculated for the 1/12^th^ octave intervals as given by the R40 series of
preferred numbers in [6].
NOTE 2: For ideal (calibrated) loudspeakers, the _P(f)_ spectra should have
equal energy in each 1/12^th^ octave intervals.
**Estimated Spectrum measurement**
a) The scene-based audio capture device under test is mounted in the _free-
field volume_ such that its geometric center coincides with the geometric
center of _free-field volume_ and the geometric center of the _periphonic
loudspeaker array_.
b) (_N_ +1)^2^ decorrelated pink noise signals are played simultaneously over
each of the (_N_ +1)^2^ coaxial loudspeakers of the _periphonic loudspeaker
array_. The pink noise signals shall be identical to the signals used for the
reference spectrum measurement.
c) The B-format scene-based audio format representation (compressed or
uncompressed, depending on the use case being tested) is stored for offline
analysis.
d) The B-format scene-based audio format representation is uncompressed (if
necessary) and converted to an _equivalent spatial domain representation_ of
order _N~DUT~_ (B-Format to ESD conversion in Figure 1), where _N~DUT~_
corresponds to the Ambisonics order of the device under test.
e) , the estimate of the sound field at the geometric center of _the free-
field volume_ and _periphonic loudspeaker array_ , is synthesized using the
_equivalent spatial domain representation_ of order _N~DUT~_.
NOTE 3: can be taken from the W component of the B-Format signal, as an
alternative to implementing the B-Format to ESD conversion in step d).
f) The magnitude spectrum of the estimated sound pressure, , is calculated for
the 1/12^th^ octave intervals as given by the R40 series of preferred numbers
in [6].
**Calculation of send frequency response for scene-based audio**
The send frequency response for scene-based audio, _G(f)_ , is calculated as .
#### 4.1.1.4 Test method with loudspeaker array and turn table
##### 4.1.1.4.1 Test Conditions
**Loudspeaker array**
a) A calibrated _loudspeaker array_ shall be placed within the _free-field
volume_.
b) The _loudspeaker array_ shall comprise one or several semi-arcs having a
radius greater or equal than 1 meter. The radius shall be reported.
c) The _loudspeaker array_ shall be composed of _N+1_ loudspeaker elements.
The ambisonic order _N_ shall be reported.
d) Each loudspeaker in the array shall be calibrated with a frequency response
of [at least 100 Hz-20,000 Hz] and minimum phase response.
e) The coordinates of the loudspeaker elements are defined according to a
Gaussian spherical grid [7] of order _N_. Directions shall comply with Annex
B.1 and the _N+1_ elevations of the spherical grid shall be reported.
**Turn table**
a) A turn table with a resolution of 0.5 degrees shall be used. The rotation
axis of the turn table and the vertical axis of the semi-arcs shall be aligned
The turn table shall be adjusted in height so that the device under test is
positioned at the geometric center of the _loudspeaker array_.
b) For measurement, an azimuth step of 180/(_N_ +1) degrees shall be used.
##### 4.1.1.4.2 Measurement
**Reference Spectrum measurement**
a) A diffuse-field / random incidence, or multi-field microphone is mounted in
the _free-field volume_ such that the tip of the microphone corresponds to the
geometric center of the _free-field volume_ and the geometric center of the
_loudspeaker array_.
> NOTE 1: Diffuse-field / random incidence microphones, are described in [5].
Repeat steps b-c) with an azimuth angular resolution of 180/(_N_ +1) degrees:
b) An exponential sweep sine signal is played over each of the _N_ +1
loudspeakers of the _loudspeaker array_.
c) The impulse response at the geometric center of the _loudspeaker array_ is
measured for each loudspeaker position.
d) The magnitude spectrum of the reference sound pressure, _P(f)_ , is
calculated for the 1/12^th^ octave intervals as given by the R40 series of
preferred numbers in [6].
NOTE 2: For ideal (calibrated) loudspeakers, the _P(f)_ spectra should have
equal energy in each 1/12^th^ octave intervals.
**Estimated Spectrum measurement**
a) The scene-based audio capture device under test is mounted in the _free-
field volume_ such that its geometric center coincides with the geometric
center of _free-field volume_ and the geometric center of the _loudspeaker
array_.
b) Repeat steps b-c) with an azimuth angular resolution of 180/(_N_ +1)
degrees::
c) An exponential sweep sine signal is played over each of the _N_ +1
loudspeakers of the _loudspeaker array_. The sweep signals shall be identical
to the signals used for the reference spectrum measurement.
d) The impulse response at the geometric center of the _loudspeaker array_ is
measured for each loudspeaker position.
e) The magnitude spectrum of the estimated sound pressure, , is calculated for
the 1/12^th^ octave intervals as given by the R40 series of preferred numbers
in [6].
**Calculation of send frequency response for scene-based audio**
The send frequency response for scene-based audio, _G(f)_ , is calculated as .
Due to practical constraints (e.g. reflections on turn table), measurements
for specific elevations (e.g. \0) in each phase. The device under test shall be flipped upside
down between the two phases, and this two-phase approach shall be reported.
### 4.1.2 Directional response measurement for scene-based audio
#### 4.1.2.1 Definition
The directional response for scene-based audio is defined as the transfer
function, represented as an impulse response, **h**(θ~i~, φ~i~), between a
device under test and a loudspeaker located at an equal distance _r_ and L
predefined directions, _(θ~i~, φ~i~)_ , _i_ =1,...,L _._
#### 4.1.2.2 Test conditions
**Free-field propagation conditions**
\- The test environment shall contain a free-field volume, wherein free-field
sound propagation conditions shall be observed.
\- The free-field sound propagation conditions shall be observed down to a
frequency of 200Hz.
**Test environment noise floor**
The equivalent continuous sound level of the test environment in each 1/3^rd^
octave band, _L~eq~(f)_ , shall be less than the limits of the NR10 curve,
following the noise rating determination procedures in [4].
**Loudspeaker array**
A real or simulated loudspeaker array comprising L loudspeakers located be a
set of predefined directions _(θ~i~, φ~i~)_ , _i_ =1,...,L, from the geometric
center of the _loudspeaker array_ shall be used.
#### 4.1.2.3 Measurement
For each loudspeaker position _(θ~i~, φ~i~)_ , _i_ =1,...,L , the following
procedure shall be used:
a) An exponential sweep sine test signal is played over the loudspeaker.
NOTE: The impact of codec on the exponential sweep sine test signal needs to
be verified before performing the measurements. An activation signal may be
needed.
b) The impulse response **h**(θ~i~, φ~i~) at the geometric center of the
_loudspeaker array_ is measured.
## 4.2 Objective Test Methodologies for Assessment of Immersive Audio Systems
in the Receiving Direction
### 4.2.1 Headset Binaural Diffuse-field Receive frequency response for Scene-
based audio
#### 4.2.1.1 Introduction
This test is applicable to UEs rendering scene-based audio (e.g. First and
Higher Order Ambisonics) over a binaural headset.
#### 4.2.1.2 Definition
The Headset Binaural Diffuse-field Receive Frequency Response for Scene-based
Audio (for left and right ears) is defined as the transfer function, _G~L,R~
(f)_ , between:
a) _P~L,R~(f)_ , the binaurally recorded sound pressure magnitude spectra,
obtained when a diffuse field signal in the equivalent spatial domain
representation, w(t), is played on the DUT; and
b) _P~ref\ L,R~_(f), the reference sound pressure magnitude spectra, obtained
by direct convolution of the diffuse field signal in the equivalent spatial
domain representation, w(t) with its corresponding set of HRTFs.
#### 4.2.1.3 Test Conditions
**Test environment noise floor**
The equivalent continuous sound level of the test environment in each 1/3^rd^
octave band, _L~eq~(f)_ , shall be less than the limits of the NR10 curve,
following the noise rating determination procedures in [4].
The set of HRTFs used by the UE shall be documented and available to the test
lab.
#### 4.2.1.4 Measurement
**Reference sound pressure magnitude spectra**
The reference sound pressure magnitude spectra are derived offline. The
reference sound pressure magnitude spectra for the left and right ears,
_P~ref\ L,R~ (f)_ is the frequency domain representation of the convolution
between the set of equivalent spatial domain signals, **w**(t)_,_ with its
corresponding set head related transfer functions _**h** ~L,R~(t),_ for each
direction _j_ in an equivalent spatial domain of order _N~DUT\ ~_ ~,~ i.e.:
The signals _w~j~(t)_ , for 1 ≤ _j_ ≤ (_N~DUT~ +1_)^2^, are uncorrelated pink
noise signals of 30s length.
**Binaurally recorded sound pressure magnitude spectra**
The binaurally recorded sound pressure magnitude spectra is obtained as
follows:
a) The binaural headset is placed on a HATS.
b) The DUT shall be configured such that the set of HRTFs used for binaural
rendering correspond to the HATS used for testing.
c) The DUT volume control (if any) is adjusted for its nominal setting.
d) The binaural time-domain signals are recorded with HATS.
e) The binaurally recorded sound pressure magnitude spectra, _P~L,R~(f)_ is
obtained by taking the Fourier transform of the binaurally recorded time-
domain signals.
**Calculation of headset binaural diffuse-field receive frequency response for
scene-based audio**
The headset binaural diffuse-field frequency response for scene-based audio,
_G(f)_ , is calculated for each supported Ambisonics order _N~DUT~_ as:
### 4.2.2 Nominal System Sensitivity in Receive Direction for Channel-based
audio
#### 4.2.2.1 Introduction
This test is applicable to UEs rendering channel-based audio (e.g. 7.1.4) over
a binaural headset.
#### 4.2.2.2 Definition
The nominal system sensitivity in receive direction for channel-based audio is
defined as the difference between the sound pressure level (in dBSPL(A))
produced by the DUT on HATS and the root mean square of the digital test
signal (in dBFS).
#### 4.2.2.3 Test Conditions
**Test environment noise floor**
The equivalent continuous sound level of the test environment in each 1/3^rd^
octave band, _L~eq~(f)_ , shall be less than the limits of the NR10 curve,
following the noise rating determination procedures in [4].
The specific HATS used for the recording shall be described in the test
report. The set of HRTFs used by the UE shall be documented and available to
the test lab.
#### 4.2.2.4 Measurement
For each audio channel supported by the DUT, a pink noise signal with -18 dBFS
RMS level is played, with the signals played only one channel at a time.
The _LAeq_ (in dBSPL(A)) is measured continuously for a period of 30 s for
each of the left and right ears.
The sensitivity G~i\ L,R~ is expressed as the difference of the recorded sound
pressure levels at the left and right ears and the root mean square digital
level of the pink noise test signal, i.e. -18 dBFS.
### 4.2.3 Motion to Sound Latency in Dynamic Binaural Rendering Systems
#### 4.2.3.1 Introduction
Motion to Sound latency is the time difference between the event of a change
in head rotation and when the immersive audio signal is finally compensated
for the head motion. The method in this specification is intended to verify
that the overall motion-to-sound latency that a user experiences upon rotating
their head is within acceptable limits.
The method allows full measurement of motion to sound, i.e. including both the
latency of the head tracking sensor as well as the audio playback. This
includes all components of a real setup and therefore contains all possible
causes of additional latency that a user may experience.
The method also provides a latency value for the isolated audio processing of
the binaural renderer without the aforementioned external hardware, assuming
that the binaural renderer can process audio data as an audio processing
plugin that can be evaluated in isolation.
NOTE: This method requires synchronized playback of two renderer instances and
may not be suitable for the measurements of UEs where such synchronization is
not possible.
#### 4.2.3.2 Requirements
The following will be required:
Software:
\- Audio processing software to run and record output of two renderers
simultaneously
\- Head tracker software
Hardware:
\- Host machine for audio processing
\- Head tracker hardware
\- Stereo audio recording interface
\- Stereo audio playback interface
\- Mechanical setup to rotate the head tracking sensor in a precise and
reproducible way
An exemplary hardware setup can be seen below in Figure 2, the method however
can also be implemented using different systems under test and accompanying
equipment:
Figure 2: Hardware Overview (Setup in Position 1 on the left, Position 2 on
the right)
The audio processing environment uses two parallel signal chains, each
containing its own instance of the same binaural renderer being tested. The
test is concerned only with yaw angles, so values of pitch and roll should be
set to zero at the beginning of the test and can be ignored thereafter.
Figure 3: Generic Audio Processing Environment
The initial conditions are that Rendering Chain 1 (RC1) has a static yaw head
rotation angle of 0 degrees and RC2 uses the physical rotation of the head
tracker to get its yaw value. A white noise signal is virtually placed
directly in front of the listener (0 degrees azimuth, elevation), meaning that
rotation of the arm directly affects how the white noise source is rendered.
#### 4.2.3.3 Calibration
The first step is to calibrate the final position of the rotating arm
(Position 2 / P2). The rotating arm is moved manually and requires only a
limited range of motion - from some small rotation away from the table
(Position 1 / P1), 20 to 30 degrees will be ample, through until contact with
the table (P2). The arm should be placed at P2 and set up so that this
position also corresponds to 0 degrees yaw.
#### 4.2.3.4 Evaluation Environment
An object within the evaluation environment, e.g. using Max/MSP, should be
created to set the value of yaw to exactly 0 degrees once the real value of
yaw (received from the head tracker) is \80 degrees and \<-80 degrees, the
accuracy shall be respectively +4/-0.5 degrees and +0.5/-4 degrees.
# B.2 Example loudspeaker array
An example implementation with an ambisonic order N = 29 is described below:
\- A turn table with constant step size of 6 degrees and starting at 0 degree
(to obtain 60 positions in azimuth).
\- Two fixed semi-arcs of radius 2.5 meters separated in azimuth by 90 degrees
with 15 loudspeakers on each semi-arc; the elevations of loudspeakers are
given (in degrees) by -85, -80, -74, -68, -62, -56, -50, -44, -38, -32, -27,
-21, -15, -9, -3, 3, 9, 15, 21, 27, 32, 38, 44, 50, 56, 62, 68, 74, 80, 85,
where succesive values are alternatively allocated to each semi-arc.
NOTE: In practice, the elevation of -85 degrees may be replaced by a nearby
value (e.g. -82 degrees) to leave room for the mounting structure at the
bottom of the loudspeaker array.
#